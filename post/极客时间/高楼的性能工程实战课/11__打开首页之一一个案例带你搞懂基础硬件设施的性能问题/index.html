<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>11__打开首页之一：一个案例，带你搞懂基础硬件设施的性能问题 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是高楼。
这节课我要带你来看一个完整的性能分析案例的第一部分，用打开首页接口做压力场景，来分析下性能问题。通过这个案例，你将看到各种基础硬件设施层面的性能问题，比如由虚机超分导致的性能问题、CPU 运行模式下的性能问题、IO 高、硬件资源耗尽但 TPS 很低的问题等等。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/11__%E6%89%93%E5%BC%80%E9%A6%96%E9%A1%B5%E4%B9%8B%E4%B8%80%E4%B8%80%E4%B8%AA%E6%A1%88%E4%BE%8B%E5%B8%A6%E4%BD%A0%E6%90%9E%E6%87%82%E5%9F%BA%E7%A1%80%E7%A1%AC%E4%BB%B6%E8%AE%BE%E6%96%BD%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/11__%E6%89%93%E5%BC%80%E9%A6%96%E9%A1%B5%E4%B9%8B%E4%B8%80%E4%B8%80%E4%B8%AA%E6%A1%88%E4%BE%8B%E5%B8%A6%E4%BD%A0%E6%90%9E%E6%87%82%E5%9F%BA%E7%A1%80%E7%A1%AC%E4%BB%B6%E8%AE%BE%E6%96%BD%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="11__打开首页之一：一个案例，带你搞懂基础硬件设施的性能问题">
  <meta property="og:description" content="你好，我是高楼。
这节课我要带你来看一个完整的性能分析案例的第一部分，用打开首页接口做压力场景，来分析下性能问题。通过这个案例，你将看到各种基础硬件设施层面的性能问题，比如由虚机超分导致的性能问题、CPU 运行模式下的性能问题、IO 高、硬件资源耗尽但 TPS 很低的问题等等。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="高楼的性能工程实战课">

  <meta itemprop="name" content="11__打开首页之一：一个案例，带你搞懂基础硬件设施的性能问题">
  <meta itemprop="description" content="你好，我是高楼。
这节课我要带你来看一个完整的性能分析案例的第一部分，用打开首页接口做压力场景，来分析下性能问题。通过这个案例，你将看到各种基础硬件设施层面的性能问题，比如由虚机超分导致的性能问题、CPU 运行模式下的性能问题、IO 高、硬件资源耗尽但 TPS 很低的问题等等。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="5677">
  <meta itemprop="keywords" content="高楼的性能工程实战课">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="11__打开首页之一：一个案例，带你搞懂基础硬件设施的性能问题">
  <meta name="twitter:description" content="你好，我是高楼。
这节课我要带你来看一个完整的性能分析案例的第一部分，用打开首页接口做压力场景，来分析下性能问题。通过这个案例，你将看到各种基础硬件设施层面的性能问题，比如由虚机超分导致的性能问题、CPU 运行模式下的性能问题、IO 高、硬件资源耗尽但 TPS 很低的问题等等。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">11__打开首页之一：一个案例，带你搞懂基础硬件设施的性能问题</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 5677 字 </span>
          <span class="more-meta"> 预计阅读 12 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#看架构图">看架构图</a></li>
        <li><a href="#顺便看下代码逻辑">顺便看下代码逻辑</a></li>
        <li><a href="#确定压力数据">确定压力数据</a></li>
        <li><a href="#拆分时间">拆分时间</a></li>
        <li><a href="#定位-gateway-上的响应时间消耗">定位 Gateway 上的响应时间消耗</a>
          <ul>
            <li></li>
          </ul>
        </li>
        <li><a href="#id----名称-------------------------状态">[root@dell-server-3 ~]# virsh list &ndash;all<br>
Id    名称                         状态</a>
          <ul>
            <li></li>
          </ul>
        </li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后作业">课后作业</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是高楼。</p>
<p>这节课我要带你来看一个完整的性能分析案例的第一部分，用打开首页接口做压力场景，来分析下性能问题。通过这个案例，你将看到各种基础硬件设施层面的性能问题，比如由虚机超分导致的性能问题、CPU 运行模式下的性能问题、IO 高、硬件资源耗尽但 TPS 很低的问题等等。</p>
<p>如果你是从零开始做一个完整的项目，那么这些问题很可能是你首先要去面对的。并且，把它们解决好，是性能分析人员必备的一种能力。同时，你还会看到针对不同计数器采集的数据，我们的分析链路是不同的，而这个分析链路就是我一直强调的证据链，如果你不清楚可以再回顾一下第 3 讲。</p>
<p>通过这节课，我希望你能明白，有些性能问题其实并没有那么单一，而且不管性能问题出在哪里，我们都必须去处理。</p>
<p>好，不啰嗦了，下面我们就把打开首页接口的性能瓶颈仔细扒一扒。</p>
<h2 id="看架构图">看架构图</h2>
<p>在每次分析性能瓶颈之前，我都会画这样一张图，看看这个接口会涉及到哪些服务和技术组件，这对我们后续的性能分析会有很大的帮助。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/4f4605f08b14cef5b9f450a66fdb3fd5.png" alt=""></p>
<p>如果你有工具可以直接展示，那就更好了。如果没有，那我建议你不要自信地认为自己可以记住一个简单的架构。相信我，哪怕是在纸上简单画一画，都会对你后面的分析思路有很大的帮助。</p>
<p>回到上面这张图，我们可以清楚地看到这个打开首页的逻辑是：User - Gateway(Redis)- Portal - (Redis,MySQL)。</p>
<h2 id="顺便看下代码逻辑">顺便看下代码逻辑</h2>
<p>在做打开首页的基准场景之前，我建议你先看一眼这个接口的代码实现逻辑，从代码中可以看到这个接口在做哪些动作。根据这些动作，我们可以分析它们的后续链路。</p>
<p>这个代码的逻辑很简单，就是列出首页上的各种信息，然后返回一个 JSON。</p>
<p>public HomeContentResult contentnew() {<br>
HomeContentResult result = new HomeContentResult();<br>
if (redisService.get(&ldquo;HomeContent&rdquo;) == null) {<br>
//首页广告<br>
result.setAdvertiseList(getHomeAdvertiseList());<br>
//品牌推荐<br>
result.setBrandList(homeDao.getRecommendBrandList(0, 6));<br>
//秒杀信息<br>
result.setHomeFlashPromotion(getHomeFlashPromotion());<br>
//新品推荐<br>
result.setNewProductList(homeDao.getNewProductList(0, 4));<br>
//人气推荐<br>
result.setHotProductList(homeDao.getHotProductList(0, 4));<br>
//专题推荐<br>
result.setSubjectList(homeDao.getRecommendSubjectList(0, 4));<br>
redisService.set(&ldquo;HomeContent&rdquo;, result);<br>
}<br>
Object homeContent = redisService.get(&ldquo;HomeContent&rdquo;);<br>
// result = JSON.parseObject(homeContent.toString(), HomeContentResult.class);<br>
result = JSONUtil.toBean(JSONUtil.toJsonPrettyStr(homeContent), HomeContentResult.class);</p>
<pre><code>    return result;  
</code></pre>
<p>}</p>
<p>我们可以看到，这里面一共调用了 6 个方法，并且这些方法都是直接到数据库里做了查询，如此而已。</p>
<h2 id="确定压力数据">确定压力数据</h2>
<p>了解完代码逻辑后，我们上 10 个线程试运行一下，看看在一个个线程递增的过程中，TPS 会有什么样的趋势。</p>
<p>运行之后，我们得到这样的结果：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/9052ce67e2241d9c2ea4fc4b1d238e20.png" alt=""></p>
<p>从结果来看，在一开始，一个线程会产生 40 左右的 TPS。这里我们就要思考一下了：<strong>如果想要执行一个场景，</strong> <strong>并且这个场景</strong> <strong>可以压出打开首页接口的最大 TPS，</strong> <strong>我们</strong> <strong>应该</strong> <strong>怎么</strong> <strong>设置压力工具中的线程数、递增策略</strong> <strong>和</strong> <strong>持续执行策略呢？</strong></p>
<p>对此，我们先看看 Portal 应用节点所在机器的硬件使用情况，了解一下 TPS 趋势和资源使用率之间的关系。这个机器的情况如下图所示（注意，我跳过了 Gateway 所在的节点）：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/0d63c6bb19a9c232a20a3563f37e6b7a.png" alt=""></p>
<p>可以看到，当前 Portal 节点所在的机器是 8C16G（虚拟机），并且这个机器基本上没什么压力。</p>
<p>现在我们先不计算其他资源，只考虑 8C16G 的配置情况。如果 TPS 是线性增长的话，那么当该机器的 CPU 使用率达到 100% 的时候，TPS 大概就是 800 左右。因此，我们压力工具中的线程数应该设置为：</p>
<p>线程数=800TPS÷40TPS=20个线程</p>
<p>不过，在压力持续的过程中，TPS 和资源使用率之间的等比关系应该是做不到的。因为在压力过程中，各种资源的消耗都会增加一些响应时间，这些也都属于正常的响应时间损耗。</p>
<p>在确定了压力工具的线程数之后，我们再来看递增策略怎么设置。</p>
<p>我希望递增时间可以增加得慢一些，以便于我们查看各环节性能数据的反应。根据第 2 讲中的性能分析决策树，在这样的场景中，我们有不少计数器需要分析查看，所以我设置为 30 秒上一个线程，也就是说递增周期为 600 秒。</p>
<p>在确定好压力参数后，我们的试运行场景就可以在 JMeter 中设置为如下值：</p>
<p><stringProp name="ThreadGroup.num_threads">20</stringProp><br>
<stringProp name="ThreadGroup.ramp_time">600</stringProp><br>
<boolProp name="ThreadGroup.scheduler">true</boolProp><br>
<stringProp name="ThreadGroup.duration">700</stringProp></p>
<p>设置好试运行参数后，我们就可以在这样的场景下进一步设置足够的线程来运行，以达到资源使用率的最大化。</p>
<p>你可能会疑惑：难道不用更高的线程了吗？如果你想做一个正常的场景，那确实不需要用更高的线程了；如果你就是想知道压力线程加多了是什么样子，那你可以试试。我在性能场景执行时，也经常用各种方式压着玩。</p>
<p>不过，话说回来，确实有一种情况需要我们正儿八经地增加更多的压力，那就是你的响应时间已经增加了，可是增加得又不多，TPS 也不再上升。这时候，我们拆分响应时间是比较困难的，特别是当一些系统很快的时候，响应时间可能只是几个毫秒之间。所以，在这种情况下，我们需要多增加一些线程，让响应时间慢的地方更清晰地表现出来，这样也就更容易拆分时间。</p>
<p>通过压力场景的递增设置（前面算的是只需要 20 个线程即可达到最大值，而这里，我把压力线程设置为 100 启动场景，目的是为了看到递增到更大压力时的 TPS 趋势以及响应时间的增加，这样更容易做时间的拆分），我们看到这个接口的响应时间确实在慢慢增加，并且随着线程数的增加，响应时间很快就上升到了几百毫秒。这是一个明显的瓶颈，我们自然是不能接受的。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/dca874b8effd2430ca9b73737fe0b757.png" alt=""></p>
<p>接下来，我们就要好好分析一下这个响应时间究竟消耗到了哪里。</p>
<h2 id="拆分时间">拆分时间</h2>
<p>我们前面提到，打开首页的逻辑是：User - Gateway(Redis)- Portal - (Redis,MySQL)，那我们就按照这个逻辑，借助链路监控工具 SkyWalking 把响应时间具体拆分一下。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/02e0e69e26ab2cc173e4d8ce71988ec4.png" alt=""></p>
<ol>
<li><strong>User —Gateway 之间的时间消耗</strong></li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/001b9021104d8613211418eb83fb2f1c.png" alt=""></p>
<p>我们看到，User - Gateway 之间的时间消耗慢慢上升到了 150 毫秒左右。</p>
<ol>
<li><strong>Gateway 响应时间</strong></li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/35927d8a0b2b7dd77220b6e4a05d8eec.png" alt=""></p>
<p>gateway 上也消耗了 150 毫秒，这就说明 user 到 gateway 之间的网络并没有多少时间消耗，在毫秒级。</p>
<ol>
<li><strong>Gateway —Portal 之间的时间消耗</strong></li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/3f667a7765d8e8c9bcb907bb94053004.png" alt=""></p>
<p>在 Portal 上，响应时间只消耗了 50 毫秒左右。我们再到 Portal 上看一眼。</p>
<ol>
<li><strong>Portal 响应时间</strong></li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/f2f8c3c4b8e221bd17badf967d4201a8.png" alt=""></p>
<p>Portal 的响应时间是 50 毫秒左右，和我们上面看到的时间一致。</p>
<p>通过上述对响应时间的拆分，我们可以确定是 Gateway 消耗了响应时间，并且这个时间达到了近 100 毫秒。所以，我们下一步定位的目标就是 Gateway 了。</p>
<h2 id="定位-gateway-上的响应时间消耗">定位 Gateway 上的响应时间消耗</h2>
<h4 id="第一阶段分析-st-cpu">第一阶段：分析 st cpu</h4>
<p>既然 Gateway 上的响应时间消耗很高，我们自然就要查一下这台主机把时间消耗在了哪里。</p>
<p>我们的分析逻辑仍然是<strong>先看全局监控，后看定向监控</strong>。全局监控要从整个架构开始看起，然后再确定某个节点上的资源消耗。注意，在看全局监控时，我们要从最基础的查起，而分析的过程中最基础的就是操作系统了。</p>
<p>通过 top 命令，我们可以看到 Gateway 节点上的资源情况，具体如下：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/abadf3d7b54b83d8c3183517f6993a2e.png" alt=""></p>
<p>其中，st cpu 达到了 15% 左右。我们知道，st cpu 是指虚拟机被宿主机上的其他应用或虚拟机抢走的 CPU，它的值这么高显然是不太正常的。所以，我们要进一步查看 st cpu 异常的原因。</p>
<p>我们用 mpstat 命令先来看看宿主机（运行 Gateway 的虚拟机所在的物理机）上的资源表现：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/b0d73325d0c497c7f4ebc84effc68d51.png" alt=""></p>
<p>可以看到，CPU 还有 20% 没有用完，说明宿主机还有空间。不过，宿主机的 CPU 使用率已经不小了，而消耗这些宿主机的就只有虚拟机里的应用。所以，我们要查一下是不是某个虚拟机的 CPU 消耗特别高。宿主机上的 KVM 列表如下：</p>
<h2 id="id----名称-------------------------状态">[root@dell-server-3 ~]# virsh list &ndash;all<br>
Id    名称                         状态</h2>
<p>12    vm-jmeter                      running<br>
13    vm-k8s-worker-8                running<br>
14    vm-k8s-worker-7                running<br>
15    vm-k8s-worker-9                running</p>
<p>[root@dell-server-3 ~]#</p>
<p>可以看到，在这个宿主机上跑了四个虚拟机，那我们就具体看一下这四个虚拟机的资源消耗情况。</p>
<ol>
<li>
<p><strong>vm-jmeter</strong></p>
<p>top - 23:42:49 up 28 days,  8:14,  6 users,  load average: 0.61, 0.48, 0.38<br>
Tasks: 220 total,   1 running, 218 sleeping,   1 stopped,   0 zombie<br>
%Cpu0  :  6.6 us,  3.5 sy,  0.0 ni, 88.5 id,  0.0 wa,  0.0 hi,  0.0 si,  1.4 st<br>
%Cpu1  :  6.5 us,  1.8 sy,  0.0 ni, 88.2 id,  0.0 wa,  0.0 hi,  0.4 si,  3.2 st<br>
KiB Mem :  3880180 total,   920804 free,  1506128 used,  1453248 buff/cache<br>
KiB Swap:  2097148 total,  1256572 free,   840576 used.  2097412 avail Mem</p>
</li>
</ol>
<p>PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                 <br>
7157 root      20   0 3699292 781204  17584 S  27.8 20.1   1:09.44 java                                                                                                                    <br>
9 root      20   0       0      0      0 S   0.3  0.0  30:25.77 rcu_sched                                                                                                               <br>
376 root      20   0       0      0      0 S   0.3  0.0  16:40.44 xfsaild/dm-</p>
<ol>
<li><strong>vm-k8s-worker-8</strong></li>
</ol>
<p>top - 23:43:47 up 5 days, 22:28,  3 users,  load average: 9.21, 6.45, 5.74<br>
Tasks: 326 total,   1 running, 325 sleeping,   0 stopped,   0 zombie<br>
%Cpu0  : 20.2 us,  3.7 sy,  0.0 ni, 60.7 id,  0.0 wa,  0.0 hi,  2.9 si, 12.5 st<br>
%Cpu1  : 27.3 us,  7.4 sy,  0.0 ni, 50.2 id,  0.0 wa,  0.0 hi,  3.7 si, 11.4 st<br>
%Cpu2  : 29.9 us,  5.6 sy,  0.0 ni, 48.5 id,  0.0 wa,  0.0 hi,  4.9 si, 11.2 st<br>
%Cpu3  : 31.2 us,  5.6 sy,  0.0 ni, 47.6 id,  0.0 wa,  0.0 hi,  4.5 si, 11.2 st<br>
%Cpu4  : 25.6 us,  4.3 sy,  0.0 ni, 52.7 id,  0.0 wa,  0.0 hi,  3.6 si, 13.7 st<br>
%Cpu5  : 26.0 us,  5.2 sy,  0.0 ni, 53.5 id,  0.0 wa,  0.0 hi,  4.1 si, 11.2 st<br>
%Cpu6  : 19.9 us,  6.2 sy,  0.0 ni, 57.6 id,  0.0 wa,  0.0 hi,  3.6 si, 12.7 st<br>
%Cpu7  : 27.3 us,  5.0 sy,  0.0 ni, 53.8 id,  0.0 wa,  0.0 hi,  2.3 si, 11.5 st<br>
KiB Mem : 16265688 total,  6772084 free,  4437840 used,  5055764 buff/cache<br>
KiB Swap:        0 total,        0 free,        0 used. 11452900 avail Mem</p>
<p>PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                 <br>
13049 root      20   0 9853712 593464  15752 S 288.4  3.6  67:24.22 java                                                                                                                    <br>
1116 root      20   0 2469728  57932  16188 S  12.6  0.4 818:40.25 containerd                                                                                                              <br>
1113 root      20   0 3496336 118048  38048 S  12.3  0.7 692:30.79 kubelet                                                                                                                 <br>
4961 root      20   0 1780136  40700  17864 S  12.3  0.3 205:51.15 calico-node                                                                                                             <br>
3830 root      20   0 2170204 114920  33304 S  11.6  0.7 508:00.00 scope                                                                                                                   <br>
1118 root      20   0 1548060 111768  29336 S  11.3  0.7 685:27.95 dockerd                                                                                                                 <br>
8216 techstar  20   0 2747240 907080 114836 S   5.0  5.6   1643:33 prometheus                                                                                                              <br>
21002 root      20   0 9898708 637616  17316 S   3.3  3.9 718:56.99 java                                                                                                                    <br>
1070 root      20   0 9806964 476716  15756 S   2.0  2.9 137:13.47 java                                                                                                                    <br>
11492 root      20   0  441996  33204   4236 S   1.3  0.2  38:10.49 gvfs-udisks2-vo</p>
<ol>
<li><strong>vm-k8s-worker-7</strong></li>
</ol>
<p>top - 23:44:22 up 5 days, 22:26,  3 users,  load average: 2.50, 1.67, 1.13<br>
Tasks: 308 total,   1 running, 307 sleeping,   0 stopped,   0 zombie<br>
%Cpu0  :  4.2 us,  3.5 sy,  0.0 ni, 82.3 id,  0.0 wa,  0.0 hi,  1.7 si,  8.3 st<br>
%Cpu1  :  6.2 us,  2.7 sy,  0.0 ni, 82.8 id,  0.0 wa,  0.0 hi,  1.4 si,  6.9 st<br>
%Cpu2  :  5.2 us,  2.8 sy,  0.0 ni, 84.0 id,  0.0 wa,  0.0 hi,  1.0 si,  6.9 st<br>
%Cpu3  :  4.5 us,  3.8 sy,  0.0 ni, 81.2 id,  0.0 wa,  0.0 hi,  1.4 si,  9.2 st<br>
%Cpu4  :  4.4 us,  2.4 sy,  0.0 ni, 83.3 id,  0.0 wa,  0.0 hi,  1.4 si,  8.5 st<br>
%Cpu5  :  5.5 us,  2.4 sy,  0.0 ni, 84.5 id,  0.0 wa,  0.0 hi,  1.0 si,  6.6 st<br>
%Cpu6  :  3.7 us,  2.7 sy,  0.0 ni, 85.6 id,  0.0 wa,  0.0 hi,  0.7 si,  7.4 st<br>
%Cpu7  :  3.1 us,  1.7 sy,  0.0 ni, 84.7 id,  0.0 wa,  0.0 hi,  1.4 si,  9.0 st<br>
KiB Mem : 16265688 total,  8715820 free,  3848432 used,  3701436 buff/cache<br>
KiB Swap:        0 total,        0 free,        0 used. 12019164 avail Mem</p>
<p>PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                 <br>
18592 27        20   0 4588208 271564  12196 S  66.9  1.7 154:58.93 mysqld                                                                                                                  <br>
1109 root      20   0 2381424 105512  37208 S   9.6  0.6 514:18.00 kubelet                                                                                                                 <br>
1113 root      20   0 1928952  55556  16024 S   8.9  0.3 567:43.53 containerd                                                                                                              <br>
1114 root      20   0 1268692 105212  29644 S   8.6  0.6 516:43.38 dockerd                                                                                                                 <br>
3122 root      20   0 2169692 117212  33416 S   7.0  0.7 408:21.79 scope                                                                                                                   <br>
4132 root      20   0 1780136  43188  17952 S   6.0  0.3 193:27.58 calico-node                                                                                                             <br>
3203 nfsnobo+  20   0  116748  19720   5864 S   2.0  0.1  42:43.57 node_exporter                                                                                                           <br>
12089 techstar  20   0 5666480   1.3g  23084 S   1.3  8.5  78:04.61 java                                                                                                                    <br>
5727 root      20   0  449428  38616   4236 S   1.0  0.2  49:02.98 gvfs-udisks2-vo</p>
<ol>
<li><strong>vm-k8s-worker-9</strong></li>
</ol>
<p>top - 23:45:23 up 5 days, 22:21,  4 users,  load average: 12.51, 10.28, 9.19<br>
Tasks: 333 total,   4 running, 329 sleeping,   0 stopped,   0 zombie<br>
%Cpu0  : 20.1 us,  7.5 sy,  0.0 ni, 43.3 id,  0.0 wa,  0.0 hi, 13.4 si, 15.7 st<br>
%Cpu1  : 20.1 us, 11.2 sy,  0.0 ni, 41.4 id,  0.0 wa,  0.0 hi, 11.9 si, 15.3 st<br>
%Cpu2  : 23.8 us, 10.0 sy,  0.0 ni, 35.4 id,  0.0 wa,  0.0 hi, 14.2 si, 16.5 st<br>
%Cpu3  : 15.1 us,  7.7 sy,  0.0 ni, 49.1 id,  0.0 wa,  0.0 hi, 12.2 si, 15.9 st<br>
%Cpu4  : 22.8 us,  6.9 sy,  0.0 ni, 40.5 id,  0.0 wa,  0.0 hi, 14.7 si, 15.1 st<br>
%Cpu5  : 17.5 us,  5.8 sy,  0.0 ni, 50.0 id,  0.0 wa,  0.0 hi, 10.6 si, 16.1 st<br>
%Cpu6  : 22.0 us,  6.6 sy,  0.0 ni, 45.1 id,  0.0 wa,  0.0 hi, 11.0 si, 15.4 st<br>
%Cpu7  : 19.2 us,  8.0 sy,  0.0 ni, 44.9 id,  0.0 wa,  0.0 hi,  9.8 si, 18.1 st<br>
KiB Mem : 16265688 total,  2567932 free,  7138952 used,  6558804 buff/cache<br>
KiB Swap:        0 total,        0 free,        0 used.  8736000 avail Mem</p>
<p>PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                 <br>
24122 root      20   0 9890064 612108  16880 S 201.0  3.8   1905:11 java                                                                                                                    <br>
2794 root      20   0 2307652 161224  33464 S  57.7  1.0   1065:54 scope                                                                                                                   <br>
1113 root      20   0 2607908  60552  15484 S  13.8  0.4   1008:04 containerd                                                                                                              <br>
1109 root      20   0 2291748 110768  39140 S  12.8  0.7 722:41.17 kubelet                                                                                                                 <br>
1114 root      20   0 1285500 108664  30112 S  11.1  0.7 826:56.51 dockerd                                                                                                                 <br>
29 root      20   0       0      0      0 S   8.9  0.0  32:09.89 ksoftirqd/4                                                                                                             <br>
6 root      20   0       0      0      0 S   8.2  0.0  41:28.14 ksoftirqd/0                                                                                                             <br>
24 root      20   0       0      0      0 R   8.2  0.0  41:00.46 ksoftirqd/3                                                                                                             <br>
39 root      20   0       0      0      0 R   8.2  0.0  41:08.18 ksoftirqd/6                                                                                                             <br>
19 root      20   0       0      0      0 S   7.9  0.0  39:10.22 ksoftirqd/2                                                                                                             <br>
14 root      20   0       0      0      0 S   6.2  0.0  40:58.25 ksoftirqd/1</p>
<p>很显然，worker-9 的 si（中断使用的 CPU）和 st（被偷走的 CPU）都不算低。那这种情况就比较奇怪了，虚拟机本身都没有很高的 CPU 使用率，为什么 st 还这么高呢？难道 CPU 只能用到这种程度？</p>
<p>来，我们接着查下去。</p>
<h4 id="第二阶段查看物理机-cpu-运行模式">第二阶段：查看物理机 CPU 运行模式</h4>
<p>在这个阶段，我们要查一下服务里有没有阻塞。就像前面提到的，我们要从全局监控的角度，来考虑所查看的性能分析计数器是不是完整，以免出现判断上的偏差。不过，我去查看了线程栈的具体内容，看到线程栈中并没有 Blocked 啥的，那我们就只能再回到物理机的配置里看了。</p>
<p>那对于物理机 CPU，我们还有什么可看的呢？即使你盖上被子蒙着头想很久，从下到上把所有的逻辑都理一遍，也找不出什么地方会有阻塞。那我们就只有看宿主机的 CPU 运行模式了。</p>
<p>&ndash; 物理机器 1<br>
[root@hp-server ~]# cpupower frequency-info<br>
analyzing CPU 0:<br>
driver: pcc-cpufreq<br>
CPUs which run at the same hardware frequency: 0<br>
CPUs which need to have their frequency coordinated by software: 0<br>
maximum transition latency:  Cannot determine or is not supported.<br>
hardware limits: 1.20 GHz - 2.10 GHz<br>
available cpufreq governors: conservative userspace powersave ondemand performance<br>
current policy: frequency should be within 1.20 GHz and 2.10 GHz.<br>
The governor &ldquo;conservative&rdquo; may decide which speed to use<br>
within this range.<br>
current CPU frequency: 1.55 GHz (asserted by call to hardware)<br>
boost state support:<br>
Supported: yes<br>
Active: yes</p>
<p>&ndash; 物理机器 2<br>
[root@dell-server-2 ~]# cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor<br>
powersave<br>
[root@dell-server-2 ~]# cpupower frequency-info<br>
analyzing CPU 0:<br>
driver: intel_pstate<br>
CPUs which run at the same hardware frequency: 0<br>
CPUs which need to have their frequency coordinated by software: 0<br>
maximum transition latency:  Cannot determine or is not supported.<br>
hardware limits: 1.20 GHz - 2.20 GHz<br>
available cpufreq governors: performance powersave<br>
current policy: frequency should be within 1.20 GHz and 2.20 GHz.<br>
The governor &ldquo;powersave&rdquo; may decide which speed to use<br>
within this range.<br>
current CPU frequency: 2.20 GHz (asserted by call to hardware)<br>
boost state support:<br>
Supported: no<br>
Active: no<br>
2200 MHz max turbo 4 active cores<br>
2200 MHz max turbo 3 active cores<br>
2200 MHz max turbo 2 active cores<br>
2200 MHz max turbo 1 active cores</p>
<p>&ndash; 物理机器 3<br>
[root@dell-server-3 ~]# cpupower frequency-info<br>
analyzing CPU 0:<br>
driver: intel_pstate<br>
CPUs which run at the same hardware frequency: 0<br>
CPUs which need to have their frequency coordinated by software: 0<br>
maximum transition latency:  Cannot determine or is not supported.<br>
hardware limits: 1.20 GHz - 2.20 GHz<br>
available cpufreq governors: performance powersave<br>
current policy: frequency should be within 1.20 GHz and 2.20 GHz.<br>
The governor &ldquo;powersave&rdquo; may decide which speed to use<br>
within this range.<br>
current CPU frequency: 2.20 GHz (asserted by call to hardware)<br>
boost state support:<br>
Supported: no<br>
Active: no<br>
2200 MHz max turbo 4 active cores<br>
2200 MHz max turbo 3 active cores<br>
2200 MHz max turbo 2 active cores<br>
2200 MHz max turbo 1 active cores</p>
<p>&ndash; 物理机器 4<br>
[root@lenvo-nfs-server ~]# cpupower frequency-info<br>
analyzing CPU 0:<br>
driver: acpi-cpufreq<br>
CPUs which run at the same hardware frequency: 0<br>
CPUs which need to have their frequency coordinated by software: 0<br>
maximum transition latency: 10.0 us<br>
hardware limits: 2.00 GHz - 2.83 GHz<br>
available frequency steps:  2.83 GHz, 2.00 GHz<br>
available cpufreq governors: conservative userspace powersave ondemand performance<br>
current policy: frequency should be within 2.00 GHz and 2.83 GHz.<br>
The governor &ldquo;conservative&rdquo; may decide which speed to use<br>
within this range.<br>
current CPU frequency: 2.00 GHz (asserted by call to hardware)<br>
boost state support:<br>
Supported: no<br>
Active: no</p>
<p>可以看到，没有一个物理机是运行在 performance 模式之下的。</p>
<p>在这里，我们需要对 CPU 的运行模式有一个了解：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/cb3ae26939c1c60337b9df953274e9de.png" alt=""></p>
<p>既然我们是性能分析人员，那自然要用 performance 模式了，所以我们把 CPU 模式修改如下：</p>
<p>&ndash; 物理机器 1<br>
[root@hp-server ~]# cpupower -c all frequency-set -g performance<br>
Setting cpu: 0<br>
Setting cpu: 1<br>
Setting cpu: 2<br>
Setting cpu: 3<br>
Setting cpu: 4<br>
Setting cpu: 5<br>
Setting cpu: 6<br>
Setting cpu: 7<br>
Setting cpu: 8<br>
Setting cpu: 9<br>
Setting cpu: 10<br>
Setting cpu: 11<br>
Setting cpu: 12<br>
Setting cpu: 13<br>
Setting cpu: 14<br>
Setting cpu: 15<br>
Setting cpu: 16<br>
Setting cpu: 17<br>
Setting cpu: 18<br>
Setting cpu: 19<br>
Setting cpu: 20<br>
Setting cpu: 21<br>
Setting cpu: 22<br>
Setting cpu: 23<br>
Setting cpu: 24<br>
Setting cpu: 25<br>
Setting cpu: 26<br>
Setting cpu: 27<br>
Setting cpu: 28<br>
Setting cpu: 29<br>
Setting cpu: 30<br>
Setting cpu: 31<br>
[root@hp-server ~]# cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor<br>
performance<br>
[root@hp-server ~]#</p>
<p>&ndash; 物理机器 2<br>
[root@dell-server-2 ~]# cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor<br>
powersave<br>
[root@dell-server-2 ~]# cpupower -c all frequency-set -g performance<br>
Setting cpu: 0<br>
Setting cpu: 1<br>
Setting cpu: 2<br>
Setting cpu: 3<br>
Setting cpu: 4<br>
Setting cpu: 5<br>
Setting cpu: 6<br>
Setting cpu: 7<br>
Setting cpu: 8<br>
Setting cpu: 9<br>
Setting cpu: 10<br>
Setting cpu: 11<br>
Setting cpu: 12<br>
Setting cpu: 13<br>
Setting cpu: 14<br>
Setting cpu: 15<br>
[root@dell-server-2 ~]# cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor<br>
performance<br>
[root@dell-server-2 ~]#</p>
<p>&ndash; 物理机器 3<br>
[root@dell-server-3 ~]# cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor<br>
powersave<br>
[root@dell-server-3 ~]#  cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor<br>
powersave<br>
[root@dell-server-3 ~]# cpupower -c all frequency-set -g performance<br>
Setting cpu: 0<br>
Setting cpu: 1<br>
Setting cpu: 2<br>
Setting cpu: 3<br>
Setting cpu: 4<br>
Setting cpu: 5<br>
Setting cpu: 6<br>
Setting cpu: 7<br>
Setting cpu: 8<br>
Setting cpu: 9<br>
Setting cpu: 10<br>
Setting cpu: 11<br>
Setting cpu: 12<br>
Setting cpu: 13<br>
Setting cpu: 14<br>
Setting cpu: 15<br>
[root@dell-server-3 ~]#  cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor<br>
performance<br>
[root@dell-server-3 ~]#</p>
<p>&ndash; 物理机器 4<br>
[root@lenvo-nfs-server ~]# cpupower -c all frequency-set -g performance<br>
Setting cpu: 0<br>
Setting cpu: 1<br>
Setting cpu: 2<br>
Setting cpu: 3<br>
[root@lenvo-nfs-server ~]# cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor<br>
performance<br>
[root@lenvo-nfs-server ~]#</p>
<p>在我们一顿操作猛如虎之后，性能会怎么样呢？</p>
<p>结果，性能并没有好起来……这里我就不截图了，因为图和一开始的那张场景运行图一样。</p>
<p>在这里我们要知道，以上的分析过程说明不止是这个问题点，还有其他资源使用有短板我们没有找到。没办法，我们只能接着查。</p>
<h2 id="总结">总结</h2>
<p>在这节课中，我们通过压力工具中的曲线，判断了瓶颈的存在。然后通过 SkyWalking 拆分了响应时间。</p>
<p>在确定了响应时间消耗点之后，我们又开始了两个阶段的分析：第一个阶段的证据链是从现象开始往下分析的，因为 st cpu 是指宿主机上的其他应用的消耗导致了此虚拟机的 cpu 资源被消耗，所以，我们去宿主机上去查了其他的虚拟机。这里我们要明确 CPU 资源应该用到什么样的程度，在发现了资源使用不合理之后，再接着做第二阶段的判断。</p>
<p>在第二阶段中，我们判断了 CPU 运行模式。在物理机中，如果我们自己不做主动的限制，CPU 的消耗是没有默认限制的，所以我们才去查看 CPU 的运行模式。</p>
<p>但是，即便我们分析并尝试解决了以上的问题，TPS 仍然没什么变化。可见，在计数器的分析逻辑中，虽然我们做了优化动作，但系统仍然有问题。只能说我们当前的优化手段，只解决了木桶中的最短板，但是其他短板，我们还没有找到。</p>
<p>请你注意，这并不是说我们这节课的分析优化过程没有意义。要知道，这些问题不解决，下一个问题也不会出现。所以，我们这节课的分析优化过程也非常有价值。</p>
<p>下节课，我们接着来找打开首页接口的性能瓶颈。</p>
<h2 id="课后作业">课后作业</h2>
<p>最后，请你思考一下：</p>
<ol>
<li>为什么我们看到虚拟机中 st cpu 高，就要去查看宿主机上的其他虚拟机？如果在宿主机上看到 st cpu 高，我们应该做怎样的判断？</li>
<li>CPU 的运行模式在 powersave 时，CPU 的运行逻辑是什么？</li>
</ol>
<p>记得在留言区和我讨论、交流你的想法，每一次思考都会让你更进一步。</p>
<p>如果这节课让你有所收获，也欢迎你分享给你的朋友，共同学习进步。我们下一讲再见！</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/">高楼的性能工程实战课</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/java%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/11__%E7%AD%94%E7%96%91%E8%AF%BE%E5%A0%82%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3nio%E7%9A%84%E4%BC%98%E5%8C%96%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">11__答疑课堂：深入了解NIO的优化实现原理</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/tob%E5%B8%82%E5%9C%BA%E5%93%81%E7%89%8C%E5%AE%9E%E6%88%98%E8%AF%BE/11__%E6%89%93%E9%80%A0%E6%A1%88%E4%BE%8B%E4%B8%8A%E5%A6%82%E4%BD%95%E5%81%9A%E4%BC%98%E8%B4%A8%E5%AE%A2%E6%88%B7%E6%A1%88%E4%BE%8B%E7%9A%84%E9%80%89%E5%9E%8B%E5%92%8C%E5%86%85%E5%AE%B9%E6%9E%84%E9%80%A0/">
            <span class="next-text nav-default">11__打造案例（上）：如何做优质客户案例的选型和内容构造？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

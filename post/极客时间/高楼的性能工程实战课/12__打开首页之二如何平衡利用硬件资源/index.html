<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>12__打开首页之二：如何平衡利用硬件资源？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是高楼。
针对打开首页接口的性能问题，我们在上节课中确定了是 Gateway 在消耗响应时间，达到了近 100 毫秒。于是，我们开始定位 Gateway 上的响应时间消耗。
在第一阶段的时候，我们关注了应用所在的主机，同时还了解到，宿主机总共有四台机器；在第二阶段，我们查看了物理机的 CPU 模式。并尝试通过修改 CPU 运行模式来优化性能。可是，问题仍然没有解决，TPS 没见提升，响应时间依旧很长。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/12__%E6%89%93%E5%BC%80%E9%A6%96%E9%A1%B5%E4%B9%8B%E4%BA%8C%E5%A6%82%E4%BD%95%E5%B9%B3%E8%A1%A1%E5%88%A9%E7%94%A8%E7%A1%AC%E4%BB%B6%E8%B5%84%E6%BA%90/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/12__%E6%89%93%E5%BC%80%E9%A6%96%E9%A1%B5%E4%B9%8B%E4%BA%8C%E5%A6%82%E4%BD%95%E5%B9%B3%E8%A1%A1%E5%88%A9%E7%94%A8%E7%A1%AC%E4%BB%B6%E8%B5%84%E6%BA%90/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="12__打开首页之二：如何平衡利用硬件资源？">
  <meta property="og:description" content="你好，我是高楼。
针对打开首页接口的性能问题，我们在上节课中确定了是 Gateway 在消耗响应时间，达到了近 100 毫秒。于是，我们开始定位 Gateway 上的响应时间消耗。
在第一阶段的时候，我们关注了应用所在的主机，同时还了解到，宿主机总共有四台机器；在第二阶段，我们查看了物理机的 CPU 模式。并尝试通过修改 CPU 运行模式来优化性能。可是，问题仍然没有解决，TPS 没见提升，响应时间依旧很长。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="高楼的性能工程实战课">

  <meta itemprop="name" content="12__打开首页之二：如何平衡利用硬件资源？">
  <meta itemprop="description" content="你好，我是高楼。
针对打开首页接口的性能问题，我们在上节课中确定了是 Gateway 在消耗响应时间，达到了近 100 毫秒。于是，我们开始定位 Gateway 上的响应时间消耗。
在第一阶段的时候，我们关注了应用所在的主机，同时还了解到，宿主机总共有四台机器；在第二阶段，我们查看了物理机的 CPU 模式。并尝试通过修改 CPU 运行模式来优化性能。可是，问题仍然没有解决，TPS 没见提升，响应时间依旧很长。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="4798">
  <meta itemprop="keywords" content="高楼的性能工程实战课">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="12__打开首页之二：如何平衡利用硬件资源？">
  <meta name="twitter:description" content="你好，我是高楼。
针对打开首页接口的性能问题，我们在上节课中确定了是 Gateway 在消耗响应时间，达到了近 100 毫秒。于是，我们开始定位 Gateway 上的响应时间消耗。
在第一阶段的时候，我们关注了应用所在的主机，同时还了解到，宿主机总共有四台机器；在第二阶段，我们查看了物理机的 CPU 模式。并尝试通过修改 CPU 运行模式来优化性能。可是，问题仍然没有解决，TPS 没见提升，响应时间依旧很长。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">12__打开首页之二：如何平衡利用硬件资源？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 4798 字 </span>
          <span class="more-meta"> 预计阅读 10 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#定位-gateway-上的响应时间消耗">定位 gateway 上的响应时间消耗</a>
          <ul>
            <li><a href="#第三阶段nfs-服务器的-wa-cpu-偏高">第三阶段：NFS 服务器的 wa cpu 偏高</a></li>
            <li><a href="#第四阶段硬件资源耗尽但-tps-仍然很低">第四阶段：硬件资源耗尽，但 TPS 仍然很低</a></li>
            <li><a href="#第五阶段硬件资源还是要用完">第五阶段：硬件资源还是要用完</a></li>
          </ul>
        </li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后作业">课后作业</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是高楼。</p>
<p>针对打开首页接口的性能问题，我们在上节课中确定了是 Gateway 在消耗响应时间，达到了近 100 毫秒。于是，我们开始定位 Gateway 上的响应时间消耗。</p>
<p>在第一阶段的时候，我们关注了应用所在的主机，同时还了解到，宿主机总共有四台机器；在第二阶段，我们查看了物理机的 CPU 模式。并尝试通过修改 CPU 运行模式来优化性能。可是，问题仍然没有解决，TPS 没见提升，响应时间依旧很长。</p>
<p>今天这节课，我们进入第三阶段，继续分析其他的瓶颈点，比如 wa cpu、资源均衡使用、网络带宽等问题。其中，**在性能的分析逻辑里，资源均衡使用是一个非常容易被忽略，但又极为重要的方面。**我们通常都盯着计数器给出的数值有什么异常，而不是考虑资源怎么做相应的调配。</p>
<p>在我们这个案例中，系统是用 k8s 来管理资源的，所以我们必须要关注资源的均衡使用，避免出现有些服务性能很差，却和性能好的服务分配同样资源的情况。另外，网络资源在 k8s 中会跨越好几层，我们也要着重关注一下。</p>
<p>在学习这节课时，我建议你多思考下资源的均衡使用问题。现在，我们就开始今天的课程。</p>
<h2 id="定位-gateway-上的响应时间消耗">定位 gateway 上的响应时间消耗</h2>
<h3 id="第三阶段nfs-服务器的-wa-cpu-偏高">第三阶段：NFS 服务器的 wa cpu 偏高</h3>
<p>根据分析的逻辑，我们仍然是先看全局监控数据，思路依旧是“全局 - 定向”，这是我一贯的顺序了。</p>
<p>因此，我们现在再来查一下全局监控计数器，得到下面这样的视图：</p>
<p>[root@lenvo-nfs-server ~]# top<br>
top - 00:12:28 up 32 days,  4:22,  3 users,  load average: 9.89, 7.87, 4.71<br>
Tasks: 217 total,   1 running, 216 sleeping,   0 stopped,   0 zombie<br>
%Cpu0  :  0.0 us,  4.0 sy,  0.0 ni, 34.8 id, 61.2 wa,  0.0 hi,  0.0 si,  0.0 st<br>
%Cpu1  :  0.0 us,  4.7 sy,  0.0 ni, 27.8 id, 67.6 wa,  0.0 hi,  0.0 si,  0.0 st<br>
%Cpu2  :  0.0 us,  6.1 sy,  0.0 ni,  0.0 id, 93.9 wa,  0.0 hi,  0.0 si,  0.0 st<br>
%Cpu3  :  0.0 us,  7.6 sy,  0.0 ni,  3.4 id, 82.8 wa,  0.0 hi,  6.2 si,  0.0 st<br>
KiB Mem :  3589572 total,    82288 free,   775472 used,  2731812 buff/cache<br>
KiB Swap:  8388604 total,  8036400 free,   352204 used.  2282192 avail Mem</p>
<p>可以看到，计数器 wa 的 CPU 使用率偏高，其中 Cpu2 的 wa 已经达到 90% 以上。我们知道，wa cpu 是指 CPU 在读写的时候，所产生的 IO 等待时间占 CPU 时间的百分比。那么，它现在竟然这么高，是因为写操作有很多吗？</p>
<p>这时候我们就要关注下 IO 的状态了，因为 IO 慢绝对是一个性能问题。通过 iostat 命令，我们看到 IO 状态如下：</p>
<p>[root@lenvo-nfs-server ~]# iostat -x -d 1<br>
Linux 3.10.0-693.el7.x86_64 (lenvo-nfs-server)   2020 年 12 月 26 日   <em>x86_64</em>  (4 CPU)<br>
&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;<br>
Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util<br>
sda               0.00     0.00   94.00   39.00 13444.00 19968.00   502.44   108.43  410.80   52.00 1275.59   7.52 100.00</p>
<p>Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util<br>
sda               0.00    18.00  137.00  173.00 17712.00 43056.00   392.05   129.46  601.10   38.80 1046.38   3.74 115.90<br>
&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;</p>
<p>你可以看到，IO 使用率达到了 100%，说明 IO 的过程实在是太慢了。</p>
<p>接下来，我们再查查 Block Size 是多少，算一下当前 IO 到底是随机读写还是顺序读写。虽然大部分操作系统都默认 Block Size 是 4096，但是，本着不出小错的原则，我们还是查一下比较放心。</p>
<p>我们先确定磁盘的格式是什么：</p>
<p>[root@lenvo-nfs-server ~]# cat /proc/mounts<br>
&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;.<br>
/dev/sda5 / xfs rw,relatime,attr2,inode64,noquota 0 0<br>
&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;.<br>
[root@lenvo-nfs-server ~]#</p>
<p>通过上述命令可以知道，这个磁盘是 XFS 格式。那我们就用下面这个命令来查看 Block Size：</p>
<p>[root@lenvo-nfs-server ~]# xfs_info /dev/sda5<br>
meta-data=/dev/sda5              isize=512    agcount=4, agsize=18991936 blks<br>
=                       sectsz=512   attr=2, projid32bit=1<br>
=                       crc=1        finobt=0 spinodes=0<br>
data     =                       bsize=4096   blocks=75967744, imaxpct=25<br>
=                       sunit=0      swidth=0 blks<br>
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1<br>
log      =internal               bsize=4096   blocks=37093, version=2<br>
=                       sectsz=512   sunit=0 blks, lazy-count=1<br>
realtime =none                   extsz=4096   blocks=0, rtextents=0<br>
[root@lenvo-nfs-server ~]#</p>
<p>结果显示，Block Size 是 4096。同时，我们也可以看到读写基本上都是顺序的，不是随机。</p>
<p>那我们就来计算一条数据，确认一下顺序写的能力。如果全部是随机写，那么：</p>
<p>次数=（43056×1024）÷4096=10,764次</p>
<p>但是，实际上写只有 173 次，所以确实是顺序写了。</p>
<p>问题又来了，一次写多少个 Block 呢？</p>
<p>（43056×1024）÷173÷4096≈62个</p>
<p>我们得出，一次写 62 个 Block。从这样的数据来看，说明顺序写的能力还是不错的。因为对普通磁盘来说，应用在读写的时候，如果是随机写多，那写的速度就会明显比较慢；如果顺序写多，那么写的速度就可以快起来。</p>
<p>你发现了吗？虽然当前磁盘的顺序写能力不错，但是等待的时间也明显比较多。所以，接下来，我们得查一下是什么程序写的。这里我们用 iotop 命令查看：</p>
<p>Total DISK READ :      20.30 M/s | Total DISK WRITE :     24.95 M/s<br>
Actual DISK READ:      20.30 M/s | Actual DISK WRITE:       8.27 M/s<br>
TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&gt;    COMMAND                 <br>
12180 be/4 root        2.39 M/s   16.01 M/s  0.00 % 35.94 % [nfsd]<br>
12176 be/4 root        3.20 M/s    0.00 B/s  0.00 % 32.25 % [nfsd]<br>
12179 be/4 root        3.03 M/s    6.43 M/s  0.00 % 32.23 % [nfsd]<br>
12177 be/4 root        2.44 M/s  625.49 K/s  0.00 % 31.64 % [nfsd]<br>
12178 be/4 root        2.34 M/s 1473.47 K/s  0.00 % 30.43 % [nfsd]<br>
12174 be/4 root        2.14 M/s   72.84 K/s  0.00 % 29.90 % [nfsd]<br>
12173 be/4 root        2.91 M/s  121.93 K/s  0.00 % 24.95 % [nfsd]<br>
12175 be/4 root     1894.69 K/s   27.71 K/s  0.00 % 24.94 % [nfsd]<br>
&hellip;&hellip;&hellip;&hellip;&hellip;</p>
<p>可以看到，IO 都是 NFS 写过来的。那 NFS 的流量又是从哪里来的呢？从下面的数据来看，这些流量是从各个挂载了 NFS 盘的机器写过来的，这是我们一开始部署应用的时候，考虑统一使用 NFS 来做 IO 的思路。因为这个机器挂载了一个大容量的磁盘，为了保证磁盘够用，就把多个主机挂载了 NFS 盘。</p>
<pre><code>                191Mb               381Mb               572Mb               763Mb          954Mb  
</code></pre>
<p>mqqqqqqqqqqqqqqqqqqqvqqqqqqqqqqqqqqqqqqqvqqqqqqqqqqqqqqqqqqqvqqqqqqqqqqqqqqqqqqqvqqqqqqqqqqqqqqqqqqq<br>
172.16.106.119:nfs                   =&gt; 172.16.106.130:multiling-http        1.64Mb  2.04Mb  3.06Mb<br>
&lt;=                                      26.2Mb  14.5Mb  19.8Mb<br>
172.16.106.119:nfs                   =&gt; 172.16.106.100:apex-mesh             1.43Mb  2.18Mb  3.79Mb<br>
&lt;=                                      25.5Mb  14.2Mb  14.4Mb<br>
172.16.106.119:nfs                   =&gt; 172.16.106.195:vatp                   356Kb  1.27Mb  1.35Mb<br>
&lt;=                                      9.71Mb  7.04Mb  7.41Mb<br>
172.16.106.119:nfs                   =&gt; 172.16.106.56:815                    7.83Kb  4.97Kb  4.81Kb<br>
&lt;=                                       302Kb   314Kb   186Kb<br>
172.16.106.119:nfs                   =&gt; 172.16.106.79:device                 11.0Kb  7.45Kb  7.57Kb<br>
&lt;=                                      12.4Kb  22.0Kb  28.5Kb<br>
172.16.106.119:ssh                   =&gt; 172.16.100.201:cnrprotocol           2.86Kb  2.87Kb  5.81Kb<br>
&lt;=                                       184b    184b    525b<br>
169.254.3.2:60010                    =&gt; 225.4.0.2:59004                      2.25Kb  2.40Kb  2.34Kb<br>
&lt;=                                         0b      0b      0b<br>
169.254.6.2:60172                    =&gt; 225.4.0.2:59004                      2.25Kb  2.40Kb  2.34Kb<br>
&lt;=                                         0b  0b  0b<br>
172.16.106.119:nfs                   =&gt; 172.16.106.149:986                      0b   1.03Kb   976b<br>
&lt;=                                         0b   1.26Kb  1.11Kb</p>
<p>qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq<br>
TX:             cum:   37.0MB   peak:   31.9Mb                      rates:   3.44Mb  5.50Mb  8.22Mb<br>
RX:                     188MB            106Mb                               61.8Mb  36.2Mb  41.8Mb<br>
TOTAL:                  225MB            111Mb                               65.2Mb  41.7Mb  50.1Mb</p>
<p>我们在 Total DISK WRITE 中可以看到，读能力才达到 20M。没办法，既然 wa 这个机器的能力不怎么好，那就只有放弃统一写的思路。不过，为了不让机器的 IO 能力差成为应用的瓶颈点，我们还是再尝试一下这两个动作：</p>
<ol>
<li>第一，把 MySQL 的数据文件移走；</li>
<li>第二，把 Log 移走。</li>
</ol>
<p>接着我们执行场景，希望结果能好。</p>
<p>可是，在我查看了 TPS 和 RT 曲线后，很遗憾地发现，结果并没有改善。TPS 依然很低并且动荡非常大：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/c631288fbbbfc491b0653d0c8a912147.png" alt=""></p>
<p>看来我们的努力并没有什么效果，悲剧！就这样，命运让我们不得不来到第四个阶段。</p>
<h3 id="第四阶段硬件资源耗尽但-tps-仍然很低">第四阶段：硬件资源耗尽，但 TPS 仍然很低</h3>
<p>这个阶段我们查什么呢？仍然是全局监控的数据。我们来看一下所有主机的 Overview 资源：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/6ed6aa81e6fac0ef7506bf1bab4aa6ba.png" alt=""></p>
<p>从上图中可以看到，虚拟机 k8s-worker-8 的 CPU 使用率已经很高了，达到了 95.95%。那我们就登录到这台虚拟机上，看看更详细的全局监控数据：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/ab3d4a0ffbb6782927dd9c8085190ef9.png" alt=""></p>
<p>因为 CPU 不超分了，所以我们可以很明显地看到，k8s-worker-8 中的 CPU 被耗尽。从进程上来看，CPU 是被我们当前正在测试的接口服务消耗的。并且在这台虚拟机上，不止有 Portal 这一个进程，还有很多其他的服务。</p>
<p>那我们就把 Portal 服务调度到一个不忙的 worker 上去，比如移到 worker-3（6C16G）上:</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/304f55efd9c4ac28aabdb410e6c13a3d.png" alt=""></p>
<p>得到如下结果：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/f54f7510c28165ef1cd4ebacd14a3a87.png" alt=""></p>
<p>我们看到，TPS 已经有所上升了，达到了近 300，性能确实变好了一些。但是，这个数据还不如我们一开始不优化的结果，毕竟一开始还能达到 300TPS 呢。那我们就接着分析当前的瓶颈在哪里。</p>
<p>我们先来看一下主机的性能数据：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/e17ae2c94f9247103caee28882b7a213.png" alt=""></p>
<p>其中，worker-8 的 CPU 使用率达到了 90.12%。为什么这个 CPU 还是如此之高呢？我们继续来 top 一下，看看 worker-8 的性能数据：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/6b3018028c0ae929734df8ba2ebaea70.png" alt=""></p>
<p>你看，在 process table 中，排在最上面的是 Gateway 服务，说明是 Gateway 进程消耗的 CPU 最多。既然如此，我们自然要看看这个进程中的线程是不是都在干活。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/982a542c9066c9e6a44f7686237e5681.png" alt=""></p>
<p>我们看到上图中全是绿色的，也就是说 Gateway 中的线程一直处于 Runnable 状态，看来工作线程确实挺忙的了。而在前面的 worker-8 性能数据中，si cpu 已经达到了 16% 左右。所以结合这一点，我们来看一下实时的软中断数据：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/21636e1587563469f9560591d04f3cca.png" alt=""></p>
<p>可以看到网络软中断一直在往上跳，这说明确实是网络软中断导致 si cpu 变高的。网络软中断的变化是我们根据证据链找下来的。证据链如下：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/27a6cedde75a7f7f4d1ef63e267a8762.png" alt=""></p>
<p>我们再看一下网络带宽有多大：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/c5c4c364cb5d79587ea61098b182016a.png" alt=""></p>
<p>可以看到，网络带宽倒是不大。</p>
<p>从上述 Gateway 的工作线程、软中断数据和网络带宽情况来看，Gateway 只负责转发，并没有什么业务逻辑，也没有什么限制。所以，针对 TPS 上不去的原因，似乎除了网络转发能力比较差之外，我们再找不到其他解释了。</p>
<p>这个思路其实是需要一些背景知识的，因为我们通常用网络带宽来判断网络是不是够用，但是这是不够的。你要知道，在网络中当小包过多的时候，网络带宽是难以达到线性流量的。所以，我们这里的网络带宽即便不会很高，也会导致网络软中断的增加和队列的出现。</p>
<p>既然如此，那我们就把这个 Gateway 也从 worker-8 移到 worker-2（6C16G）上去，做这一步是为了减少网络软中断的争用。我们再看一下集群的整体性能：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/de1dc57f26af9e52f2eb26182a27d794.png" alt=""></p>
<p>看起来不错哦，worker-3 的 CPU 使用率降到了 70.78%。不过网络带宽有几个地方变红了，这个我们后面再分析。至少我们从这里看到，压力是起来了。</p>
<p>我们回来看一下压力的情况：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/7546ad3c1a023c053a5b3182448c5d1e.png" alt=""></p>
<p>TPS 已经达到 1000 左右了！棒棒的，有没有！我们画一个 TPS 对比图庆祝一下：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/5aed62aafec087fe140ca63b368cf4fa.png" alt=""></p>
<p>其实到这里，打开首页这个接口的基准场景就可以结束了，因为我们已经优化到了比需求还要高的程度。只是从技术角度来说，一个系统优化到最后是会有上限的，所以，我们仍然需要知道这个上限在哪里。</p>
<h3 id="第五阶段硬件资源还是要用完">第五阶段：硬件资源还是要用完</h3>
<p>现在压力把 worker-3 的 CPU 资源用得最高，用到了 70.78%。那么，下面我们就要把这个机器的硬件资源给用完，因为只有将资源都用尽，我们才能判断系统容量的最上限。这也就是我一直强调的，要将**性能优化分为两个阶段：一是把资源用起来；二是把容量调上去。**就算不是 CPU 资源，把其他的资源用完也可以。</p>
<p>既然这时候压力已经把 worker-3 的 CPU 资源用到了 70.78%，那我们就到这个应用中看一下线程把 CPU 用得怎么样。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/458b199b37862bc8c42eb889c7ac18ef.png" alt=""></p>
<p>你看，这里面的线程确实都忙起来了。</p>
<p>既然如此，那我们把 Tomcat 和 JDBC 连接的最大值都改到 80，再来看一下 TPS 的表现（请你注意，这里只是一个尝试，所以改大即可，并没有什么道理。在后续的测试过程中，我们还要根据实际情况来做调整，就是不能让线程太大，也不能不够用）。</p>
<p>为了让压力能直接压到一个节点上，我们跳过 Ingress，用分段的测法直接把压力发到服务上。然后，我们去 Pod 里设置一个 node port 把服务代理出来，再修改一下压力脚本。得到结果如下：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/753ba1f3ada2b28b4b3865196b77192e.png" alt=""></p>
<p>TPS 还是抖动大。那我们接着看全局监控：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/fbe63c597f9da3df9d28b976c75c5154.png" alt=""></p>
<p>看上图就可以知道，有几个主机的带宽都飘红了，而其他的资源使用率并没有特别高。前面我们有说过，分析网络问题，不应该只看网络带宽，还要分析其他的内容，下面我们就得分析一下网络带宽。</p>
<p>我们到监控工具中看一下网络的流量，你可以看到确实有一些非被测应用在占用带宽，并且占得还不小：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/b8bd26a829f38c6866cb58ad16513ccb.png" alt=""></p>
<p>我们再看总体带宽，发现已经用了 4G 多：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/04344aa352185e50ba57ef7e27afd41b.png" alt=""></p>
<p>为了弄清楚那些与被测系统无关的应用，会对带宽消耗产生影响进而影响 TPS，我们现在先把影响带宽的应用都删除了，比如 Weave Scope、Monitoring 的监控工具等，从列表中来看这些应用占了不小的带宽。</p>
<p>然后我们再次测试，发现 TPS 有所上升，关键是稳定了很多：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/68843a4e72dc880f464ec42555cde116.png" alt=""></p>
<p>我们可以看到，TPS 已经上升到了 1200 左右，可见带宽对 TPS 还是造成了不小的影响。</p>
<p>接着，我们查一下网络的队列，发现应用上面已经出现了不小的 Recv_Q。</p>
<p>Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name     Timer<br>
tcp      759      0 10.100.69.229:8085      10.100.140.32:35444     ESTABLISHED 1/java               off (0.00/0/0)<br>
tcp      832      0 10.100.69.229:34982     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4871.85/0/0)<br>
tcp     1056      0 10.100.69.229:34766     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4789.93/0/0)<br>
tcp      832      0 10.100.69.229:35014     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4888.23/0/0)<br>
tcp     3408      0 10.100.69.229:34912     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4855.46/0/0)<br>
tcp     3408      0 10.100.69.229:35386     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (5019.30/0/0)<br>
tcp     3392      0 10.100.69.229:33878     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4495.01/0/0)<br>
tcp      560      0 10.100.69.229:35048     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4888.23/0/0)<br>
tcp     1664      0 10.100.69.229:34938     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4855.46/0/0)<br>
tcp      759      0 10.100.69.229:8085      10.100.140.32:35500     ESTABLISHED 1/java               off (0.00/0/0)<br>
tcp      832      0 10.100.69.229:35114     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4921.00/0/0)<br>
tcp     1056      0 10.100.69.229:34840     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4822.69/0/0)<br>
tcp     1056      0 10.100.69.229:35670     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (5117.60/0/0)<br>
tcp     1664      0 10.100.69.229:34630     10.96.224.111:3306      ESTABLISHED 1/java               keepalive (4757.16/0/0)</p>
<p>从这里来看，网络已经成为了下一个瓶颈（关于这一点，我们在后续的课程里会讲）。</p>
<p>如果你想接着调优，还可以从应用代码下手，让应用处理得更快。不过，对于基准测试来说，一个没有走任何缓存的接口，在一个 6C16G 的单节点虚拟机上能达到这么高的 TPS，我觉得差不多了。</p>
<p>接下来，我们还要去折腾其他的接口，所以，我们对这个接口的优化到这里就结束了。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/bbd7803b665c8988836ea6f98e3d94f0.png" alt=""></p>
<h2 id="总结">总结</h2>
<p>在打开首页这个接口的基准场景中，涉及到了很多方面的内容。从一开始的信息整理，比如访问路径、查看代码逻辑、场景试运行等，都是在为后面的分析做准备。</p>
<p>而当我们看到响应时间高，然后做拆分时间这一步，就是我一直在 RESAR 性能工程中强调的“<strong>分析的起点</strong>”。因为在此之前，我们用的都是压力工具上的数据，只是把它们罗列出来就好了，没有任何分析的部分。</p>
<p>对于拆分时间，我们能用的手段有多种，你可以用你喜欢的方式，像日志、APM 工具，甚至抓包都是可以的。拆分了时间之后，我们就要分析在某个节点上响应时间高的时候，要怎么做。这时就用到了我一直强调的“全局 - 定向”监控分析思路。</p>
<p>在每一个阶段，你一定要清楚地定义优化的方向和目标，否则容易迷失方向。特别是对于一些喜欢把鼠标操作得特别快的同学，容易失去焦点，我劝你慢点操作，想清楚下一步再动。</p>
<p>而我们上述整个过程，都依赖于我说的性能分析决策树。从树顶往下，一层层找下去，不慌不乱，不急不燥。</p>
<p>只要你想，就能做到。</p>
<h2 id="课后作业">课后作业</h2>
<p>最后，我给你留三个思考题。</p>
<ol>
<li>当 st cpu 高的时候，你要去看什么？</li>
<li>当 wa cpu 高的时候，你要去看什么？</li>
<li>为什么我们要把硬件资源用完？</li>
</ol>
<p>记得在留言区和我讨论、交流你的想法，每一次思考都会让你更进一步。</p>
<p>如果你读完这篇文章有所收获，也欢迎你分享给你的朋友，共同学习进步。我们下一讲再见！</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/">高楼的性能工程实战课</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/android%E5%BC%80%E5%8F%91%E9%AB%98%E6%89%8B%E8%AF%BE/12__%E5%AD%98%E5%82%A8%E4%BC%98%E5%8C%96%E4%B8%8A%E5%B8%B8%E8%A7%81%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E6%96%B9%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">12__存储优化（上）：常见的数据存储方法有哪些？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/tob%E5%B8%82%E5%9C%BA%E5%93%81%E7%89%8C%E5%AE%9E%E6%88%98%E8%AF%BE/12__%E6%89%93%E9%80%A0%E6%A1%88%E4%BE%8B%E4%B8%AD%E5%A6%82%E4%BD%95%E5%BC%95%E5%8F%91%E7%8E%B0%E8%B1%A1%E7%BA%A7%E8%AE%A8%E8%AE%BA%E6%89%93%E8%B5%A2pr%E6%88%98%E5%BD%B9/">
            <span class="next-text nav-default">12__打造案例（中）：如何引发现象级讨论，打赢PR战役？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

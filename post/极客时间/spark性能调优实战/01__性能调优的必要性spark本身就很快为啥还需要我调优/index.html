<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>01__性能调优的必要性：Spark本身就很快，为啥还需要我调优？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是吴磊。
在日常的开发工作中，我发现有个现象很普遍。很多开发者都认为 Spark 的执行性能已经非常强了，实际工作中只要按部就班地实现业务功能就可以了，没有必要进行性能调优。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/01__%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7spark%E6%9C%AC%E8%BA%AB%E5%B0%B1%E5%BE%88%E5%BF%AB%E4%B8%BA%E5%95%A5%E8%BF%98%E9%9C%80%E8%A6%81%E6%88%91%E8%B0%83%E4%BC%98/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/01__%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7spark%E6%9C%AC%E8%BA%AB%E5%B0%B1%E5%BE%88%E5%BF%AB%E4%B8%BA%E5%95%A5%E8%BF%98%E9%9C%80%E8%A6%81%E6%88%91%E8%B0%83%E4%BC%98/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="01__性能调优的必要性：Spark本身就很快，为啥还需要我调优？">
  <meta property="og:description" content="你好，我是吴磊。
在日常的开发工作中，我发现有个现象很普遍。很多开发者都认为 Spark 的执行性能已经非常强了，实际工作中只要按部就班地实现业务功能就可以了，没有必要进行性能调优。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Spark性能调优实战">

  <meta itemprop="name" content="01__性能调优的必要性：Spark本身就很快，为啥还需要我调优？">
  <meta itemprop="description" content="你好，我是吴磊。
在日常的开发工作中，我发现有个现象很普遍。很多开发者都认为 Spark 的执行性能已经非常强了，实际工作中只要按部就班地实现业务功能就可以了，没有必要进行性能调优。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="3934">
  <meta itemprop="keywords" content="Spark性能调优实战">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="01__性能调优的必要性：Spark本身就很快，为啥还需要我调优？">
  <meta name="twitter:description" content="你好，我是吴磊。
在日常的开发工作中，我发现有个现象很普遍。很多开发者都认为 Spark 的执行性能已经非常强了，实际工作中只要按部就班地实现业务功能就可以了，没有必要进行性能调优。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">01__性能调优的必要性：Spark本身就很快，为啥还需要我调优？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 3934 字 </span>
          <span class="more-meta"> 预计阅读 8 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#开发案例-1数据抽取">开发案例 1：数据抽取</a></li>
        <li><a href="#开发案例-2数据过滤与数据聚合">开发案例 2：数据过滤与数据聚合</a></li>
        <li><a href="#小结">小结</a></li>
        <li><a href="#每日一练">每日一练</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是吴磊。</p>
<p>在日常的开发工作中，我发现有个现象很普遍。很多开发者都认为 Spark 的执行性能已经非常强了，实际工作中只要按部就班地实现业务功能就可以了，没有必要进行性能调优。</p>
<p>你是不是也这么认为呢？确实，Spark 的核心竞争力就是它的执行性能，这主要得益于 Spark 基于内存计算的运行模式和钨丝计划的锦上添花，以及 Spark SQL 上的专注与发力。</p>
<p>但是，真如大家所说，<strong>开发者只要把业务逻辑实现了就万事大吉了吗</strong>？这样，咱们先不急于得出结论，你先跟着我一起看两个日常开发中常见的例子，最后我们再来回答这个问题。</p>
<p>在数据应用场景中，ETL（Extract Transform Load）往往是打头阵的那个，毕竟源数据经过抽取和转换才能用于探索和分析，或者是供养给机器学习算法进行模型训练，从而挖掘出数据深层次的价值。我们今天要举的两个例子，都取自典型 ETL 端到端作业中常见的操作和计算任务。</p>
<h2 id="开发案例-1数据抽取">开发案例 1：数据抽取</h2>
<p>第一个例子很简单：给定数据条目，从中抽取特定字段。这样的数据处理需求在平时的 ETL 作业中相当普遍。想要实现这个需求，我们需要定义一个函数 extractFields：它的输入参数是 Seq[Row] 类型，也即数据条目序列；输出结果的返回类型是 Seq[(String, Int)]，也就是（String, Int）对儿的序列；函数的计算逻辑是从数据条目中抽取索引为 2 的字符串和索引为 4 的整型。</p>
<p>应该说这个业务需求相当简单明了，实现起来简直是小菜一碟。在实际开发中，我观察到有不少同学一上来就迅速地用下面的方式去实现，干脆利落，代码写得挺快，功能也没问题，UT、功能测试都能过。</p>
<p>//实现方案 1 —— 反例<br>
val extractFields: Seq[Row] =&gt; Seq[(String, Int)] = {<br>
(rows: Seq[Row]) =&gt; {<br>
var fields = Seq<a href="">(String, Int)</a><br>
rows.map(row =&gt; {<br>
fields = fields :+ (row.getString(2), row.getInt(4))<br>
})<br>
fields<br>
}<br>
}</p>
<p>在上面这个函数体中，是先定义一个类型是 Seq[(String, Int)] 的变量 fields，变量类型和函数返回类型完全一致。然后，函数逐个遍历输入参数中的数据条目，抽取数据条目中索引是 2 和 4 的字段并且构建二元元组，紧接着把元组追加到最初定义的变量 fields 中。最后，函数返回类型是 Seq[(String, Int)] 的变量 fields。</p>
<p>乍看上去，这个函数似乎没什么问题。特殊的地方在于，尽管这个数据抽取函数很小，在复杂的 ETL 应用里是非常微小的一环，但在整个 ETL 作业中，它会在不同地方被频繁地反复调用。如果我基于这份代码把整个 ETL 应用推上线，就会发现 ETL 作业端到端的执行效率非常差，在分布式环境下完成作业需要两个小时，这样的速度难免有点让人沮丧。</p>
<p>想要让 ETL 作业跑得更快，我们自然需要做性能调优。可问题是我们该从哪儿入手呢？既然 extractFields 这个小函数会被频繁地调用，不如我们从它下手好了，看看有没有可能给它“减个肥、瘦个身”。重新审视函数 extractFields 的类型之后，我们不难发现，这个函数从头到尾无非是从 Seq[Row] 到 Seq[(String, Int)] 的转换，函数体的核心逻辑就是字段提取，只要从 Seq[Row] 可以得到 Seq[(String, Int)]，目的就达到了。</p>
<p>要达成这两种数据类型之间的转换，除了利用上面这种开发者信手拈来的过程式编程，我们还可以用函数式的编程范式。函数式编程的原则之一就是尽可能地在函数体中避免副作用（Side effect），副作用指的是函数对于状态的修改和变更，比如上例中 extractFields 函数对于 fields 变量不停地执行追加操作就属于副作用。</p>
<p>基于这个想法，我们就有了第二种实现方式，如下所示。与第一种实现相比，它最大的区别在于去掉了 fields 变量。之后，为了达到同样的效果，我们在输入参数 Seq[Row] 上直接调用 map 操作逐一地提取特定字段并构建元组，最后通过 toSeq 将映射转换为序列，干净利落，一气呵成。</p>
<p>//实现方案 2 —— 正例<br>
val extractFields: Seq[Row] =&gt; Seq[(String, Int)] = {<br>
(rows: Seq[Row]) =&gt;<br>
rows.map(row =&gt; (row.getString(2), row.getInt(4))).toSeq<br>
}</p>
<p>你可能会问：“两份代码实现无非是差了个中间变量而已，能有多大差别呢？看上去不过是代码更简洁了而已。”事实上，我基于第二份代码把 ETL 作业推上线后，就惊奇地发现端到端执行性能提升了一倍！从原来的两个小时缩短到一个小时。<strong>两份功能完全一样的代码，在分布式环境中的执行性能竟然有着成倍的差别。因此你看，在日常的开发工作中，仅仅专注于业务功能实现还是不够的，任何一个可以进行调优的小环节咱们都不能放过。</strong></p>
<h2 id="开发案例-2数据过滤与数据聚合">开发案例 2：数据过滤与数据聚合</h2>
<p>你也许会说：“你这个例子只是个例吧？更何况，这个例子里的优化，仅仅是编程范式的调整，看上去和 Spark 似乎也没什么关系啊！”不要紧，我们再来看第二个例子。第二个例子会稍微复杂一些，我们先来把业务需求和数据关系交代清楚。</p>
<p>/**<br>
(startDate, endDate)<br>
e.g. (&ldquo;2021-01-01&rdquo;, &ldquo;2021-01-31&rdquo;)<br>
*/<br>
val pairDF: DataFrame = _</p>
<p>/**<br>
(dim1, dim2, dim3, eventDate, value)<br>
e.g. (&ldquo;X&rdquo;, &ldquo;Y&rdquo;, &ldquo;Z&rdquo;, &ldquo;2021-01-15&rdquo;, 12)<br>
*/<br>
val factDF: DataFrame = _</p>
<p>// Storage root path<br>
val rootPath: String = _</p>
<p>在这个案例中，我们有两份数据，分别是 pairDF 和 factDF，数据类型都是 DataFrame。第一份数据 pairDF 的 Schema 包含两个字段，分别是开始日期和结束日期。第二份数据的字段较多，不过最主要的字段就两个，一个是 Event date 事件日期，另一个是业务关心的统计量，取名为 Value。其他维度如 dim1、dim2、dim3 主要用于数据分组，具体含义并不重要。从数据量来看，pairDF 的数据量很小，大概几百条记录，factDF 数据量很大，有上千万行。</p>
<p>对于这两份数据来说，具体的业务需求可以拆成 3 步：</p>
<ol>
<li>对于 pairDF 中的每一组时间对，从 factDF 中过滤出 Event date 落在其间的数据条目；</li>
<li>从 dim1、dim2、dim3 和 Event date 4 个维度对 factDF 分组，再对业务统计量 Value 进行汇总；</li>
<li>将最终的统计结果落盘到 Amazon S3。</li>
</ol>
<p>针对这样的业务需求，不少同学按照上面的步骤按部就班地进行了如下的实现。接下来，我就结合具体的代码来和你说说其中的计算逻辑。</p>
<p>//实现方案 1 —— 反例<br>
def createInstance(factDF: DataFrame, startDate: String, endDate: String): DataFrame = {<br>
val instanceDF = factDF<br>
.filter(col(&ldquo;eventDate&rdquo;) &gt; lit(startDate) &amp;&amp; col(&ldquo;eventDate&rdquo;) &lt;= lit(endDate))<br>
.groupBy(&ldquo;dim1&rdquo;, &ldquo;dim2&rdquo;, &ldquo;dim3&rdquo;, &ldquo;event_date&rdquo;)<br>
.agg(sum(&ldquo;value&rdquo;) as &ldquo;sum_value&rdquo;)<br>
instanceDF<br>
}</p>
<p>pairDF.collect.foreach{<br>
case (startDate: String, endDate: String) =&gt;<br>
val instance = createInstance(factDF, startDate, endDate)<br>
val outPath = s&quot;${rootPath}/endDate=${endDate}/startDate=${startDate}&quot;<br>
instance.write.parquet(outPath)<br>
}</p>
<p>首先，他们是以 factDF、开始时间和结束时间为形参定义 createInstance 函数。在函数体中，先根据 Event date 对 factDF 进行过滤，然后从 4 个维度分组汇总统计量，最后将汇总结果返回。定义完 createInstance 函数之后，收集 pairDF 到 Driver 端并逐条遍历每一个时间对，然后以 factDF、开始时间、结束时间为实参调用 createInstance 函数，来获取满足过滤要求的汇总结果。最后，以 Parquet 的形式将结果落盘。</p>
<p>同样地，这段代码从功能的角度来说没有任何问题，而且从线上的结果来看，数据的处理逻辑也完全符合预期。不过，端到端的执行性能可以说是惨不忍睹，在 16 台机型为 C5.4xlarge AWS EC2 的分布式运行环境中，基于上面这份代码的 ETL 作业花费了半个小时才执行完毕。</p>
<p>没有对比就没有伤害，在同一份数据集之上，采用下面的第二种实现方式，仅用 2 台同样机型的 EC2 就能让 ETL 作业在 15 分钟以内完成端到端的计算任务。<strong>两份代码的业务功能和计算逻辑完全一致，执行性能却差了十万八千里</strong>。</p>
<p>//实现方案 2 —— 正例<br>
val instances = factDF<br>
.join(pairDF, factDF(&ldquo;eventDate&rdquo;) &gt; pairDF(&ldquo;startDate&rdquo;) &amp;&amp; factDF(&ldquo;eventDate&rdquo;) &lt;= pairDF(&ldquo;endDate&rdquo;))<br>
.groupBy(&ldquo;dim1&rdquo;, &ldquo;dim2&rdquo;, &ldquo;dim3&rdquo;, &ldquo;eventDate&rdquo;, &ldquo;startDate&rdquo;, &ldquo;endDate&rdquo;)<br>
.agg(sum(&ldquo;value&rdquo;) as &ldquo;sum_value&rdquo;)</p>
<p>instances.write.partitionBy(&ldquo;endDate&rdquo;, &ldquo;startDate&rdquo;).parquet(rootPath)</p>
<p>那么问题来了，这两份代码到底差在哪里，是什么导致它们的执行性能差别如此之大。我们不妨先来回顾第一种实现方式，嗅一嗅这里面有哪些不好的代码味道。</p>
<p>我们都知道，触发 Spark 延迟计算的 Actions 算子主要有两类：一类是将分布式计算结果直接落盘的操作，如 DataFrame 的 write、RDD 的 saveAsTextFile 等；另一类是将分布式结果收集到 Driver 端的操作，如 first、take、collect。</p>
<p>显然，对于第二类算子来说，Driver 有可能形成单点瓶颈，尤其是用 collect 算子去全量收集较大的结果集时，更容易出现性能问题。因此，在第一种实现方式中，我们很容易就能嗅到 collect 这里的调用，味道很差。</p>
<p>尽管 collect 这里味道不好，但在我们的场景里，pairDF 毕竟是一份很小的数据集，才几百条数据记录而已，全量搜集到 Driver 端也不是什么大问题。</p>
<p>最要命的是 collect 后面的 foreach。要知道，factDF 是一份庞大的分布式数据集，尽管 createInstance 的逻辑仅仅是对 factDF 进行过滤、汇总并落盘，但是 createInstance 函数在 foreach 中会被调用几百次，pairDF 中有多少个时间对，createInstance 就会被调用多少次。对于 Spark 中的 DAG 来说，在没有缓存的情况下，每一次 Action 的触发都会导致整条 DAG 从头到尾重新执行。</p>
<p>明白了这一点之后，我们再来仔细观察这份代码，你品、你细品，目不转睛地盯着 foreach 和 createInstance 中的 factDF，你会惊讶地发现：有着上千万行数据的 factDF 被反复扫描了几百次！而且，是全量扫描哟！吓不吓人？可不可怕？这么分析下来，ETL 作业端到端执行效率低下的始作俑者，是不是就暴露无遗了？</p>
<p>反观第二份代码，factDF 和 pairDF 用 pairDF.startDate &lt; factDF.eventDate &lt;= pairDF.endDate 的不等式条件进行数据关联。在 Spark 中，不等式 Join 的实现方式是 Nested Loop Join。尽管 Nested Loop Join 是所有 Join 实现方式（Merge Join，Hash Join，Broadcast Join 等）中性能最差的一种，而且这种 Join 方式没有任何优化空间，但 factDF 与 pairDF 的数据关联只需要扫描一次全量数据，仅这一项优势在执行效率上就可以吊打第一份代码实现。</p>
<h2 id="小结">小结</h2>
<p>今天，我们分析了两个案例，这两个案例都来自数据应用的 ETL 场景。第一个案例讲的是，在函数被频繁调用的情况下，函数里面一个简单变量所引入的性能开销被成倍地放大。第二个例子讲的是，不恰当的实现方式导致海量数据被反复地扫描成百上千次。</p>
<p>通过对这两个案例进行分析和探讨，我们发现，对于 Spark 的应用开发，绝不仅仅是完成业务功能实现就高枕无忧了。<strong>Spark 天生的执行效率再高，也需要你针对具体的应用场景和运行环境进行性能调优</strong>。</p>
<p>而性能调优的收益显而易见：一来可以节约成本，尤其是按需付费的云上成本，更短的执行时间意味着更少的花销；二来可以提升开发的迭代效率，尤其是对于从事数据分析、数据科学、机器学习的同学来说，更高的执行效率可以更快地获取数据洞察，更快地找到模型收敛的最优解。因此你看，性能调优不是一件锦上添花的事情，而是开发者必须要掌握的一项傍身技能。</p>
<p>那么，对于 Spark 的性能调优，你准备好了吗？生活不止眼前的苟且，让我们来一场说走就走的性能调优之旅吧。来吧！快上车！扶稳坐好，系好安全带，咱们准备发车了！</p>
<h2 id="每日一练">每日一练</h2>
<ol>
<li>日常工作中，你还遇到过哪些功能实现一致、但性能大相径庭的案例吗？</li>
<li>我们今天讲的第二个案例中的正例代码，你觉得还有可能进一步优化吗？</li>
</ol>
<p>期待在留言区看到你分享，也欢迎把你对开发案例的思考写下来，我们下节课见！</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/">Spark性能调优实战</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%A0%94%E5%8F%91%E6%95%88%E7%8E%87%E7%A0%B4%E5%B1%80%E4%B9%8B%E9%81%93/01__%E6%95%88%E8%83%BD%E6%A8%A1%E5%9E%8B%E5%A6%82%E4%BD%95%E7%B3%BB%E7%BB%9F%E5%9C%B0%E7%90%86%E8%A7%A3%E7%A0%94%E5%8F%91%E6%95%88%E8%83%BD/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">01__效能模型：如何系统地理解研发效能？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E9%AB%98%E6%A5%BC%E7%9A%84%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/01__%E6%80%A7%E8%83%BD%E5%B7%A5%E7%A8%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BE%88%E5%A4%9A%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E4%BA%BA%E5%91%98%E6%97%A0%E6%B3%95%E5%AF%B9%E6%80%A7%E8%83%BD%E7%BB%93%E6%9E%9C%E8%B4%9F%E8%B4%A3/">
            <span class="next-text nav-default">01__性能工程：为什么很多性能测试人员无法对性能结果负责？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

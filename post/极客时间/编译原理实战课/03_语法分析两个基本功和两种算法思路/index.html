<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>03_语法分析：两个基本功和两种算法思路 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是宫文学。
通过第 1 讲的学习，现在你已经清楚了语法分析阶段的任务：依据语法规则，把 Token 串转化成 AST。
今天，我就带你来掌握语法分析阶段的核心知识点，也就是两个基本功和两种算法思路。理解了这些重要的知识点，对于语法分析，你就不是外行了。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/03_%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%A4%E4%B8%AA%E5%9F%BA%E6%9C%AC%E5%8A%9F%E5%92%8C%E4%B8%A4%E7%A7%8D%E7%AE%97%E6%B3%95%E6%80%9D%E8%B7%AF/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/03_%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%A4%E4%B8%AA%E5%9F%BA%E6%9C%AC%E5%8A%9F%E5%92%8C%E4%B8%A4%E7%A7%8D%E7%AE%97%E6%B3%95%E6%80%9D%E8%B7%AF/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="03_语法分析：两个基本功和两种算法思路">
  <meta property="og:description" content="你好，我是宫文学。
通过第 1 讲的学习，现在你已经清楚了语法分析阶段的任务：依据语法规则，把 Token 串转化成 AST。
今天，我就带你来掌握语法分析阶段的核心知识点，也就是两个基本功和两种算法思路。理解了这些重要的知识点，对于语法分析，你就不是外行了。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="编译原理实战课">

  <meta itemprop="name" content="03_语法分析：两个基本功和两种算法思路">
  <meta itemprop="description" content="你好，我是宫文学。
通过第 1 讲的学习，现在你已经清楚了语法分析阶段的任务：依据语法规则，把 Token 串转化成 AST。
今天，我就带你来掌握语法分析阶段的核心知识点，也就是两个基本功和两种算法思路。理解了这些重要的知识点，对于语法分析，你就不是外行了。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="6831">
  <meta itemprop="keywords" content="编译原理实战课">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="03_语法分析：两个基本功和两种算法思路">
  <meta name="twitter:description" content="你好，我是宫文学。
通过第 1 讲的学习，现在你已经清楚了语法分析阶段的任务：依据语法规则，把 Token 串转化成 AST。
今天，我就带你来掌握语法分析阶段的核心知识点，也就是两个基本功和两种算法思路。理解了这些重要的知识点，对于语法分析，你就不是外行了。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">03_语法分析：两个基本功和两种算法思路</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 6831 字 </span>
          <span class="more-meta"> 预计阅读 14 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#上下文无关文法context-free-grammar">上下文无关文法（Context-Free Grammar）</a></li>
        <li><a href="#递归下降算法recursive-descent-parsing">递归下降算法（Recursive Descent Parsing）</a></li>
        <li><a href="#ll-算法计算-first-和-follow-集合">LL 算法：计算 First 和 Follow 集合</a></li>
        <li><a href="#lr-算法移进和规约">LR 算法：移进和规约</a></li>
        <li><a href="#课程小结">课程小结</a></li>
        <li><a href="#一课一思">一课一思</a></li>
        <li><a href="#参考资料">参考资料</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是宫文学。</p>
<p>通过第 1 讲的学习，现在你已经清楚了语法分析阶段的任务：依据语法规则，把 Token 串转化成 AST。</p>
<p>今天，我就带你来掌握语法分析阶段的核心知识点，也就是两个基本功和两种算法思路。理解了这些重要的知识点，对于语法分析，你就不是外行了。</p>
<ol>
<li><strong>两个基本功</strong>：第一，必须能够阅读和书写语法规则，也就是掌握上下文无关文法；第二，必须要掌握递归下降算法。</li>
<li><strong>两种算法思路</strong>：一种是自顶向下的语法分析，另一种则是自底向上的语法分析。</li>
</ol>
<h2 id="上下文无关文法context-free-grammar">上下文无关文法（Context-Free Grammar）</h2>
<p>在开始语法分析之前，我们要解决的第一个问题，就是<strong>如何表达语法规则</strong>。在上一讲中，你已经了解了，我们可以用正则表达式来表达词法规则，语法规则其实也差不多。</p>
<p>我还是以下面这个示例程序为例，里面用到了变量声明语句、加法表达式，我们看看语法规则应该怎么写：</p>
<p>int a = 2;<br>
int b = a + 3;<br>
return b;</p>
<p>第一种写法是下面这个样子，它看起来跟上一讲的词法规则差不多，都是左边是规则名称，右边是正则表达式。</p>
<p>start：blockStmts ;               //起始<br>
block : &lsquo;{&rsquo; blockStmts &lsquo;}&rsquo; ;      //语句块<br>
blockStmts : stmt* ;              //语句块中的语句<br>
stmt = varDecl | expStmt | returnStmt | block;   //语句<br>
varDecl : type Id varInitializer？ &lsquo;;&rsquo; ;         //变量声明<br>
type : Int | Long ;                              //类型<br>
varInitializer : &lsquo;=&rsquo; exp ;                       //变量初始化<br>
expStmt : exp &lsquo;;&rsquo; ;                              //表达式语句<br>
returnStmt : Return exp &lsquo;;&rsquo; ;                    //return 语句<br>
exp : add ;                                      //表达式      <br>
add : add &lsquo;+&rsquo; mul | mul;                         //加法表达式<br>
mul : mul &lsquo;*&rsquo; pri | pri;                         //乘法表达式<br>
pri : IntLiteral | Id | &lsquo;(&rsquo; exp &lsquo;)&rsquo; ;            //基础表达式</p>
<p>在语法规则里，我们把冒号左边的叫做<strong>非终结符</strong>（Non-terminal），又叫<strong>变元</strong>（Variable）。非终结符可以按照右边的正则表达式来逐步展开，直到最后都变成标识符、字面量、运算符这些不可再展开的符号，也就是<strong>终结符</strong>（Terminal）。终结符其实也是词法分析过程中形成的 Token。</p>
<p>提示： 1. 在本课程，非终结符以小写字母开头，终结符则以大写字母开头，或者是一个原始的字符串格式。 2. 在谈论语法分析的时候，我们可以把 Token 和非终结符这两个术语互换使用。</p>
<p>像这样左边是非终结符，右边是正则表达式的书写语法规则的方式，就叫做**扩展巴科斯范式（EBNF）。**你在 ANTLR 这样的语法分析器生成工具中，经常会看到这种格式的语法规则。</p>
<p>对于 EBNF 的严格定义，你可以去参考Wikipedia上的解释。</p>
<p>在教科书中，我们还经常采用另一种写法，就是<strong>产生式</strong>（Production Rule），又叫做<strong>替换规则</strong>（Substitution Rule）。产生式的左边是非终结符（变元），它可以用右边的部分替代，中间通常会用箭头连接。</p>
<p>为了避免跟 EBNF 中的“*”号、“+”号等冲突，在本节课中，凡是采用 EBNF 格式，就给字符串格式的终结符加引号，左右两边用“::=”或冒号分隔开；凡是采用产生式，字符串就不加引号，并且采用“-&gt;”分隔产生式的左右两侧。</p>
<p>add -&gt; add + mul<br>
add -&gt; mul<br>
mul -&gt; mul * pri<br>
mul -&gt; pri</p>
<p>也有个偷懒的写法，就是把同一个变元的多个产生式写在一起，用竖线分隔（但这时候，如果产生式里面原本就要用到“|”终结符，那么就要加引号来进行区分）。但也就仅此为止了，不会再引入“*”和“+”等符号，否则就成了 EBNF 了。</p>
<p>add -&gt; add + mul | mul<br>
mul -&gt; mul * pri | pri</p>
<p>产生式不用“ * ”和“+”来表示重复，而是用迭代，并引入“ε”（空字符串）。所以“blockStmts : stmt*”可以写成下面这个样子：</p>
<p>blockStmts -&gt; stmt blockStmts | ε</p>
<p>总结起来，语法规则是由 4 个部分组成的：</p>
<ol>
<li>一个有穷的非终结符（或变元）的集合；</li>
<li>一个有穷的终结符的集合；</li>
<li>一个有穷的产生式集合；</li>
<li>一个起始非终结符（变元）。</li>
</ol>
<p>那么符合这四个特点的文法规则，就叫做<strong>上下文无关文法</strong>（Context-Free Grammar，CFG）。</p>
<p>你可能会问，<strong>上下文无关文法和词法分析中用到的正则文法是否有一定的关系？</strong></p>
<p>**是的，正则文法是上下文无关文法的一个子集。**其实，正则文法也可以写成产生式的格式。比如，数字字面量（正则表达式为“[0-9]+”）可以写成：</p>
<p>IntLiteral -&gt; Digit IntLiteral1<br>
IntLiteral1 -&gt; Digit IntLiteral1<br>
IntLiteral1 -&gt; ε<br>
Digit -&gt; [0-9]</p>
<p>但是，在上下文无关文法里，产生式的右边可以放置任意的终结符和非终结符，而正则文法只是其中的一个子集，叫做<strong>线性文法</strong>（Linear Grammar）。它的特点是产生式的右边部分最多只有一个非终结符，比如 X-&gt;aYb，其中 a 和 b 是终结符。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/a55bd0cbd1115df33d09b8ea1922fbb1.png" alt=""></p>
<p>图 1：正则文法是上下文无关文法的子集</p>
<p>你可以试一下，把上一讲用到的正则表达式“a[a-zA-Z0-9]*bc”写成产生式的格式，它就符合线性文法的特点。</p>
<p>S0 -&gt; aS1bc         <br>
S1 -&gt; [a-zA-Z0-9]S1 <br>
S1 -&gt; ε</p>
<p>但对于常见的语法规则来说，正则文法是不够的。比如，你最常用的算术表达式的规则，就没法用正则文法表示，因为有的产生式需要包含两个非终结符（如“add + mul”）。你可以试试看，能把“2+3”“2+3*5”“2+3+4+5”等各种可能的算术表达式，用一个正则表达式写出来吗？实际是不可能的。</p>
<p>add -&gt; add + mul<br>
add -&gt; mul<br>
mul -&gt; mul * pri<br>
mul -&gt; pri</p>
<p>好，现在你已经了解了上下文无关文法，以及它与正则文法的区别。可是，<strong>为什么它会叫“上下文无关文法”这样一个奇怪的名字呢？难道还有上下文相关的文法吗？</strong></p>
<p>答案的确是有的。举个例子来说，在高级语言里，本地变量必须先声明，才能在后面使用。这种制约关系就是上下文相关的。</p>
<p>不过，在语法分析阶段，我们一般不管上下文之间的依赖关系，这样能使得语法分析的任务更简单。而对于上下文相关的情况，则放到语义分析阶段再去处理。</p>
<p>好了，现在你已经知道，用上下文无关文法可以描述程序的语法结构。学习编译原理，阅读和书写语法规则是一项基本功。针对高级语言中的各种语句，你要都能够手写出它们的语法规则来才可以。</p>
<p>接下来，我们就要**依据语法规则，编写语法分析程序，把 Token 串转化成 AST。**语法分析的算法有很多，但有一个算法也是你必须掌握的一项基本功，这就是递归下降算法。</p>
<h2 id="递归下降算法recursive-descent-parsing">递归下降算法（Recursive Descent Parsing）</h2>
<p>递归下降算法其实很简单，它的基本思路就是按照语法规则去匹配 Token 串。比如说，变量声明语句的规则如下：</p>
<p>varDecl : types Id varInitializer？ &lsquo;;&rsquo; ;        //变量声明<br>
varInitializer : &lsquo;=&rsquo; exp ;                       //变量初始化<br>
exp : add ;                                      //表达式      <br>
add : add &lsquo;+&rsquo; mul | mul;                         //加法表达式<br>
mul : mul &lsquo;*&rsquo; pri | pri;                         //乘法表达式<br>
pri : IntLiteral | Id | &lsquo;(&rsquo; exp &lsquo;)&rsquo; ;            //基础表达式</p>
<p>如果写成产生式格式，是下面这样：</p>
<p>varDecl -&gt; types Id varInitializer &lsquo;;&rsquo;<br>
varInitializer -&gt; &lsquo;=&rsquo; exp             <br>
varInitializer -&gt; ε<br>
exp -&gt; add<br>
add -&gt; add + mul<br>
add -&gt; mul<br>
mul -&gt; mul * pri<br>
mul -&gt; pri<br>
pri -&gt; IntLiteral<br>
pri -&gt; Id<br>
pri -&gt; ( exp )</p>
<p>而基于这个规则做解析的算法如下：</p>
<p>匹配一个数据类型 (types)<br>
匹配一个标识符 (Id)，作为变量名称<br>
匹配初始化部分 (varInitializer)，而这会导致下降一层，使用一个新的语法规则：<br>
匹配一个等号<br>
匹配一个表达式 (在这个步骤会导致多层下降：exp-&gt;add-&gt;mul-&gt;pri-&gt;IntLiteral)<br>
创建一个 varInitializer 对应的 AST 节点并返回<br>
如果没有成功地匹配初始化部分，则回溯，匹配ε，也就是没有初始化部分。<br>
匹配一个分号  <br>
创建一个 varDecl 对应的 AST 节点并返回</p>
<p>用上述算法解析“int a = 2”，就会生成下面的 AST：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/755755dfdd4c48d5c5129faa465be579.png" alt=""></p>
<p>图 2：“int a = 2”对应的 AST</p>
<p>那么总结起来，递归下降算法的特点是：</p>
<ol>
<li>对于一个非终结符，要从左到右依次匹配其产生式中的每个项，包括非终结符和终结符。</li>
<li>在匹配产生式右边的非终结符时，要下降一层，继续匹配该非终结符的产生式。</li>
<li>如果一个语法规则有多个可选的产生式，那么只要有一个产生式匹配成功就行。如果一个产生式匹配不成功，那就回退回来，尝试另一个产生式。这种回退过程，叫做<strong>回溯</strong>（Backtracking）。</li>
</ol>
<p>所以说，递归下降算法是非常容易理解的。它能非常有效地处理很多语法规则，但是它也有两个缺点。</p>
<p>**第一个缺点，就是著名的左递归（Left Recursion）问题。**比如，在匹配算术表达式时，产生式的第一项就是一个非终结符 add，那么按照算法，要下降一层，继续匹配 add。这个过程会一直持续下去，无限递归下去。</p>
<p>add -&gt; add + mul</p>
<p>所以，递归下降算法是无法处理左递归问题的。那么有什么解决办法吗？</p>
<p>你可能会说，把产生式改成右递归不就可以了吗？也就是 add 这个递归项在右边：</p>
<p>add -&gt; mul + add</p>
<p>这样确实可以避免左递归问题，但它同时也会导致<strong>结合性</strong>的问题。</p>
<p>举个例子来说，我们按照上面的语法规则来解析“2+3+4”这个表达式，会形成如下所示的 AST。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/e475b88c621390234c8f9cb1a05ecfbb.png" alt=""></p>
<p>图 3：结合性错误的 AST</p>
<p>它会先计算“3+4”，而不是先计算“2+3”。这破坏了加法的结合性规则，加法运算本来应该是左结合的。</p>
<p>其实有一个标准的方法，能避免左递归问题。我们可以改写原来的语法规则，也就是引入<code>add'</code>，把左递归变成右递归：</p>
<p>add -&gt; mul add&rsquo;<br>
add&rsquo; -&gt; + mul add&rsquo; | ε</p>
<p>接下来，我们用刚刚改写的规则再次解析一下“2+3+4”这个表达式，会得到下图中的 AST：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/108d0bd06f9032072fa9016d0494bb3f.png" alt=""></p>
<p>图 4：基于改写后的文法所生成的 AST</p>
<p>你能看出，这种改写方法虽然能够避免左递归问题，但由于<code>add'</code>的规则是右递归的，采用标准的递归下降算法，仍然会出现运算符结合性的错误。那么针对这点，我们有没有解决办法呢？</p>
<p>有的，方法就是<strong>把递归调用转化成循环</strong>。这里利用了很多同学都知道的一个原理，即递归调用可以转化为循环。</p>
<p>其实我把上面的规则换成用 EBNF 方式来表达就很清楚了。在 EBNF 格式里，允许用“*”号和“+”号表示重复：</p>
<p>add：mul (&rsquo;+&rsquo; mul)*  ；</p>
<p>所以说，对于<code>('+'mul)*</code>这部分，我们其实可以写成一个循环。而在循环里，我们可以根据结合性的要求，手工生成正确的 AST。它的伪代码如下：</p>
<p>左子节点 = 匹配一个 mul<br>
while(下一个 Token 是+){<br>
消化掉+<br>
右子节点 = 匹配一个 mul<br>
用左、右子节点创建一个 add 节点<br>
左子节点 = 该 add 节点<br>
}</p>
<p>采用上面的算法，就可以创建正确的 AST，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/5c8c88daebb282e3463fa55027c9b81c.png" alt=""></p>
<p>图 5：结合性正确的 AST</p>
<p><strong>递归下降算法的第二个缺点，就是当产生式匹配失败的时候，必须要“回溯”，这就可能导致浪费。</strong></p>
<p>这个时候，我们有个针对性的解决办法，就是预读后续的一个 Token，判断该选择哪个产生式。</p>
<p>以 stmt 变元为例，考虑它的三个产生式，分别是变量声明语句、表达式语句和 return 语句。那么在递归下降算法中，我们可以在这里预读一个 Token，看看能否根据这个 Token 来选择某个产生式。</p>
<p>经过仔细观察，你发现如果预读的 Token 是 Int 或 Long，就选择变量声明语句；如果是 IntLiteral、Id 或左括号，就选择表达式语句；而如果是 Return，则肯定是选择 return 语句。因为这三个语句开头的 Token 是不重叠的，所以你可以很明确地做出选择。</p>
<p>如果我们手写递归下降算法，可以用肉眼识别出每次应该基于哪个 Token，选择用哪个产生式。但是，对于一些比较复杂的语法规则，我们要去看好几层规则，这样比较辛苦。</p>
<p>**那么能否有一个算法，来自动计算出选择不同产生式的依据呢？**当然是有的，这就是 LL 算法家族。</p>
<h2 id="ll-算法计算-first-和-follow-集合">LL 算法：计算 First 和 Follow 集合</h2>
<p>LL 算法的要点，就是计算 First 和 Follow 集合。</p>
<p>**First 集合是每个产生式开头可能会出现的 Token 的集合。**就像 stmt 有三个产生式，它的 First 集合如下表所示。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/49aac8d34d3549b0b7a9286d132fa491.png" alt=""></p>
<p>而 stmt 的 First 集合，就是三个产生式的 First 集合的并集，也是 Int Long IntLiteral Id ( Return。</p>
<p>总体来说，针对非终结符 x，它的 First 集合的计算规则是这样的：</p>
<ol>
<li>如果产生式以终结符开头，那么把这个终结符加入 First(x)；</li>
<li>如果产生式以非终结符 y 开头，那么把 First(y) 加入 First(x);</li>
<li>如果 First(y) 包含ε，那要把下一个项的 First 集合也加入进来，以此类推；</li>
<li>如果 x 有多个产生式，那么 First(x) 是每个产生式的并集。</li>
</ol>
<p>在计算 First 集合的时候，具体可以采用“<strong>不动点法</strong>”。相关细节这里就不展开了，你可以参考示例程序FirstFollowSet类的 CalcFirstSets() 方法，运行示例程序能打印各个非终结符的 First 集合。</p>
<p>不过，这样是不是就万事大吉了呢？</p>
<p>其实还有一种特殊情况我们需要考虑，那就是对于某个非终结符，它自身会产生ε的情况。比如说，示例文法中的 blockStmts，它是可能产生ε的，也就是块中一个语句都没有。</p>
<p>block : &lsquo;{&rsquo; blockStmts &lsquo;}&rsquo; ;                 //语句块<br>
blockStmts : stmt* ;                         //语句块中的语句<br>
stmt = varDecl | expStmt | returnStmt;       //语句</p>
<p>语法解析器在这个时候预读的下一个 Token 是什么呢？是右花括号。这证明 blockStmts 产生了ε，所以才读到了后续跟着的花括号。</p>
<p>**对于某个非终结符后面可能跟着的 Token 的集合，我们叫做 Follow 集合。**如果预读到的 Token 在 Follow 中，那么我们就可以判断当前正在匹配的这个非终结符，产生了ε。</p>
<p>Follow 的算法也比较简单，以非终结符 x 为例：</p>
<ol>
<li>扫描语法规则，看看 x 后面都可能跟着哪些符号；</li>
<li>对于后面跟着的终结符，都加到 Follow(x) 集合中去；</li>
<li>如果后面是非终结符 y，就把 First(y) 加 Follow(x) 集合中去；</li>
<li>最后，如果 First(y) 中包含ε，就继续往后找；</li>
<li>如果 x 可能出现在程序结尾，那么要把程序的终结符 $ 加入到 Follow(x) 中去。</li>
</ol>
<p>这样在计算了 First 和 Follow 集合之后，你就可以通过预读一个 Token，来完全确定采用哪个产生式。这种算法，就叫做 <strong>LL(1) 算法</strong>。</p>
<p>LL(1) 中的第一个 L，是 Left-to-right 的缩写，代表从左向右处理 Token 串。第二个 L，是 Leftmost 的缩写，意思是最左推导。**最左推导是什么呢？**就是它总是先把产生式中最左侧的非终结符展开完毕以后，再去展开下一个。这也就相当于对 AST 从左子节点开始的深度优先遍历。LL(1) 中的 1，指的是预读一个 Token。</p>
<h2 id="lr-算法移进和规约">LR 算法：移进和规约</h2>
<p>前面讲的递归下降和 LL 算法，都是自顶向下的算法。还有一类算法，是自底向上的，其中的代表就是 <strong>LR 算法</strong>。</p>
<p>自顶向下的算法，是从根节点逐层往下分解，形成最后的 AST；而 LR 算法的原理呢，则是从底下先拼凑出 AST 的一些局部拼图，并逐步组装成一棵完整的 AST。<strong>所以，其中的关键之处在于如何“拼凑”。</strong></p>
<p>假设我们采用下面的上下文无关文法，来推演一个实例，具体语法规则如下所示：</p>
<p>start-&gt;add<br>
add-&gt;add+mul<br>
add-&gt;mul<br>
mul-&gt;mul*pri<br>
mul-&gt;pri<br>
pri-&gt;Int<br>
pri-&gt;(add)</p>
<p>如果用于解析“2+3*5”，最终会形成下面的 AST：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/42723978f903e0d9e396f57b56e5eb42.png" alt=""></p>
<p>图 6:2+3*5 对应的 AST</p>
<p>那算法是怎么从底部凑出这棵 AST 来的呢？</p>
<p>LR 算法和 LL 算法一样，也是从左到右地消化掉 Token。在第 1 步，它会取出“2”这个 Token，放到一个栈里，这个栈是用来组装 AST 的工作区。同时，它还会预读下一个 Token，也就是“+”号，用来帮助算法做判断。</p>
<p>在下面的示意图里，我画了一条橙色竖线，竖线的左边是栈，右边是预读到的一个 Token。在做语法解析的过程中，竖线会不断地往右移动，把 Token 放到栈里，这个过程叫做“<strong>移进</strong>”（Shift）。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/eff69b1bb43db3a2aba9c55848dfd9ba.png" alt=""></p>
<p>图 7：第 1 步，移进一个 Token</p>
<p>注意，我在图 7 中还用虚线框推测了 AST 的其他部分。也就是说，如果第一个 Token 遇到的是整型字面量，而后面跟着一个 + 号，那么这两个 Token 就决定了它们必然是这棵推测出来的 AST 的一部分。而图中右边就是它的推导过程，其中的每个步骤，都使用了一个产生式加了一个点（如“.add”）。这个点，就相当于图中左边的橙色竖线。</p>
<p>所以你就可以根据这棵假想的 AST，也就是依据假想的推导过程，给它反推回去。把 Int 还原为 pri。这个还原过程，就叫做“<strong>规约</strong>”（Reduce）。工作区里的元素也随之更新成 pri。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/0c826e534ddec432c5c7b7a92f7f8fab.png" alt=""></p>
<p>图 8：第 2 步，Int 规约为 pri</p>
<p>按照这样的思路，不断地移进和规约，这棵 AST 中推测出来的节点会不断地被证实。而随着读入的 Token 越来越多，这棵 AST 也会长得越来越高，整棵树变得更大。下图是推导过程中间的一个步骤。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/af3d1b6d45c40b12f6115e0d11e3e9f9.png" alt=""></p>
<p>图 9：移进和规约过程中的一个步骤</p>
<p>最后，整个 AST 构造完毕，而工作区里也就只剩了一个 Start 节点。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/aed744d51b82b498a1ac6c8ffd841f3a.png" alt=""></p>
<p>图 10：最后一步，add 规约为 start</p>
<p>通过上面的介绍，你应该已经建立了对 LR 算法的直觉认识。如果要把这个推导过程写成严密的算法，你可以参考《编译原理之美》的第 18 讲。</p>
<p>从示例中，你应该已经看出来了，相对于 LL 算法，LR 算法的优点是能够处理左递归文法。但它也有缺点，比如不利于输出全面的编译错误信息。因为在没有解析完毕之前，算法并不知道最后的 AST 是什么样子，所以也不清楚当前的语法错误在整体 AST 中的位置。</p>
<p>最后我再提一下 LR 的意思，来帮你更完整地理解 LR 算法。L 还是代表从左到右读入 Token，而 R 是最右推导（Rightmost）的意思。我把“2+3*5”最右推导的过程写在了下面，而如果你从最后一行往前一步步地看，它恰好就是规约的过程。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/e0d7184e5c937a937319fb9397df40b5.png" alt=""></p>
<p>如果你见到 LR(k)，那它的意思就是会预读 k 个 Token，我们在示例中采用的是 LR(1)。</p>
<h2 id="课程小结">课程小结</h2>
<p>今天花了一讲的时间，把语法分析的要点给你讲解了一下。</p>
<p>对于上下文无关的文法，你要知道产生式、非终结符、终结符、EBNF 这几个基本概念，能够熟练阅读各种语言的语法规则，这是一个基本功。</p>
<p>递归下降算法是另一项基本功，所以也一定要掌握。**你要注意，递归下降是深度优先的，只有最左边的子树都生成完了，才会往右生成它的兄弟节点。**有的同学会在没有把左侧的非终结符匹配完毕的情况下，就开始匹配右边的项，从而不自觉地采用了宽度优先的思路，这是我发现很多同学会容易陷入的一个思维误区。</p>
<p>对于 LL 算法和 LR 算法，我只做了简单的讲解，目的是为了帮助你建立直观的理解。我们在后面的课程中，还会遇到使用它们的实际例子，到时你可以与这一讲的内容相互印证。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/34cdfa52ccb95ebd5b8f0e2f795b02b8.png" alt=""></p>
<h2 id="一课一思">一课一思</h2>
<p>你可以计算一下示例文法中 block、blockStmts、stmt、varDecl、returnStmt 和 expStmt 的 First 和 Follow 集合吗？这样，你也可以熟悉一下 First 和 Follow 集合的计算方法。</p>
<p>欢迎在留言区分享你的答案。如果觉得有收获，也欢迎你把这节课分享给你的朋友。</p>
<h2 id="参考资料">参考资料</h2>
<p>1. 线性文法（Linear Grammar）：参见Wikipedia。</p>
<p>2. 左递归及其消除方法：参见Wikipedia。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE/">编译原理实战课</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%88%B1%E4%B8%8A%E8%B7%91%E6%AD%A5/03_%E4%B8%BA%E4%BB%80%E4%B9%88%E8%B7%91%E6%AD%A5%E8%A6%81%E5%85%88%E7%83%AD%E8%BA%AB/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">03_为什么跑步要先热身？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B9%8B%E7%BE%8E/03_%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%80%E7%BA%AF%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0%E5%85%AC%E5%BC%8F%E8%AE%A1%E7%AE%97%E5%99%A8/">
            <span class="next-text nav-default">03_语法分析（一）：纯手工打造公式计算器</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

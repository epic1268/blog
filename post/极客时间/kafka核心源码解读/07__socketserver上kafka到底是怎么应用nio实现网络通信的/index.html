<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>07__SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是胡夕。这节课我们来说说 Kafka 底层的 NIO 通信机制源码。
在谈到 Kafka 高性能、高吞吐量实现原理的时候，很多人都对它使用了 Java NIO 这件事津津乐道。实际上，搞懂“Kafka 究竟是怎么应用 NIO 来实现网络通信的”，不仅是我们掌握 Kafka 请求全流程处理的前提条件，对我们了解 Reactor 模式的实现大有裨益，而且还能帮助我们解决很多实际问题。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/07__socketserver%E4%B8%8Akafka%E5%88%B0%E5%BA%95%E6%98%AF%E6%80%8E%E4%B9%88%E5%BA%94%E7%94%A8nio%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E7%9A%84/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/07__socketserver%E4%B8%8Akafka%E5%88%B0%E5%BA%95%E6%98%AF%E6%80%8E%E4%B9%88%E5%BA%94%E7%94%A8nio%E5%AE%9E%E7%8E%B0%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E7%9A%84/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="07__SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？">
  <meta property="og:description" content="你好，我是胡夕。这节课我们来说说 Kafka 底层的 NIO 通信机制源码。
在谈到 Kafka 高性能、高吞吐量实现原理的时候，很多人都对它使用了 Java NIO 这件事津津乐道。实际上，搞懂“Kafka 究竟是怎么应用 NIO 来实现网络通信的”，不仅是我们掌握 Kafka 请求全流程处理的前提条件，对我们了解 Reactor 模式的实现大有裨益，而且还能帮助我们解决很多实际问题。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Kafka核心源码解读">

  <meta itemprop="name" content="07__SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？">
  <meta itemprop="description" content="你好，我是胡夕。这节课我们来说说 Kafka 底层的 NIO 通信机制源码。
在谈到 Kafka 高性能、高吞吐量实现原理的时候，很多人都对它使用了 Java NIO 这件事津津乐道。实际上，搞懂“Kafka 究竟是怎么应用 NIO 来实现网络通信的”，不仅是我们掌握 Kafka 请求全流程处理的前提条件，对我们了解 Reactor 模式的实现大有裨益，而且还能帮助我们解决很多实际问题。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="6633">
  <meta itemprop="keywords" content="Kafka核心源码解读">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="07__SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？">
  <meta name="twitter:description" content="你好，我是胡夕。这节课我们来说说 Kafka 底层的 NIO 通信机制源码。
在谈到 Kafka 高性能、高吞吐量实现原理的时候，很多人都对它使用了 Java NIO 这件事津津乐道。实际上，搞懂“Kafka 究竟是怎么应用 NIO 来实现网络通信的”，不仅是我们掌握 Kafka 请求全流程处理的前提条件，对我们了解 Reactor 模式的实现大有裨益，而且还能帮助我们解决很多实际问题。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">07__SocketServer（上）：Kafka到底是怎么应用NIO实现网络通信的？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 6633 字 </span>
          <span class="more-meta"> 预计阅读 14 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#网络通信层">网络通信层</a></li>
        <li><a href="#socketserver-概览">SocketServer 概览</a></li>
        <li><a href="#acceptor-线程">Acceptor 线程</a>
          <ul>
            <li><a href="#addprocessors">addProcessors</a></li>
            <li><a href="#startprocessors">startProcessors</a></li>
            <li><a href="#removeprocessors">removeProcessors</a></li>
          </ul>
        </li>
        <li><a href="#processor-线程">Processor 线程</a>
          <ul>
            <li><a href="#configurenewconnections">configureNewConnections</a></li>
            <li><a href="#processnewresponses">processNewResponses</a></li>
            <li><a href="#poll">poll</a></li>
            <li><a href="#processcompletedreceives">processCompletedReceives</a></li>
            <li><a href="#processcompletedsends">processCompletedSends</a></li>
            <li><a href="#processdisconnected">processDisconnected</a></li>
            <li><a href="#closeexcessconnections">closeExcessConnections</a></li>
          </ul>
        </li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后讨论">课后讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是胡夕。这节课我们来说说 Kafka 底层的 NIO 通信机制源码。</p>
<p>在谈到 Kafka 高性能、高吞吐量实现原理的时候，很多人都对它使用了 Java NIO 这件事津津乐道。实际上，搞懂“Kafka 究竟是怎么应用 NIO 来实现网络通信的”，不仅是我们掌握 Kafka 请求全流程处理的前提条件，对我们了解 Reactor 模式的实现大有裨益，而且还能帮助我们解决很多实际问题。</p>
<p>比如说，当 Broker 处理速度很慢、需要优化的时候，你只有明确知道 SocketServer 组件的工作原理，才能制定出恰当的解决方案，并有针对性地给出对应的调优参数。</p>
<p>那么，今天，我们就一起拿下这个至关重要的 NIO 通信机制吧。</p>
<h2 id="网络通信层">网络通信层</h2>
<p>在深入学习 Kafka 各个网络组件之前，我们先从整体上看一下完整的网络通信层架构，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/cd9667eac39be97479e9de857d0bbfa0.png" alt=""></p>
<p>可以看出，Kafka 网络通信组件主要由两大部分构成：<strong>SocketServer</strong> 和 <strong>KafkaRequestHandlerPool</strong>。</p>
<p><strong>SocketServer 组件是核心</strong>，主要实现了 Reactor 模式，用于处理外部多个 Clients（这里的 Clients 指的是广义的 Clients，可能包含 Producer、Consumer 或其他 Broker）的并发请求，并负责将处理结果封装进 Response 中，返还给 Clients。</p>
<p><strong>KafkaRequestHandlerPool 组件就是我们常说的 I/O 线程池</strong>，里面定义了若干个 I/O 线程，用于执行真实的请求处理逻辑。</p>
<p>两者的交互点在于 SocketServer 中定义的 RequestChannel 对象和 Processor 线程。对了，我所说的线程，在代码中本质上都是 Runnable 类型，不管是 Acceptor 类、Processor 类，还是后面我们会单独讨论的 KafkaRequestHandler 类。</p>
<p>讲到这里，我稍微提示你一下。在第 9 节课，我会给出 KafkaRequestHandlerPool 线程池的详细介绍。但你现在需要知道的是，KafkaRequestHandlerPool 线程池定义了多个 KafkaRequestHandler 线程，而 KafkaRequestHandler 线程是真正处理请求逻辑的地方。和 KafkaRequestHandler 相比，今天所说的 Acceptor 和 Processor 线程从某种意义上来说，只能算是请求和响应的“搬运工”罢了。</p>
<p>了解了完整的网络通信层架构之后，我们要重点关注一下 SocketServer 组件。<strong>这个组件是 Kafka 网络通信层中最重要的子模块。它下辖的 Acceptor 线程、Processor 线程和 RequestChannel 等对象，都是实施网络通信的重要组成部分</strong>。你可能会感到意外的是，这套线程组合在源码中有多套，分别具有不同的用途。在下节课，我会具体跟你分享一下，不同的线程组合会被应用到哪些实际场景中。</p>
<p>下面我们进入到 SocketServer 组件的学习。</p>
<h2 id="socketserver-概览">SocketServer 概览</h2>
<p>SocketServer 组件的源码位于 Kafka 工程的 core 包下，具体位置是 src/main/scala/kafka/network 路径下的 SocketServer.scala 文件。</p>
<p>SocketServer.scala 可谓是元老级的源码文件了。在 Kafka 的源码演进历史中，很多代码文件进进出出，这个文件却一直“坚强地活着”，而且还在不断完善。如果翻开它的 Git 修改历史，你会发现，它最早的修改提交历史可回溯到 2011 年 8 月，足见它的资历之老。</p>
<p>目前，SocketServer.scala 文件是一个近 2000 行的大文件，共有 8 个代码部分。我使用一张思维导图帮你梳理下：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/cbbef4e81ec2be37dc70cfbbf16ee8ac.png" alt=""></p>
<p>乍一看组件有很多，但你也不必担心，我先对这些组件做个简单的介绍，然后我们重点学习一下 Acceptor 类和 Processor 类的源码。毕竟，<strong>这两个类是实现网络通信的关键部件</strong>。另外，今天我给出的都是 SocketServer 组件的基本情况介绍，下节课我再详细向你展示它的定义。</p>
<p>1.<strong>AbstractServerThread 类</strong>：这是 Acceptor 线程和 Processor 线程的抽象基类，定义了这两个线程的公有方法，如 shutdown（关闭线程）等。我不会重点展开这个抽象类的代码，但你要重点关注下 CountDownLatch 类在线程启动和线程关闭时的作用。</p>
<p>如果你苦于寻找 Java 线程安全编程的最佳实践案例，那一定不要错过 CountDownLatch 这个类。Kafka 中的线程控制代码大量使用了基于 CountDownLatch 的编程技术，依托于它来实现优雅的线程启动、线程关闭等操作。因此，我建议你熟练掌握它们，并应用到你日后的工作当中去。</p>
<p>2.<strong>Acceptor 线程类</strong>：这是接收和创建外部 TCP 连接的线程。每个 SocketServer 实例只会创建一个 Acceptor 线程。它的唯一目的就是创建连接，并将接收到的 Request 传递给下游的 Processor 线程处理。</p>
<p>3.<strong>Processor 线程类</strong>：这是处理单个 TCP 连接上所有请求的线程。每个 SocketServer 实例默认创建若干个（num.network.threads）Processor 线程。Processor 线程负责将接收到的 Request 添加到 RequestChannel 的 Request 队列上，同时还负责将 Response 返还给 Request 发送方。</p>
<p>4.<strong>Processor 伴生对象类</strong>：仅仅定义了一些与 Processor 线程相关的常见监控指标和常量等，如 Processor 线程空闲率等。</p>
<p>5.<strong>ConnectionQuotas 类</strong>：是控制连接数配额的类。我们能够设置单个 IP 创建 Broker 连接的最大数量，以及单个 Broker 能够允许的最大连接数。</p>
<p>6.<strong>TooManyConnectionsException 类</strong>：SocketServer 定义的一个异常类，用于标识连接数配额超限情况。</p>
<p>7.<strong>SocketServer 类</strong>：实现了对以上所有组件的管理和操作，如创建和关闭 Acceptor、Processor 线程等。</p>
<p>8.<strong>SocketServer 伴生对象类</strong>：定义了一些有用的常量，同时明确了 SocketServer 组件中的哪些参数是允许动态修改的。</p>
<h2 id="acceptor-线程">Acceptor 线程</h2>
<p>经典的 Reactor 模式有个 Dispatcher 的角色，接收外部请求并分发给下面的实际处理线程。在 Kafka 中，这个 Dispatcher 就是 Acceptor 线程。</p>
<p>我们看下它的定义：</p>
<p>private[kafka] class Acceptor(val endPoint: EndPoint,<br>
val sendBufferSize: Int,<br>
val recvBufferSize: Int,<br>
brokerId: Int,<br>
connectionQuotas: ConnectionQuotas,<br>
metricPrefix: String) extends AbstractServerThread(connectionQuotas) with KafkaMetricsGroup {<br>
// 创建底层的 NIO Selector 对象<br>
// Selector 对象负责执行底层实际 I/O 操作，如监听连接创建请求、读写请求等<br>
private val nioSelector = NSelector.open()<br>
// Broker 端创建对应的 ServerSocketChannel 实例<br>
// 后续把该 Channel 向上一步的 Selector 对象注册<br>
val serverChannel = openServerSocket(endPoint.host, endPoint.port)<br>
// 创建 Processor 线程池，实际上是 Processor 线程数组<br>
private val processors = new ArrayBuffer<a href="">Processor</a><br>
private val processorsStarted = new AtomicBoolean</p>
<p>private val blockedPercentMeter = newMeter(s&quot;${metricPrefix}AcceptorBlockedPercent&quot;,<br>
&ldquo;blocked time&rdquo;, TimeUnit.NANOSECONDS, Map(ListenerMetricTag -&gt; endPoint.listenerName.value))<br>
&hellip;&hellip;<br>
}</p>
<p>从定义来看，Acceptor 线程接收 5 个参数，其中比较重要的有 3 个。</p>
<ol>
<li><strong>endPoint</strong>。它就是你定义的 Kafka Broker 连接信息，比如 PLAINTEXT://localhost:9092。Acceptor 需要用到 endPoint 包含的主机名和端口信息创建 Server Socket。</li>
<li><strong>sendBufferSize</strong>。它设置的是 SocketOptions 的 SO_SNDBUF，即用于设置出站（Outbound）网络 I/O 的底层缓冲区大小。该值默认是 Broker 端参数 socket.send.buffer.bytes 的值，即 100KB。</li>
<li><strong>recvBufferSize</strong>。它设置的是 SocketOptions 的 SO_RCVBUF，即用于设置入站（Inbound）网络 I/O 的底层缓冲区大小。该值默认是 Broker 端参数 socket.receive.buffer.bytes 的值，即 100KB。</li>
</ol>
<p>说到这儿，我想给你提一个优化建议。如果在你的生产环境中，Clients 与 Broker 的通信网络延迟很大（比如 RTT&gt;10ms），那么我建议你调大控制缓冲区大小的两个参数，也就是 sendBufferSize 和 recvBufferSize。通常来说，默认值 100KB 太小了。</p>
<p>除了类定义的字段，Acceptor 线程还有两个非常关键的自定义属性。</p>
<ol>
<li><strong>nioSelector</strong>：是 Java NIO 库的 Selector 对象实例，也是后续所有网络通信组件实现 Java NIO 机制的基础。如果你不熟悉 Java NIO，那么我推荐你学习这个系列教程：Java NIO。</li>
<li><strong>processors</strong>：网络 Processor 线程池。Acceptor 线程在初始化时，需要创建对应的网络 Processor 线程池。可见，Processor 线程是在 Acceptor 线程中管理和维护的。</li>
</ol>
<p>既然如此，那它就必须要定义相关的方法。Acceptor 代码中，提供了 3 个与 Processor 相关的方法，分别是 addProcessors、startProcessors 和 removeProcessors。鉴于它们的代码都非常简单，我用注释的方式给出主体逻辑的步骤：</p>
<h3 id="addprocessors">addProcessors</h3>
<p>private[network] def addProcessors(<br>
newProcessors: Buffer[Processor], processorThreadPrefix: String): Unit = synchronized {<br>
processors ++= newProcessors // 添加一组新的 Processor 线程<br>
if (processorsStarted.get) // 如果 Processor 线程池已经启动<br>
startProcessors(newProcessors, processorThreadPrefix) // 启动新的 Processor 线程<br>
}</p>
<h3 id="startprocessors">startProcessors</h3>
<p>private[network] def startProcessors(processorThreadPrefix: String): Unit = synchronized {<br>
if (!processorsStarted.getAndSet(true)) {  // 如果 Processor 线程池未启动<br>
startProcessors(processors, processorThreadPrefix) // 启动给定的 Processor 线程<br>
}<br>
}</p>
<p>private def startProcessors(processors: Seq[Processor], processorThreadPrefix: String): Unit = synchronized {<br>
processors.foreach { processor =&gt; // 依次创建并启动 Processor 线程<br>
// 线程命名规范：processor 线程前缀-kafka-network-thread-broker 序号 - 监听器名称 - 安全协议-Processor 序号<br>
// 假设为序号为 0 的 Broker 设置 PLAINTEXT://localhost:9092 作为连接信息，那么 3 个 Processor 线程名称分别为：<br>
// data-plane-kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0<br>
// data-plane-kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1<br>
// data-plane-kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2<br>
KafkaThread.nonDaemon(s&quot;${processorThreadPrefix}-kafka-network-thread-$brokerId-${endPoint.listenerName}-${endPoint.securityProtocol}-${processor.id}&quot;, processor).start()<br>
}<br>
}</p>
<h3 id="removeprocessors">removeProcessors</h3>
<p>private[network] def removeProcessors(removeCount: Int, requestChannel: RequestChannel): Unit = synchronized {<br>
// 获取 Processor 线程池中最后 removeCount 个线程<br>
val toRemove = processors.takeRight(removeCount)<br>
// 移除最后 removeCount 个线程<br>
processors.remove(processors.size - removeCount, removeCount)<br>
// 关闭最后 removeCount 个线程<br>
toRemove.foreach(_.shutdown())<br>
// 在 RequestChannel 中移除这些 Processor<br>
toRemove.foreach(processor =&gt; requestChannel.removeProcessor(processor.id))<br>
}</p>
<p>为了更加形象地展示这些方法的逻辑，我画了一张图，它同时包含了这 3 个方法的执行流程，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/3e9b5fb4ccbd1b30f43aa9c3334d2530.png" alt=""></p>
<p>刚才我们学到的 addProcessors、startProcessors 和 removeProcessors 方法是管理 Processor 线程用的。应该这么说，有了这三个方法，Acceptor 类就具备了基本的 Processor 线程池管理功能。不过，<strong>Acceptor 类逻辑的重头戏其实是 run 方法，它是处理 Reactor 模式中分发逻辑的主要实现方法</strong>。下面我使用注释的方式给出 run 方法的大体运行逻辑，如下所示：</p>
<p>def run(): Unit = {<br>
//注册 OP_ACCEPT 事件<br>
serverChannel.register(nioSelector, SelectionKey.OP_ACCEPT)<br>
// 等待 Acceptor 线程启动完成<br>
startupComplete()<br>
try {<br>
// 当前使用的 Processor 序号，从 0 开始，最大值是 num.network.threads - 1<br>
var currentProcessorIndex = 0<br>
while (isRunning) {<br>
try {<br>
// 每 500 毫秒获取一次就绪 I/O 事件<br>
val ready = nioSelector.select(500)<br>
if (ready &gt; 0) { // 如果有 I/O 事件准备就绪<br>
val keys = nioSelector.selectedKeys()<br>
val iter = keys.iterator()<br>
while (iter.hasNext &amp;&amp; isRunning) {<br>
try {<br>
val key = iter.next<br>
iter.remove()<br>
if (key.isAcceptable) {<br>
// 调用 accept 方法创建 Socket 连接<br>
accept(key).foreach { socketChannel =&gt;<br>
var retriesLeft = synchronized(processors.length)<br>
var processor: Processor = null<br>
do {<br>
retriesLeft -= 1<br>
// 指定由哪个 Processor 线程进行处理<br>
processor = synchronized {<br>
currentProcessorIndex = currentProcessorIndex % processors.length<br>
processors(currentProcessorIndex)<br>
}<br>
// 更新 Processor 线程序号<br>
currentProcessorIndex += 1<br>
} while (!assignNewConnection(socketChannel, processor, retriesLeft == 0)) // Processor 是否接受了该连接<br>
}<br>
} else<br>
throw new IllegalStateException(&ldquo;Unrecognized key state for acceptor thread.&rdquo;)<br>
} catch {<br>
case e: Throwable =&gt; error(&ldquo;Error while accepting connection&rdquo;, e)<br>
}<br>
}<br>
}<br>
}<br>
catch {<br>
case e: ControlThrowable =&gt; throw e<br>
case e: Throwable =&gt; error(&ldquo;Error occurred&rdquo;, e)<br>
}<br>
}<br>
} finally { // 执行各种资源关闭逻辑<br>
debug(&ldquo;Closing server socket and selector.&rdquo;)<br>
CoreUtils.swallow(serverChannel.close(), this, Level.ERROR)<br>
CoreUtils.swallow(nioSelector.close(), this, Level.ERROR)<br>
shutdownComplete()<br>
}<br>
}</p>
<p>看上去代码似乎有点多，我再用一张图来说明一下 run 方法的主要处理逻辑吧。这里的关键点在于，Acceptor 线程会先为每个入站请求确定要处理它的 Processor 线程，然后调用 assignNewConnection 方法令 Processor 线程创建与发送方的连接。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/194469fbe529f8b2762052c618663579.png" alt=""></p>
<p>基本上，Acceptor 线程使用 Java NIO 的 Selector + SocketChannel 的方式循环地轮询准备就绪的 I/O 事件。这里的 I/O 事件，主要是指网络连接创建事件，即代码中的 SelectionKey.OP_ACCEPT。一旦接收到外部连接请求，Acceptor 就会指定一个 Processor 线程，并将该请求交由它，让它创建真正的网络连接。总的来说，Acceptor 线程就做这么点事。</p>
<h2 id="processor-线程">Processor 线程</h2>
<p>下面我们进入到 Processor 线程源码的学习。</p>
<p><strong>如果说 Acceptor 是做入站连接处理的，那么，Processor 代码则是真正创建连接以及分发请求的地方</strong>。显然，它要做的事情远比 Acceptor 要多得多。我先给出 Processor 线程的 run 方法，你大致感受一下：</p>
<p>override def run(): Unit = {<br>
startupComplete() // 等待 Processor 线程启动完成<br>
try {<br>
while (isRunning) {<br>
try {<br>
configureNewConnections() // 创建新连接<br>
// register any new responses for writing<br>
processNewResponses() // 发送 Response，并将 Response 放入到 inflightResponses 临时队列<br>
poll() // 执行 NIO poll，获取对应 SocketChannel 上准备就绪的 I/O 操作<br>
processCompletedReceives() // 将接收到的 Request 放入 Request 队列<br>
processCompletedSends() // 为临时 Response 队列中的 Response 执行回调逻辑<br>
processDisconnected() // 处理因发送失败而导致的连接断开<br>
closeExcessConnections() // 关闭超过配额限制部分的连接<br>
} catch {<br>
case e: Throwable =&gt; processException(&ldquo;Processor got uncaught exception.&rdquo;, e)<br>
}<br>
}<br>
} finally { // 关闭底层资源<br>
debug(s&quot;Closing selector - processor $id&quot;)<br>
CoreUtils.swallow(closeAll(), this, Level.ERROR)<br>
shutdownComplete()<br>
}<br>
}</p>
<p>run 方法逻辑被切割得相当好，各个子方法的边界非常清楚。因此，从整体上看，该方法呈现出了面向对象领域中非常难得的封装特性。我使用一张图来展示下该方法要做的事情：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/721abcd2b29eb1a439f845786cdf6cc1.png" alt=""></p>
<p>在详细说 run 方法之前，我们先来看下 Processor 线程初始化时要做的事情。</p>
<p>每个 Processor 线程在创建时都会创建 3 个队列。注意，这里的队列是广义的队列，其底层使用的数据结构可能是阻塞队列，也可能是一个 Map 对象而已，如下所示：</p>
<p>private val newConnections = new ArrayBlockingQueue<a href="./connectionQueueSize.md">SocketChannel</a><br>
private val inflightResponses = mutable.Map<a href="">String, RequestChannel.Response</a><br>
private val responseQueue = new LinkedBlockingDeque<a href="">RequestChannel.Response</a></p>
<p><strong>队列一：newConnections</strong></p>
<p><strong>它保存的是要创建的新连接信息</strong>，具体来说，就是 SocketChannel 对象。这是一个默认上限是 20 的队列，而且，目前代码中硬编码了队列的长度，因此，你无法变更这个队列的长度。</p>
<p>每当 Processor 线程接收新的连接请求时，都会将对应的 SocketChannel 放入这个队列。后面在创建连接时（也就是调用 configureNewConnections 时），就从该队列中取出 SocketChannel，然后注册新的连接。</p>
<p><strong>队列二：inflightResponses</strong></p>
<p>严格来说，这是一个临时 Response 队列。当 Processor 线程将 Response 返还给 Request 发送方之后，还要将 Response 放入这个临时队列。</p>
<p>为什么需要这个临时队列呢？这是因为，有些 Response 回调逻辑要在 Response 被发送回发送方之后，才能执行，因此需要暂存在一个临时队列里面。这就是 inflightResponses 存在的意义。</p>
<p><strong>队列三：responseQueue</strong></p>
<p>看名字我们就可以知道，这是 Response 队列，而不是 Request 队列。这告诉了我们一个事实：<strong>每个 Processor 线程都会维护自己的 Response 队列</strong>，而不是像网上的某些文章说的，Response 队列是线程共享的或是保存在 RequestChannel 中的。Response 队列里面保存着需要被返还给发送方的所有 Response 对象。</p>
<p>好了，了解了这些之后，现在我们来深入地查看一下 Processor 线程的工作逻辑。根据 run 方法中的方法调用顺序，我先来介绍下 configureNewConnections 方法。</p>
<h3 id="configurenewconnections">configureNewConnections</h3>
<p>就像我前面所说的，configureNewConnections 负责处理新连接请求。接下来，我用注释的方式给出这个方法的主体逻辑：</p>
<p>private def configureNewConnections(): Unit = {<br>
var connectionsProcessed = 0 // 当前已配置的连接数计数器<br>
while (connectionsProcessed &lt; connectionQueueSize &amp;&amp; !newConnections.isEmpty) { // 如果没超配额并且有待处理新连接<br>
val channel = newConnections.poll() // 从连接队列中取出 SocketChannel<br>
try {<br>
debug(s&quot;Processor $id listening to new connection from ${channel.socket.getRemoteSocketAddress}&quot;)<br>
// 用给定 Selector 注册该 Channel<br>
// 底层就是调用 Java NIO 的 SocketChannel.register(selector, SelectionKey.OP_READ)<br>
selector.register(connectionId(channel.socket), channel)<br>
connectionsProcessed += 1 // 更新计数器<br>
} catch {<br>
case e: Throwable =&gt;<br>
val remoteAddress = channel.socket.getRemoteSocketAddress<br>
close(listenerName, channel)<br>
processException(s&quot;Processor $id closed connection from $remoteAddress&quot;, e)<br>
}<br>
}<br>
}</p>
<p><strong>该方法最重要的逻辑是调用 selector 的 register 来注册 SocketChannel</strong>。每个 Processor 线程都维护了一个 Selector 类实例。Selector 类是社区提供的一个基于 Java NIO Selector 的接口，用于执行非阻塞多通道的网络 I/O 操作。在核心功能上，Kafka 提供的 Selector 和 Java 提供的是一致的。</p>
<h3 id="processnewresponses">processNewResponses</h3>
<p>它负责发送 Response 给 Request 发送方，并且将 Response 放入临时 Response 队列。处理逻辑如下：</p>
<p>private def processNewResponses(): Unit = {<br>
var currentResponse: RequestChannel.Response = null<br>
while ({currentResponse = dequeueResponse(); currentResponse != null}) { // Response 队列中存在待处理 Response<br>
val channelId = currentResponse.request.context.connectionId // 获取连接通道 ID<br>
try {<br>
currentResponse match {<br>
case response: NoOpResponse =&gt; // 无需发送 Response<br>
updateRequestMetrics(response)<br>
trace(s&quot;Socket server received empty response to send, registering for read: $response&quot;)<br>
handleChannelMuteEvent(channelId, ChannelMuteEvent.RESPONSE_SENT)<br>
tryUnmuteChannel(channelId)<br>
case response: SendResponse =&gt; // 发送 Response 并将 Response 放入 inflightResponses<br>
sendResponse(response, response.responseSend)<br>
case response: CloseConnectionResponse =&gt; // 关闭对应的连接<br>
updateRequestMetrics(response)<br>
trace(&ldquo;Closing socket connection actively according to the response code.&rdquo;)<br>
close(channelId)<br>
case _: StartThrottlingResponse =&gt;<br>
handleChannelMuteEvent(channelId, ChannelMuteEvent.THROTTLE_STARTED)<br>
case _: EndThrottlingResponse =&gt;<br>
handleChannelMuteEvent(channelId, ChannelMuteEvent.THROTTLE_ENDED)<br>
tryUnmuteChannel(channelId)<br>
case _ =&gt;<br>
throw new IllegalArgumentException(s&quot;Unknown response type: ${currentResponse.getClass}&quot;)<br>
}<br>
} catch {<br>
case e: Throwable =&gt;<br>
processChannelException(channelId, s&quot;Exception while processing response for $channelId&quot;, e)<br>
}<br>
}<br>
}</p>
<p>这里的关键是 <strong>SendResponse 分支上的 sendResponse 方法</strong>。这个方法的核心代码其实只有三行：</p>
<p>if (openOrClosingChannel(connectionId).isDefined) { // 如果该连接处于可连接状态<br>
selector.send(responseSend) // 发送 Response<br>
inflightResponses += (connectionId -&gt; response) // 将 Response 加入到 inflightResponses 队列<br>
}</p>
<h3 id="poll">poll</h3>
<p>严格来说，上面提到的所有发送的逻辑都不是执行真正的发送。真正执行 I/O 动作的方法是这里的 poll 方法。</p>
<p>poll 方法的核心代码就只有 1 行：<strong>selector.poll(pollTimeout)</strong>。在底层，它实际上调用的是 Java NIO Selector 的 select 方法去执行那些准备就绪的 I/O 操作，不管是接收 Request，还是发送 Response。因此，你需要记住的是，<strong>poll 方法才是真正执行 I/O 操作逻辑的地方</strong>。</p>
<h3 id="processcompletedreceives">processCompletedReceives</h3>
<p>它是接收和处理 Request 的。代码如下：</p>
<p>private def processCompletedReceives(): Unit = {<br>
// 遍历所有已接收的 Request<br>
selector.completedReceives.asScala.foreach { receive =&gt;<br>
try {<br>
// 保证对应连接通道已经建立<br>
openOrClosingChannel(receive.source) match {<br>
case Some(channel) =&gt;<br>
val header = RequestHeader.parse(receive.payload)<br>
if (header.apiKey == ApiKeys.SASL_HANDSHAKE &amp;&amp; channel.maybeBeginServerReauthentication(receive, nowNanosSupplier))<br>
trace(s&quot;Begin re-authentication: $channel&quot;)<br>
else {<br>
val nowNanos = time.nanoseconds()<br>
// 如果认证会话已过期，则关闭连接<br>
if (channel.serverAuthenticationSessionExpired(nowNanos)) {<br>
debug(s&quot;Disconnecting expired channel: $channel : $header&quot;)<br>
close(channel.id)<br>
expiredConnectionsKilledCount.record(null, 1, 0)<br>
} else {<br>
val connectionId = receive.source<br>
val context = new RequestContext(header, connectionId, channel.socketAddress,<br>
channel.principal, listenerName, securityProtocol,<br>
channel.channelMetadataRegistry.clientInformation)<br>
val req = new RequestChannel.Request(processor = id, context = context,<br>
startTimeNanos = nowNanos, memoryPool, receive.payload, requestChannel.metrics)<br>
if (header.apiKey == ApiKeys.API_VERSIONS) {<br>
val apiVersionsRequest = req.body[ApiVersionsRequest]<br>
if (apiVersionsRequest.isValid) {<br>
channel.channelMetadataRegistry.registerClientInformation(new ClientInformation(<br>
apiVersionsRequest.data.clientSoftwareName,<br>
apiVersionsRequest.data.clientSoftwareVersion))<br>
}<br>
}<br>
// 核心代码：将 Request 添加到 Request 队列<br>
requestChannel.sendRequest(req)<br>
selector.mute(connectionId)<br>
handleChannelMuteEvent(connectionId, ChannelMuteEvent.REQUEST_RECEIVED)<br>
}<br>
}<br>
case None =&gt;<br>
throw new IllegalStateException(s&quot;Channel ${receive.source} removed from selector before processing completed receive&quot;)<br>
}<br>
} catch {<br>
case e: Throwable =&gt;<br>
processChannelException(receive.source, s&quot;Exception while processing request from ${receive.source}&quot;, e)<br>
}<br>
}<br>
}</p>
<p>看上去代码有很多，但其实最核心的代码就只有 1 行：<strong>requestChannel.sendRequest(req)</strong>，也就是将此 Request 放入 Request 队列。其他代码只是一些常规化的校验和辅助逻辑。</p>
<p>这个方法的意思是说，<strong>Processor 从底层 Socket 通道不断读取已接收到的网络请求，然后转换成 Request 实例，并将其放入到 Request 队列</strong>。整个逻辑还是很简单的，对吧？</p>
<h3 id="processcompletedsends">processCompletedSends</h3>
<p>它负责处理 Response 的回调逻辑。我之前说过，Response 需要被发送之后才能执行对应的回调逻辑，这便是该方法代码要实现的功能：</p>
<p>private def processCompletedSends(): Unit = {<br>
// 遍历底层 SocketChannel 已发送的 Response<br>
selector.completedSends.asScala.foreach { send =&gt;<br>
try {<br>
// 取出对应 inflightResponses 中的 Response<br>
val response = inflightResponses.remove(send.destination).getOrElse {<br>
throw new IllegalStateException(s&quot;Send for ${send.destination} completed, but not in <code>inflightResponses</code>&quot;)<br>
}<br>
updateRequestMetrics(response) // 更新一些统计指标<br>
// 执行回调逻辑<br>
response.onComplete.foreach(onComplete =&gt; onComplete(send))<br>
handleChannelMuteEvent(send.destination, ChannelMuteEvent.RESPONSE_SENT)<br>
tryUnmuteChannel(send.destination)<br>
} catch {<br>
case e: Throwable =&gt; processChannelException(send.destination,<br>
s&quot;Exception while processing completed send to ${send.destination}&quot;, e)<br>
}<br>
}<br>
}</p>
<p>这里通过调用 Response 对象的 onComplete 方法，来实现回调函数的执行。</p>
<h3 id="processdisconnected">processDisconnected</h3>
<p>顾名思义，它就是处理已断开连接的。该方法的逻辑很简单，我用注释标注了主要的执行步骤：</p>
<p>private def processDisconnected(): Unit = {<br>
// 遍历底层 SocketChannel 的那些已经断开的连接<br>
selector.disconnected.keySet.asScala.foreach { connectionId =&gt;<br>
try {<br>
// 获取断开连接的远端主机名信息<br>
val remoteHost = ConnectionId.fromString(connectionId).getOrElse {<br>
throw new IllegalStateException(s&quot;connectionId has unexpected format: $connectionId&quot;)<br>
}.remoteHost<br>
// 将该连接从 inflightResponses 中移除，同时更新一些监控指标<br>
inflightResponses.remove(connectionId).foreach(updateRequestMetrics)<br>
// 更新配额数据<br>
connectionQuotas.dec(listenerName, InetAddress.getByName(remoteHost))<br>
} catch {<br>
case e: Throwable =&gt; processException(s&quot;Exception while processing disconnection of $connectionId&quot;, e)<br>
}<br>
}<br>
}</p>
<p>比较关键的代码是需要从底层 Selector 中获取那些已经断开的连接，之后把它们从 inflightResponses 中移除掉，同时也要更新它们的配额数据。</p>
<h3 id="closeexcessconnections">closeExcessConnections</h3>
<p>这是 Processor 线程的 run 方法执行的最后一步，即<strong>关闭超限连接</strong>。代码很简单：</p>
<p>private def closeExcessConnections(): Unit = {<br>
// 如果配额超限了<br>
if (connectionQuotas.maxConnectionsExceeded(listenerName)) {<br>
// 找出优先关闭的那个连接<br>
val channel = selector.lowestPriorityChannel()<br>
if (channel != null)<br>
close(channel.id) // 关闭该连接<br>
}<br>
}</p>
<p>所谓优先关闭，是指在诸多 TCP 连接中找出最近未被使用的那个。这里“未被使用”就是说，在最近一段时间内，没有任何 Request 经由这个连接被发送到 Processor 线程。</p>
<h2 id="总结">总结</h2>
<p>今天，我带你了解了 Kafka 网络通信层的全貌，大致介绍了核心组件 SocketServer，还花了相当多的时间研究 SocketServer 下的 Acceptor 和 Processor 线程代码。我们来简单总结一下。</p>
<ol>
<li>网络通信层由 SocketServer 组件和 KafkaRequestHandlerPool 组件构成。</li>
<li>SocketServer 实现了 Reactor 模式，用于高性能地并发处理 I/O 请求。</li>
<li>SocketServer 底层使用了 Java 的 Selector 实现 NIO 通信。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/f59119ae23c4ecc24c50f2022e48c75e.png" alt=""></p>
<p>在下节课，我会重点介绍 SocketServer 处理不同类型 Request 所做的设计及其对应的代码。这是社区为了提高 Broker 处理控制类请求的重大举措，也是为了改善 Broker 一致性所做的努力，非常值得我们重点关注。</p>
<h2 id="课后讨论">课后讨论</h2>
<p>最后，请思考这样一个问题：为什么 Request 队列被设计成线程共享的，而 Response 队列则是每个 Processor 线程专属的？</p>
<p>欢迎你在留言区畅所欲言，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/">Kafka核心源码解读</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98/07__raft%E7%AE%97%E6%B3%95%E4%B8%80%E5%A6%82%E4%BD%95%E9%80%89%E4%B8%BE%E9%A2%86%E5%AF%BC%E8%80%85/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">07__Raft算法（一）：如何选举领导者？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/webassembly%E5%85%A5%E9%97%A8%E8%AF%BE/07__wasi%E4%BD%A0%E5%90%AC%E8%AF%B4%E8%BF%87_webassembly_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%8E%A5%E5%8F%A3%E5%90%97/">
            <span class="next-text nav-default">07__WASI：你听说过_WebAssembly_操作系统接口吗？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>15__如何理解Controller在Kafka集群中的作用？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是胡夕。
上节课，我们学习了 Controller 选举的源码，了解了 Controller 组件的选举触发场景，以及它是如何被选举出来的。Controller 就绪之后，就会行使它作为控制器的重要权利了，包括管理集群成员、维护主题、操作元数据，等等。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/15__%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3controller%E5%9C%A8kafka%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/15__%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3controller%E5%9C%A8kafka%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="15__如何理解Controller在Kafka集群中的作用？">
  <meta property="og:description" content="你好，我是胡夕。
上节课，我们学习了 Controller 选举的源码，了解了 Controller 组件的选举触发场景，以及它是如何被选举出来的。Controller 就绪之后，就会行使它作为控制器的重要权利了，包括管理集群成员、维护主题、操作元数据，等等。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Kafka核心源码解读">

  <meta itemprop="name" content="15__如何理解Controller在Kafka集群中的作用？">
  <meta itemprop="description" content="你好，我是胡夕。
上节课，我们学习了 Controller 选举的源码，了解了 Controller 组件的选举触发场景，以及它是如何被选举出来的。Controller 就绪之后，就会行使它作为控制器的重要权利了，包括管理集群成员、维护主题、操作元数据，等等。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="5755">
  <meta itemprop="keywords" content="Kafka核心源码解读">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="15__如何理解Controller在Kafka集群中的作用？">
  <meta name="twitter:description" content="你好，我是胡夕。
上节课，我们学习了 Controller 选举的源码，了解了 Controller 组件的选举触发场景，以及它是如何被选举出来的。Controller 就绪之后，就会行使它作为控制器的重要权利了，包括管理集群成员、维护主题、操作元数据，等等。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">15__如何理解Controller在Kafka集群中的作用？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 5755 字 </span>
          <span class="more-meta"> 预计阅读 12 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#集群成员管理">集群成员管理</a>
          <ul>
            <li><a href="#成员数量管理">成员数量管理</a></li>
            <li><a href="#成员信息管理">成员信息管理</a></li>
          </ul>
        </li>
        <li><a href="#主题管理">主题管理</a>
          <ul>
            <li><a href="#主题创建--变更">主题创建 / 变更</a></li>
            <li><a href="#主题删除">主题删除</a></li>
          </ul>
        </li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后讨论">课后讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是胡夕。</p>
<p>上节课，我们学习了 Controller 选举的源码，了解了 Controller 组件的选举触发场景，以及它是如何被选举出来的。Controller 就绪之后，就会行使它作为控制器的重要权利了，包括管理集群成员、维护主题、操作元数据，等等。</p>
<p>之前在学习 Kafka 的时候，我一直很好奇，新启动的 Broker 是如何加入到集群中的。官方文档里的解释是：“Adding servers to a Kafka cluster is easy, just assign them a unique broker id and start up Kafka on your new servers.”显然，你只要启动 Broker 进程，就可以实现集群的扩展，甚至包括集群元数据信息的同步。</p>
<p>不过，你是否思考过，这一切是怎么做到的呢？其实，这就是 Controller 组件源码提供的一个重要功能：管理新集群成员。</p>
<p>当然，作为核心组件，Controller 提供的功能非常多。除了集群成员管理，主题管理也是一个极其重要的功能。今天，我就带你深入了解下它们的实现代码。可以说，这是 Controller 最核心的两个功能，它们几乎涉及到了集群元数据中的所有重要数据。掌握了这些，之后你在探索 Controller 的其他代码时，会更加游刃有余。</p>
<h2 id="集群成员管理">集群成员管理</h2>
<p>首先，我们来看 Controller 管理集群成员部分的代码。这里的成员管理包含两个方面：</p>
<ol>
<li>成员数量的管理，主要体现在新增成员和移除现有成员；</li>
<li>单个成员的管理，如变更单个 Broker 的数据等。</li>
</ol>
<h3 id="成员数量管理">成员数量管理</h3>
<p>每个 Broker 在启动的时候，会在 ZooKeeper 的 /brokers/ids 节点下创建一个名为 broker.id 参数值的临时节点。</p>
<p>举个例子，假设 Broker 的 broker.id 参数值设置为 1001，那么，当 Broker 启动后，你会在 ZooKeeper 的 /brokers/ids 下观测到一个名为 1001 的子节点。该节点的内容包括了 Broker 配置的主机名、端口号以及所用监听器的信息（注意：这里的监听器和上面说的 ZooKeeper 监听器不是一回事）。</p>
<p>当该 Broker 正常关闭或意外退出时，ZooKeeper 上对应的临时节点会自动消失。</p>
<p>基于这种临时节点的机制，Controller 定义了 BrokerChangeHandler 监听器，专门负责监听 /brokers/ids 下的子节点数量变化。</p>
<p>一旦发现新增或删除 Broker，/brokers/ids 下的子节点数目一定会发生变化。这会被 Controller 侦测到，进而触发 BrokerChangeHandler 的处理方法，即 handleChildChange 方法。</p>
<p>我给出 BrokerChangeHandler 的代码。可以看到，这里面定义了 handleChildChange 方法：</p>
<p>class BrokerChangeHandler(eventManager: ControllerEventManager) extends ZNodeChildChangeHandler {<br>
// Broker ZooKeeper ZNode: /brokers/ids<br>
override val path: String = BrokerIdsZNode.path<br>
override def handleChildChange(): Unit = {<br>
eventManager.put(BrokerChange) // 仅仅是向事件队列写入 BrokerChange 事件<br>
}<br>
}</p>
<p>该方法的作用就是向 Controller 事件队列写入一个 BrokerChange 事件。<strong>事实上，Controller 端定义的所有 Handler 的处理逻辑，都是向事件队列写入相应的 ControllerEvent，真正的事件处理逻辑位于 KafkaController 类的 process 方法中。</strong></p>
<p>那么，接下来，我们就来看 process 方法。你会发现，处理 BrokerChange 事件的方法实际上是 processBrokerChange，代码如下：</p>
<p>private def processBrokerChange(): Unit = {<br>
// 如果该 Broker 不是 Controller，自然无权处理，直接返回<br>
if (!isActive) return<br>
// 第 1 步：从 ZooKeeper 中获取集群 Broker 列表<br>
val curBrokerAndEpochs = zkClient.getAllBrokerAndEpochsInCluster<br>
val curBrokerIdAndEpochs = curBrokerAndEpochs map { case (broker, epoch) =&gt; (broker.id, epoch) }<br>
val curBrokerIds = curBrokerIdAndEpochs.keySet<br>
// 第 2 步：获取 Controller 当前保存的 Broker 列表<br>
val liveOrShuttingDownBrokerIds = controllerContext.liveOrShuttingDownBrokerIds<br>
// 第 3 步：比较两个列表，获取新增 Broker 列表、待移除 Broker 列表、<br>
// 已重启 Broker 列表和当前运行中的 Broker 列表<br>
val newBrokerIds = curBrokerIds.diff(liveOrShuttingDownBrokerIds)<br>
val deadBrokerIds = liveOrShuttingDownBrokerIds.diff(curBrokerIds)<br>
val bouncedBrokerIds = (curBrokerIds &amp; liveOrShuttingDownBrokerIds)<br>
.filter(brokerId =&gt; curBrokerIdAndEpochs(brokerId) &gt; controllerContext.liveBrokerIdAndEpochs(brokerId))<br>
val newBrokerAndEpochs = curBrokerAndEpochs.filter { case (broker, _) =&gt; newBrokerIds.contains(broker.id) }<br>
val bouncedBrokerAndEpochs = curBrokerAndEpochs.filter { case (broker, _) =&gt; bouncedBrokerIds.contains(broker.id) }<br>
val newBrokerIdsSorted = newBrokerIds.toSeq.sorted<br>
val deadBrokerIdsSorted = deadBrokerIds.toSeq.sorted<br>
val liveBrokerIdsSorted = curBrokerIds.toSeq.sorted<br>
val bouncedBrokerIdsSorted = bouncedBrokerIds.toSeq.sorted<br>
info(s&quot;Newly added brokers: ${newBrokerIdsSorted.mkString(&quot;,&quot;)}, &quot; +<br>
s&quot;deleted brokers: ${deadBrokerIdsSorted.mkString(&quot;,&quot;)}, &quot; +<br>
s&quot;bounced brokers: ${bouncedBrokerIdsSorted.mkString(&quot;,&quot;)}, &quot; +<br>
s&quot;all live brokers: ${liveBrokerIdsSorted.mkString(&quot;,&quot;)}&quot;)<br>
// 第 4 步：为每个新增 Broker 创建与之连接的通道管理器和<br>
// 底层的请求发送线程（RequestSendThread）<br>
newBrokerAndEpochs.keySet.foreach(<br>
controllerChannelManager.addBroker)<br>
// 第 5 步：为每个已重启的 Broker 移除它们现有的配套资源<br>
//（通道管理器、RequestSendThread 等），并重新添加它们<br>
bouncedBrokerIds.foreach(controllerChannelManager.removeBroker)<br>
bouncedBrokerAndEpochs.keySet.foreach(<br>
controllerChannelManager.addBroker)<br>
// 第 6 步：为每个待移除 Broker 移除对应的配套资源<br>
deadBrokerIds.foreach(controllerChannelManager.removeBroker)<br>
// 第 7 步：为新增 Broker 执行更新 Controller 元数据和 Broker 启动逻辑<br>
if (newBrokerIds.nonEmpty) {<br>
controllerContext.addLiveBrokers(newBrokerAndEpochs)<br>
onBrokerStartup(newBrokerIdsSorted)<br>
}<br>
// 第 8 步：为已重启 Broker 执行重添加逻辑，包含<br>
// 更新 ControllerContext、执行 Broker 重启动逻辑<br>
if (bouncedBrokerIds.nonEmpty) {<br>
controllerContext.removeLiveBrokers(bouncedBrokerIds)<br>
onBrokerFailure(bouncedBrokerIdsSorted)<br>
controllerContext.addLiveBrokers(bouncedBrokerAndEpochs)<br>
onBrokerStartup(bouncedBrokerIdsSorted)<br>
}<br>
// 第 9 步：为待移除 Broker 执行移除 ControllerContext 和 Broker 终止逻辑<br>
if (deadBrokerIds.nonEmpty) {<br>
controllerContext.removeLiveBrokers(deadBrokerIds)<br>
onBrokerFailure(deadBrokerIdsSorted)<br>
}<br>
if (newBrokerIds.nonEmpty || deadBrokerIds.nonEmpty ||<br>
bouncedBrokerIds.nonEmpty) {<br>
info(s&quot;Updated broker epochs cache: ${controllerContext.liveBrokerIdAndEpochs}&quot;)<br>
}<br>
}</p>
<p>代码有点长，你可以看下我添加的重点注释。同时，我再画一张图，帮你梳理下这个方法做的事情。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/15535b91dbf1ff6b4888b838cecae0ea.png" alt=""></p>
<p>整个方法共有 9 步。</p>
<p>第 1~3 步：</p>
<p>前两步分别是从 ZooKeeper 和 ControllerContext 中获取 Broker 列表；第 3 步是获取 4 个 Broker 列表：新增 Broker 列表、待移除 Broker 列表、已重启的 Broker 列表和当前运行中的 Broker 列表。</p>
<p>假设前两步中的 Broker 列表分别用 A 和 B 表示，由于 Kafka 以 ZooKeeper 上的数据为权威数据，因此，A 就是最新的运行中 Broker 列表，“A-B”就表示新增的 Broker，“B-A”就表示待移除的 Broker。</p>
<p>已重启的 Broker 的判断逻辑要复杂一些，它判断的是 A∧B 集合中的那些 Epoch 值变更了的 Broker。你大体上可以把 Epoch 值理解为 Broker 的版本或重启的次数。显然，Epoch 值变更了，就说明 Broker 发生了重启行为。</p>
<p>第 4~9 步：</p>
<p>拿到这些集合之后，Controller 会分别为这 4 个 Broker 列表执行相应的操作，也就是这个方法中第 4~9 步要做的事情。总体上，这些相应的操作分为 3 类。</p>
<ol>
<li>执行元数据更新操作：调用 ControllerContext 类的各个方法，更新不同的集群元数据信息。比如需要将新增 Broker 加入到集群元数据，将待移除 Broker 从元数据中移除等。</li>
<li>执行 Broker 终止操作：为待移除 Broker 和已重启 Broker 调用 onBrokerFailure 方法。</li>
<li>执行 Broker 启动操作：为已重启 Broker 和新增 Broker 调用 onBrokerStartup 方法。</li>
</ol>
<p>下面我们深入了解下 onBrokerFailure 和 onBrokerStartup 方法的逻辑。相比于其他方法，这两个方法的代码逻辑有些复杂，要做的事情也很多，因此，我们重点研究下它们。</p>
<p>首先是处理 Broker 终止逻辑的 onBrokerFailure 方法，代码如下：</p>
<p>private def onBrokerFailure(deadBrokers: Seq[Int]): Unit = {<br>
info(s&quot;Broker failure callback for ${deadBrokers.mkString(&quot;,&quot;)}&quot;)<br>
// 第 1 步：为每个待移除 Broker，删除元数据对象中的相关项<br>
deadBrokers.foreach(controllerContext.replicasOnOfflineDirs.remove<br>
// 第 2 步：将待移除 Broker 从元数据对象中处于已关闭状态的 Broker 列表中去除            <br>
val deadBrokersThatWereShuttingDown =<br>
deadBrokers.filter(id =&gt; controllerContext.shuttingDownBrokerIds.remove(id))<br>
if (deadBrokersThatWereShuttingDown.nonEmpty)<br>
info(s&quot;Removed ${deadBrokersThatWereShuttingDown.mkString(&quot;,&quot;)} from list of shutting down brokers.&quot;)<br>
// 第 3 步：找出待移除 Broker 上的所有副本对象，执行相应操作，<br>
// 将其置为“不可用状态”（即 Offline） <br>
val allReplicasOnDeadBrokers = controllerContext.replicasOnBrokers(deadBrokers.toSet)<br>
onReplicasBecomeOffline(allReplicasOnDeadBrokers)<br>
// 第 4 步：注销注册的 BrokerModificationsHandler 监听器<br>
unregisterBrokerModificationsHandler(deadBrokers)<br>
}</p>
<p>Broker 终止，意味着我们必须要删除 Controller 元数据缓存中与之相关的所有项，还要处理这些 Broker 上保存的副本。最后，我们还要注销之前为该 Broker 注册的 BrokerModificationsHandler 监听器。</p>
<p>其实，主体逻辑在于如何处理 Broker 上的副本对象，即 onReplicasBecomeOffline 方法。该方法大量调用了 Kafka 副本管理器和分区管理器的相关功能，后面我们会专门学习这两个管理器，因此这里我就不展开讲了。</p>
<p>现在，我们看 onBrokerStartup 方法。它是处理 Broker 启动的方法，也就是 Controller 端应对集群新增 Broker 启动的方法。同样，我先给出带注释的完整方法代码：</p>
<p>private def onBrokerStartup(newBrokers: Seq[Int]): Unit = {<br>
info(s&quot;New broker startup callback for ${newBrokers.mkString(&quot;,&quot;)}&quot;)<br>
// 第 1 步：移除元数据中新增 Broker 对应的副本集合<br>
newBrokers.foreach(controllerContext.replicasOnOfflineDirs.remove)<br>
val newBrokersSet = newBrokers.toSet<br>
val existingBrokers = controllerContext.<br>
liveOrShuttingDownBrokerIds.diff(newBrokersSet)<br>
// 第 2 步：给集群现有 Broker 发送元数据更新请求，令它们感知到新增 Broker 的到来<br>
sendUpdateMetadataRequest(existingBrokers.toSeq, Set.empty)<br>
// 第 3 步：给新增 Broker 发送元数据更新请求，令它们同步集群当前的所有分区数据<br>
sendUpdateMetadataRequest(newBrokers, controllerContext.partitionLeadershipInfo.keySet)<br>
val allReplicasOnNewBrokers = controllerContext.replicasOnBrokers(newBrokersSet)<br>
// 第 4 步：将新增 Broker 上的所有副本设置为 Online 状态，即可用状态<br>
replicaStateMachine.handleStateChanges(<br>
allReplicasOnNewBrokers.toSeq, OnlineReplica)<br>
partitionStateMachine.triggerOnlinePartitionStateChange()<br>
// 第 5 步：重启之前暂停的副本迁移操作<br>
maybeResumeReassignments { (<em>, assignment) =&gt;<br>
assignment.targetReplicas.exists(newBrokersSet.contains)<br>
}<br>
val replicasForTopicsToBeDeleted = allReplicasOnNewBrokers.filter(p =&gt; topicDeletionManager.isTopicQueuedUpForDeletion(p.topic))<br>
// 第 6 步：重启之前暂停的主题删除操作<br>
if (replicasForTopicsToBeDeleted.nonEmpty) {<br>
info(s&quot;Some replicas ${replicasForTopicsToBeDeleted.mkString(&quot;,&quot;)} for topics scheduled for deletion &quot; +<br>
s&quot;${controllerContext.topicsToBeDeleted.mkString(&quot;,&quot;)} are on the newly restarted brokers &quot; +<br>
s&quot;${newBrokers.mkString(&quot;,&quot;)}. Signaling restart of topic deletion for these topics&quot;)<br>
topicDeletionManager.resumeDeletionForTopics(<br>
replicasForTopicsToBeDeleted.map(</em>.topic))<br>
}<br>
// 第 7 步：为新增 Broker 注册 BrokerModificationsHandler 监听器<br>
registerBrokerModificationsHandler(newBrokers)<br>
}</p>
<p>如代码所示，第 1 步是移除新增 Broker 在元数据缓存中的信息。你可能会问：“这些 Broker 不都是新增的吗？元数据缓存中有它们的数据吗？”实际上，这里的 newBrokers 仅仅表示新启动的 Broker，它们不一定是全新的 Broker。因此，这里的删除元数据缓存是非常安全的做法。</p>
<p>第 2、3 步：分别给集群的已有 Broker 和新增 Broker 发送更新元数据请求。这样一来，整个集群上的 Broker 就可以互相感知到彼此，而且最终所有的 Broker 都能保存相同的分区数据。</p>
<p>第 4 步：将新增 Broker 上的副本状态置为 Online 状态。Online 状态表示这些副本正常提供服务，即 Leader 副本对外提供读写服务，Follower 副本自动向 Leader 副本同步消息。</p>
<p>第 5、6 步：分别重启可能因为新增 Broker 启动、而能够重新被执行的副本迁移和主题删除操作。</p>
<p>第 7 步：为所有新增 Broker 注册 BrokerModificationsHandler 监听器，允许 Controller 监控它们在 ZooKeeper 上的节点的数据变更。</p>
<h3 id="成员信息管理">成员信息管理</h3>
<p>了解了 Controller 管理集群成员数量的机制之后，接下来，我们要重点学习下 Controller 如何监听 Broker 端信息的变更，以及具体的操作。</p>
<p>和管理集群成员类似，Controller 也是通过 ZooKeeper 监听器的方式来应对 Broker 的变化。这个监听器就是 BrokerModificationsHandler。一旦 Broker 的信息发生变更，该监听器的 handleDataChange 方法就会被调用，向事件队列写入 BrokerModifications 事件。</p>
<p>KafkaController 类的 processBrokerModification 方法负责处理这类事件，代码如下：</p>
<p>private def processBrokerModification(brokerId: Int): Unit = {<br>
if (!isActive) return<br>
// 第 1 步：获取目标 Broker 的详细数据，<br>
// 包括每套监听器配置的主机名、端口号以及所使用的安全协议等<br>
val newMetadataOpt = zkClient.getBroker(brokerId)<br>
// 第 2 步：从元数据缓存中获得目标 Broker 的详细数据<br>
val oldMetadataOpt = controllerContext.liveOrShuttingDownBroker(brokerId)<br>
if (newMetadataOpt.nonEmpty &amp;&amp; oldMetadataOpt.nonEmpty) {<br>
val oldMetadata = oldMetadataOpt.get<br>
val newMetadata = newMetadataOpt.get<br>
// 第 3 步：如果两者不相等，说明 Broker 数据发生了变更<br>
// 那么，更新元数据缓存，以及执行 onBrokerUpdate 方法处理 Broker 更新的逻辑<br>
if (newMetadata.endPoints != oldMetadata.endPoints) {<br>
info(s&quot;Updated broker metadata: $oldMetadata -&gt; $newMetadata&quot;)<br>
controllerContext.updateBrokerMetadata(oldMetadata, newMetadata)<br>
onBrokerUpdate(brokerId)<br>
}<br>
}<br>
}</p>
<p>该方法首先获取 ZooKeeper 上最权威的 Broker 数据，将其与元数据缓存上的数据进行比对。如果发现两者不一致，就会更新元数据缓存，同时调用 onBrokerUpdate 方法执行更新逻辑。</p>
<p>那么，onBrokerUpdate 方法又是如何实现的呢？我们先看下代码：</p>
<p>private def onBrokerUpdate(updatedBrokerId: Int): Unit = {<br>
info(s&quot;Broker info update callback for $updatedBrokerId&quot;)<br>
// 给集群所有 Broker 发送 UpdateMetadataRequest，让她它们去更新元数据<br>
sendUpdateMetadataRequest(<br>
controllerContext.liveOrShuttingDownBrokerIds.toSeq, Set.empty)<br>
}</p>
<p>可以看到，onBrokerUpdate 就是向集群所有 Broker 发送更新元数据信息请求，把变更信息广播出去。</p>
<p>怎么样，应对 Broker 信息变更的方法还是比较简单的吧？</p>
<h2 id="主题管理">主题管理</h2>
<p>除了维护集群成员之外，Controller 还有一个重要的任务，那就是对所有主题进行管理，主要包括主题的创建、变更与删除。</p>
<p>掌握了前面集群成员管理的方法，在学习下面的内容时会轻松很多。因为它们的实现机制是一脉相承的，几乎没有任何差异。</p>
<h3 id="主题创建--变更">主题创建 / 变更</h3>
<p>我们重点学习下主题是如何被创建的。实际上，主题变更与创建是相同的逻辑，因此，源码使用了一套监听器统一处理这两种情况。</p>
<p>你一定使用过 Kafka 的 kafka-topics 脚本或 AdminClient 创建主题吧？实际上，这些工具仅仅是向 ZooKeeper 对应的目录下写入相应的数据而已，那么，Controller，或者说 Kafka 集群是如何感知到新创建的主题的呢？</p>
<p>这当然要归功于监听主题路径的 ZooKeeper 监听器：TopicChangeHandler。代码如下：</p>
<p>class TopicChangeHandler(eventManager: ControllerEventManager) extends ZNodeChildChangeHandler {<br>
// ZooKeeper 节点：/brokers/topics<br>
override val path: String = TopicsZNode.path<br>
// 向事件队列写入 TopicChange 事件<br>
override def handleChildChange(): Unit = eventManager.put(TopicChange)<br>
}</p>
<p>代码中的 TopicsZNode.path 就是 ZooKeeper 下 /brokers/topics 节点。一旦该节点下新增了主题信息，该监听器的 handleChildChange 就会被触发，Controller 通过 ControllerEventManager 对象，向事件队列写入 TopicChange 事件。</p>
<p>KafkaController 的 process 方法接到该事件后，调用 processTopicChange 方法执行主题创建。代码如下：</p>
<p>private def processTopicChange(): Unit = {<br>
if (!isActive) return<br>
// 第 1 步：从 ZooKeeper 中获取所有主题<br>
val topics = zkClient.getAllTopicsInCluster(true)<br>
// 第 2 步：与元数据缓存比对，找出新增主题列表与已删除主题列表<br>
val newTopics = topics &ndash; controllerContext.allTopics<br>
val deletedTopics = controllerContext.allTopics.diff(topics)<br>
// 第 3 步：使用 ZooKeeper 中的主题列表更新元数据缓存<br>
controllerContext.setAllTopics(topics)<br>
// 第 4 步：为新增主题注册分区变更监听器<br>
// 分区变更监听器是监听主题分区变更的<br>
registerPartitionModificationsHandlers(newTopics.toSeq)<br>
// 第 5 步：从 ZooKeeper 中获取新增主题的副本分配情况<br>
val addedPartitionReplicaAssignment = zkClient.getFullReplicaAssignmentForTopics(newTopics)<br>
// 第 6 步：清除元数据缓存中属于已删除主题的缓存项<br>
deletedTopics.foreach(controllerContext.removeTopic)<br>
// 第 7 步：为新增主题更新元数据缓存中的副本分配条目<br>
addedPartitionReplicaAssignment.foreach {<br>
case (topicAndPartition, newReplicaAssignment) =&gt; controllerContext.updatePartitionFullReplicaAssignment(topicAndPartition, newReplicaAssignment)<br>
}<br>
info(s&quot;New topics: [$newTopics], deleted topics: [$deletedTopics], new partition replica assignment &quot; +<br>
s&quot;[$addedPartitionReplicaAssignment]&quot;)<br>
// 第 8 步：调整新增主题所有分区以及所属所有副本的运行状态为“上线”状态<br>
if (addedPartitionReplicaAssignment.nonEmpty)<br>
onNewPartitionCreation(addedPartitionReplicaAssignment.keySet)<br>
}</p>
<p>虽然一共有 8 步，但大部分的逻辑都与更新元数据缓存项有关，因此，处理逻辑总体上还是比较简单的。需要注意的是，第 8 步涉及到了使用分区管理器和副本管理器来调整分区和副本状态。后面我们会详细介绍。这里你只需要知道，分区和副本处于“上线”状态，就表明它们能够正常工作，就足够了。</p>
<h3 id="主题删除">主题删除</h3>
<p>和主题创建或变更类似，删除主题也依赖 ZooKeeper 监听器完成。</p>
<p>Controller 定义了 TopicDeletionHandler，用它来实现对删除主题的监听，代码如下：</p>
<p>class TopicDeletionHandler(eventManager: ControllerEventManager) extends ZNodeChildChangeHandler {<br>
// ZooKeeper 节点：/admin/delete_topics<br>
override val path: String = DeleteTopicsZNode.path<br>
// 向事件队列写入 TopicDeletion 事件<br>
override def handleChildChange(): Unit = eventManager.put(TopicDeletion)<br>
}</p>
<p>这里的 DeleteTopicsZNode.path 指的是 /admin/delete_topics 节点。目前，无论是 kafka-topics 脚本，还是 AdminClient，删除主题都是在 /admin/delete_topics 节点下创建名为待删除主题名的子节点。</p>
<p>比如，如果我要删除 test-topic 主题，那么，Kafka 的删除命令仅仅是在 ZooKeeper 上创建 /admin/delete_topics/test-topic 节点。一旦监听到该节点被创建，TopicDeletionHandler 的 handleChildChange 方法就会被触发，Controller 会向事件队列写入 TopicDeletion 事件。</p>
<p>处理 TopicDeletion 事件的方法是 processTopicDeletion，代码如下：</p>
<p>private def processTopicDeletion(): Unit = {<br>
if (!isActive) return<br>
// 从 ZooKeeper 中获取待删除主题列表<br>
var topicsToBeDeleted = zkClient.getTopicDeletions.toSet<br>
debug(s&quot;Delete topics listener fired for topics ${topicsToBeDeleted.mkString(&quot;,&quot;)} to be deleted&quot;)<br>
// 找出不存在的主题列表<br>
val nonExistentTopics = topicsToBeDeleted &ndash; controllerContext.allTopics<br>
if (nonExistentTopics.nonEmpty) {<br>
warn(s&quot;Ignoring request to delete non-existing topics ${nonExistentTopics.mkString(&quot;,&quot;)}&quot;)<br>
zkClient.deleteTopicDeletions(nonExistentTopics.toSeq, controllerContext.epochZkVersion)<br>
}<br>
topicsToBeDeleted &ndash;= nonExistentTopics<br>
// 如果 delete.topic.enable 参数设置成 true<br>
if (config.deleteTopicEnable) {<br>
if (topicsToBeDeleted.nonEmpty) {<br>
info(s&quot;Starting topic deletion for topics ${topicsToBeDeleted.mkString(&quot;,&quot;)}&quot;)<br>
topicsToBeDeleted.foreach { topic =&gt;<br>
val partitionReassignmentInProgress = controllerContext.partitionsBeingReassigned.map(_.topic).contains(topic)<br>
if (partitionReassignmentInProgress)<br>
topicDeletionManager.markTopicIneligibleForDeletion(<br>
Set(topic), reason = &ldquo;topic reassignment in progress&rdquo;)<br>
}<br>
// 将待删除主题插入到删除等待集合交由 TopicDeletionManager 处理<br>
topicDeletionManager.enqueueTopicsForDeletion(topicsToBeDeleted)<br>
}<br>
} else { // 不允许删除主题<br>
info(s&quot;Removing $topicsToBeDeleted since delete topic is disabled&quot;)<br>
// 清除 ZooKeeper 下/admin/delete_topics 下的子节点<br>
zkClient.deleteTopicDeletions(topicsToBeDeleted.toSeq, controllerContext.epochZkVersion)<br>
}<br>
}</p>
<p>为了帮助你更直观地理解，我再画一张图来说明下：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/b0e0c032cdf904f3d4722bc598fa53a1.png" alt=""></p>
<p>首先，代码从 ZooKeeper 的 /admin/delete_topics 下获取子节点列表，即待删除主题列表。</p>
<p>之后，比对元数据缓存中的主题列表，获知压根不存在的主题列表。如果确实有不存在的主题，删除 /admin/delete_topics 下对应的子节点就行了。同时，代码会更新待删除主题列表，将这些不存在的主题剔除掉。</p>
<p>接着，代码会检查 Broker 端参数 delete.topic.enable 的值。如果该参数为 false，即不允许删除主题，代码就会清除 ZooKeeper 下的对应子节点，不会做其他操作。反之，代码会遍历待删除主题列表，将那些正在执行分区迁移的主题暂时设置成“不可删除”状态。</p>
<p>最后，把剩下可以删除的主题交由 TopicDeletionManager，由它执行真正的删除逻辑。</p>
<p>这里的 TopicDeletionManager 是 Kafka 专门负责删除主题的管理器，下节课我会详细讲解它的代码实现。</p>
<h2 id="总结">总结</h2>
<p>今天，我们学习了 Controller 的两个主要功能：管理集群 Broker 成员和主题。这两个功能是 Controller 端提供的重要服务。我建议你仔细地查看这两部分的源码，弄明白 Controller 是如何管理集群中的重要资源的。</p>
<p>针对这些内容，我总结了几个重点，希望可以帮助你更好地理解和记忆。</p>
<ol>
<li>集群成员管理：Controller 负责对集群所有成员进行有效管理，包括自动发现新增 Broker、自动处理下线 Broker，以及及时响应 Broker 数据的变更。</li>
<li>主题管理：Controller 负责对集群上的所有主题进行高效管理，包括创建主题、变更主题以及删除主题，等等。对于删除主题而言，实际的删除操作由底层的 TopicDeletionManager 完成。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/9beeeba3db75930b75cbf214b6a22c66.png" alt=""></p>
<p>接下来，我们将进入到下一个模块：状态机模块。在该模块中，我们将系统学习 Kafka 提供的三大状态机或管理器。Controller 非常依赖这些状态机对下辖的所有 Kafka 对象进行管理。在下一个模块中，我将带你深入了解分区或副本在底层的状态流转是怎么样的，你一定不要错过。</p>
<h2 id="课后讨论">课后讨论</h2>
<p>如果我们想要使用脚本命令增加一个主题的分区，你知道应该用 KafkaController 类中的哪个方法吗？</p>
<p>欢迎你在留言区畅所欲言，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/">Kafka核心源码解读</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E6%A1%88%E4%BE%8B%E8%AF%BE/15__%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88%E7%9A%84%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">15__如何建立设计方案的验证模型？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/webassembly%E5%85%A5%E9%97%A8%E8%AF%BE/15__%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA_webassembly_%E5%9C%A8%E7%BA%BF%E5%A4%9A%E5%AA%92%E4%BD%93%E5%A4%84%E7%90%86%E5%BA%94%E7%94%A8%E4%B8%80/">
            <span class="next-text nav-default">15__如何实现一个_WebAssembly_在线多媒体处理应用（一）？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

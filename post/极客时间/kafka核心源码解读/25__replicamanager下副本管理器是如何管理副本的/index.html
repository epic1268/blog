<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>25__ReplicaManager（下）：副本管理器是如何管理副本的？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是胡夕。
上节课我们学习了 ReplicaManager 类源码中副本管理器是如何执行副本读写操作的。现在我们知道了，这个副本读写操作主要是通过 appendRecords 和 fetchMessages 这两个方法实现的，而这两个方法其实在底层分别调用了 Log 的 append 和 read 方法，也就是我们在第 3 节课中学到的日志消息写入和日志消息读取方法。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/25__replicamanager%E4%B8%8B%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E5%89%AF%E6%9C%AC%E7%9A%84/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/25__replicamanager%E4%B8%8B%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E5%89%AF%E6%9C%AC%E7%9A%84/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="25__ReplicaManager（下）：副本管理器是如何管理副本的？">
  <meta property="og:description" content="你好，我是胡夕。
上节课我们学习了 ReplicaManager 类源码中副本管理器是如何执行副本读写操作的。现在我们知道了，这个副本读写操作主要是通过 appendRecords 和 fetchMessages 这两个方法实现的，而这两个方法其实在底层分别调用了 Log 的 append 和 read 方法，也就是我们在第 3 节课中学到的日志消息写入和日志消息读取方法。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Kafka核心源码解读">

  <meta itemprop="name" content="25__ReplicaManager（下）：副本管理器是如何管理副本的？">
  <meta itemprop="description" content="你好，我是胡夕。
上节课我们学习了 ReplicaManager 类源码中副本管理器是如何执行副本读写操作的。现在我们知道了，这个副本读写操作主要是通过 appendRecords 和 fetchMessages 这两个方法实现的，而这两个方法其实在底层分别调用了 Log 的 append 和 read 方法，也就是我们在第 3 节课中学到的日志消息写入和日志消息读取方法。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="8461">
  <meta itemprop="keywords" content="Kafka核心源码解读">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="25__ReplicaManager（下）：副本管理器是如何管理副本的？">
  <meta name="twitter:description" content="你好，我是胡夕。
上节课我们学习了 ReplicaManager 类源码中副本管理器是如何执行副本读写操作的。现在我们知道了，这个副本读写操作主要是通过 appendRecords 和 fetchMessages 这两个方法实现的，而这两个方法其实在底层分别调用了 Log 的 append 和 read 方法，也就是我们在第 3 节课中学到的日志消息写入和日志消息读取方法。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">25__ReplicaManager（下）：副本管理器是如何管理副本的？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 8461 字 </span>
          <span class="more-meta"> 预计阅读 17 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#分区及副本管理">分区及副本管理</a>
          <ul>
            <li><a href="#becomeleaderorfollower-方法">becomeLeaderOrFollower 方法</a></li>
            <li><a href="#makeleaders-方法">makeLeaders 方法</a></li>
            <li><a href="#makefollowers-方法">makeFollowers 方法</a></li>
          </ul>
        </li>
        <li><a href="#isr-管理">ISR 管理</a>
          <ul>
            <li><a href="#maybeshrinkisr-方法">maybeShrinkIsr 方法</a></li>
            <li><a href="#maybepropagateisrchanges-方法">maybePropagateIsrChanges 方法</a></li>
          </ul>
        </li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后讨论">课后讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是胡夕。</p>
<p>上节课我们学习了 ReplicaManager 类源码中副本管理器是如何执行副本读写操作的。现在我们知道了，这个副本读写操作主要是通过 appendRecords 和 fetchMessages 这两个方法实现的，而这两个方法其实在底层分别调用了 Log 的 append 和 read 方法，也就是我们在第 3 节课中学到的日志消息写入和日志消息读取方法。</p>
<p>今天，我们继续学习 ReplicaManager 类源码，看看副本管理器是如何管理副本的。这里的副本，涵盖了广义副本对象的方方面面，包括副本和分区对象、副本位移值和 ISR 管理等。因此，本节课我们结合着源码，具体学习下这几个方面。</p>
<h2 id="分区及副本管理">分区及副本管理</h2>
<p>除了对副本进行读写之外，副本管理器还有一个重要的功能，就是管理副本和对应的分区。ReplicaManager 管理它们的方式，是通过字段 allPartitions 来实现的。</p>
<p>所以，我想先带你复习下第 23 节课中的 allPartitions 的代码。不过，这次为了强调它作为容器的属性，我们要把注意力放在它是对象池这个特点上，即 allPartitions 把所有分区对象汇集在一起，统一放入到一个对象池进行管理。</p>
<p>private val allPartitions = new Pool<a href="./valueFactory_=_Some(tp_=__HostedPartition.Online(Partition(tp,_time,_this.md)))">TopicPartition, HostedPartition</a></p>
<p>从代码可以看到，每个 ReplicaManager 实例都维护了所在 Broker 上保存的所有分区对象，而每个分区对象 Partition 下面又定义了一组副本对象 Replica。通过这样的层级关系，副本管理器实现了对于分区的直接管理和对副本对象的间接管理。应该这样说，<strong>ReplicaManager 通过直接操作分区对象来间接管理下属的副本对象</strong>。</p>
<p>对于一个 Broker 而言，它管理下辖的分区和副本对象的主要方式，就是要确定在它保存的这些副本中，哪些是 Leader 副本、哪些是 Follower 副本。</p>
<p>这些划分可不是一成不变的，而是随着时间的推移不断变化的。比如说，这个时刻 Broker 是分区 A 的 Leader 副本、分区 B 的 Follower 副本，但在接下来的某个时刻，Broker 很可能变成分区 A 的 Follower 副本、分区 B 的 Leader 副本。</p>
<p>而这些变更是通过 Controller 给 Broker 发送 LeaderAndIsrRequest 请求来实现的。当 Broker 端收到这类请求后，会调用副本管理器的 becomeLeaderOrFollower 方法来处理，并依次执行“成为 Leader 副本”和“成为 Follower 副本”的逻辑，令当前 Broker 互换分区 A、B 副本的角色。</p>
<h3 id="becomeleaderorfollower-方法">becomeLeaderOrFollower 方法</h3>
<p>这里我们又提到了 LeaderAndIsrRequest 请求。其实，我们在学习 Controller 和控制类请求的时候就多次提到过它，在第 12 讲中也详细学习过它的作用了。因为隔的时间比较长了，我怕你忘记了，所以这里我们再回顾下。</p>
<p>简单来说，它就是告诉接收该请求的 Broker：在我传给你的这些分区中，哪些分区的 Leader 副本在你这里；哪些分区的 Follower 副本在你这里。</p>
<p>becomeLeaderOrFollower 方法，就是具体处理 LeaderAndIsrRequest 请求的地方，同时也是副本管理器添加分区的地方。下面我们就完整地学习下这个方法的源码。由于这部分代码很长，我将会分为 3 个部分向你介绍，分别是处理 Controller Epoch 事宜、执行成为 Leader 和 Follower 的逻辑以及构造 Response。</p>
<p>我们先看 becomeLeaderOrFollower 方法的第 1 大部分，<strong>处理 Controller Epoch 及其他相关准备工作</strong>的流程图：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/2fbe82eee3e0dc13a8419413bebd7c7e.png" alt=""></p>
<p>因为 becomeLeaderOrFollower 方法的开头是一段仅用于调试的日志输出，不是很重要，因此，我直接从 if 语句开始讲起。第一部分的主体代码如下：</p>
<p>// 如果 LeaderAndIsrRequest 携带的 Controller Epoch<br>
// 小于当前 Controller 的 Epoch 值<br>
if (leaderAndIsrRequest.controllerEpoch &lt; controllerEpoch) {<br>
stateChangeLogger.warn(s&quot;Ignoring LeaderAndIsr request from controller $controllerId with &quot; +<br>
s&quot;correlation id $correlationId since its controller epoch ${leaderAndIsrRequest.controllerEpoch} is old. &quot; +<br>
s&quot;Latest known controller epoch is $controllerEpoch&quot;)<br>
// 说明 Controller 已经易主，抛出相应异常<br>
leaderAndIsrRequest.getErrorResponse(0, Errors.STALE_CONTROLLER_EPOCH.exception)<br>
} else {<br>
val responseMap = new mutable.HashMap[TopicPartition, Errors]<br>
// 更新当前 Controller Epoch 值<br>
controllerEpoch = leaderAndIsrRequest.controllerEpoch<br>
val partitionStates = new mutable.HashMap<a href="">Partition, LeaderAndIsrPartitionState</a><br>
// 遍历 LeaderAndIsrRequest 请求中的所有分区<br>
requestPartitionStates.foreach { partitionState =&gt;<br>
val topicPartition = new TopicPartition(partitionState.topicName, partitionState.partitionIndex)<br>
// 从 allPartitions 中获取对应分区对象<br>
val partitionOpt = getPartition(topicPartition) match {<br>
// 如果是 Offline 状态<br>
case HostedPartition.Offline =&gt;<br>
stateChangeLogger.warn(s&quot;Ignoring LeaderAndIsr request from &quot; +<br>
s&quot;controller $controllerId with correlation id $correlationId &quot; +<br>
s&quot;epoch $controllerEpoch for partition $topicPartition as the local replica for the &quot; +<br>
&ldquo;partition is in an offline log directory&rdquo;)<br>
// 添加对象异常到 Response，并设置分区对象变量 partitionOpt=None<br>
responseMap.put(topicPartition, Errors.KAFKA_STORAGE_ERROR)<br>
None<br>
// 如果是 Online 状态，直接赋值 partitionOpt 即可<br>
case HostedPartition.Online(partition) =&gt;<br>
Some(partition)<br>
// 如果是 None 状态，则表示没有找到分区对象<br>
// 那么创建新的分区对象将，新创建的分区对象加入到 allPartitions 统一管理<br>
// 然后赋值 partitionOpt 字段<br>
case HostedPartition.None =&gt;<br>
val partition = Partition(topicPartition, time, this)<br>
allPartitions.putIfNotExists(topicPartition, HostedPartition.Online(partition))<br>
Some(partition)<br>
}<br>
// 检查分区的 Leader Epoch 值<br>
&hellip;&hellip;<br>
}</p>
<p>现在，我们一起来学习下这部分内容的核心逻辑。</p>
<p>首先，比较 LeaderAndIsrRequest 携带的 Controller Epoch 值和当前 Controller Epoch 值。如果发现前者小于后者，说明 Controller 已经变更到别的 Broker 上了，需要构造一个 STALE_CONTROLLER_EPOCH 异常并封装进 Response 返回。否则，代码进入 else 分支。</p>
<p>然后，becomeLeaderOrFollower 方法会更新当前缓存的 Controller Epoch 值，再提取出 LeaderAndIsrRequest 请求中涉及到的分区，之后依次遍历这些分区，并执行下面的两步逻辑。</p>
<p>第 1 步，从 allPartitions 中取出对应的分区对象。在第 23 节课，我们学习了分区有 3 种状态，即在线（Online）、离线（Offline）和不存在（None），这里代码就需要分别应对这 3 种情况：</p>
<ol>
<li>如果是 Online 状态的分区，直接将其赋值给 partitionOpt 字段即可；</li>
<li>如果是 Offline 状态的分区，说明该分区副本所在的 Kafka 日志路径出现 I/O 故障时（比如磁盘满了），需要构造对应的 KAFKA_STORAGE_ERROR 异常并封装进 Response，同时令 partitionOpt 字段为 None；</li>
<li>如果是 None 状态的分区，则创建新分区对象，然后将其加入到 allPartitions 中，进行统一管理，并赋值给 partitionOpt 字段。</li>
</ol>
<p>第 2 步，检查 partitionOpt 字段表示的分区的 Leader Epoch。检查的原则是要确保请求中携带的 Leader Epoch 值要大于当前缓存的 Leader Epoch，否则就说明是过期 Controller 发送的请求，就直接忽略它，不做处理。</p>
<p>总之呢，becomeLeaderOrFollower 方法的第一部分代码，主要做的事情就是创建新分区、更新 Controller Epoch 和校验分区 Leader Epoch。我们在第 3 讲说到过 Leader Epoch 机制，因为是比较高阶的用法，你可以不用重点掌握，这不会影响到我们学习副本管理。不过，如果你想深入了解的话，推荐你课下自行阅读下 LeaderEpochFileCache.scala 的源码。</p>
<p>当为所有分区都执行完这两个步骤之后，<strong>becomeLeaderOrFollower 方法进入到第 2 部分，开始执行 Broker 成为 Leader 副本和 Follower 副本的逻辑</strong>：</p>
<p>// 确定 Broker 上副本是哪些分区的 Leader 副本<br>
val partitionsToBeLeader = partitionStates.filter { case (_, partitionState) =&gt;<br>
partitionState.leader == localBrokerId<br>
}<br>
// 确定 Broker 上副本是哪些分区的 Follower 副本<br>
val partitionsToBeFollower = partitionStates.filter { case (k, _) =&gt; !partitionsToBeLeader.contains(k) }</p>
<p>val highWatermarkCheckpoints = new LazyOffsetCheckpoints(this.highWatermarkCheckpoints)<br>
val partitionsBecomeLeader = if (partitionsToBeLeader.nonEmpty)<br>
// 调用 makeLeaders 方法为 partitionsToBeLeader 所有分区<br>
// 执行&quot;成为 Leader 副本&quot;的逻辑<br>
makeLeaders(controllerId, controllerEpoch, partitionsToBeLeader, correlationId, responseMap,<br>
highWatermarkCheckpoints)<br>
else<br>
Set.empty[Partition]<br>
val partitionsBecomeFollower = if (partitionsToBeFollower.nonEmpty)<br>
// 调用 makeFollowers 方法为令 partitionsToBeFollower 所有分区<br>
// 执行&quot;成为 Follower 副本&quot;的逻辑<br>
makeFollowers(controllerId, controllerEpoch, partitionsToBeFollower, correlationId, responseMap,<br>
highWatermarkCheckpoints)<br>
else<br>
Set.empty[Partition]<br>
val leaderTopicSet = leaderPartitionsIterator.map(<em>.topic).toSet<br>
val followerTopicSet = partitionsBecomeFollower.map(</em>.topic).toSet<br>
// 对于当前 Broker 成为 Follower 副本的主题<br>
// 移除它们之前的 Leader 副本监控指标<br>
followerTopicSet.diff(leaderTopicSet).foreach(brokerTopicStats.removeOldLeaderMetrics)<br>
// 对于当前 Broker 成为 Leader 副本的主题<br>
// 移除它们之前的 Follower 副本监控指<br>
leaderTopicSet.diff(followerTopicSet).foreach(brokerTopicStats.removeOldFollowerMetrics)<br>
// 如果有分区的本地日志为空，说明底层的日志路径不可用<br>
// 标记该分区为 Offline 状态<br>
leaderAndIsrRequest.partitionStates.forEach { partitionState =&gt;<br>
val topicPartition = new TopicPartition(partitionState.topicName, partitionState.partitionIndex)<br>
if (localLog(topicPartition).isEmpty)<br>
markPartitionOffline(topicPartition)<br>
}</p>
<p><strong>首先</strong>，这部分代码需要先确定两个分区集合，一个是把该 Broker 当成 Leader 的所有分区；一个是把该 Broker 当成 Follower 的所有分区。判断的依据，主要是看 LeaderAndIsrRequest 请求中分区的 Leader 信息，是不是和本 Broker 的 ID 相同。如果相同，则表明该 Broker 是这个分区的 Leader；否则，表示当前 Broker 是这个分区的 Follower。</p>
<p>一旦确定了这两个分区集合，<strong>接着</strong>，代码就会分别为它们调用 makeLeaders 和 makeFollowers 方法，正式让 Leader 和 Follower 角色生效。之后，对于那些当前 Broker 成为 Follower 副本的主题，代码需要移除它们之前的 Leader 副本监控指标，以防出现系统资源泄露的问题。同样地，对于那些当前 Broker 成为 Leader 副本的主题，代码要移除它们之前的 Follower 副本监控指标。</p>
<p><strong>最后</strong>，如果有分区的本地日志为空，说明底层的日志路径不可用，那么标记该分区为 Offline 状态。所谓的标记为 Offline 状态，主要是两步：第 1 步是更新 allPartitions 中分区的状态；第 2 步是移除对应分区的监控指标。</p>
<p>小结一下，becomeLeaderOrFollower 方法第 2 大部分的主要功能是，调用 makeLeaders 和 makeFollowers 方法，令 Broker 在不同分区上的 Leader 或 Follower 角色生效。关于这两个方法的实现细节，一会儿我再详细说。</p>
<p>现在，让我们看看<strong>第 3 大部分的代码，构造 Response 对象</strong>。这部分代码是 becomeLeaderOrFollower 方法的收尾操作。</p>
<p>// 启动高水位检查点专属线程<br>
// 定期将 Broker 上所有非 Offline 分区的高水位值写入到检查点文件<br>
startHighWatermarkCheckPointThread()<br>
// 添加日志路径数据迁移线程<br>
maybeAddLogDirFetchers(partitionStates.keySet, highWatermarkCheckpoints)<br>
// 关闭空闲副本拉取线程<br>
replicaFetcherManager.shutdownIdleFetcherThreads()<br>
// 关闭空闲日志路径数据迁移线程<br>
replicaAlterLogDirsManager.shutdownIdleFetcherThreads()<br>
// 执行 Leader 变更之后的回调逻辑<br>
onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)<br>
// 构造 LeaderAndIsrRequest 请求的 Response 并返回<br>
val responsePartitions = responseMap.iterator.map { case (tp, error) =&gt;<br>
new LeaderAndIsrPartitionError()<br>
.setTopicName(tp.topic)<br>
.setPartitionIndex(tp.partition)<br>
.setErrorCode(error.code)<br>
}.toBuffer<br>
new LeaderAndIsrResponse(new LeaderAndIsrResponseData()<br>
.setErrorCode(Errors.NONE.code)<br>
.setPartitionErrors(responsePartitions.asJava))</p>
<p>我们来分析下这部分代码的执行逻辑吧。</p>
<p>首先，这部分开始时会启动一个专属线程来执行高水位值持久化，定期地将 Broker 上所有非 Offline 分区的高水位值写入检查点文件。这个线程是个后台线程，默认每 5 秒执行一次。</p>
<p>同时，代码还会添加日志路径数据迁移线程。这个线程的主要作用是，将路径 A 上面的数据搬移到路径 B 上。这个功能是 Kafka 支持 JBOD（Just a Bunch of Disks）的重要前提。</p>
<p>之后，becomeLeaderOrFollower 方法会关闭空闲副本拉取线程和空闲日志路径数据迁移线程。判断空闲与否的主要条件是，分区 Leader/Follower 角色调整之后，是否存在不再使用的拉取线程了。代码要确保及时关闭那些不再被使用的线程对象。</p>
<p>再之后是执行 LeaderAndIsrRequest 请求的回调处理逻辑。这里的回调逻辑，实际上只是对 Kafka 两个内部主题（__consumer_offsets 和 __transaction_state）有用，其他主题一概不适用。所以通常情况下，你可以无视这里的回调逻辑。</p>
<p>等这些都做完之后，代码开始执行这部分最后，也是最重要的任务：构造 LeaderAndIsrRequest 请求的 Response，然后将新创建的 Response 返回。至此，这部分方法的逻辑结束。</p>
<p>纵观 becomeLeaderOrFollower 方法的这 3 大部分，becomeLeaderOrFollower 方法最重要的职责，在我看来就是调用 makeLeaders 和 makeFollowers 方法，为各自的分区列表执行相应的角色确认工作。</p>
<p>接下来，我们就分别看看这两个方法是如何实现这种角色确认的。</p>
<h3 id="makeleaders-方法">makeLeaders 方法</h3>
<p>makeLeaders 方法的作用是，让当前 Broker 成为给定一组分区的 Leader，也就是让当前 Broker 下该分区的副本成为 Leader 副本。这个方法主要有 3 步：</p>
<ol>
<li>停掉这些分区对应的获取线程；</li>
<li>更新 Broker 缓存中的分区元数据信息；</li>
<li>将指定分区添加到 Leader 分区集合。</li>
</ol>
<p>我们结合代码分析下这些都是如何实现的。首先，我们看下 makeLeaders 的方法签名：</p>
<p>// controllerId：Controller 所在 Broker 的 ID<br>
// controllEpoch：Controller Epoch 值，可以认为是 Controller 版本号<br>
// partitionStates：LeaderAndIsrRequest 请求中携带的分区信息<br>
// correlationId：请求的 Correlation 字段，只用于日志调试<br>
// responseMap：按照主题分区分组的异常错误集合<br>
// highWatermarkCheckpoints：操作磁盘上高水位检查点文件的工具类<br>
private def makeLeaders(controllerId: Int,<br>
controllerEpoch: Int,<br>
partitionStates: Map[Partition, LeaderAndIsrPartitionState],<br>
correlationId: Int,<br>
responseMap: mutable.Map[TopicPartition, Errors],<br>
highWatermarkCheckpoints: OffsetCheckpoints): Set[Partition] = {<br>
&hellip;&hellip;<br>
}</p>
<p>可以看出，makeLeaders 方法接收 6 个参数，并返回一个分区对象集合。这个集合就是当前 Broker 是 Leader 的所有分区。在这 6 个参数中，以下 3 个参数比较关键，我们看下它们的含义。</p>
<ol>
<li>controllerId：Controller 所在 Broker 的 ID。该字段只是用于日志输出，无其他实际用途。</li>
<li>controllerEpoch：Controller Epoch 值，可以认为是 Controller 版本号。该字段用于日志输出使用，无其他实际用途。</li>
<li>partitionStates：LeaderAndIsrRequest 请求中携带的分区信息，包括每个分区的 Leader 是谁、ISR 都有哪些等数据。</li>
</ol>
<p>好了，现在我们继续学习 makeLeaders 的代码。我把这个方法的关键步骤放在了注释里，并省去了一些日志输出相关的代码。</p>
<p>&hellip;&hellip;<br>
// 使用 Errors.NONE 初始化 ResponseMap<br>
partitionStates.keys.foreach { partition =&gt;<br>
&hellip;&hellip;<br>
responseMap.put(partition.topicPartition, Errors.NONE)<br>
}<br>
val partitionsToMakeLeaders = mutable.Set<a href="">Partition</a><br>
try {<br>
// 停止消息拉取<br>
replicaFetcherManager.removeFetcherForPartitions(<br>
partitionStates.keySet.map(_.topicPartition))<br>
stateChangeLogger.info(s&quot;Stopped fetchers as part of LeaderAndIsr request correlationId $correlationId from &quot; +<br>
s&quot;controller $controllerId epoch $controllerEpoch as part of the become-leader transition for &quot; +<br>
s&quot;${partitionStates.size} partitions&quot;)<br>
// 更新指定分区的 Leader 分区信息<br>
partitionStates.foreach { case (partition, partitionState) =&gt;<br>
try {<br>
if (partition.makeLeader(partitionState, highWatermarkCheckpoints))<br>
partitionsToMakeLeaders += partition<br>
else<br>
&hellip;&hellip;<br>
} catch {<br>
case e: KafkaStorageException =&gt;<br>
&hellip;&hellip;<br>
// 把 KAFKA_SOTRAGE_ERRROR 异常封装到 Response 中<br>
responseMap.put(partition.topicPartition, Errors.KAFKA_STORAGE_ERROR)<br>
}<br>
}<br>
} catch {<br>
case e: Throwable =&gt;<br>
&hellip;&hellip;<br>
}<br>
&hellip;&hellip;<br>
partitionsToMakeLeaders</p>
<p>我把主要的执行流程，梳理为了一张流程图：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/08b2b970441ad12e1bb040f8f1f5bd76.png" alt=""></p>
<p>结合着图，我再带着你学习下这个方法的执行逻辑。</p>
<p>首先，将给定的一组分区的状态全部初始化成 Errors.None。</p>
<p>然后，停止为这些分区服务的所有拉取线程。毕竟该 Broker 现在是这些分区的 Leader 副本了，不再是 Follower 副本了，所以没有必要再使用拉取线程了。</p>
<p>最后，makeLeaders 方法调用 Partition 的 makeLeader 方法，去更新给定一组分区的 Leader 分区信息，而这些是由 Partition 类中的 makeLeader 方法完成的。该方法保存分区的 Leader 和 ISR 信息，同时创建必要的日志对象、重设远端 Follower 副本的 LEO 值。</p>
<p>那远端 Follower 副本，是什么意思呢？远端 Follower 副本，是指保存在 Leader 副本本地内存中的一组 Follower 副本集合，在代码中用字段 remoteReplicas 来表征。</p>
<p>ReplicaManager 在处理 FETCH 请求时，会更新 remoteReplicas 中副本对象的 LEO 值。同时，Leader 副本会将自己更新后的 LEO 值与 remoteReplicas 中副本的 LEO 值进行比较，来决定是否“抬高”高水位值。</p>
<p>而 Partition 类中的 makeLeader 方法的一个重要步骤，就是要重设这组远端 Follower 副本对象的 LEO 值。</p>
<p>makeLeaders 方法执行完 Partition.makeLeader 后，如果当前 Broker 成功地成为了该分区的 Leader 副本，就返回 True，表示新 Leader 配置成功，否则，就表示处理失败。倘若成功设置了 Leader，那么，就把该分区加入到已成功设置 Leader 的分区列表中，并返回该列表。</p>
<p>至此，方法结束。我再来小结下，makeLeaders 的作用是令当前 Broker 成为给定分区的 Leader 副本。接下来，我们再看看与 makeLeaders 方法功能相反的 makeFollowers 方法。</p>
<h3 id="makefollowers-方法">makeFollowers 方法</h3>
<p>makeFollowers 方法的作用是，将当前 Broker 配置成指定分区的 Follower 副本。我们还是先看下方法签名：</p>
<p>// controllerId：Controller 所在 Broker 的 Id<br>
// controllerEpoch：Controller Epoch 值<br>
// partitionStates：当前 Broker 是 Follower 副本的所有分区的详细信息<br>
// correlationId：连接请求与响应的关联字段<br>
// responseMap：封装 LeaderAndIsrRequest 请求处理结果的字段<br>
// highWatermarkCheckpoints：操作高水位检查点文件的工具类<br>
private def makeFollowers(<br>
controllerId: Int,<br>
controllerEpoch: Int,<br>
partitionStates: Map[Partition, LeaderAndIsrPartitionState],<br>
correlationId: Int,<br>
responseMap: mutable.Map[TopicPartition, Errors],<br>
highWatermarkCheckpoints: OffsetCheckpoints) : Set[Partition] = {<br>
&hellip;&hellip;<br>
}</p>
<p>你看，makeFollowers 方法的参数列表与 makeLeaders 方法，是一模一样的。这里我也就不再展开了。</p>
<p>其中比较重要的字段，就是 partitionStates 和 responseMap。基本上，你可以认为 partitionStates 是 makeFollowers 方法的输入，responseMap 是输出。</p>
<p>因为整个 makeFollowers 方法的代码很长，所以我接下来会先用一张图解释下它的核心逻辑，让你先有个全局观；然后，我再按照功能划分带你学习每一部分的代码。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/d9f77ea739ebf66e46d94affe10ae358.png" alt=""></p>
<p>总体来看，makeFollowers 方法分为两大步：</p>
<ol>
<li>第 1 步，遍历 partitionStates 中的所有分区，然后执行“成为 Follower”的操作；</li>
<li>第 2 步，执行其他动作，主要包括重建 Fetcher 线程、完成延时请求等。</li>
</ol>
<p>首先，<strong>我们学习第 1 步遍历 partitionStates 所有分区的代码</strong>：</p>
<p>// 第一部分：遍历 partitionStates 所有分区<br>
&hellip;&hellip;<br>
partitionStates.foreach { case (partition, partitionState) =&gt;<br>
&hellip;&hellip;<br>
// 将所有分区的处理结果的状态初始化为 Errors.NONE<br>
responseMap.put(partition.topicPartition, Errors.NONE)<br>
}<br>
val partitionsToMakeFollower: mutable.Set[Partition] = mutable.Set()<br>
try {<br>
// 遍历 partitionStates 所有分区<br>
partitionStates.foreach { case (partition, partitionState) =&gt;<br>
// 拿到分区的 Leader Broker ID<br>
val newLeaderBrokerId = partitionState.leader<br>
try {<br>
// 在元数据缓存中找到 Leader Broke 对象<br>
metadataCache.getAliveBrokers.find(<em>.id == newLeaderBrokerId) match {<br>
// 如果 Leader 确实存在<br>
case Some(</em>) =&gt;<br>
// 执行 makeFollower 方法，将当前 Broker 配置成该分区的 Follower 副本<br>
if (partition.makeFollower(partitionState, highWatermarkCheckpoints))<br>
// 如果配置成功，将该分区加入到结果返回集中<br>
partitionsToMakeFollower += partition<br>
else // 如果失败，打印错误日志<br>
&hellip;&hellip;<br>
// 如果 Leader 不存在<br>
case None =&gt;<br>
&hellip;&hellip;<br>
// 依然创建出分区 Follower 副本的日志对象<br>
partition.createLogIfNotExists(isNew = partitionState.isNew, isFutureReplica = false,<br>
highWatermarkCheckpoints)<br>
}<br>
} catch {<br>
case e: KafkaStorageException =&gt;<br>
&hellip;&hellip;<br>
}<br>
}</p>
<p>在这部分代码中，我们可以把它的执行逻辑划分为两大步骤。</p>
<p>第 1 步，将结果返回集合中所有分区的处理结果状态初始化为 Errors.NONE；第 2 步，遍历 partitionStates 中的所有分区，依次为每个分区执行以下逻辑：</p>
<ol>
<li>从分区的详细信息中获取分区的 Leader Broker ID；</li>
<li>拿着上一步获取的 Broker ID，去 Broker 元数据缓存中找到 Leader Broker 对象；</li>
<li>如果 Leader 对象存在，则执行 Partition 类的 makeFollower 方法将当前 Broker 配置成该分区的 Follower 副本。如果 makeFollower 方法执行成功，就说明当前 Broker 被成功配置为指定分区的 Follower 副本，那么将该分区加入到结果返回集中。</li>
<li>如果 Leader 对象不存在，依然创建出分区 Follower 副本的日志对象。</li>
</ol>
<p>说到 Partition 的 makeFollower 方法的执行逻辑，主要是包括以下 4 步：</p>
<ol>
<li>更新 Controller Epoch 值；</li>
<li>保存副本列表（Assigned Replicas，AR）和清空 ISR；</li>
<li>创建日志对象；</li>
<li>重设 Leader 副本的 Broker ID。</li>
</ol>
<p>接下来，<strong>我们看下 makeFollowers 方法的第 2 步，执行其他动作的代码</strong>：</p>
<p>// 第二部分：执行其他动作<br>
// 移除现有 Fetcher 线程<br>
replicaFetcherManager.removeFetcherForPartitions(<br>
partitionsToMakeFollower.map(<em>.topicPartition))<br>
&hellip;&hellip;<br>
// 尝试完成延迟请求<br>
partitionsToMakeFollower.foreach { partition =&gt;<br>
completeDelayedFetchOrProduceRequests(partition.topicPartition)<br>
}<br>
if (isShuttingDown.get()) {<br>
&hellip;..<br>
} else {<br>
// 为需要将当前 Broker 设置为 Follower 副本的分区<br>
// 确定 Leader Broker 和起始读取位移值 fetchOffset<br>
val partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map { partition =&gt;<br>
val leader = metadataCache.getAliveBrokers<br>
.find(</em>.id == partition.leaderReplicaIdOpt.get).get<br>
.brokerEndPoint(config.interBrokerListenerName)<br>
val fetchOffset = partition.localLogOrException.highWatermark<br>
partition.topicPartition -&gt; InitialFetchState(leader,<br>
partition.getLeaderEpoch, fetchOffset)<br>
}.toMap<br>
// 使用上一步确定的 Leader Broker 和 fetchOffset 添加新的 Fetcher 线程<br>
replicaFetcherManager.addFetcherForPartitions(<br>
partitionsToMakeFollowerWithLeaderAndOffset)<br>
}<br>
} catch {<br>
case e: Throwable =&gt;<br>
&hellip;&hellip;<br>
throw e<br>
}<br>
&hellip;&hellip;<br>
// 返回需要将当前 Broker 设置为 Follower 副本的分区列表<br>
partitionsToMakeFollower</p>
<p>你看，这部分代码的任务比较简单，逻辑也都是线性递进的，很好理解。我带你简单地梳理一下。</p>
<p>首先，移除现有 Fetcher 线程。因为 Leader 可能已经更换了，所以要读取的 Broker 以及要读取的位移值都可能随之发生变化。</p>
<p>然后，为需要将当前 Broker 设置为 Follower 副本的分区，确定 Leader Broker 和起始读取位移值 fetchOffset。这些信息都已经在 LeaderAndIsrRequest 中了。</p>
<p>接下来，使用上一步确定的 Leader Broker 和 fetchOffset 添加新的 Fetcher 线程。</p>
<p>最后，返回需要将当前 Broker 设置为 Follower 副本的分区列表。</p>
<p>至此，副本管理器管理分区和副本的主要方法实现，我们就都学完啦。可以看出，这些代码实现的大部分，都是围绕着如何处理 LeaderAndIsrRequest 请求数据展开的。比如，makeLeaders 拿到请求数据后，会为分区设置 Leader 和 ISR；makeFollowers 拿到数据后，会为分区更换 Fetcher 线程以及清空 ISR。</p>
<p>LeaderAndIsrRequest 请求是 Kafka 定义的最重要的控制类请求。搞懂它是如何被处理的，对于你弄明白 Kafka 的副本机制是大有裨益的。</p>
<h2 id="isr-管理">ISR 管理</h2>
<p>除了读写副本、管理分区和副本的功能之外，副本管理器还有一个重要的功能，那就是管理 ISR。这里的管理主要体现在两个方法：</p>
<ol>
<li>一个是 maybeShrinkIsr 方法，作用是阶段性地查看 ISR 中的副本集合是否需要收缩；</li>
<li>另一个是 maybePropagateIsrChanges 方法，作用是定期向集群 Broker 传播 ISR 的变更。</li>
</ol>
<p>首先，我们看下 ISR 的收缩操作。</p>
<h3 id="maybeshrinkisr-方法">maybeShrinkIsr 方法</h3>
<p>收缩是指，把 ISR 副本集合中那些与 Leader 差距过大的副本移除的过程。所谓的差距过大，就是 ISR 中 Follower 副本滞后 Leader 副本的时间，超过了 Broker 端参数 replica.lag.time.max.ms 值的 1.5 倍。</p>
<p>稍等，为什么是 1.5 倍呢？你可以看下面的代码：</p>
<p>def startup(): Unit = {<br>
scheduler.schedule(&ldquo;isr-expiration&rdquo;, maybeShrinkIsr _, period = config.replicaLagTimeMaxMs / 2, unit = TimeUnit.MILLISECONDS)<br>
&hellip;&hellip;<br>
}</p>
<p>我来解释下。ReplicaManager 类的 startup 方法会在被调用时创建一个异步线程，定时查看是否有 ISR 需要进行收缩。这里的定时频率是 replicaLagTimeMaxMs 值的一半，而判断 Follower 副本是否需要被移除 ISR 的条件是，滞后程度是否超过了 replicaLagTimeMaxMs 值。</p>
<p>因此理论上，滞后程度小于 1.5 倍 replicaLagTimeMaxMs 值的 Follower 副本，依然有可能在 ISR 中，不会被移除。这就是数字“1.5”的由来了。</p>
<p>接下来，我们看下 maybeShrinkIsr 方法的源码。</p>
<p>private def maybeShrinkIsr(): Unit = {<br>
trace(&ldquo;Evaluating ISR list of partitions to see which replicas can be removed from the ISR&rdquo;)<br>
allPartitions.keys.foreach { topicPartition =&gt;<br>
nonOfflinePartition(topicPartition).foreach(_.maybeShrinkIsr())<br>
}<br>
}</p>
<p>可以看出，maybeShrinkIsr 方法会遍历该副本管理器上所有分区对象，依次为这些分区中状态为 Online 的分区，执行 Partition 类的 maybeShrinkIsr 方法。这个方法的源码如下：</p>
<p>def maybeShrinkIsr(): Unit = {<br>
// 判断是否需要执行 ISR 收缩<br>
val needsIsrUpdate = inReadLock(leaderIsrUpdateLock) {<br>
needsShrinkIsr()<br>
}<br>
val leaderHWIncremented = needsIsrUpdate &amp;&amp; inWriteLock(leaderIsrUpdateLock) {<br>
leaderLogIfLocal match {<br>
// 如果是 Leader 副本<br>
case Some(leaderLog) =&gt;<br>
// 获取不同步的副本 Id 列表<br>
val outOfSyncReplicaIds = getOutOfSyncReplicas(replicaLagTimeMaxMs)<br>
// 如果存在不同步的副本 Id 列表<br>
if (outOfSyncReplicaIds.nonEmpty) {<br>
// 计算收缩之后的 ISR 列表<br>
val newInSyncReplicaIds = inSyncReplicaIds &ndash; outOfSyncReplicaIds<br>
assert(newInSyncReplicaIds.nonEmpty)<br>
info(&ldquo;Shrinking ISR from %s to %s. Leader: (highWatermark: %d, endOffset: %d). Out of sync replicas: %s.&rdquo;<br>
.format(inSyncReplicaIds.mkString(&quot;,&quot;),<br>
newInSyncReplicaIds.mkString(&quot;,&quot;),<br>
leaderLog.highWatermark,<br>
leaderLog.logEndOffset,<br>
outOfSyncReplicaIds.map { replicaId =&gt;<br>
s&quot;(brokerId: $replicaId, endOffset: ${getReplicaOrException(replicaId).logEndOffset})&quot;<br>
}.mkString(&quot; &ldquo;)<br>
)<br>
)<br>
// 更新 ZooKeeper 中分区的 ISR 数据以及 Broker 的元数据缓存中的数据<br>
shrinkIsr(newInSyncReplicaIds)<br>
// 尝试更新 Leader 副本的高水位值<br>
maybeIncrementLeaderHW(leaderLog)<br>
} else {<br>
false<br>
}<br>
// 如果不是 Leader 副本，什么都不做<br>
case None =&gt; false<br>
}<br>
}<br>
// 如果 Leader 副本的高水位值抬升了<br>
if (leaderHWIncremented)<br>
// 尝试解锁一下延迟请求<br>
tryCompleteDelayedRequests()<br>
}</p>
<p>可以看出，maybeShrinkIsr 方法的整个执行流程是：</p>
<ol>
<li><strong>第 1 步</strong>，判断是否需要执行 ISR 收缩。主要的方法是，调用 needShrinkIsr 方法来获取与 Leader 不同步的副本。如果存在这样的副本，说明需要执行 ISR 收缩。</li>
<li><strong>第 2 步</strong>，再次获取与 Leader 不同步的副本列表，并把它们从当前 ISR 中剔除出去，然后计算得出最新的 ISR 列表。</li>
<li><strong>第 3 步</strong>，调用 shrinkIsr 方法去更新 ZooKeeper 上分区的 ISR 数据以及 Broker 上元数据缓存。</li>
<li><strong>第 4 步</strong>，尝试更新 Leader 分区的高水位值。这里有必要检查一下是否可以抬升高水位值的原因在于，如果 ISR 收缩后只剩下 Leader 副本一个了，那么高水位值的更新就不再受那么多限制了。</li>
<li><strong>第 5 步</strong>，根据上一步的结果，来尝试解锁之前不满足条件的延迟操作。</li>
</ol>
<p>我把这个执行过程，梳理到了一张流程图中：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/737bc1ecbc2ce4a061f46b0033d96f9f.png" alt=""></p>
<h3 id="maybepropagateisrchanges-方法">maybePropagateIsrChanges 方法</h3>
<p>ISR 收缩之后，ReplicaManager 还需要将这个操作的结果传递给集群的其他 Broker，以同步这个操作的结果。这是由 ISR 通知事件来完成的。</p>
<p>在 ReplicaManager 类中，方法 maybePropagateIsrChanges 专门负责创建 ISR 通知事件。这也是由一个异步线程定期完成的，代码如下：</p>
<p>scheduler.schedule(&ldquo;isr-change-propagation&rdquo;, maybePropagateIsrChanges _, period = 2500L, unit = TimeUnit.MILLISECONDS)</p>
<p>接下来，我们看下 maybePropagateIsrChanges 方法的代码：</p>
<p>def maybePropagateIsrChanges(): Unit = {<br>
val now = System.currentTimeMillis()<br>
isrChangeSet synchronized {<br>
// ISR 变更传播的条件，需要同时满足：<br>
// 1. 存在尚未被传播的 ISR 变更<br>
// 2. 最近 5 秒没有任何 ISR 变更，或者自上次 ISR 变更已经有超过 1 分钟的时间<br>
if (isrChangeSet.nonEmpty &amp;&amp;<br>
(lastIsrChangeMs.get() + ReplicaManager.IsrChangePropagationBlackOut &lt; now ||<br>
lastIsrPropagationMs.get() + ReplicaManager.IsrChangePropagationInterval &lt; now)) {<br>
// 创建 ZooKeeper 相应的 Znode 节点<br>
zkClient.propagateIsrChanges(isrChangeSet)<br>
// 清空 isrChangeSet 集合<br>
isrChangeSet.clear()<br>
// 更新最近 ISR 变更时间戳<br>
lastIsrPropagationMs.set(now)<br>
}<br>
}<br>
}</p>
<p>可以看到，maybePropagateIsrChanges 方法的逻辑也比较简单。我来概括下其执行逻辑。</p>
<p>首先，确定 ISR 变更传播的条件。这里需要同时满足两点：</p>
<ol>
<li>一是，存在尚未被传播的 ISR 变更；</li>
<li>二是，最近 5 秒没有任何 ISR 变更，或者自上次 ISR 变更已经有超过 1 分钟的时间。</li>
</ol>
<p>一旦满足了这两个条件，代码会创建 ZooKeeper 相应的 Znode 节点；然后，清空 isrChangeSet 集合；最后，更新最近 ISR 变更时间戳。</p>
<h2 id="总结">总结</h2>
<p>今天，我们重点学习了 ReplicaManager 类的分区和副本管理功能，以及 ISR 管理。我们再完整地梳理下 ReplicaManager 类的核心功能和方法。</p>
<ol>
<li>分区 / 副本管理。ReplicaManager 类的核心功能是，应对 Broker 端接收的 LeaderAndIsrRequest 请求，并将请求中的分区信息抽取出来，让所在 Broker 执行相应的动作。</li>
<li>becomeLeaderOrFollower 方法。它是应对 LeaderAndIsrRequest 请求的入口方法。它会将请求中的分区划分成两组，分别调用 makeLeaders 和 makeFollowers 方法。</li>
<li>makeLeaders 方法。它的作用是让 Broker 成为指定分区 Leader 副本。</li>
<li>makeFollowers 方法。它的作用是让 Broker 成为指定分区 Follower 副本的方法。</li>
<li>ISR 管理。ReplicaManager 类提供了 ISR 收缩和定期传播 ISR 变更通知的功能。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/952a6be433a66b9cfabeb51fe9ca554b.png" alt=""></p>
<p>掌握了这些核心知识点，你差不多也就掌握了绝大部分的副本管理器功能，比如说 Broker 如何成为分区的 Leader 副本和 Follower 副本，以及 ISR 是如何被管理的。</p>
<p>你可能也发现了，有些非核心小功能我们今天并没有展开，比如 Broker 上的元数据缓存是怎么回事。下一节课，我将带你深入到这个缓存当中，去看看它到底是什么。</p>
<h2 id="课后讨论">课后讨论</h2>
<p>maybePropagateIsrChanges 源码中，有个 isrChangeSet 字段。你知道它是在哪里被更新的吗？</p>
<p>欢迎在留言区写下你的思考和答案，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/">Kafka核心源码解读</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/mysql%E5%AE%9E%E6%88%9845%E8%AE%B2/25__mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">25__MySQL是怎么保证高可用的？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%AB%98%E6%89%8B%E8%AF%BE/25__rocketmq%E4%B8%8Ekafka%E4%B8%AD%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%BA%8B%E5%8A%A1/">
            <span class="next-text nav-default">25__RocketMQ与Kafka中如何实现事务？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>09__SocketServer（下）：请求处理全流程源码分析 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是胡夕。前几节课，我们花了很多时间学习 SocketServer 核心组件的源代码，包括 Acceptor 线程、Processor 线程，也研究了 Data plane 和 Control plane 针对不同类型请求的处理方案。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/09__socketserver%E4%B8%8B%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E5%85%A8%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/09__socketserver%E4%B8%8B%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%E5%85%A8%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="09__SocketServer（下）：请求处理全流程源码分析">
  <meta property="og:description" content="你好，我是胡夕。前几节课，我们花了很多时间学习 SocketServer 核心组件的源代码，包括 Acceptor 线程、Processor 线程，也研究了 Data plane 和 Control plane 针对不同类型请求的处理方案。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Kafka核心源码解读">

  <meta itemprop="name" content="09__SocketServer（下）：请求处理全流程源码分析">
  <meta itemprop="description" content="你好，我是胡夕。前几节课，我们花了很多时间学习 SocketServer 核心组件的源代码，包括 Acceptor 线程、Processor 线程，也研究了 Data plane 和 Control plane 针对不同类型请求的处理方案。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="6629">
  <meta itemprop="keywords" content="Kafka核心源码解读">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="09__SocketServer（下）：请求处理全流程源码分析">
  <meta name="twitter:description" content="你好，我是胡夕。前几节课，我们花了很多时间学习 SocketServer 核心组件的源代码，包括 Acceptor 线程、Processor 线程，也研究了 Data plane 和 Control plane 针对不同类型请求的处理方案。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">09__SocketServer（下）：请求处理全流程源码分析</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 6629 字 </span>
          <span class="more-meta"> 预计阅读 14 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#kafkarequesthandlerpool">KafkaRequestHandlerPool</a>
          <ul>
            <li><a href="#kafkarequesthandler">KafkaRequestHandler</a></li>
            <li><a href="#kafkarequesthandlerpool-1">KafkaRequestHandlerPool</a></li>
          </ul>
        </li>
        <li><a href="#全处理流程">全处理流程</a>
          <ul>
            <li><a href="#第-1-步clients-或其他-broker-发送请求给-acceptor-线程">第 1 步：Clients 或其他 Broker 发送请求给 Acceptor 线程</a></li>
            <li><a href="#第-2--3-步processor-线程处理请求并放入请求队列">第 2 &amp; 3 步：Processor 线程处理请求，并放入请求队列</a></li>
            <li><a href="#第-4-步io-线程处理请求">第 4 步：I/O 线程处理请求</a></li>
            <li><a href="#第-5-步kafkarequesthandler-线程将-response-放入-processor-线程的-response-队列">第 5 步：KafkaRequestHandler 线程将 Response 放入 Processor 线程的 Response 队列</a></li>
            <li><a href="#第-6-步processor-线程发送-response-给-request-发送方">第 6 步：Processor 线程发送 Response 给 Request 发送方</a></li>
          </ul>
        </li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后讨论">课后讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是胡夕。前几节课，我们花了很多时间学习 SocketServer 核心组件的源代码，包括 Acceptor 线程、Processor 线程，也研究了 Data plane 和 Control plane 针对不同类型请求的处理方案。</p>
<p>今天，我带你完整地梳理一下 Kafka 请求处理的全流程。这个全流程涉及到多个源码文件，为了弄懂其中的原理，我们必须在不同的方法间“跳来跳去”。比起学习单个源码文件，将多个文件中的方法组合在一起串成完整流程要难得多，因此，你最好多花一些时间，仔细研读一下跟这套流程相关的所有方法。</p>
<p>当然了，你可能有这样的疑问：“我为什么要关心请求被处理的流程呢？阅读这部分源码的意义是什么呢？”其实，<strong>弄明白这部分原理，非常有助于我们有针对性地调优 Broker 端请求处理的性能</strong>。</p>
<p>举个例子，Broker 端有两个参数与这个流程相关，分别是 num.network.threads 和 num.io.threads。如果我们不掌握请求被处理的流程，是没有办法有的放矢地调整这些参数的。</p>
<p>要知道，Kafka 官网可没有告诉我们，什么是网络线程和 I/O 线程。如果不明白“请求是被网络线程接收并放入请求队列的”这件事，我们就很可能犯这样的错误——当请求队列快满了的时候，我们会以为是网络线程处理能力不够，进而盲目地增加 num.network.threads 值，但最终效果很可能是适得其反的。我相信，在今天的课程结束之后，你就会知道，碰到这种情况的时候，我们更应该增加的是 num.io.threads 的值。</p>
<p>num.io.threads 参数表征的就是 I/O 线程池的大小。所谓的 I/O 线程池，即 KafkaRequestHandlerPool，也称请求处理线程池。这节课我会先讲解 <strong>KafkaRequestHandlerPool 源码</strong>，再具体解析<strong>请求处理全流程的代码</strong>。</p>
<h2 id="kafkarequesthandlerpool">KafkaRequestHandlerPool</h2>
<p><strong>KafkaRequestHandlerPool 是真正处理 Kafka 请求的地方</strong>。切记，Kafka 中处理请求的类不是 SocketServer，也不是 RequestChannel，而是 KafkaRequestHandlerPool。</p>
<p>它所在的文件是 KafkaRequestHandler.scala，位于 core 包的 src/main/scala/kafka/server 下。这是一个不到 400 行的小文件，掌握起来并不难。</p>
<p>我先用一张图给你展示下这个文件里都有哪些组件：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/d745d14db86af61ec97023d1b79ec0c7.png" alt=""></p>
<ol>
<li><strong>KafkaRequestHandler</strong>：请求处理线程类。每个请求处理线程实例，负责从 SocketServer 的 RequestChannel 的请求队列中获取请求对象，并进行处理。</li>
<li><strong>KafkaRequestHandlerPool</strong>：请求处理线程池，负责创建、维护、管理和销毁下辖的请求处理线程。</li>
<li><strong>BrokerTopicMetrics</strong>：Broker 端与主题相关的监控指标的管理类。</li>
<li><strong>BrokerTopicStats（C）</strong>：定义 Broker 端与主题相关的监控指标的管理操作。</li>
<li><strong>BrokerTopicStats（O）</strong>：BrokerTopicStats 的伴生对象类，定义 Broker 端与主题相关的监控指标，比如常见的 MessagesInPerSec 和 MessagesOutPerSec 等。</li>
</ol>
<p>我们重点看前两个组件的代码。后面的三个类或对象都是与监控指标相关的，代码多为一些工具类方法或定义常量，非常容易理解。所以，我们不必在它们身上花费太多时间，要把主要精力放在 KafkaRequestHandler 及其相关管理类的学习上。</p>
<h3 id="kafkarequesthandler">KafkaRequestHandler</h3>
<p>首先，我们来看下它的定义：</p>
<p>// 关键字段说明<br>
// id: I/O 线程序号<br>
// brokerId：所在 Broker 序号，即 broker.id 值<br>
// totalHandlerThreads：I/O 线程池大小<br>
// requestChannel：请求处理通道<br>
// apis：KafkaApis 类，用于真正实现请求处理逻辑的类<br>
class KafkaRequestHandler(<br>
id: Int,<br>
brokerId: Int,<br>
val aggregateIdleMeter: Meter,<br>
val totalHandlerThreads: AtomicInteger,<br>
val requestChannel: RequestChannel,<br>
apis: KafkaApis,<br>
time: Time) extends Runnable with Logging {<br>
&hellip;&hellip;<br>
}</p>
<p>从定义可知，KafkaRequestHandler 是一个 Runnable 对象，因此，你可以把它当成是一个线程。每个 KafkaRequestHandler 实例，都有 4 个关键的属性。</p>
<ol>
<li><strong>id</strong>：请求处理线程的序号，类似于 Processor 线程的 ID 序号，仅仅用于标识这是线程池中的第几个线程。</li>
<li><strong>brokerId</strong>：Broker 序号，用于标识这是哪个 Broker 上的请求处理线程。</li>
<li><strong>requestChannel</strong>：SocketServer 中的请求通道对象。KafkaRequestHandler 对象为什么要定义这个字段呢？我们说过，它是负责处理请求的类，那请求保存在什么地方呢？实际上，请求恰恰是保存在 RequestChannel 中的请求队列中，因此，Kafka 在构造 KafkaRequestHandler 实例时，必须关联 SocketServer 组件中的 RequestChannel 实例，也就是说，要让 I/O 线程能够找到请求被保存的地方。</li>
<li><strong>apis</strong>：这是一个 KafkaApis 类。如果说 KafkaRequestHandler 是真正处理请求的，那么，KafkaApis 类就是真正执行请求处理逻辑的地方。在第 10 节课，我会具体讲解 KafkaApis 的代码。目前，你需要知道的是，它有个 handle 方法，用于执行请求处理逻辑。</li>
</ol>
<p>既然 KafkaRequestHandler 是一个线程类，那么，除去常规的 close、stop、initiateShutdown 和 awaitShutdown 方法，最重要的当属 run 方法实现了，如下所示：</p>
<p>def run(): Unit = {<br>
// 只要该线程尚未关闭，循环运行处理逻辑<br>
while (!stopped) {<br>
val startSelectTime = time.nanoseconds<br>
// 从请求队列中获取下一个待处理的请求<br>
val req = requestChannel.receiveRequest(300)<br>
val endTime = time.nanoseconds<br>
// 统计线程空闲时间<br>
val idleTime = endTime - startSelectTime<br>
// 更新线程空闲百分比指标<br>
aggregateIdleMeter.mark(idleTime / totalHandlerThreads.get)<br>
req match {<br>
// 关闭线程请求<br>
case RequestChannel.ShutdownRequest =&gt;<br>
debug(s&quot;Kafka request handler $id on broker $brokerId received shut down command&quot;)<br>
// 关闭线程<br>
shutdownComplete.countDown()<br>
return<br>
// 普通请求<br>
case request: RequestChannel.Request =&gt;<br>
try {<br>
request.requestDequeueTimeNanos = endTime<br>
trace(s&quot;Kafka request handler $id on broker $brokerId handling request $request&quot;)<br>
// 由 KafkaApis.handle 方法执行相应处理逻辑<br>
apis.handle(request)<br>
} catch {<br>
// 如果出现严重错误，立即关闭线程<br>
case e: FatalExitError =&gt;<br>
shutdownComplete.countDown()<br>
Exit.exit(e.statusCode)<br>
// 如果是普通异常，记录错误日志<br>
case e: Throwable =&gt; error(&ldquo;Exception when handling request&rdquo;, e)<br>
} finally {<br>
// 释放请求对象占用的内存缓冲区资源<br>
request.releaseBuffer()<br>
}<br>
case null =&gt; // 继续<br>
}<br>
}<br>
shutdownComplete.countDown()<br>
}</p>
<p>虽然我给一些主要的代码都标记了注释，但为了方便你更好地理解，我画一张图，借助它来展示下 KafkaRequestHandler 线程的处理逻辑：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/ff27e7def1e4c8b663a9cece2a92a180.png" alt=""></p>
<p>我来解释下 run 方法的主要运行逻辑。它的所有执行逻辑都在 while 循环之下，因此，只要标志线程关闭状态的 stopped 为 false，run 方法将一直循环执行 while 下的语句。</p>
<p>那，第 1 步是从请求队列中获取下一个待处理的请求，同时更新一些相关的统计指标。如果本次循环没取到，那么本轮循环结束，进入到下一轮。如果是 ShutdownRequest 请求，则说明该 Broker 发起了关闭操作。</p>
<p>而 Broker 关闭时会调用 KafkaRequestHandler 的 shutdown 方法，进而调用 initiateShutdown 方法，以及 RequestChannel 的 sendShutdownRequest 方法，而后者就是将 ShutdownRequest 写入到请求队列。</p>
<p>一旦从请求队列中获取到 ShutdownRequest，run 方法代码会调用 shutdownComplete 的 countDown 方法，正式完成对 KafkaRequestHandler 线程的关闭操作。你看看 KafkaRequestHandlerPool 的 shutdown 方法代码，就能明白这是怎么回事了。</p>
<p>def shutdown(): Unit = synchronized {<br>
info(&ldquo;shutting down&rdquo;)<br>
for (handler &lt;- runnables)<br>
handler.initiateShutdown() // 调用 initiateShutdown 方法发起关闭<br>
for (handler &lt;- runnables)<br>
// 调用 awaitShutdown 方法等待关闭完成<br>
// run 方法一旦调用 countDown 方法，这里将解除等待状态<br>
handler.awaitShutdown()<br>
info(&ldquo;shut down completely&rdquo;)<br>
}</p>
<p>就像代码注释中写的那样，一旦 run 方法执行了 countDown 方法，程序流解除在 awaitShutdown 方法这里的等待，从而完成整个线程的关闭操作。</p>
<p>我们继续说回 run 方法。如果从请求队列中获取的是普通请求，那么，首先更新请求移出队列的时间戳，然后交由 KafkaApis 的 handle 方法执行实际的请求处理逻辑代码。待请求处理完成，并被释放缓冲区资源后，代码进入到下一轮循环，周而复始地执行以上所说的逻辑。</p>
<h3 id="kafkarequesthandlerpool-1">KafkaRequestHandlerPool</h3>
<p>从上面的分析来看，KafkaRequestHandler 逻辑大体上还是比较简单的。下面我们来看下 KafkaRequestHandlerPool 线程池的实现。它是管理 I/O 线程池的，实现逻辑也不复杂。它的 shutdown 方法前面我讲过了，这里我们重点学习下，<strong>它是如何创建这些线程的，以及创建它们的时机</strong>。</p>
<p>首先看它的定义：</p>
<p>// 关键字段说明<br>
// brokerId：所属 Broker 的序号，即 broker.id 值<br>
// requestChannel：SocketServer 组件下的 RequestChannel 对象<br>
// api：KafkaApis 类，实际请求处理逻辑类<br>
// numThreads：I/O 线程池初始大小<br>
class KafkaRequestHandlerPool(<br>
val brokerId: Int,<br>
val requestChannel: RequestChannel,<br>
val apis: KafkaApis,<br>
time: Time,<br>
numThreads: Int,<br>
requestHandlerAvgIdleMetricName: String,<br>
logAndThreadNamePrefix : String)<br>
extends Logging with KafkaMetricsGroup {<br>
// I/O 线程池大小<br>
private val threadPoolSize: AtomicInteger = new AtomicInteger(numThreads)<br>
// I/O 线程池<br>
val runnables = new mutable.ArrayBuffer<a href="./numThreads.md">KafkaRequestHandler</a><br>
&hellip;&hellip;<br>
}</p>
<p>KafkaRequestHandlerPool 对象定义了 7 个属性，其中比较关键的有 4 个，我分别来解释下。</p>
<ol>
<li><strong>brokerId</strong>：和 KafkaRequestHandler 中的一样，保存 Broker 的序号。</li>
<li><strong>requestChannel</strong>：SocketServer 的请求处理通道，它下辖的请求队列为所有 I/O 线程所共享。requestChannel 字段也是 KafkaRequestHandler 类的一个重要属性。</li>
<li><strong>apis</strong>：KafkaApis 实例，执行实际的请求处理逻辑。它同时也是 KafkaRequestHandler 类的一个重要属性。</li>
<li><strong>numThreads</strong>：线程池中的初始线程数量。它是 Broker 端参数 num.io.threads 的值。目前，Kafka 支持动态修改 I/O 线程池的大小，因此，这里的 numThreads 是初始线程数，调整后的 I/O 线程池的实际大小可以和 numThreads 不一致。</li>
</ol>
<p>这里我再详细解释一下 numThreads 属性和实际线程池中线程数的关系。就像我刚刚说过的，I/O 线程池的大小是可以修改的。如果你查看 KafkaServer.scala 中的 startup 方法，你会看到以下这两行代码：</p>
<p>// KafkaServer.scala<br>
dataPlaneRequestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.dataPlaneRequestChannel, dataPlaneRequestProcessor, time, config.numIoThreads, s&quot;${SocketServer.DataPlaneMetricPrefix}RequestHandlerAvgIdlePercent&quot;, SocketServer.DataPlaneThreadPrefix)</p>
<p>controlPlaneRequestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.controlPlaneRequestChannelOpt.get, controlPlaneRequestProcessor, time, 1, s&quot;${SocketServer.ControlPlaneMetricPrefix}RequestHandlerAvgIdlePercent&quot;, SocketServer.ControlPlaneThreadPrefix)</p>
<p>由代码可知，Data plane 所属的 KafkaRequestHandlerPool 线程池的初始数量，就是 Broker 端的参数 nums.io.threads，即这里的 config.numIoThreads 值；而用于 Control plane 的线程池的数量，则硬编码为 1。</p>
<p>因此，你可以发现，Broker 端参数 num.io.threads 的值控制的是 Broker 启动时 KafkaRequestHandler 线程的数量。因此，<strong>当你想要在一开始就提升 Broker 端请求处理能力的时候，不妨试着增加这个参数值</strong>。</p>
<p>除了上面那 4 个属性，该类还定义了一个 threadPoolSize 变量。本质上，它就是用 AtomicInteger 包了一层 numThreads 罢了。</p>
<p>为什么要这么做呢？这是因为，目前 Kafka 支持动态调整 KafkaRequestHandlerPool 线程池的线程数量，但类定义中的 numThreads 一旦传入，就不可变更了，因此，需要单独创建一个支持更新操作的线程池数量的变量。至于为什么使用 AtomicInteger，你应该可以想到，这是为了保证多线程访问的线程安全性。毕竟，这个线程池大小的属性可能被多个线程访问到，而 AtomicInteger 本身提供的原子操作，能够有效地确保这种并发访问，同时还能提供必要的内存可见性。</p>
<p>既然是管理 I/O 线程池的类，KafkaRequestHandlerPool 中最重要的字段当属线程池字段 runnables 了。就代码而言，Kafka 选择使用 Scala 的数组对象类实现 I/O 线程池。</p>
<p><strong>createHandler 方法</strong></p>
<p>当线程池初始化时，Kafka 使用下面这段代码批量创建线程，并将它们添加到线程池中：</p>
<p>for (i &lt;- 0 until numThreads) {<br>
createHandler(i) // 创建 numThreads 个 I/O 线程<br>
}<br>
// 创建序号为指定 id 的 I/O 线程对象，并启动该线程<br>
def createHandler(id: Int): Unit = synchronized {<br>
// 创建 KafkaRequestHandler 实例并加入到 runnables 中<br>
runnables += new KafkaRequestHandler(id, brokerId, aggregateIdleMeter, threadPoolSize, requestChannel, apis, time)<br>
// 启动 KafkaRequestHandler 线程<br>
KafkaThread.daemon(logAndThreadNamePrefix + &ldquo;-kafka-request-handler-&rdquo; + id, runnables(id)).start()<br>
}</p>
<p>我来解释下这段代码。源码使用 for 循环批量调用 createHandler 方法，创建多个 I/O 线程。createHandler 方法的主体逻辑分为三步：</p>
<ol>
<li>创建 KafkaRequestHandler 实例；</li>
<li>将创建的线程实例加入到线程池数组；</li>
<li>启动该线程。</li>
</ol>
<p><strong>resizeThreadPool 方法</strong></p>
<p>下面我们说说 resizeThreadPool 方法的代码。这个方法的目的是，<strong>把 I/O 线程池的线程数重设为指定的数值</strong>。代码如下：</p>
<p>def resizeThreadPool(newSize: Int): Unit = synchronized {<br>
val currentSize = threadPoolSize.get<br>
info(s&quot;Resizing request handler thread pool size from $currentSize to $newSize&quot;)<br>
if (newSize &gt; currentSize) {<br>
for (i &lt;- currentSize until newSize) {<br>
createHandler(i)<br>
}<br>
} else if (newSize &lt; currentSize) {<br>
for (i &lt;- 1 to (currentSize - newSize)) {<br>
runnables.remove(currentSize - i).stop()<br>
}<br>
}<br>
threadPoolSize.set(newSize)<br>
}</p>
<p>该方法首先获取当前线程数量。如果目标数量比当前数量大，就利用刚才说到的 createHandler 方法将线程数补齐到目标值 newSize；否则的话，就将多余的线程从线程池中移除，并停止它们。最后，把标识线程数量的变量 threadPoolSize 的值调整为目标值 newSize。</p>
<p>至此，KafkaRequestHandlerPool 类的 3 个方法 shutdown、createHandler 和 resizeThreadPool 我们就学完了。总体而言，它就是负责管理 I/O 线程池的类。</p>
<h2 id="全处理流程">全处理流程</h2>
<p>有了上面的这些铺垫，我们就可以来学习下 Kafka 请求处理全流程的代码路径了。</p>
<p>我们再来看一下第 7 讲里的这张图。上一次，我主要是想借助它，让你对网络线程池有个整体的了解，今天，我来具体给你讲解下，这张图所展示的完整请求处理逻辑。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/cd9667eac39be97479e9de857d0bbfa0.png" alt=""></p>
<p>图中一共有 6 步。我分别解释一下，同时还会带你去找寻对应的源码。</p>
<h3 id="第-1-步clients-或其他-broker-发送请求给-acceptor-线程">第 1 步：Clients 或其他 Broker 发送请求给 Acceptor 线程</h3>
<p>我在第 7 节课讲过，Acceptor 线程实时接收来自外部的发送请求。一旦接收到了之后，就会创建对应的 Socket 通道，就像下面这段代码所示：</p>
<p>// SocketServer.scala 中 Acceptor 的 run 方法片段<br>
// 读取底层通道上准备就绪 I/O 操作的数量<br>
val ready = nioSelector.select(500)<br>
// 如果存在准备就绪的 I/O 事件<br>
if (ready &gt; 0) {<br>
// 获取对应的 SelectionKey 集合<br>
val keys = nioSelector.selectedKeys()<br>
val iter = keys.iterator()<br>
// 遍历这些 SelectionKey<br>
while (iter.hasNext &amp;&amp; isRunning) {<br>
try {<br>
val key = iter.next<br>
iter.remove()<br>
// 测试 SelectionKey 的底层通道是否能够接受新 Socket 连接<br>
if (key.isAcceptable) {<br>
// 接受此连接并分配对应的 Processor 线程<br>
accept(key).foreach { socketChannel =&gt;<br>
var processor: Processor = null<br>
do {<br>
retriesLeft -= 1<br>
processor = synchronized {<br>
currentProcessorIndex = currentProcessorIndex % processors.length<br>
processors(currentProcessorIndex)<br>
}<br>
currentProcessorIndex += 1<br>
// 将新 Socket 连接加入到 Processor 线程待处理连接队列<br>
// 等待 Processor 线程后续处理<br>
} while (!assignNewConnection(socketChannel, processor, retriesLeft == 0))<br>
}<br>
} else {<br>
&hellip;&hellip;<br>
}<br>
&hellip;&hellip;<br>
}</p>
<p>可以看到，Acceptor 线程通过调用 accept 方法，创建对应的 SocketChannel，然后将该 Channel 实例传给 assignNewConnection 方法，等待 Processor 线程将该 Socket 连接请求，放入到它维护的待处理连接队列中。后续 Processor 线程的 run 方法会不断地从该队列中取出这些 Socket 连接请求，然后创建对应的 Socket 连接。</p>
<p>assignNewConnection 方法的主要作用是，将这个新建的 SocketChannel 对象存入 Processors 线程的 newConnections 队列中。之后，Processor 线程会不断轮询这个队列中的待处理 Channel（可以参考第 7 讲的 configureNewConnections 方法），并向这些 Channel 注册基于 Java NIO 的 Selector，用于真正的请求获取和响应发送 I/O 操作。</p>
<p>严格来说，Acceptor 线程处理的这一步并非真正意义上的获取请求，仅仅是 Acceptor 线程为后续 Processor 线程获取请求铺路而已，也就是把需要用到的 Socket 通道创建出来，传给下面的 Processor 线程使用。</p>
<h3 id="第-2--3-步processor-线程处理请求并放入请求队列">第 2 &amp; 3 步：Processor 线程处理请求，并放入请求队列</h3>
<p>一旦 Processor 线程成功地向 SocketChannel 注册了 Selector，Clients 端或其他 Broker 端发送的请求就能通过该 SocketChannel 被获取到，具体的方法是 Processor 的 processCompleteReceives：</p>
<p>// SocketServer.scala<br>
private def processCompletedReceives(): Unit = {<br>
// 从 Selector 中提取已接收到的所有请求数据<br>
selector.completedReceives.asScala.foreach { receive =&gt;<br>
try {<br>
// 打开与发送方对应的 Socket Channel，如果不存在可用的 Channel，抛出异常<br>
openOrClosingChannel(receive.source) match {<br>
case Some(channel) =&gt;<br>
&hellip;&hellip;<br>
val header = RequestHeader.parse(receive.payload)<br>
if (header.apiKey == ApiKeys.SASL_HANDSHAKE &amp;&amp; channel.maybeBeginServerReauthentication(receive, nowNanosSupplier))<br>
……<br>
else {<br>
val nowNanos = time.nanoseconds()<br>
if (channel.serverAuthenticationSessionExpired(nowNanos)) {<br>
……<br>
} else {<br>
val connectionId = receive.source<br>
val context = new RequestContext(header, connectionId, channel.socketAddress,<br>
channel.principal, listenerName, securityProtocol,<br>
channel.channelMetadataRegistry.clientInformation)<br>
// 根据 Channel 中获取的 Receive 对象，构建 Request 对象<br>
val req = new RequestChannel.Request(processor = id, context = context,<br>
startTimeNanos = nowNanos, memoryPool, receive.payload, requestChannel.metrics)</p>
<pre><code>            ……  
            // 将该请求放入请求队列  
            requestChannel.sendRequest(req)  
            ......  
          }  
        }  
      ……  
    }  
  } catch {  
    ……  
  }  
}  
</code></pre>
<p>}</p>
<p>因为代码很多，我进行了精简，只保留了最关键的逻辑。该方法会将 Selector 获取到的所有 Receive 对象转换成对应的 Request 对象，然后将这些 Request 实例放置到请求队列中，就像上图中第 2、3 步展示的那样。</p>
<p>所谓的 Processor 线程处理请求，就是指它从底层 I/O 获取到发送数据，将其转换成 Request 对象实例，并最终添加到请求队列的过程。</p>
<h3 id="第-4-步io-线程处理请求">第 4 步：I/O 线程处理请求</h3>
<p>所谓的 I/O 线程，就是我们开头提到的 KafkaRequestHandler 线程，它的处理逻辑就在 KafkaRequestHandler 类的 run 方法中：</p>
<p>// KafkaRequestHandler.scala<br>
def run(): Unit = {<br>
while (!stopped) {<br>
&hellip;&hellip;<br>
// 从请求队列中获取 Request 实例<br>
val req = requestChannel.receiveRequest(300)<br>
&hellip;&hellip;<br>
req match {<br>
case RequestChannel.ShutdownRequest =&gt;<br>
&hellip;&hellip;<br>
case request: RequestChannel.Request =&gt;<br>
try {<br>
&hellip;&hellip;<br>
apis.handle(request)<br>
} {<br>
&hellip;&hellip;<br>
}<br>
case null =&gt; // 什么也不做<br>
}<br>
}<br>
&hellip;&hellip;<br>
}</p>
<p>KafkaRequestHandler 线程循环地从请求队列中获取 Request 实例，然后交由 KafkaApis 的 handle 方法，执行真正的请求处理逻辑。</p>
<h3 id="第-5-步kafkarequesthandler-线程将-response-放入-processor-线程的-response-队列">第 5 步：KafkaRequestHandler 线程将 Response 放入 Processor 线程的 Response 队列</h3>
<p>这一步的工作由 KafkaApis 类完成。当然，这依然是由 KafkaRequestHandler 线程来完成的。KafkaApis.scala 中有个 sendResponse 方法，将 Request 的处理结果 Response 发送出去。本质上，它就是调用了 RequestChannel 的 sendResponse 方法，代码如下：</p>
<p>def sendResponse(response: RequestChannel.Response): Unit = {<br>
&hellip;&hellip;<br>
// 找到这个 Request 当初是由哪个 Processor 线程处理的<br>
val processor = processors.get(response.processor)<br>
if (processor != null) {<br>
// 将 Response 添加到该 Processor 线程的 Response 队列上<br>
processor.enqueueResponse(response)<br>
}<br>
}</p>
<h3 id="第-6-步processor-线程发送-response-给-request-发送方">第 6 步：Processor 线程发送 Response 给 Request 发送方</h3>
<p>最后一步是，Processor 线程取出 Response 队列中的 Response，返还给 Request 发送方。具体代码位于 Processor 线程的 processNewResponses 方法中：</p>
<p>// SocketServer.scala<br>
private def processNewResponses(): Unit = {<br>
var currentResponse: RequestChannel.Response = null<br>
while ({currentResponse = dequeueResponse(); currentResponse != null}) { // 循环获取 Response 队列中的 Response<br>
val channelId = currentResponse.request.context.connectionId<br>
try {<br>
currentResponse match {<br>
case response: NoOpResponse =&gt; // 不需要发送 Response<br>
updateRequestMetrics(response)<br>
trace(s&quot;Socket server received empty response to send, registering for read: $response&quot;)<br>
handleChannelMuteEvent(channelId, ChannelMuteEvent.RESPONSE_SENT)<br>
tryUnmuteChannel(channelId)</p>
<pre><code>      case response: SendResponse =&gt; // 需要发送 Response  
        sendResponse(response, response.responseSend)  
      ......  
    }  
  }  
  ......  
}  
</code></pre>
<p>}</p>
<p>从这段代码可知，最核心的部分是 sendResponse 方法来执行 Response 发送。该方法底层使用 Selector 实现真正的发送逻辑。至此，一个请求被完整处理的流程我就讲完了。</p>
<p>最后，我想再补充一点，还记得我之前说过，有些 Response 是需要有回调逻辑的吗？</p>
<p>实际上，在第 6 步执行完毕之后，Processor 线程通常还会尝试执行 Response 中的回调逻辑，即 Processor 类的 processCompletedSends 方法。不过，并非所有 Request 或 Response 都指定了回调逻辑。事实上，只有很少的 Response 携带了回调逻辑。比如说，FETCH 请求在发送 Response 之后，就要求更新下 Broker 端与消息格式转换操作相关的统计指标。</p>
<h2 id="总结">总结</h2>
<p>今天，我们学习了 KafkaRequestHandlerPool 线程池及其下辖的 KafkaRequestHandler 线程，该线程就是 Kafka 社区所称的 I/O 线程。另外，我结合源代码把 Kafka 的请求处理流程串讲了一遍。我们来回顾下这节课的重点。</p>
<ol>
<li>KafkaRequestHandler：I/O 线程，负责处理 Processor 线程下发的 Request 对象。</li>
<li>KafkaRequestHandlerPool：创建和管理一组 KafkaRequestHandler 线程。</li>
<li>请求处理流程：总共分为 6 步。</li>
<li>Clients 或其他 Broker 通过 Selector 机制发起创建连接请求。</li>
<li>Processor 线程接收请求，并将其转换成可处理的 Request 对象。</li>
<li>Processor 线程将 Request 对象放入 Request 队列。</li>
<li>KafkaRequestHandler 线程从 Request 队列中取出待处理请求，并进行处理。</li>
<li>KafkaRequestHandler 线程将 Response 放回到对应 Processor 线程的 Response 队列。</li>
<li>Processor 线程发送 Response 给 Request 发送方。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/2a9409073e312fe77f6bbbcb1d22b920.png" alt=""></p>
<p>其实，今天在谈到 Request 逻辑执行的时候，我卖了个关子——我提到，KafkaApis 是请求逻辑的真正处理方法。也就是说，所有类型的请求处理逻辑都封装在 KafkaApis 文件下，但我并没有深入地去讲它。下节课，我会重点和你聊聊这个 KafkaApis 类。我一直认为，该类是查看所有 Kafka 源码的首要入口类，绝对值得我们花一整节课的时间去学习。</p>
<h2 id="课后讨论">课后讨论</h2>
<p>最后，请你结合今天的内容思考一个问题：你觉得，请求处理流程的哪些部分应用了经典的“生产者 - 消费者”模式？</p>
<p>欢迎你在留言区畅所欲言，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/">Kafka核心源码解读</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98/09__raft%E7%AE%97%E6%B3%95%E4%B8%89%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%88%90%E5%91%98%E5%8F%98%E6%9B%B4%E7%9A%84%E9%97%AE%E9%A2%98/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">09__Raft算法（三）：如何解决成员变更的问题？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/webassembly%E5%85%A5%E9%97%A8%E8%AF%BE/09__webassembly_%E8%83%BD%E5%A4%9F%E4%B8%BA_web_%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6%E8%B5%8B%E8%83%BD%E5%90%97/">
            <span class="next-text nav-default">09__WebAssembly_能够为_Web_前端框架赋能吗？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

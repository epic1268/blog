<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>24__ReplicaManager（中）：副本管理器是如何读写副本的？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是胡夕。上节课，我们学习了 ReplicaManager 类的定义和重要字段，今天我们接着学习这个类中的读写副本对象部分的源码。无论是读取副本还是写入副本，都是通过底层的 Partition 对象完成的，而这些分区对象全部保存在上节课所学的 allPartitions 字段中。可以说，理解这些字段的用途，是后续我们探索副本管理器类功能的重要前提。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/24__replicamanager%E4%B8%AD%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E8%AF%BB%E5%86%99%E5%89%AF%E6%9C%AC%E7%9A%84/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/24__replicamanager%E4%B8%AD%E5%89%AF%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E8%AF%BB%E5%86%99%E5%89%AF%E6%9C%AC%E7%9A%84/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="24__ReplicaManager（中）：副本管理器是如何读写副本的？">
  <meta property="og:description" content="你好，我是胡夕。上节课，我们学习了 ReplicaManager 类的定义和重要字段，今天我们接着学习这个类中的读写副本对象部分的源码。无论是读取副本还是写入副本，都是通过底层的 Partition 对象完成的，而这些分区对象全部保存在上节课所学的 allPartitions 字段中。可以说，理解这些字段的用途，是后续我们探索副本管理器类功能的重要前提。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Kafka核心源码解读">

  <meta itemprop="name" content="24__ReplicaManager（中）：副本管理器是如何读写副本的？">
  <meta itemprop="description" content="你好，我是胡夕。上节课，我们学习了 ReplicaManager 类的定义和重要字段，今天我们接着学习这个类中的读写副本对象部分的源码。无论是读取副本还是写入副本，都是通过底层的 Partition 对象完成的，而这些分区对象全部保存在上节课所学的 allPartitions 字段中。可以说，理解这些字段的用途，是后续我们探索副本管理器类功能的重要前提。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="5829">
  <meta itemprop="keywords" content="Kafka核心源码解读">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="24__ReplicaManager（中）：副本管理器是如何读写副本的？">
  <meta name="twitter:description" content="你好，我是胡夕。上节课，我们学习了 ReplicaManager 类的定义和重要字段，今天我们接着学习这个类中的读写副本对象部分的源码。无论是读取副本还是写入副本，都是通过底层的 Partition 对象完成的，而这些分区对象全部保存在上节课所学的 allPartitions 字段中。可以说，理解这些字段的用途，是后续我们探索副本管理器类功能的重要前提。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">24__ReplicaManager（中）：副本管理器是如何读写副本的？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 5829 字 </span>
          <span class="more-meta"> 预计阅读 12 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#副本写入appendrecords">副本写入：appendRecords</a></li>
        <li><a href="#副本读取fetchmessages">副本读取：fetchMessages</a></li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后讨论">课后讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是胡夕。上节课，我们学习了 ReplicaManager 类的定义和重要字段，今天我们接着学习这个类中的读写副本对象部分的源码。无论是读取副本还是写入副本，都是通过底层的 Partition 对象完成的，而这些分区对象全部保存在上节课所学的 allPartitions 字段中。可以说，理解这些字段的用途，是后续我们探索副本管理器类功能的重要前提。</p>
<p>现在，我们就来学习下副本读写功能。整个 Kafka 的同步机制，本质上就是副本读取 + 副本写入，搞懂了这两个功能，你就知道了 Follower 副本是如何同步 Leader 副本数据的。</p>
<h2 id="副本写入appendrecords">副本写入：appendRecords</h2>
<p>所谓的副本写入，是指向副本底层日志写入消息。在 ReplicaManager 类中，实现副本写入的方法叫 appendRecords。</p>
<p>放眼整个 Kafka 源码世界，需要副本写入的场景有 4 个。</p>
<ol>
<li>场景一：生产者向 Leader 副本写入消息；</li>
<li>场景二：Follower 副本拉取消息后写入副本；</li>
<li>场景三：消费者组写入组信息；</li>
<li>场景四：事务管理器写入事务信息（包括事务标记、事务元数据等）。</li>
</ol>
<p>除了第二个场景是直接调用 Partition 对象的方法实现之外，其他 3 个都是调用 appendRecords 来完成的。</p>
<p>该方法将给定一组分区的消息写入到对应的 Leader 副本中，并且根据 PRODUCE 请求中 acks 设置的不同，有选择地等待其他副本写入完成。然后，调用指定的回调逻辑。</p>
<p>我们先来看下它的方法签名：</p>
<p>def appendRecords(<br>
timeout: Long,  // 请求处理超时时间<br>
requiredAcks: Short,  // 请求 acks 设置<br>
internalTopicsAllowed: Boolean,  // 是否允许写入内部主题<br>
origin: AppendOrigin,  // 写入方来源<br>
entriesPerPartition: Map[TopicPartition, MemoryRecords], // 待写入消息<br>
// 回调逻辑<br>
responseCallback: Map[TopicPartition, PartitionResponse] =&gt; Unit,<br>
delayedProduceLock: Option[Lock] = None,<br>
recordConversionStatsCallback:<br>
Map[TopicPartition, RecordConversionStats] =&gt; Unit = _ =&gt; ())<br>
: Unit = {<br>
&hellip;&hellip;<br>
}</p>
<p>输入参数有很多，而且都很重要，我一个一个地说。</p>
<ol>
<li><strong>timeout</strong>：请求处理超时时间。对于生产者来说，它就是 request.timeout.ms 参数值。</li>
<li><strong>requiredAcks</strong>：是否需要等待其他副本写入。对于生产者而言，它就是 acks 参数的值。而在其他场景中，Kafka 默认使用 -1，表示等待其他副本全部写入成功再返回。</li>
<li><strong>internalTopicsAllowed</strong>：是否允许向内部主题写入消息。对于普通的生产者而言，该字段是 False，即不允许写入内部主题。对于 Coordinator 组件，特别是消费者组 GroupCoordinator 组件来说，它的职责之一就是向内部位移主题写入消息，因此，此时，该字段值是 True。</li>
<li><strong>origin</strong>：AppendOrigin 是一个接口，表示写入方来源。当前，它定义了 3 类写入方，分别是 Replication、Coordinator 和 Client。Replication 表示写入请求是由 Follower 副本发出的，它要将从 Leader 副本获取到的消息写入到底层的消息日志中。Coordinator 表示这些写入由 Coordinator 发起，它既可以是管理消费者组的 GroupCooridnator，也可以是管理事务的 TransactionCoordinator。Client 表示本次写入由客户端发起。前面我们说过了，Follower 副本同步过程不调用 appendRecords 方法，因此，这里的 origin 值只可能是 Replication 或 Coordinator。</li>
<li><strong>entriesPerPartitio</strong>n：按分区分组的、实际要写入的消息集合。</li>
<li><strong>responseCallback</strong>：写入成功之后，要调用的回调逻辑函数。</li>
<li><strong>delayedProduceLock</strong>：专门用来保护消费者组操作线程安全的锁对象，在其他场景中用不到。</li>
<li><strong>recordConversionStatsCallback</strong>：消息格式转换操作的回调统计逻辑，主要用于统计消息格式转换操作过程中的一些数据指标，比如总共转换了多少条消息，花费了多长时间。</li>
</ol>
<p>接下来，我们就看看，appendRecords 如何利用这些输入参数向副本日志写入消息。我把它的完整代码贴出来。对于重要的步骤，我标注了注释：</p>
<p>// requiredAcks 合法取值是 -1，0，1，否则视为非法<br>
if (isValidRequiredAcks(requiredAcks)) {<br>
val sTime = time.milliseconds<br>
// 调用 appendToLocalLog 方法写入消息集合到本地日志<br>
val localProduceResults = appendToLocalLog(<br>
internalTopicsAllowed = internalTopicsAllowed,<br>
origin, entriesPerPartition, requiredAcks)<br>
debug(&ldquo;Produce to local log in %d ms&rdquo;.format(time.milliseconds - sTime))<br>
val produceStatus = localProduceResults.map { case (topicPartition, result) =&gt;<br>
topicPartition -&gt;<br>
ProducePartitionStatus(<br>
result.info.lastOffset + 1, // 设置下一条待写入消息的位移值<br>
// 构建 PartitionResponse 封装写入结果<br>
new PartitionResponse(result.error, result.info.firstOffset.getOrElse(-1), result.info.logAppendTime,<br>
result.info.logStartOffset, result.info.recordErrors.asJava, result.info.errorMessage))<br>
}<br>
// 尝试更新消息格式转换的指标数据<br>
recordConversionStatsCallback(localProduceResults.map { case (k, v) =&gt; k -&gt; v.info.recordConversionStats })<br>
// 需要等待其他副本完成写入<br>
if (delayedProduceRequestRequired(<br>
requiredAcks, entriesPerPartition, localProduceResults)) {<br>
val produceMetadata = ProduceMetadata(requiredAcks, produceStatus)<br>
// 创建 DelayedProduce 延时请求对象<br>
val delayedProduce = new DelayedProduce(timeout, produceMetadata, this, responseCallback, delayedProduceLock)<br>
val producerRequestKeys = entriesPerPartition.keys.map(TopicPartitionOperationKey(_)).toSeq<br>
// 再一次尝试完成该延时请求<br>
// 如果暂时无法完成，则将对象放入到相应的 Purgatory 中等待后续处理<br>
delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)<br>
} else { // 无需等待其他副本写入完成，可以立即发送 Response<br>
val produceResponseStatus = produceStatus.map { case (k, status) =&gt; k -&gt; status.responseStatus }<br>
// 调用回调逻辑然后返回即可<br>
responseCallback(produceResponseStatus)<br>
}<br>
} else { // 如果 requiredAcks 值不合法<br>
val responseStatus = entriesPerPartition.map { case (topicPartition, _) =&gt;<br>
topicPartition -&gt; new PartitionResponse(Errors.INVALID_REQUIRED_ACKS,<br>
LogAppendInfo.UnknownLogAppendInfo.firstOffset.getOrElse(-1), RecordBatch.NO_TIMESTAMP, LogAppendInfo.UnknownLogAppendInfo.logStartOffset)<br>
}<br>
// 构造 INVALID_REQUIRED_ACKS 异常并封装进回调函数调用中<br>
responseCallback(responseStatus)<br>
}</p>
<p>为了帮助你更好地理解，我再用一张图说明一下 appendRecords 方法的完整流程。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/6be1a26835acf4301cec04bc2494f269.png" alt=""></p>
<p>我再给你解释一下它的执行流程。</p>
<p>首先，它会判断 requiredAcks 的取值是否在合理范围内，也就是“是否是 -1、0、1 这 3 个数值中的一个”。如果不是合理取值，代码就进入到外层的 else 分支，构造名为 INVALID_REQUIRED_ACKS 的异常，并将其封装进回调函数中执行，然后返回结果。否则的话，代码进入到外层的 if 分支下。</p>
<p>进入到 if 分支后，代码调用 <strong>appendToLocalLog</strong> 方法，将要写入的消息集合保存到副本的本地日志上。然后构造 PartitionResponse 对象实例，来封装写入结果以及一些重要的元数据信息，比如本次写入有没有错误（errorMessage）、下一条待写入消息的位移值、本次写入消息集合首条消息的位移值，等等。待这些做完了之后，代码会尝试更新消息格式转换的指标数据。此时，源码需要调用 delayedProduceRequestRequired 方法，来判断本次写入是否算是成功了。</p>
<p>如果还需要等待其他副本同步完成消息写入，那么就不能立即返回，代码要创建 DelayedProduce 延时请求对象，并把该对象交由 Purgatory 来管理。DelayedProduce 是生产者端的延时发送请求，对应的 Purgatory 就是 ReplicaManager 类构造函数中的 delayedProducePurgatory。所谓的 Purgatory 管理，主要是调用 tryCompleteElseWatch 方法尝试完成延时发送请求。如果暂时无法完成，就将对象放入到相应的 Purgatory 中，等待后续处理。</p>
<p>如果无需等待其他副本同步完成消息写入，那么，appendRecords 方法会构造响应的 Response，并调用回调逻辑函数，至此，方法结束。</p>
<p>从刚刚的分析中，我们可以知道，appendRecords 实现消息写入的方法是 <strong>appendToLocalLog</strong>，用于判断是否需要等待其他副本写入的方法是 <strong>delayedProduceRequestRequired</strong>。下面我们就深入地学习下这两个方法的代码。</p>
<p>首先来看 appendToLocalLog。从它的名字来看，就是写入副本本地日志。我们来看一下该方法的主要代码片段。</p>
<p>private def appendToLocalLog(<br>
internalTopicsAllowed: Boolean,<br>
origin: AppendOrigin,<br>
entriesPerPartition: Map[TopicPartition, MemoryRecords],<br>
requiredAcks: Short): Map[TopicPartition, LogAppendResult] = {<br>
&hellip;&hellip;<br>
entriesPerPartition.map { case (topicPartition, records) =&gt;<br>
brokerTopicStats.topicStats(topicPartition.topic)<br>
.totalProduceRequestRate.mark()<br>
brokerTopicStats.allTopicsStats.totalProduceRequestRate.mark()<br>
// 如果要写入的主题是内部主题，而 internalTopicsAllowed=false，则返回错误<br>
if (Topic.isInternal(topicPartition.topic)<br>
&amp;&amp; !internalTopicsAllowed) {<br>
(topicPartition, LogAppendResult(<br>
LogAppendInfo.UnknownLogAppendInfo,<br>
Some(new InvalidTopicException(s&quot;Cannot append to internal topic ${topicPartition.topic}&quot;))))<br>
} else {<br>
try {<br>
// 获取分区对象<br>
val partition = getPartitionOrException(topicPartition, expectLeader = true)<br>
// 向该分区对象写入消息集合<br>
val info = partition.appendRecordsToLeader(records, origin, requiredAcks)<br>
&hellip;&hellip;<br>
// 返回写入结果<br>
(topicPartition, LogAppendResult(info))<br>
} catch {<br>
&hellip;&hellip;<br>
}<br>
}<br>
}<br>
}</p>
<p>我忽略了很多打日志以及错误处理的代码。你可以看到，该方法主要就是利用 Partition 的 appendRecordsToLeader 方法写入消息集合，而后者就是利用我们在第 3 节课学到的 appendAsLeader 方法写入本地日志的。总体来说，appendToLocalLog 的逻辑不复杂，你应该很容易理解。</p>
<p>下面我们看下 delayedProduceRequestRequired 方法的源码。它用于判断消息集合被写入到日志之后，是否需要等待其他副本也写入成功。我们看下它的代码：</p>
<p>private def delayedProduceRequestRequired(<br>
requiredAcks: Short,<br>
entriesPerPartition: Map[TopicPartition, MemoryRecords],<br>
localProduceResults: Map[TopicPartition, LogAppendResult]): Boolean = {<br>
requiredAcks == -1 &amp;&amp; entriesPerPartition.nonEmpty &amp;&amp;<br>
localProduceResults.values.count(_.exception.isDefined) &lt; entriesPerPartition.size<br>
}</p>
<p>该方法返回一个布尔值，True 表示需要等待其他副本完成；False 表示无需等待。上面的代码表明，如果需要等待其他副本的写入，就必须同时满足 3 个条件：</p>
<ol>
<li>requiredAcks 必须等于 -1；</li>
<li>依然有数据尚未写完；</li>
<li>至少有一个分区的消息已经成功地被写入到本地日志。</li>
</ol>
<p>其实，你可以把条件 2 和 3 联合在一起来看。如果所有分区的数据写入都不成功，就表明可能出现了很严重的错误，此时，比较明智的做法是不再等待，而是直接返回错误给发送方。相反地，如果有部分分区成功写入，而部分分区写入失败了，就表明可能是由偶发的瞬时错误导致的。此时，不妨将本次写入请求放入 Purgatory，再给它一个重试的机会。</p>
<h2 id="副本读取fetchmessages">副本读取：fetchMessages</h2>
<p>好了，说完了副本的写入，下面我们进入到副本读取的源码学习。</p>
<p>在 ReplicaManager 类中，负责读取副本数据的方法是 fetchMessages。不论是 Java 消费者 API，还是 Follower 副本，它们拉取消息的主要途径都是向 Broker 发送 FETCH 请求，Broker 端接收到该请求后，调用 fetchMessages 方法从底层的 Leader 副本取出消息。</p>
<p>和 appendRecords 方法类似，fetchMessages 方法也可能会延时处理 FETCH 请求，因为 Broker 端必须要累积足够多的数据之后，才会返回 Response 给请求发送方。</p>
<p>可以看一下下面的这张流程图，它展示了 fetchMessages 方法的主要逻辑。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/ab6a06dbaa193ff1fb9054b3d8e288e8.png" alt=""></p>
<p>我们来看下该方法的签名：</p>
<p>def fetchMessages(timeout: Long,<br>
replicaId: Int,<br>
fetchMinBytes: Int,<br>
fetchMaxBytes: Int,<br>
hardMaxBytesLimit: Boolean,<br>
fetchInfos: Seq[(TopicPartition, PartitionData)],<br>
quota: ReplicaQuota,<br>
responseCallback: Seq[(TopicPartition, FetchPartitionData)] =&gt; Unit,<br>
isolationLevel: IsolationLevel,<br>
clientMetadata: Option[ClientMetadata]): Unit = {<br>
&hellip;&hellip;<br>
}</p>
<p>这些输入参数都是我们理解下面的重要方法的基础，所以，我们来逐个分析一下。</p>
<ol>
<li><strong>timeout</strong>：请求处理超时时间。对于消费者而言，该值就是 request.timeout.ms 参数值；对于 Follower 副本而言，该值是 Broker 端参数 replica.fetch.wait.max.ms 的值。</li>
<li><strong>replicaId</strong>：副本 ID。对于消费者而言，该参数值是 -1；对于 Follower 副本而言，该值就是 Follower 副本所在的 Broker ID。</li>
<li><strong>fetchMinBytes &amp; fetchMaxBytes</strong>：能够获取的最小字节数和最大字节数。对于消费者而言，它们分别对应于 Consumer 端参数 fetch.min.bytes 和 fetch.max.bytes 值；对于 Follower 副本而言，它们分别对应于 Broker 端参数 replica.fetch.min.bytes 和 replica.fetch.max.bytes 值。</li>
<li><strong>hardMaxBytesLimit</strong>：对能否超过最大字节数做硬限制。如果 hardMaxBytesLimit=True，就表示，读取请求返回的数据字节数绝不允许超过最大字节数。</li>
<li><strong>fetchInfos</strong>：规定了读取分区的信息，比如要读取哪些分区、从这些分区的哪个位移值开始读、最多可以读多少字节，等等。</li>
<li><strong>quota</strong>：这是一个配额控制类，主要是为了判断是否需要在读取的过程中做限速控制。</li>
<li><strong>responseCallback</strong>：Response 回调逻辑函数。当请求被处理完成后，调用该方法执行收尾逻辑。</li>
</ol>
<p>有了这些铺垫之后，我们进入到方法代码的学习。为了便于学习，我将整个方法的代码分成两部分：第一部分是读取本地日志；第二部分是根据读取结果确定 Response。</p>
<p>我们先看第一部分的源码：</p>
<p>// 判断该读取请求是否来自于 Follower 副本或 Consumer<br>
val isFromFollower = Request.isValidBrokerId(replicaId)<br>
val isFromConsumer = !(isFromFollower || replicaId == Request.FutureLocalReplicaId)<br>
// 根据请求发送方判断可读取范围<br>
// 如果请求来自于普通消费者，那么可以读到 LEO 值<br>
// 如果请求来自于配置了 READ_COMMITTED 的消费者，那么可以读到 Log Stable Offset 值<br>
// 如果请求来自于 Follower 副本，那么可以读到高水位值<br>
val fetchIsolation = if (!isFromConsumer)<br>
FetchLogEnd<br>
else if (isolationLevel == IsolationLevel.READ_COMMITTED)<br>
FetchTxnCommitted<br>
else<br>
FetchHighWatermark<br>
val fetchOnlyFromLeader = isFromFollower || (isFromConsumer &amp;&amp; clientMetadata.isEmpty)<br>
// 定义 readFromLog 方法读取底层日志中的消息<br>
def readFromLog(): Seq[(TopicPartition, LogReadResult)] = {<br>
val result = readFromLocalLog(<br>
replicaId = replicaId,<br>
fetchOnlyFromLeader = fetchOnlyFromLeader,<br>
fetchIsolation = fetchIsolation,<br>
fetchMaxBytes = fetchMaxBytes,<br>
hardMaxBytesLimit = hardMaxBytesLimit,<br>
readPartitionInfo = fetchInfos,<br>
quota = quota,<br>
clientMetadata = clientMetadata)<br>
if (isFromFollower) updateFollowerFetchState(replicaId, result)<br>
else result<br>
}<br>
// 读取消息并返回日志读取结果<br>
val logReadResults = readFromLog()</p>
<p>这部分代码首先会判断，读取消息的请求方到底是 Follower 副本，还是普通的 Consumer。判断的依据就是看 <strong>replicaId 字段是否大于 0</strong>。Consumer 的 replicaId 是 -1，而 Follower 副本的则是大于 0 的数。一旦确定了请求方，代码就能确定可读取范围。</p>
<p>这里的 fetchIsolation 是读取隔离级别的意思。对于 Follower 副本而言，它能读取到 Leader 副本 LEO 值以下的所有消息；对于普通 Consumer 而言，它只能“看到”Leader 副本高水位值以下的消息。</p>
<p>待确定了可读取范围后，fetchMessages 方法会调用它的内部方法 <strong>readFromLog</strong>，读取本地日志上的消息数据，并将结果赋值给 logReadResults 变量。readFromLog 方法的主要实现是调用 readFromLocalLog 方法，而后者就是在待读取分区上依次调用其日志对象的 read 方法执行实际的消息读取。</p>
<p>fetchMessages 方法的第二部分，是根据上一步的读取结果创建对应的 Response。我们看下具体实现：</p>
<p>var bytesReadable: Long = 0<br>
var errorReadingData = false<br>
val logReadResultMap = new mutable.HashMap[TopicPartition, LogReadResult]<br>
// 统计总共可读取的字节数<br>
logReadResults.foreach { case (topicPartition, logReadResult) =&gt;<br>
brokerTopicStats.topicStats(topicPartition.topic).totalFetchRequestRate.mark()<br>
brokerTopicStats.allTopicsStats.totalFetchRequestRate.mark()<br>
if (logReadResult.error != Errors.NONE)<br>
errorReadingData = true<br>
bytesReadable = bytesReadable + logReadResult.info.records.sizeInBytes<br>
logReadResultMap.put(topicPartition, logReadResult)<br>
}<br>
// 判断是否能够立即返回 Reponse，满足以下 4 个条件中的任意一个即可：<br>
// 1. 请求没有设置超时时间，说明请求方想让请求被处理后立即返回<br>
// 2. 未获取到任何数据<br>
// 3. 已累积到足够多的数据<br>
// 4. 读取过程中出错<br>
if (timeout &lt;= 0 || fetchInfos.isEmpty || bytesReadable &gt;= fetchMinBytes || errorReadingData) {<br>
// 构建返回结果<br>
val fetchPartitionData = logReadResults.map { case (tp, result) =&gt;<br>
tp -&gt; FetchPartitionData(result.error, result.highWatermark, result.leaderLogStartOffset, result.info.records,<br>
result.lastStableOffset, result.info.abortedTransactions, result.preferredReadReplica, isFromFollower &amp;&amp; isAddingReplica(tp, replicaId))<br>
}<br>
// 调用回调函数<br>
responseCallback(fetchPartitionData)<br>
} else { // 如果无法立即完成请求<br>
val fetchPartitionStatus = new mutable.ArrayBuffer[(TopicPartition, FetchPartitionStatus)]<br>
fetchInfos.foreach { case (topicPartition, partitionData) =&gt;<br>
logReadResultMap.get(topicPartition).foreach(logReadResult =&gt; {<br>
val logOffsetMetadata = logReadResult.info.fetchOffsetMetadata<br>
fetchPartitionStatus += (topicPartition -&gt; FetchPartitionStatus(logOffsetMetadata, partitionData))<br>
})<br>
}<br>
val fetchMetadata: SFetchMetadata = SFetchMetadata(fetchMinBytes, fetchMaxBytes, hardMaxBytesLimit,<br>
fetchOnlyFromLeader, fetchIsolation, isFromFollower, replicaId, fetchPartitionStatus)<br>
// 构建 DelayedFetch 延时请求对象 <br>
val delayedFetch = new DelayedFetch(timeout, fetchMetadata, this, quota, clientMetadata,<br>
responseCallback)<br>
val delayedFetchKeys = fetchPartitionStatus.map { case (tp, _) =&gt; TopicPartitionOperationKey(tp) }<br>
// 再一次尝试完成请求，如果依然不能完成，则交由 Purgatory 等待后续处理<br>
delayedFetchPurgatory.tryCompleteElseWatch(delayedFetch, delayedFetchKeys)<br>
}</p>
<p>这部分代码首先会根据上一步得到的读取结果，统计可读取的总字节数，之后，判断此时是否能够立即返回 Reponse。那么，怎么判断是否能够立即返回 Response 呢？实际上，只要满足以下 4 个条件中的任意一个即可：</p>
<ol>
<li>请求没有设置超时时间，说明请求方想让请求被处理后立即返回；</li>
<li>未获取到任何数据；</li>
<li>已累积到足够多数据；</li>
<li>读取过程中出错。</li>
</ol>
<p>如果这 4 个条件一个都不满足，就需要进行延时处理了。具体来说，就是构建 DelayedFetch 对象，然后把该延时对象交由 delayedFetchPurgatory 后续自动处理。</p>
<p>至此，关于副本管理器读写副本的两个方法 appendRecords 和 fetchMessages，我们就学完了。本质上，它们在底层分别调用 Log 的 append 和 read 方法，以实现本地日志的读写操作。当完成读写操作之后，这两个方法还定义了延时处理的条件。一旦发现满足了延时处理的条件，就交给对应的 Purgatory 进行处理。</p>
<p>从这两个方法中，我们已经看到了之前课程中单个组件融合在一起的趋势。就像我在开篇词里面说的，虽然我们学习单个源码文件的顺序是自上而下，但串联 Kafka 主要组件功能的路径却是自下而上。</p>
<p>就拿这节课的副本写入操作来说，日志对象的 append 方法被上一层 Partition 对象中的方法调用，而后者又进一步被副本管理器中的方法调用。我们是按照自上而下的方式阅读副本管理器、日志对象等单个组件的代码，了解它们各自的独立功能的，现在，我们开始慢慢地把它们融合在一起，勾勒出了 Kafka 操作分区副本日志对象的完整调用路径。咱们同时采用这两种方式来阅读源码，就可以更快、更深入地搞懂 Kafka 源码的原理了。</p>
<h2 id="总结">总结</h2>
<p>今天，我们学习了 Kafka 副本状态机类 ReplicaManager 是如何读写副本的，重点学习了它的两个重要方法 appendRecords 和 fetchMessages。我们再简单回顾一下。</p>
<ol>
<li>appendRecords：向副本写入消息的方法，主要利用 Log 的 append 方法和 Purgatory 机制，共同实现 Follower 副本向 Leader 副本获取消息后的数据同步工作。</li>
<li>fetchMessages：从副本读取消息的方法，为普通 Consumer 和 Follower 副本所使用。当它们向 Broker 发送 FETCH 请求时，Broker 上的副本管理器调用该方法从本地日志中获取指定消息。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/d6af952938bff6048a2bc3bc62f390bf.png" alt=""></p>
<p>下节课中，我们要把重心转移到副本管理器对副本和分区对象的管理上。这是除了读写副本之外，副本管理器另一大核心功能，你一定不要错过！</p>
<h2 id="课后讨论">课后讨论</h2>
<p>appendRecords 参数列表中有个 origin。我想请你思考一下，在写入本地日志的过程中，这个参数的作用是什么？你能找出最终使用 origin 参数的具体源码位置吗？</p>
<p>欢迎在留言区写下你的思考和答案，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/">Kafka核心源码解读</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/mysql%E5%AE%9E%E6%88%9845%E8%AE%B2/24__mysql%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">24__MySQL是怎么保证主备一致的？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%90%8E%E7%AB%AF%E5%AD%98%E5%82%A8%E5%AE%9E%E6%88%98%E8%AF%BE/24__rocksdb%E4%B8%8D%E4%B8%A2%E6%95%B0%E6%8D%AE%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BDkv%E5%AD%98%E5%82%A8/">
            <span class="next-text nav-default">24__RocksDB：不丢数据的高性能KV存储</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>11__Controller元数据：Controller都保存有哪些东西？有几种状态？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是胡夕。从今天开始，我们正式进入到第三大模块的学习：控制器（Controller）模块。
提起 Kafka 中的 Controller 组件，我相信你一定不陌生。从某种意义上说，它是 Kafka 最核心的组件。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他 Broker 上。既然我们是 Kafka 源码解读课，那就绝对不能错过这么重量级的组件。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/11__controller%E5%85%83%E6%95%B0%E6%8D%AEcontroller%E9%83%BD%E4%BF%9D%E5%AD%98%E6%9C%89%E5%93%AA%E4%BA%9B%E4%B8%9C%E8%A5%BF%E6%9C%89%E5%87%A0%E7%A7%8D%E7%8A%B6%E6%80%81/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/11__controller%E5%85%83%E6%95%B0%E6%8D%AEcontroller%E9%83%BD%E4%BF%9D%E5%AD%98%E6%9C%89%E5%93%AA%E4%BA%9B%E4%B8%9C%E8%A5%BF%E6%9C%89%E5%87%A0%E7%A7%8D%E7%8A%B6%E6%80%81/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="11__Controller元数据：Controller都保存有哪些东西？有几种状态？">
  <meta property="og:description" content="你好，我是胡夕。从今天开始，我们正式进入到第三大模块的学习：控制器（Controller）模块。
提起 Kafka 中的 Controller 组件，我相信你一定不陌生。从某种意义上说，它是 Kafka 最核心的组件。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他 Broker 上。既然我们是 Kafka 源码解读课，那就绝对不能错过这么重量级的组件。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Kafka核心源码解读">

  <meta itemprop="name" content="11__Controller元数据：Controller都保存有哪些东西？有几种状态？">
  <meta itemprop="description" content="你好，我是胡夕。从今天开始，我们正式进入到第三大模块的学习：控制器（Controller）模块。
提起 Kafka 中的 Controller 组件，我相信你一定不陌生。从某种意义上说，它是 Kafka 最核心的组件。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他 Broker 上。既然我们是 Kafka 源码解读课，那就绝对不能错过这么重量级的组件。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="5511">
  <meta itemprop="keywords" content="Kafka核心源码解读">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="11__Controller元数据：Controller都保存有哪些东西？有几种状态？">
  <meta name="twitter:description" content="你好，我是胡夕。从今天开始，我们正式进入到第三大模块的学习：控制器（Controller）模块。
提起 Kafka 中的 Controller 组件，我相信你一定不陌生。从某种意义上说，它是 Kafka 最核心的组件。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他 Broker 上。既然我们是 Kafka 源码解读课，那就绝对不能错过这么重量级的组件。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">11__Controller元数据：Controller都保存有哪些东西？有几种状态？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 5511 字 </span>
          <span class="more-meta"> 预计阅读 11 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#案例分享">案例分享</a></li>
        <li><a href="#集群元数据">集群元数据</a></li>
        <li><a href="#controllercontext">ControllerContext</a>
          <ul>
            <li><a href="#controllerstats">ControllerStats</a></li>
            <li><a href="#offlinepartitioncount">offlinePartitionCount</a></li>
            <li><a href="#shuttingdownbrokerids">shuttingDownBrokerIds</a></li>
            <li><a href="#livebrokers">liveBrokers</a></li>
            <li><a href="#livebrokerepochs">liveBrokerEpochs</a></li>
            <li><a href="#epoch--epochzkversion">epoch &amp; epochZkVersion</a></li>
            <li><a href="#alltopics">allTopics</a></li>
            <li><a href="#partitionassignments">partitionAssignments</a></li>
          </ul>
        </li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后讨论">课后讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是胡夕。从今天开始，我们正式进入到第三大模块的学习：控制器（Controller）模块。</p>
<p>提起 Kafka 中的 Controller 组件，我相信你一定不陌生。从某种意义上说，它是 Kafka 最核心的组件。一方面，它要为集群中的所有主题分区选举领导者副本；另一方面，它还承载着集群的全部元数据信息，并负责将这些元数据信息同步到其他 Broker 上。既然我们是 Kafka 源码解读课，那就绝对不能错过这么重量级的组件。</p>
<p>我画了一张图片，希望借助它帮你建立起对这个模块的整体认知。今天，我们先学习下 Controller 元数据。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/f82db21c7398e43f85e15f4bf93db9eb.png" alt=""></p>
<h2 id="案例分享">案例分享</h2>
<p>在正式学习源码之前，我想向你分享一个真实的案例。</p>
<p>在我们公司的 Kafka 集群环境上，曾经出现了一个比较“诡异”的问题：某些核心业务的主题分区一直处于“不可用”状态。</p>
<p>通过使用“kafka-topics”命令查询，我们发现，这些分区的 Leader 显示是 -1。之前，这些 Leader 所在的 Broker 机器因为负载高宕机了，当 Broker 重启回来后，Controller 竟然无法成功地为这些分区选举 Leader，因此，它们一直处于“不可用”状态。</p>
<p>由于是生产环境，我们的当务之急是马上恢复受损分区，然后才能调研问题的原因。有人提出，重启这些分区旧 Leader 所在的所有 Broker 机器——这很容易想到，毕竟“重启大法”一直很好用。但是，这一次竟然没有任何作用。</p>
<p>之后，有人建议升级重启大法，即重启集群的所有 Broker——这在当时是不能接受的。且不说有很多业务依然在运行着，单是重启 Kafka 集群本身，就是一件非常缺乏计划性的事情。毕竟，生产环境怎么能随意重启呢？！</p>
<p>后来，我突然想到了 Controller 组件中重新选举 Controller 的代码。一旦 Controller 被选举出来，它就会向所有 Broker 更新集群元数据，也就是说，会“重刷”这些分区的状态。</p>
<p>那么问题来了，我们如何在避免重启集群的情况下，干掉已有 Controller 并执行新的 Controller 选举呢？答案就在源码中的 <strong>ControllerZNode.path</strong> 上，也就是 ZooKeeper 的 /controller 节点。倘若我们手动删除了 /controller 节点，Kafka 集群就会触发 Controller 选举。于是，我们马上实施了这个方案，效果出奇得好：之前的受损分区全部恢复正常，业务数据得以正常生产和消费。</p>
<p>当然，给你分享这个案例的目的，并不是让你记住可以随意干掉 /controller 节点——这个操作其实是有一点危险的。事实上，我只是想通过这个真实的例子，向你说明，很多打开“精通 Kafka 之门”的钥匙是隐藏在源码中的。那么，接下来，我们就开始找“钥匙”吧。</p>
<h2 id="集群元数据">集群元数据</h2>
<p>想要完整地了解 Controller 的工作原理，我们首先就要学习它管理了哪些数据。毕竟，Controller 的很多代码仅仅是做数据的管理操作而已。今天，我们就来重点学习 Kafka 集群元数据都有哪些。</p>
<p>如果说 ZooKeeper 是整个 Kafka 集群元数据的“真理之源（Source of Truth）”，那么 Controller 可以说是集群元数据的“真理之源副本（Backup Source of Truth）”。好吧，后面这个词是我自己发明的。你只需要理解，Controller 承载了 ZooKeeper 上的所有元数据即可。</p>
<p>事实上，集群 Broker 是不会与 ZooKeeper 直接交互去获取元数据的。相反地，它们总是与 Controller 进行通信，获取和更新最新的集群数据。而且社区已经打算把 ZooKeeper“干掉”了（我会在之后的“特别放送”里具体给你解释社区干掉 ZooKeeper 的操作），以后 Controller 将成为新的“真理之源”。</p>
<p>我们总说元数据，那么，到底什么是集群的元数据，或者说，Kafka 集群的元数据都定义了哪些内容呢？我用一张图给你完整地展示一下，当前 Kafka 定义的所有集群元数据信息。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/3fc9e0e105407836f9aa5925403bbc1a.png" alt=""></p>
<p>可以看到，目前，Controller 定义的元数据有 17 项之多。不过，并非所有的元数据都同等重要，你也不用完整地记住它们，我们只需要重点关注那些最重要的元数据，并结合源代码来了解下这些元数据都是用来做什么的。</p>
<p>在了解具体的元数据之前，我要先介绍下 ControllerContext 类。刚刚我们提到的这些元数据信息全部封装在这个类里。应该这么说，<strong>这个类是 Controller 组件的数据容器类</strong>。</p>
<h2 id="controllercontext">ControllerContext</h2>
<p>Controller 组件的源代码位于 core 包的 src/main/scala/kafka/controller 路径下，这里面有很多 Scala 源文件，<strong>ControllerContext 类就位于这个路径下的 ControllerContext.scala 文件中。</strong></p>
<p>该文件只有几百行代码，其中，最重要的数据结构就是 ControllerContext 类。前面说过，<strong>它定义了前面提到的所有元数据信息，以及许多实用的工具方法</strong>。比如，获取集群上所有主题分区对象的 allPartitions 方法、获取某主题分区副本列表的 partitionReplicaAssignment 方法，等等。</p>
<p>首先，我们来看下 ControllerContext 类的定义，如下所示：</p>
<p>class ControllerContext {<br>
val stats = new ControllerStats // Controller 统计信息类<br>
var offlinePartitionCount = 0   // 离线分区计数器<br>
val shuttingDownBrokerIds = mutable.Set.empty[Int]  // 关闭中 Broker 的 Id 列表<br>
private val liveBrokers = mutable.Set.empty[Broker] // 当前运行中 Broker 对象列表<br>
private val liveBrokerEpochs = mutable.Map.empty[Int, Long]   // 运行中 Broker Epoch 列表<br>
var epoch: Int = KafkaController.InitialControllerEpoch   // Controller 当前 Epoch 值<br>
var epochZkVersion: Int = KafkaController.InitialControllerEpochZkVersion  // Controller 对应 ZooKeeper 节点的 Epoch 值<br>
val allTopics = mutable.Set.empty[String]  // 集群主题列表<br>
val partitionAssignments = mutable.Map.empty[String, mutable.Map[Int, ReplicaAssignment]]  // 主题分区的副本列表<br>
val partitionLeadershipInfo = mutable.Map.empty[TopicPartition, LeaderIsrAndControllerEpoch]  // 主题分区的 Leader/ISR 副本信息<br>
val partitionsBeingReassigned = mutable.Set.empty[TopicPartition]  // 正处于副本重分配过程的主题分区列表<br>
val partitionStates = mutable.Map.empty[TopicPartition, PartitionState] // 主题分区状态列表<br>
val replicaStates = mutable.Map.empty[PartitionAndReplica, ReplicaState]  // 主题分区的副本状态列表<br>
val replicasOnOfflineDirs = mutable.Map.empty[Int, Set[TopicPartition]]  // 不可用磁盘路径上的副本列表<br>
val topicsToBeDeleted = mutable.Set.empty[String]  // 待删除主题列表<br>
val topicsWithDeletionStarted = mutable.Set.empty[String]  // 已开启删除的主题列表<br>
val topicsIneligibleForDeletion = mutable.Set.empty[String]  // 暂时无法执行删除的主题列表<br>
&hellip;&hellip;<br>
}</p>
<p>不多不少，这段代码中定义的字段正好 17 个，它们一一对应着上图中的那些元数据信息。下面，我选取一些重要的元数据，来详细解释下它们的含义。</p>
<p>这些元数据理解起来还是比较简单的，掌握了它们之后，你在理解 MetadataCache，也就是元数据缓存的时候，就容易得多了。比如，接下来我要讲到的 liveBrokers 信息，就是 Controller 通过 UpdateMetadataRequest 请求同步给其他 Broker 的 MetadataCache 的。</p>
<h3 id="controllerstats">ControllerStats</h3>
<p>第一个是 ControllerStats 类的变量。它的完整代码如下：</p>
<p>private[controller] class ControllerStats extends KafkaMetricsGroup {<br>
// 统计每秒发生的 Unclean Leader 选举次数<br>
val uncleanLeaderElectionRate = newMeter(&ldquo;UncleanLeaderElectionsPerSec&rdquo;, &ldquo;elections&rdquo;, TimeUnit.SECONDS)<br>
// Controller 事件通用的统计速率指标的方法<br>
val rateAndTimeMetrics: Map[ControllerState, KafkaTimer] = ControllerState.values.flatMap { state =&gt;<br>
state.rateAndTimeMetricName.map { metricName =&gt;<br>
state -&gt; new KafkaTimer(newTimer(metricName, TimeUnit.MILLISECONDS, TimeUnit.SECONDS))<br>
}<br>
}.toMap<br>
}</p>
<p>顾名思义，它表征的是 Controller 的一些统计信息。目前，源码中定义了两大类统计指标：<strong>UncleanLeaderElectionsPerSec 和所有 Controller 事件状态的执行速率与时间</strong>。</p>
<p>其中，<strong>前者是计算 Controller 每秒执行的 Unclean Leader 选举数量，通常情况下，执行 Unclean Leader 选举可能造成数据丢失，一般不建议开启它</strong>。一旦开启，你就需要时刻关注这个监控指标的值，确保 Unclean Leader 选举的速率维持在一个很低的水平，否则会出现很多数据丢失的情况。</p>
<p><strong>后者是统计所有 Controller 状态的速率和时间信息</strong>，单位是毫秒。当前，Controller 定义了很多事件，比如，TopicDeletion 是执行主题删除的 Controller 事件、ControllerChange 是执行 Controller 重选举的事件。ControllerStats 的这个指标通过在每个事件名后拼接字符串 RateAndTimeMs 的方式，为每类 Controller 事件都创建了对应的速率监控指标。</p>
<p>由于 Controller 事件有很多种，对应的速率监控指标也有很多，有一些 Controller 事件是需要你额外关注的。</p>
<p>举个例子，IsrChangeNotification 事件是标志 ISR 列表变更的事件，如果这个事件经常出现，说明副本的 ISR 列表经常发生变化，而这通常被认为是非正常情况，因此，你最好关注下这个事件的速率监控指标。</p>
<h3 id="offlinepartitioncount">offlinePartitionCount</h3>
<p><strong>该字段统计集群中所有离线或处于不可用状态的主题分区数量</strong>。所谓的不可用状态，就是我最开始举的例子中“Leader=-1”的情况。</p>
<p>ControllerContext 中的 updatePartitionStateMetrics 方法根据<strong>给定主题分区的当前状态和目标状态</strong>，来判断该分区是否是离线状态的分区。如果是，则累加 offlinePartitionCount 字段的值，否则递减该值。方法代码如下：</p>
<p>// 更新 offlinePartitionCount 元数据<br>
private def updatePartitionStateMetrics(<br>
partition: TopicPartition,<br>
currentState: PartitionState,<br>
targetState: PartitionState): Unit = {<br>
// 如果该主题当前并未处于删除中状态<br>
if (!isTopicDeletionInProgress(partition.topic)) {<br>
// targetState 表示该分区要变更到的状态<br>
// 如果当前状态不是 OfflinePartition，即离线状态并且目标状态是离线状态<br>
// 这个 if 语句判断是否要将该主题分区状态转换到离线状态<br>
if (currentState != OfflinePartition &amp;&amp; targetState == OfflinePartition) {<br>
offlinePartitionCount = offlinePartitionCount + 1<br>
// 如果当前状态已经是离线状态，但 targetState 不是<br>
// 这个 else if 语句判断是否要将该主题分区状态转换到非离线状态<br>
} else if (currentState == OfflinePartition &amp;&amp; targetState != OfflinePartition) {<br>
offlinePartitionCount = offlinePartitionCount - 1<br>
}<br>
}<br>
}</p>
<p>该方法首先要判断，此分区所属的主题当前是否处于删除操作的过程中。如果是的话，Kafka 就不能修改这个分区的状态，那么代码什么都不做，直接返回。否则，代码会判断该分区是否要转换到离线状态。如果 targetState 是 OfflinePartition，那么就将 offlinePartitionCount 值加 1，毕竟多了一个离线状态的分区。相反地，如果 currentState 是 offlinePartition，而 targetState 反而不是，那么就将 offlinePartitionCount 值减 1。</p>
<h3 id="shuttingdownbrokerids">shuttingDownBrokerIds</h3>
<p>顾名思义，<strong>该字段保存所有正在关闭中的 Broker ID 列表</strong>。当 Controller 在管理集群 Broker 时，它要依靠这个字段来甄别 Broker 当前是否已关闭，因为处于关闭状态的 Broker 是不适合执行某些操作的，如分区重分配（Reassignment）以及主题删除等。</p>
<p>另外，Kafka 必须要为这些关闭中的 Broker 执行很多清扫工作，Controller 定义了一个 onBrokerFailure 方法，它就是用来做这个的。代码如下：</p>
<p>private def onBrokerFailure(deadBrokers: Seq[Int]): Unit = {<br>
info(s&quot;Broker failure callback for ${deadBrokers.mkString(&quot;,&quot;)}&quot;)<br>
// deadBrokers：给定的一组已终止运行的 Broker Id 列表<br>
// 更新 Controller 元数据信息，将给定 Broker 从元数据的 replicasOnOfflineDirs 中移除<br>
deadBrokers.foreach(controllerContext.replicasOnOfflineDirs.remove)<br>
// 找出这些 Broker 上的所有副本对象<br>
val deadBrokersThatWereShuttingDown =<br>
deadBrokers.filter(id =&gt; controllerContext.shuttingDownBrokerIds.remove(id))<br>
if (deadBrokersThatWereShuttingDown.nonEmpty)<br>
info(s&quot;Removed ${deadBrokersThatWereShuttingDown.mkString(&quot;,&quot;)} from list of shutting down brokers.&quot;)<br>
// 执行副本清扫工作<br>
val allReplicasOnDeadBrokers = controllerContext.replicasOnBrokers(deadBrokers.toSet)<br>
onReplicasBecomeOffline(allReplicasOnDeadBrokers)<br>
// 取消这些 Broker 上注册的 ZooKeeper 监听器<br>
unregisterBrokerModificationsHandler(deadBrokers)<br>
}</p>
<p>该方法接收一组已终止运行的 Broker ID 列表，首先是更新 Controller 元数据信息，将给定 Broker 从元数据的 replicasOnOfflineDirs 和 shuttingDownBrokerIds 中移除，然后为这组 Broker 执行必要的副本清扫工作，也就是 onReplicasBecomeOffline 方法做的事情。</p>
<p>该方法主要依赖于分区状态机和副本状态机来完成对应的工作。在后面的课程中，我们会专门讨论副本状态机和分区状态机，这里你只要简单了解下它要做的事情就行了。后面等我们学完了这两个状态机之后，你可以再看下这个方法的具体实现原理。</p>
<p>这个方法的主要目的是把给定的副本标记成 Offline 状态，即不可用状态。具体分为以下这几个步骤：</p>
<ol>
<li>利用分区状态机将给定副本所在的分区标记为 Offline 状态；</li>
<li>将集群上所有新分区和 Offline 分区状态变更为 Online 状态；</li>
<li>将相应的副本对象状态变更为 Offline。</li>
</ol>
<h3 id="livebrokers">liveBrokers</h3>
<p><strong>该字段保存当前所有运行中的 Broker 对象</strong>。每个 Broker 对象就是一个 &lt;Id，EndPoint，机架信息 &gt; 的三元组。ControllerContext 中定义了很多方法来管理该字段，如 addLiveBrokersAndEpochs、removeLiveBrokers 和 updateBrokerMetadata 等。我拿 updateBrokerMetadata 方法进行说明，以下是源码：</p>
<p>def updateBrokerMetadata(oldMetadata: Broker, newMetadata: Broker): Unit = {<br>
liveBrokers -= oldMetadata<br>
liveBrokers += newMetadata<br>
}</p>
<p>每当新增或移除已有 Broker 时，ZooKeeper 就会更新其保存的 Broker 数据，从而引发 Controller 修改元数据，也就是会调用 updateBrokerMetadata 方法来增减 Broker 列表中的对象。怎么样，超简单吧？！</p>
<h3 id="livebrokerepochs">liveBrokerEpochs</h3>
<p><strong>该字段保存所有运行中 Broker 的 Epoch 信息</strong>。Kafka 使用 Epoch 数据防止 Zombie Broker，即一个非常老的 Broker 被选举成为 Controller。</p>
<p>另外，源码大多使用这个字段来获取所有运行中 Broker 的 ID 序号，如下面这个方法定义的那样：</p>
<p>def liveBrokerIds: Set[Int] = liveBrokerEpochs.keySet &ndash; shuttingDownBrokerIds</p>
<p>liveBrokerEpochs 的 keySet 方法返回 Broker 序号列表，然后从中移除关闭中的 Broker 序号，剩下的自然就是处于运行中的 Broker 序号列表了。</p>
<h3 id="epoch--epochzkversion">epoch &amp; epochZkVersion</h3>
<p>这两个字段一起说，因为它们都有“epoch”字眼，放在一起说，可以帮助你更好地理解两者的区别。epoch 实际上就是 ZooKeeper 中 /controller_epoch 节点的值，你可以认为它就是 Controller 在整个 Kafka 集群的版本号，而 epochZkVersion 实际上是 /controller_epoch 节点的 dataVersion 值。</p>
<p>Kafka 使用 epochZkVersion 来判断和防止 Zombie Controller。这也就是说，原先在老 Controller 任期内的 Controller 操作在新 Controller 不能成功执行，因为新 Controller 的 epochZkVersion 要比老 Controller 的大。</p>
<p>另外，你可能会问：“这里的两个 Epoch 和上面的 liveBrokerEpochs 有啥区别呢？”实际上，这里的两个 Epoch 值都是属于 Controller 侧的数据，而 liveBrokerEpochs 是每个 Broker 自己的 Epoch 值。</p>
<h3 id="alltopics">allTopics</h3>
<p><strong>该字段保存集群上所有的主题名称</strong>。每当有主题的增减，Controller 就要更新该字段的值。</p>
<p>比如 Controller 有个 processTopicChange 方法，从名字上来看，它就是处理主题变更的。我们来看下它的代码实现，我把主要逻辑以注释的方式标注了出来：</p>
<p>private def processTopicChange(): Unit = {<br>
if (!isActive) return // 如果 Contorller 已经关闭，直接返回<br>
val topics = zkClient.getAllTopicsInCluster(true) // 从 ZooKeeper 中获取当前所有主题列表<br>
val newTopics = topics &ndash; controllerContext.allTopics // 找出当前元数据中不存在、ZooKeeper 中存在的主题，视为新增主题<br>
val deletedTopics = controllerContext.allTopics &ndash; topics // 找出当前元数据中存在、ZooKeeper 中不存在的主题，视为已删除主题<br>
controllerContext.allTopics = topics // 更新 Controller 元数据<br>
// 为新增主题和已删除主题执行后续处理操作<br>
registerPartitionModificationsHandlers(newTopics.toSeq)<br>
val addedPartitionReplicaAssignment = zkClient.getFullReplicaAssignmentForTopics(newTopics)<br>
deletedTopics.foreach(controllerContext.removeTopic)<br>
addedPartitionReplicaAssignment.foreach {<br>
case (topicAndPartition, newReplicaAssignment) =&gt; controllerContext.updatePartitionFullReplicaAssignment(topicAndPartition, newReplicaAssignment)<br>
}<br>
info(s&quot;New topics: [$newTopics], deleted topics: [$deletedTopics], new partition replica assignment &quot; +<br>
s&quot;[$addedPartitionReplicaAssignment]&quot;)<br>
if (addedPartitionReplicaAssignment.nonEmpty)<br>
onNewPartitionCreation(addedPartitionReplicaAssignment.keySet)<br>
}</p>
<h3 id="partitionassignments">partitionAssignments</h3>
<p>该字段保存所有主题分区的副本分配情况。在我看来，这是 Controller 最重要的元数据了。事实上，你可以从这个字段衍生、定义很多实用的方法，来帮助 Kafka 从各种维度获取数据。</p>
<p>比如，如果 Kafka 要获取某个 Broker 上的所有分区，那么，它可以这样定义：</p>
<p>partitionAssignments.flatMap {<br>
case (topic, topicReplicaAssignment) =&gt; topicReplicaAssignment.filter {<br>
case (_, partitionAssignment) =&gt; partitionAssignment.replicas.contains(brokerId)<br>
}.map {<br>
case (partition, _) =&gt; new TopicPartition(topic, partition)<br>
}<br>
}.toSet</p>
<p>再比如，如果 Kafka 要获取某个主题的所有分区对象，代码可以这样写：</p>
<p>partitionAssignments.getOrElse(topic, mutable.Map.empty).map {<br>
case (partition, _) =&gt; new TopicPartition(topic, partition)<br>
}.toSet</p>
<p>实际上，这两段代码分别是 ControllerContext.scala 中 partitionsOnBroker 方法和 partitionsForTopic 两个方法的主体实现代码。</p>
<p>讲到这里，9 个重要的元数据字段我就介绍完了。前面说过，ControllerContext 中一共定义了 17 个元数据字段，你可以结合这 9 个字段，把其余 8 个的定义也过一遍，做到心中有数。<strong>你对 Controller 元数据掌握得越好，就越能清晰地理解 Controller 在集群中发挥的作用</strong>。</p>
<p>值得注意的是，在学习每个元数据字段时，除了它的定义之外，我建议你去搜索一下，与之相关的工具方法都是如何实现的。如果后面你想要新增获取或更新元数据的方法，你要对操作它们的代码有很强的把控力才行。</p>
<h2 id="总结">总结</h2>
<p>今天，我们揭开了 Kafka 重要组件 Controller 的学习大幕。我给出了 Controller 模块的学习路线，还介绍了 Controller 的重要元数据。</p>
<ol>
<li>Controller 元数据：Controller 当前定义了 17 种元数据，涵盖 Kafka 集群数据的方方面面。</li>
<li>ControllerContext：定义元数据以及操作它们的类。</li>
<li>关键元数据字段：最重要的元数据包括 offlinePartitionCount、liveBrokers、partitionAssignments 等。</li>
<li>ControllerContext 工具方法：ControllerContext 类定义了很多实用方法来管理这些元数据信息。</li>
</ol>
<p>下节课，我们将学习 Controller 是如何给 Broker 发送请求的。Controller 与 Broker 进行交互与通信，是 Controller 奠定王者地位的重要一环，我会向你详细解释它是如何做到这一点的。</p>
<h2 id="课后讨论">课后讨论</h2>
<p>我今天并未给出所有的元数据说明，请你自行结合代码分析一下，partitionLeadershipInfo 里面保存的是什么数据？</p>
<p>欢迎你在留言区写下你的思考和答案，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/">Kafka核心源码解读</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E8%AF%BE/11__context%E4%BF%A1%E6%81%AF%E7%A9%BF%E9%80%8F%E4%B8%8A%E4%B8%8B%E6%96%87/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">11__Context：信息穿透上下文</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/ddd%E5%AE%9E%E6%88%98%E8%AF%BE/11__ddd%E5%AE%9E%E8%B7%B5%E5%A6%82%E4%BD%95%E7%94%A8ddd%E9%87%8D%E6%9E%84%E4%B8%AD%E5%8F%B0%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%9E%8B/">
            <span class="next-text nav-default">11__DDD实践：如何用DDD重构中台业务模型？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

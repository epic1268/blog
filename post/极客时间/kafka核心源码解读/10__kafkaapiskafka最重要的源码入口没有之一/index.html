<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>10__KafkaApis：Kafka最重要的源码入口，没有之一 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是胡夕。今天，我们来收尾 Kafka 请求处理模块的源码学习。讲到这里，关于整个模块，我们还有最后一个知识点尚未掌握，那就是 KafkaApis 类。
在上节课中，我提到过，请求的实际处理逻辑是封装在 KafkaApis 类中的。你一定很想知道，这个类到底是做什么的吧。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/10__kafkaapiskafka%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%BA%90%E7%A0%81%E5%85%A5%E5%8F%A3%E6%B2%A1%E6%9C%89%E4%B9%8B%E4%B8%80/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/10__kafkaapiskafka%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%BA%90%E7%A0%81%E5%85%A5%E5%8F%A3%E6%B2%A1%E6%9C%89%E4%B9%8B%E4%B8%80/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="10__KafkaApis：Kafka最重要的源码入口，没有之一">
  <meta property="og:description" content="你好，我是胡夕。今天，我们来收尾 Kafka 请求处理模块的源码学习。讲到这里，关于整个模块，我们还有最后一个知识点尚未掌握，那就是 KafkaApis 类。
在上节课中，我提到过，请求的实际处理逻辑是封装在 KafkaApis 类中的。你一定很想知道，这个类到底是做什么的吧。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Kafka核心源码解读">

  <meta itemprop="name" content="10__KafkaApis：Kafka最重要的源码入口，没有之一">
  <meta itemprop="description" content="你好，我是胡夕。今天，我们来收尾 Kafka 请求处理模块的源码学习。讲到这里，关于整个模块，我们还有最后一个知识点尚未掌握，那就是 KafkaApis 类。
在上节课中，我提到过，请求的实际处理逻辑是封装在 KafkaApis 类中的。你一定很想知道，这个类到底是做什么的吧。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="5410">
  <meta itemprop="keywords" content="Kafka核心源码解读">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="10__KafkaApis：Kafka最重要的源码入口，没有之一">
  <meta name="twitter:description" content="你好，我是胡夕。今天，我们来收尾 Kafka 请求处理模块的源码学习。讲到这里，关于整个模块，我们还有最后一个知识点尚未掌握，那就是 KafkaApis 类。
在上节课中，我提到过，请求的实际处理逻辑是封装在 KafkaApis 类中的。你一定很想知道，这个类到底是做什么的吧。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">10__KafkaApis：Kafka最重要的源码入口，没有之一</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 5410 字 </span>
          <span class="more-meta"> 预计阅读 11 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#kafkaapis-类定义">KafkaApis 类定义</a></li>
        <li><a href="#kafkaapis-方法入口">KafkaApis 方法入口</a></li>
        <li><a href="#其他重要方法">其他重要方法</a></li>
        <li><a href="#kafkaapis-请求处理实例解析">KafkaApis 请求处理实例解析</a></li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后讨论">课后讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是胡夕。今天，我们来收尾 Kafka 请求处理模块的源码学习。讲到这里，关于整个模块，我们还有最后一个知识点尚未掌握，那就是 KafkaApis 类。</p>
<p>在上节课中，我提到过，请求的实际处理逻辑是封装在 KafkaApis 类中的。你一定很想知道，这个类到底是做什么的吧。</p>
<p>实际上，我一直认为，KafkaApis 是 Kafka 最重要的源码入口。因为，每次要查找 Kafka 某个功能的实现代码时，我们几乎总要从这个 KafkaApis.scala 文件开始找起，然后一层一层向下钻取，直到定位到实现功能的代码处为止。比如，如果你想知道创建 Topic 的流程，你只需要查看 KafkaApis 的 handleCreateTopicsRequest 方法；如果你想弄懂 Consumer 提交位移是怎么实现的，查询 handleOffsetCommitRequest 方法就行了。</p>
<p>除此之外，在这一遍遍的钻取过程中，我们还会慢慢地<strong>掌握 Kafka 实现各种功能的代码路径和源码分布，从而建立起对整个 Kafka 源码工程的完整认识</strong>。</p>
<p>如果这些还不足以吸引你阅读这部分源码，那么，我再给你分享一个真实的案例。</p>
<p>之前，在使用 Kafka 时，我发现，Producer 程序一旦向一个不存在的主题发送消息，在创建主题之后，Producer 端会抛出一个警告：</p>
<p>Error while fetching metadata with correlation id 3 : {test-topic=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)</p>
<p>我一直很好奇，这里的 LEADER_NOT_AVAILABLE 异常是在哪里抛出来的。直到有一天，我在浏览 KafkaApis 代码时，突然发现了 createTopics 方法的这两行代码：</p>
<p>private def createTopic(topic: String,<br>
numPartitions: Int, replicationFactor: Int,<br>
properties: util.Properties = new util.Properties()): MetadataResponseTopic = {<br>
try {<br>
adminZkClient.createTopic(topic, numPartitions, replicationFactor, properties, RackAwareMode.Safe)<br>
&hellip;&hellip;<br>
// 显式封装一个 LEADER_NOT_AVAILABLE Response<br>
metadataResponseTopic(Errors.LEADER_NOT_AVAILABLE, topic, isInternal(topic), util.Collections.emptyList())<br>
} catch {<br>
&hellip;&hellip;<br>
}<br>
}</p>
<p>这时，我才恍然大悟，原来，Broker 端创建完主题后，会显式地通知 Clients 端 LEADER_NOT_AVAILABLE 异常。Clients 端接收到该异常后，会主动更新元数据，去获取新创建主题的信息。你看，如果不是亲自查看源代码，我们是无法解释这种现象的。</p>
<p>那么，既然 KafkaApis 这么重要，现在，我们就来看看这个大名鼎鼎的入口文件吧。我会先给你介绍下它的定义以及最重要的 handle 方法，然后再解释一下其他的重要方法。学完这节课以后，你就能掌握，从 KafkaApis 类开始去寻找单个功能具体代码位置的方法了。</p>
<p>事实上，相比于之前更多是向你分享知识的做法，<strong>这节课我分享的是学习知识的方法</strong>。</p>
<h2 id="kafkaapis-类定义">KafkaApis 类定义</h2>
<p>好了，我们首先来看下 KafkaApis 类的定义。KafkaApis 类定义在源码文件 KafkaApis.scala 中。该文件位于 core 工程的 server 包下，是一个将近 3000 行的巨型文件。好在它实现的逻辑并不复杂，绝大部分代码都是用来处理所有 Kafka 请求类型的，因此，代码结构整体上显得非常规整。一会儿我们在学习 handle 方法时，你一定会所有体会。</p>
<p>KafkaApis 类的定义代码如下：</p>
<p>class KafkaApis(<br>
val requestChannel: RequestChannel, // 请求通道<br>
val replicaManager: ReplicaManager, // 副本管理器<br>
val adminManager: AdminManager,   // 主题、分区、配置等方面的管理器<br>
val groupCoordinator: GroupCoordinator,  // 消费者组协调器组件<br>
val txnCoordinator: TransactionCoordinator,  // 事务管理器组件<br>
val controller: KafkaController,  // 控制器组件<br>
val zkClient: KafkaZkClient,    // ZooKeeper 客户端程序，Kafka 依赖于该类实现与 ZooKeeper 交互<br>
val brokerId: Int,          // broker.id 参数值<br>
val config: KafkaConfig,      // Kafka 配置类<br>
val metadataCache: MetadataCache,  // 元数据缓存类<br>
val metrics: Metrics,     <br>
val authorizer: Option[Authorizer],<br>
val quotas: QuotaManagers,          // 配额管理器组件<br>
val fetchManager: FetchManager,<br>
brokerTopicStats: BrokerTopicStats,<br>
val clusterId: String,<br>
time: Time,<br>
val tokenManager: DelegationTokenManager) extends Logging {<br>
type FetchResponseStats = Map[TopicPartition, RecordConversionStats]<br>
this.logIdent = &ldquo;[KafkaApi-%d] &ldquo;.format(brokerId)<br>
val adminZkClient = new AdminZkClient(zkClient)<br>
private val alterAclsPurgatory = new DelayedFuturePurgatory(purgatoryName = &ldquo;AlterAcls&rdquo;, brokerId = config.brokerId)<br>
&hellip;&hellip;<br>
}</p>
<p>我为一些重要的字段添加了注释信息。为了方便你理解，我还画了一张思维导图，罗列出了比较重要的组件：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/06db45b7608cb50766a38fc0b28dfbb8.png" alt=""></p>
<p>从这张图可以看出，KafkaApis 下可谓是大牌云集。放眼整个源码工程，KafkaApis 关联的“大佬级”组件都是最多的！在 KafkaApis 中，你几乎能找到 Kafka 所有重量级的组件，比如，负责副本管理的 ReplicaManager、维护消费者组的 GroupCoordinator 以及操作 Controller 组件的 KafkaController，等等。</p>
<p>在处理不同类型的 RPC 请求时，KafkaApis 会用到不同的组件，因此，在创建 KafkaApis 实例时，我们必须把可能用到的组件一并传给它，这也是它汇聚众多大牌组件于一身的原因。</p>
<p>我说 KafkaApis 是入口类的另一个原因也在于此。你完全可以打开 KafkaApis.scala 文件，然后根据它的定义一个一个地去研习这些重量级组件的实现原理。等你对这些组件的代码了然于胸了，说不定下一个写源码课的人就是你了。</p>
<h2 id="kafkaapis-方法入口">KafkaApis 方法入口</h2>
<p>那，作为 Kafka 源码的入口类，它都定义了哪些方法呢？</p>
<p>如果你翻开 KafkaApis 类的代码，你会发现，它封装了很多以 handle 开头的方法。每一个这样的方法都对应于一类请求类型，而它们的总方法入口就是 handle 方法。实际上，你完全可以在 handle 方法间不断跳转，去到任意一类请求被处理的实际代码中。下面这段代码就是 handle 方法的完整实现，我们来看一下：</p>
<p>def handle(request: RequestChannel.Request): Unit = {<br>
try {<br>
trace(s&quot;Handling request:${request.requestDesc(true)} from connection ${request.context.connectionId};&rdquo; +<br>
s&quot;securityProtocol:${request.context.securityProtocol},principal:${request.context.principal}&rdquo;)<br>
// 根据请求头部信息中的 apiKey 字段判断属于哪类请求<br>
// 然后调用响应的 handle<em><strong>方法<br>
// 如果新增 RPC 协议类型，则：<br>
// 1. 添加新的 apiKey 标识新请求类型<br>
// 2. 添加新的 case 分支<br>
// 3. 添加对应的 handle</strong></em>方法  <br>
request.header.apiKey match {<br>
case ApiKeys.PRODUCE =&gt; handleProduceRequest(request)<br>
case ApiKeys.FETCH =&gt; handleFetchRequest(request)<br>
case ApiKeys.LIST_OFFSETS =&gt; handleListOffsetRequest(request)<br>
case ApiKeys.METADATA =&gt; handleTopicMetadataRequest(request)<br>
case ApiKeys.LEADER_AND_ISR =&gt; handleLeaderAndIsrRequest(request)<br>
case ApiKeys.STOP_REPLICA =&gt; handleStopReplicaRequest(request)<br>
case ApiKeys.UPDATE_METADATA =&gt; handleUpdateMetadataRequest(request)<br>
case ApiKeys.CONTROLLED_SHUTDOWN =&gt; handleControlledShutdownRequest(request)<br>
case ApiKeys.OFFSET_COMMIT =&gt; handleOffsetCommitRequest(request)<br>
case ApiKeys.OFFSET_FETCH =&gt; handleOffsetFetchRequest(request)<br>
case ApiKeys.FIND_COORDINATOR =&gt; handleFindCoordinatorRequest(request)<br>
case ApiKeys.JOIN_GROUP =&gt; handleJoinGroupRequest(request)<br>
case ApiKeys.HEARTBEAT =&gt; handleHeartbeatRequest(request)<br>
case ApiKeys.LEAVE_GROUP =&gt; handleLeaveGroupRequest(request)<br>
case ApiKeys.SYNC_GROUP =&gt; handleSyncGroupRequest(request)<br>
case ApiKeys.DESCRIBE_GROUPS =&gt; handleDescribeGroupRequest(request)<br>
case ApiKeys.LIST_GROUPS =&gt; handleListGroupsRequest(request)<br>
case ApiKeys.SASL_HANDSHAKE =&gt; handleSaslHandshakeRequest(request)<br>
case ApiKeys.API_VERSIONS =&gt; handleApiVersionsRequest(request)<br>
case ApiKeys.CREATE_TOPICS =&gt; handleCreateTopicsRequest(request)<br>
case ApiKeys.DELETE_TOPICS =&gt; handleDeleteTopicsRequest(request)<br>
case ApiKeys.DELETE_RECORDS =&gt; handleDeleteRecordsRequest(request)<br>
case ApiKeys.INIT_PRODUCER_ID =&gt; handleInitProducerIdRequest(request)<br>
case ApiKeys.OFFSET_FOR_LEADER_EPOCH =&gt; handleOffsetForLeaderEpochRequest(request)<br>
case ApiKeys.ADD_PARTITIONS_TO_TXN =&gt; handleAddPartitionToTxnRequest(request)<br>
case ApiKeys.ADD_OFFSETS_TO_TXN =&gt; handleAddOffsetsToTxnRequest(request)<br>
case ApiKeys.END_TXN =&gt; handleEndTxnRequest(request)<br>
case ApiKeys.WRITE_TXN_MARKERS =&gt; handleWriteTxnMarkersRequest(request)<br>
case ApiKeys.TXN_OFFSET_COMMIT =&gt; handleTxnOffsetCommitRequest(request)<br>
case ApiKeys.DESCRIBE_ACLS =&gt; handleDescribeAcls(request)<br>
case ApiKeys.CREATE_ACLS =&gt; handleCreateAcls(request)<br>
case ApiKeys.DELETE_ACLS =&gt; handleDeleteAcls(request)<br>
case ApiKeys.ALTER_CONFIGS =&gt; handleAlterConfigsRequest(request)<br>
case ApiKeys.DESCRIBE_CONFIGS =&gt; handleDescribeConfigsRequest(request)<br>
case ApiKeys.ALTER_REPLICA_LOG_DIRS =&gt; handleAlterReplicaLogDirsRequest(request)<br>
case ApiKeys.DESCRIBE_LOG_DIRS =&gt; handleDescribeLogDirsRequest(request)<br>
case ApiKeys.SASL_AUTHENTICATE =&gt; handleSaslAuthenticateRequest(request)<br>
case ApiKeys.CREATE_PARTITIONS =&gt; handleCreatePartitionsRequest(request)<br>
case ApiKeys.CREATE_DELEGATION_TOKEN =&gt; handleCreateTokenRequest(request)<br>
case ApiKeys.RENEW_DELEGATION_TOKEN =&gt; handleRenewTokenRequest(request)<br>
case ApiKeys.EXPIRE_DELEGATION_TOKEN =&gt; handleExpireTokenRequest(request)<br>
case ApiKeys.DESCRIBE_DELEGATION_TOKEN =&gt; handleDescribeTokensRequest(request)<br>
case ApiKeys.DELETE_GROUPS =&gt; handleDeleteGroupsRequest(request)<br>
case ApiKeys.ELECT_LEADERS =&gt; handleElectReplicaLeader(request)<br>
case ApiKeys.INCREMENTAL_ALTER_CONFIGS =&gt; handleIncrementalAlterConfigsRequest(request)<br>
case ApiKeys.ALTER_PARTITION_REASSIGNMENTS =&gt; handleAlterPartitionReassignmentsRequest(request)<br>
case ApiKeys.LIST_PARTITION_REASSIGNMENTS =&gt; handleListPartitionReassignmentsRequest(request)<br>
case ApiKeys.OFFSET_DELETE =&gt; handleOffsetDeleteRequest(request)<br>
case ApiKeys.DESCRIBE_CLIENT_QUOTAS =&gt; handleDescribeClientQuotasRequest(request)<br>
case ApiKeys.ALTER_CLIENT_QUOTAS =&gt; handleAlterClientQuotasRequest(request)<br>
}<br>
} catch {<br>
// 如果是严重错误，则抛出异常<br>
case e: FatalExitError =&gt; throw e<br>
// 普通异常的话，记录下错误日志<br>
case e: Throwable =&gt; handleError(request, e)<br>
} finally {<br>
// 记录一下请求本地完成时间，即 Broker 处理完该请求的时间<br>
if (request.apiLocalCompleteTimeNanos &lt; 0)<br>
request.apiLocalCompleteTimeNanos = time.nanoseconds<br>
}<br>
}</p>
<p>如果你跟着这门课一直学习的话，你应该会发现，我很少贴某个类或方法的完整代码，因为没必要，还会浪费你的时间。但是，这个 handle 方法有点特殊，所以我把完整的代码展现给你。</p>
<p>它利用 Scala 语言中的模式匹配语法，完整地列出了对所有请求类型的处理逻辑。通过该方法，你能串联出 Kafka 处理任何请求的源码路径。我强烈推荐你在课下以几个比较重要的请求类型为学习目标，从 handle 方法出发，去探寻一下代码是如何为这些请求服务的，以加深你对 Broker 端代码的整体熟练度。这对你后续深入学习源码或解决实际问题非常有帮助。</p>
<p>从上面的代码中，你应该很容易就能找到其中的规律：<strong>这个方法是处理具体请求用的</strong>。处理每类请求的方法名均以 handle 开头，即 handle×××Request。比如，处理 PRODUCE 请求的方法叫 handleProduceRequest，处理 FETCH 请求的方法叫 handleFetchRequest 等。</p>
<p>如果你点开 ApiKeys，你会发现，<strong>它实际上是一个枚举类型，里面封装了目前 Kafka 定义所有的 RPC 协议</strong>。值得一提的是，Kafka 社区维护了一个官方文档，专门记录这些 RPC 协议，包括不同版本所需的 Request 格式和 Response 格式。</p>
<p>从这个 handle 方法中，我们也能得到这样的结论：每当社区添加新的 RPC 协议时，Broker 端大致需要做三件事情。</p>
<ol>
<li>更新 ApiKeys 枚举，加入新的 RPC ApiKey；</li>
<li>在 KafkaApis 中添加对应的 handle×××Request 方法，实现对该 RPC 请求的处理逻辑；</li>
<li>更新 KafkaApis 的 handle 方法，添加针对 RPC 协议的 case 分支。</li>
</ol>
<h2 id="其他重要方法">其他重要方法</h2>
<p>抛开 KafkaApis 的定义和 handle 方法，还有几个常用的方法也很重要，比如，用于发送 Response 的一组方法，以及用于鉴权的方法。特别是前者，它是任何一类请求被处理之后都要做的必要步骤。毕竟，请求被处理完成还不够，Kafka 还需要把处理结果发送给请求发送方。</p>
<p>首先就是 <strong>sendResponse 系列方法</strong>。</p>
<p>为什么说是系列方法呢？因为源码中带有 sendResponse 字眼的方法有 7 个之多。我分别来介绍一下。</p>
<ol>
<li><strong>sendResponse</strong>（RequestChannel.Response）：最底层的 Response 发送方法。本质上，它调用了 SocketServer 组件中 RequestChannel 的 sendResponse 方法，我在前面的课程中讲到过，RequestChannel 的 sendResponse 方法会把待发送的 Response 对象添加到对应 Processor 线程的 Response 队列上，然后交由 Processor 线程完成网络间的数据传输。</li>
<li><strong>sendResponse</strong>（RequestChannel.Request，responseOpt: Option[AbstractResponse]，onComplete: Option[Send =&gt; Unit]）：该方法接收的实际上是 Request，而非 Response，因此，它会在内部构造出 Response 对象之后，再调用 sendResponse 方法。</li>
<li><strong>sendNoOpResponseExemptThrottle</strong>：发送 NoOpResponse 类型的 Response 而不受请求通道上限流（throttling）的限制。所谓的 NoOpResponse，是指 Processor 线程取出该类型的 Response 后，不执行真正的 I/O 发送操作。</li>
<li><strong>sendErrorResponseExemptThrottle</strong>：发送携带错误信息的 Response 而不受限流限制。</li>
<li><strong>sendResponseExemptThrottle</strong>：发送普通 Response 而不受限流限制。</li>
<li><strong>sendErrorResponseMaybeThrottle</strong>：发送携带错误信息的 Response 但接受限流的约束。</li>
<li><strong>sendResponseMaybeThrottle</strong>：发送普通 Response 但接受限流的约束。</li>
</ol>
<p>这组方法最关键的还是第一个 sendResponse 方法。大部分类型的请求被处理完成后都会使用这个方法将 Response 发送出去。至于上面这组方法中的其他方法，它们会在内部调用第一个 sendResponse 方法。当然，在调用之前，这些方法通常都拥有一些定制化的逻辑。比如 sendResponseMaybeThrottle 方法就会在执行 sendResponse 逻辑前，先尝试对请求所属的请求通道进行限流操作。因此，<strong>我们要着重掌握第一个 sendResponse 方法是怎么将 Response 对象发送出去的</strong>。</p>
<p>就像我前面说的，<strong>KafkaApis 实际上是把处理完成的 Response 放回到前端 Processor 线程的 Response 队列中，而真正将 Response 返还给 Clients 或其他 Broker 的，其实是 Processor 线程，而不是执行 KafkaApis 逻辑的 KafkaRequestHandler 线程</strong>。</p>
<p>另一个非常重要的方法是 authorize 方法，咱们看看它的代码：</p>
<p>private[server] def authorize(requestContext: RequestContext,<br>
operation: AclOperation,<br>
resourceType: ResourceType,<br>
resourceName: String,<br>
logIfAllowed: Boolean = true,<br>
logIfDenied: Boolean = true,<br>
refCount: Int = 1): Boolean = {<br>
authorizer.forall { authZ =&gt;<br>
// 获取待鉴权的资源类型<br>
// 常见的资源类型如 TOPIC、GROUP、CLUSTER 等<br>
val resource = new ResourcePattern(resourceType, resourceName, PatternType.LITERAL)<br>
val actions = Collections.singletonList(new Action(operation, resource, refCount, logIfAllowed, logIfDenied))<br>
// 返回鉴权结果，是 ALLOWED 还是 DENIED<br>
authZ.authorize(requestContext, actions).asScala.head == AuthorizationResult.ALLOWED<br>
}<br>
}</p>
<p>这个方法是做<strong>授权检验</strong>的。目前，Kafka 所有的 RPC 请求都要求发送者（无论是 Clients，还是其他 Broker）必须具备特定的权限。</p>
<p>接下来，我用创建主题的代码来举个例子，说明一下 authorize 方法的实际应用，以下是 handleCreateTopicsRequest 方法的片段：</p>
<p>// 是否具有 CLUSTER 资源的 CREATE 权限<br>
val hasClusterAuthorization = authorize(request, CREATE, CLUSTER, CLUSTER_NAME, logIfDenied = false)<br>
val topics = createTopicsRequest.data.topics.asScala.map(_.name)<br>
// 如果具有 CLUSTER CREATE 权限，则允许主题创建，否则，还要查看是否具有 TOPIC 资源的 CREATE 权限<br>
val authorizedTopics = if (hasClusterAuthorization) topics.toSet else filterAuthorized(request, CREATE, TOPIC, topics.toSeq)<br>
// 是否具有 TOPIC 资源的 DESCRIBE_CONFIGS 权限<br>
val authorizedForDescribeConfigs = filterAuthorized(request, DESCRIBE_CONFIGS, TOPIC, topics.toSeq, logIfDenied = false)<br>
.map(name =&gt; name -&gt; results.find(name)).toMap</p>
<p>results.asScala.foreach(topic =&gt; {<br>
if (results.findAll(topic.name).size &gt; 1) {<br>
topic.setErrorCode(Errors.INVALID_REQUEST.code)<br>
topic.setErrorMessage(&ldquo;Found multiple entries for this topic.&rdquo;)<br>
} else if (!authorizedTopics.contains(topic.name)) { // 如果不具备 CLUSTER 资源的 CREATE 权限或 TOPIC 资源的 CREATE 权限，认证失败！<br>
topic.setErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)<br>
topic.setErrorMessage(&ldquo;Authorization failed.&rdquo;)<br>
}<br>
if (!authorizedForDescribeConfigs.contains(topic.name)) { // 如果不具备 TOPIC 资源的 DESCRIBE_CONFIGS 权限，设置主题配置错误码<br>
topic.setTopicConfigErrorCode(Errors.TOPIC_AUTHORIZATION_FAILED.code)<br>
}<br>
})<br>
&hellip;&hellip;</p>
<p>这段代码调用 authorize 方法，来判断 Clients 方法是否具有创建主题的权限，如果没有，则显式标记 TOPIC_AUTHORIZATION_FAILED，告知 Clients 端。目前，Kafka 所有的权限控制均发生在 KafkaApis 中，即<strong>所有请求在处理前，都需要调用 authorize 方法做权限校验，以保证请求能够被继续执行</strong>。</p>
<h2 id="kafkaapis-请求处理实例解析">KafkaApis 请求处理实例解析</h2>
<p>在了解了 KafkaApis 的代码结构之后，我拿一段真实的代码，来说明一下该类中某个协议处理方法大致的执行流程是什么样的，以便让你更清楚地了解请求处理逻辑。</p>
<p>值得注意的是，这里的请求处理逻辑和之前所说的请求处理全流程是有所区别的。今天，我们关注的是<strong>功能层面上请求被处理的逻辑代码</strong>，之前的请求处理全流程主要聚焦流程方面的代码，即一个请求从被发送到 Broker 端到 Broker 端返还 Response 的代码路径。应该这么说，<strong>所有类型请求的被处理流程都是相同的，但是，每类请求却有不同的功能实现逻辑</strong>，而这就是 KafkaApis 类中的各个 handle×××Request 方法要做的事情。</p>
<p>下面，我以 handleListGroupsRequest 方法为例来介绍一下。顾名思义，这是处理 ListGroupsRequest 请求的方法。这类请求的 Response 应该返回集群中的消费者组信息。我们来看下它的实现：</p>
<p>def handleListGroupsRequest(request: RequestChannel.Request): Unit = {<br>
val (error, groups) = groupCoordinator.handleListGroups() // 调用 GroupCoordinator 的 handleListGroups 方法拿到所有 Group 信息<br>
// 如果 Clients 具备 CLUSTER 资源的 DESCRIBE 权限<br>
if (authorize(request, DESCRIBE, CLUSTER, CLUSTER_NAME))<br>
// 直接使用刚才拿到的 Group 数据封装进 Response 然后发送<br>
sendResponseMaybeThrottle(request, requestThrottleMs =&gt;<br>
new ListGroupsResponse(new ListGroupsResponseData()<br>
.setErrorCode(error.code)<br>
.setGroups(groups.map { group =&gt; new ListGroupsResponseData.ListedGroup()<br>
.setGroupId(group.groupId)<br>
.setProtocolType(group.protocolType)}.asJava<br>
)<br>
.setThrottleTimeMs(requestThrottleMs)<br>
))<br>
else {<br>
// 找出 Clients 对哪些 Group 有 GROUP 资源的 DESCRIBE 权限，返回这些 Group 信息<br>
val filteredGroups = groups.filter(group =&gt; authorize(request, DESCRIBE, GROUP, group.groupId))<br>
sendResponseMaybeThrottle(request, requestThrottleMs =&gt;<br>
new ListGroupsResponse(new ListGroupsResponseData()<br>
.setErrorCode(error.code)<br>
.setGroups(filteredGroups.map { group =&gt; new ListGroupsResponseData.ListedGroup()<br>
.setGroupId(group.groupId)<br>
.setProtocolType(group.protocolType)}.asJava<br>
)<br>
.setThrottleTimeMs(requestThrottleMs)<br>
))<br>
}<br>
}</p>
<p>我用一张流程图，来说明一下这个执行逻辑：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/b250b6f23bdb1b09e86081499f6e9799.png" alt=""></p>
<p>大体来看，handleListGroupsRequest 方法的实现逻辑非常简单。通过 GroupCoordinator 组件获取到所有的消费者组信息之后，代码对这些 Group 进行了权限校验，并最终根据校验结果，决定给 Clients 返回哪些可见的消费者组。</p>
<h2 id="总结">总结</h2>
<p>好了，我们总结一下 KafkaApis 类的要点。如前所述，我们重点学习了 KafkaApis 类的定义及其重要方法 handle。下面这些关键知识点，希望你能掌握。</p>
<ol>
<li>KafkaApis 是 Broker 端所有功能的入口，同时关联了超多的 Kafka 组件。它绝对是你学习源码的第一入口。面对庞大的源码工程，如果你不知道从何下手，那就先从 KafkaApis.scala 这个文件开始吧。</li>
<li>handle 方法封装了所有 RPC 请求的具体处理逻辑。每当社区新增 RPC 协议时，增加对应的 handle×××Request 方法和 case 分支都是首要的。</li>
<li>sendResponse 系列方法负责发送 Response 给请求发送方。发送 Response 的逻辑是将 Response 对象放置在 Processor 线程的 Response 队列中，然后交由 Processor 线程实现网络发送。</li>
<li>authorize 方法是请求处理前权限校验层的主要逻辑实现。你可以查看一下官方文档，了解一下当前都有哪些权限，然后对照着具体的方法，找出每类 RPC 协议都要求 Clients 端具备什么权限。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/df5b843c3a1b39cdf06368af908eb982.png" alt=""></p>
<p>至此，关于 Kafka 请求处理模块的内容，我们就全部学完了。在这个模块中，我们先从 RequestChannel 入手，探讨了 Kafka 中请求队列的实现原理，之后，我花了两节课的时间，重点介绍了 SocketServer 组件，包括 Acceptor 线程、Processor 线程等子组件的源码以及请求被处理的全流程。今天，我们重点研究了 KafkaApis 类这个顶层的请求功能处理逻辑入口，补齐了请求处理的最后一块“拼图”。我希望你能够把这个模块的课程多看几遍，认真思考一下这里面的关键实现要点，彻底搞明白 Kafka 网络通信的核心机制。</p>
<p>从下节课开始，我们将进入鼎鼎有名的控制器（Controller）组件的源码学习。我会花 5 节课的时间，带你深入学习 Controller 的方方面面，敬请期待。</p>
<h2 id="课后讨论">课后讨论</h2>
<p>最后，请思考这样一个问题：如果一个 Consumer 要向 Broker 提交位移，它应该具备什么权限？你能说出 KafkaApis 中的哪段代码说明了所需的权限要求吗？</p>
<p>欢迎你在留言区写下你的思考和答案，跟我交流讨论，也欢迎你把今天的内容分享给你的朋友。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kafka%E6%A0%B8%E5%BF%83%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/">Kafka核心源码解读</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/openresty%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E6%88%98/10__jit%E7%BC%96%E8%AF%91%E5%99%A8%E7%9A%84%E6%AD%BB%E7%A9%B4%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E9%81%BF%E5%85%8D%E4%BD%BF%E7%94%A8_nyi_/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">10__JIT编译器的死穴：为什么要避免使用_NYI_？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90kubernetes/10__kubernetes%E4%B8%80%E9%94%AE%E9%83%A8%E7%BD%B2%E5%88%A9%E5%99%A8kubeadm/">
            <span class="next-text nav-default">10__Kubernetes一键部署利器：kubeadm</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

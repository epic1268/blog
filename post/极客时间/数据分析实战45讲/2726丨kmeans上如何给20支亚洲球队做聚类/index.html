<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>2726丨KMeans上如何给20支亚洲球队做聚类 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="26丨K-Means（上）：如何给20支亚洲球队做聚类？
今天我来带你进行 K-Means 的学习。K-Means 是一种非监督学习，解决的是聚类问题。K 代表的是 K 类，Means 代表的是中心，你可以理解这个算法的本质是确定 K 类的中心点，当你找到了这些中心点，也就完成了聚类。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/2726%E4%B8%A8kmeans%E4%B8%8A%E5%A6%82%E4%BD%95%E7%BB%9920%E6%94%AF%E4%BA%9A%E6%B4%B2%E7%90%83%E9%98%9F%E5%81%9A%E8%81%9A%E7%B1%BB/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/2726%E4%B8%A8kmeans%E4%B8%8A%E5%A6%82%E4%BD%95%E7%BB%9920%E6%94%AF%E4%BA%9A%E6%B4%B2%E7%90%83%E9%98%9F%E5%81%9A%E8%81%9A%E7%B1%BB/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="2726丨KMeans上如何给20支亚洲球队做聚类">
  <meta property="og:description" content="26丨K-Means（上）：如何给20支亚洲球队做聚类？
今天我来带你进行 K-Means 的学习。K-Means 是一种非监督学习，解决的是聚类问题。K 代表的是 K 类，Means 代表的是中心，你可以理解这个算法的本质是确定 K 类的中心点，当你找到了这些中心点，也就完成了聚类。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="数据分析实战45讲">

  <meta itemprop="name" content="2726丨KMeans上如何给20支亚洲球队做聚类">
  <meta itemprop="description" content="26丨K-Means（上）：如何给20支亚洲球队做聚类？
今天我来带你进行 K-Means 的学习。K-Means 是一种非监督学习，解决的是聚类问题。K 代表的是 K 类，Means 代表的是中心，你可以理解这个算法的本质是确定 K 类的中心点，当你找到了这些中心点，也就完成了聚类。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="3532">
  <meta itemprop="keywords" content="数据分析实战45讲">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="2726丨KMeans上如何给20支亚洲球队做聚类">
  <meta name="twitter:description" content="26丨K-Means（上）：如何给20支亚洲球队做聚类？
今天我来带你进行 K-Means 的学习。K-Means 是一种非监督学习，解决的是聚类问题。K 代表的是 K 类，Means 代表的是中心，你可以理解这个算法的本质是确定 K 类的中心点，当你找到了这些中心点，也就完成了聚类。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">2726丨KMeans上如何给20支亚洲球队做聚类</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 3532 字 </span>
          <span class="more-meta"> 预计阅读 8 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents"></nav>
  </div>
</div>
    <div class="post-content">
      <p>26丨K-Means（上）：如何给20支亚洲球队做聚类？</p>
<p>今天我来带你进行 K-Means 的学习。K-Means 是一种非监督学习，解决的是聚类问题。K 代表的是 K 类，Means 代表的是中心，你可以理解这个算法的本质是确定 K 类的中心点，当你找到了这些中心点，也就完成了聚类。</p>
<p>那么请你和我思考以下三个问题：</p>
<p>如何确定 K 类的中心点？</p>
<p>如何将其他点划分到 K 类中？</p>
<p>如何区分 K-Means 与 KNN？</p>
<p>如果理解了上面这 3 个问题，那么对 K-Means 的原理掌握得也就差不多了。</p>
<p>先请你和我思考一个场景，假设我有 20 支亚洲足球队，想要将它们按照成绩划分成 3 个等级，可以怎样划分？</p>
<p>K-Means 的工作原理</p>
<p>对亚洲足球队的水平，你可能也有自己的判断。比如一流的亚洲球队有谁？你可能会说伊朗或韩国。二流的亚洲球队呢？你可能说是中国。三流的亚洲球队呢？你可能会说越南。</p>
<p>其实这些都是靠我们的经验来划分的，那么伊朗、中国、越南可以说是三个等级的典型代表，也就是我们每个类的中心点。</p>
<p>所以回过头来，如何确定 K 类的中心点？一开始我们是可以随机指派的，当你确认了中心点后，就可以按照距离将其他足球队划分到不同的类别中。</p>
<p>这也就是 K-Means 的中心思想，就是这么简单直接。你可能会问：如果一开始，选择一流球队是中国，二流球队是伊朗，三流球队是韩国，中心点选择错了怎么办？其实不用担心，K-Means 有自我纠正机制，在不断的迭代过程中，会纠正中心点。中心点在整个迭代过程中，并不是唯一的，只是你需要一个初始值，一般算法会随机设置初始的中心点。</p>
<p>好了，那我来把 K-Means 的工作原理给你总结下：</p>
<p>选取 K 个点作为初始的类中心点，这些点一般都是从数据集中随机抽取的；</p>
<p>将每个点分配到最近的类中心点，这样就形成了 K 个类，然后重新计算每个类的中心点；</p>
<p>重复第二步，直到类不发生变化，或者你也可以设置最大迭代次数，这样即使类中心点发生变化，但是只要达到最大迭代次数就会结束。</p>
<p>如何给亚洲球队做聚类</p>
<p>对于机器来说需要数据才能判断类中心点，所以我整理了 2015-2019 年亚洲球队的排名，如下表所示。</p>
<p>我来说明一下数据概况。</p>
<p>其中 2019 年国际足联的世界排名，2015 年亚洲杯排名均为实际排名。2018 年世界杯中，很多球队没有进入到决赛圈，所以只有进入到决赛圈的球队才有实际的排名。如果是亚洲区预选赛 12 强的球队，排名会设置为 40。如果没有进入亚洲区预选赛 12 强，球队排名会设置为 50。</p>
<p>针对上面的排名，我们首先需要做的是数据规范化。你可以把这些值划分到 [0,1] 或者按照均值为 0，方差为 1 的正态分布进行规范化。具体数据规范化的步骤可以看下 13 篇，也就是数据变换那一篇。</p>
<p>我先把数值都规范化到 [0,1] 的空间中，得到了以下的数值表：</p>
<p>如果我们随机选取中国、日本、韩国为三个类的中心点，我们就需要看下这些球队到中心点的距离。</p>
<p>距离有多种计算的方式，有关距离的计算我在 KNN 算法中也讲到过：</p>
<p>欧氏距离</p>
<p>曼哈顿距离</p>
<p>切比雪夫距离</p>
<p>余弦距离</p>
<p>欧氏距离是最常用的距离计算方式，这里我选择欧氏距离作为距离的标准，计算每个队伍分别到中国、日本、韩国的距离，然后根据距离远近来划分。我们看到大部分的队，会和中国队聚类到一起。这里我整理了距离的计算过程，比如中国和中国的欧氏距离为 0，中国和日本的欧式距离为 0.732003。如果按照中国、日本、韩国为 3 个分类的中心点，欧氏距离的计算结果如下表所示：</p>
<p>然后我们再重新计算这三个类的中心点，如何计算呢？最简单的方式就是取平均值，然后根据新的中心点按照距离远近重新分配球队的分类，再根据球队的分类更新中心点的位置。计算过程这里不展开，最后一直迭代（重复上述的计算过程：计算中心点和划分分类）到分类不再发生变化，可以得到以下的分类结果：</p>
<p>所以我们能看出来第一梯队有日本、韩国、伊朗、沙特、澳洲；第二梯队有中国、伊拉克、阿联酋、乌兹别克斯坦；第三梯队有卡塔尔、泰国、越南、阿曼、巴林、朝鲜、印尼、叙利亚、约旦、科威特和巴勒斯坦。</p>
<p>如何使用 sklearn 中的 K-Means 算法</p>
<p>sklearn 是 Python 的机器学习工具库，如果从功能上来划分，sklearn 可以实现分类、聚类、回归、降维、模型选择和预处理等功能。这里我们使用的是 sklearn 的聚类函数库，因此需要引用工具包，具体代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">from sklearn.cluster import KMeans
</span></span></code></pre></td></tr></table>
</div>
</div><p>当然 K-Means 只是 sklearn.cluster 中的一个聚类库，实际上包括 K-Means 在内，sklearn.cluster 一共提供了 9 种聚类方法，比如 Mean-shift，DBSCAN，Spectral clustering（谱聚类）等。这些聚类方法的原理和 K-Means 不同，这里不做介绍。</p>
<p>我们看下 K-Means 如何创建：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">KMeans(n_clusters=8, init=&#39;k-means++&#39;, n_init=10, max_iter=300, tol=0.0001, precompute_distances=&#39;auto&#39;, verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm=&#39;auto&#39;)
</span></span></code></pre></td></tr></table>
</div>
</div><p>我们能看到在 K-Means 类创建的过程中，有一些主要的参数：</p>
<p>n_clusters: 即 K 值，一般需要多试一些 K 值来保证更好的聚类效果。你可以随机设置一些 K 值，然后选择聚类效果最好的作为最终的 K 值；</p>
<p>max_iter： 最大迭代次数，如果聚类很难收敛的话，设置最大迭代次数可以让我们及时得到反馈结果，否则程序运行时间会非常长；</p>
<p>n_init：初始化中心点的运算次数，默认是 10。程序是否能快速收敛和中心点的选择关系非常大，所以在中心点选择上多花一些时间，来争取整体时间上的快速收敛还是非常值得的。由于每一次中心点都是随机生成的，这样得到的结果就有好有坏，非常不确定，所以要运行 n_init 次, 取其中最好的作为初始的中心点。如果 K 值比较大的时候，你可以适当增大 n_init 这个值；</p>
<p>init： 即初始值选择的方式，默认是采用优化过的 k-means++ 方式，你也可以自己指定中心点，或者采用 random 完全随机的方式。自己设置中心点一般是对于个性化的数据进行设置，很少采用。random 的方式则是完全随机的方式，一般推荐采用优化过的 k-means++ 方式；</p>
<p>algorithm：k-means 的实现算法，有“auto” “full”“elkan”三种。一般来说建议直接用默认的&quot;auto&quot;。简单说下这三个取值的区别，如果你选择&quot;full&quot;采用的是传统的 K-Means 算法，“auto”会根据数据的特点自动选择是选择“full”还是“elkan”。我们一般选择默认的取值，即“auto” 。</p>
<p>在创建好 K-Means 类之后，就可以使用它的方法，最常用的是 fit 和 predict 这个两个函数。你可以单独使用 fit 函数和 predict 函数，也可以合并使用 fit_predict 函数。其中 fit(data) 可以对 data 数据进行 k-Means 聚类。 predict(data) 可以针对 data 中的每个样本，计算最近的类。</p>
<p>现在我们要完整地跑一遍 20 支亚洲球队的聚类问题。我把数据上传到了GitHub上，你可以自行下载。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># coding: utf-8
</span></span><span class="line"><span class="cl">from sklearn.cluster import KMeans
</span></span><span class="line"><span class="cl">from sklearn import preprocessing
</span></span><span class="line"><span class="cl">import pandas as pd
</span></span><span class="line"><span class="cl">import numpy as np
</span></span><span class="line"><span class="cl"># 输入数据
</span></span><span class="line"><span class="cl">data = pd.read_csv(&#39;data.csv&#39;, encoding=&#39;gbk&#39;)
</span></span><span class="line"><span class="cl">train_x = data[[&#34;2019 年国际排名 &#34;,&#34;2018 世界杯 &#34;,&#34;2015 亚洲杯 &#34;]]
</span></span><span class="line"><span class="cl">df = pd.DataFrame(train_x)
</span></span><span class="line"><span class="cl">kmeans = KMeans(n_clusters=3)
</span></span><span class="line"><span class="cl"># 规范化到 [0,1] 空间
</span></span><span class="line"><span class="cl">min_max_scaler=preprocessing.MinMaxScaler()
</span></span><span class="line"><span class="cl">train_x=min_max_scaler.fit_transform(train_x)
</span></span><span class="line"><span class="cl"># kmeans 算法
</span></span><span class="line"><span class="cl">kmeans.fit(train_x)
</span></span><span class="line"><span class="cl">predict_y = kmeans.predict(train_x)
</span></span><span class="line"><span class="cl"># 合并聚类结果，插入到原数据中
</span></span><span class="line"><span class="cl">result = pd.concat((data,pd.DataFrame(predict_y)),axis=1)
</span></span><span class="line"><span class="cl">result.rename({0:u&#39;聚类&#39;},axis=1,inplace=True)
</span></span><span class="line"><span class="cl">print(result)
</span></span></code></pre></td></tr></table>
</div>
</div><p>运行结果：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">国家  2019 年国际排名  2018 世界杯  2015 亚洲杯  聚类
</span></span><span class="line"><span class="cl">0       中国         73       40        7   2
</span></span><span class="line"><span class="cl">1       日本         60       15        5   0
</span></span><span class="line"><span class="cl">2       韩国         61       19        2   0
</span></span><span class="line"><span class="cl">3       伊朗         34       18        6   0
</span></span><span class="line"><span class="cl">4       沙特         67       26       10   0
</span></span><span class="line"><span class="cl">5      伊拉克         91       40        4   2
</span></span><span class="line"><span class="cl">6      卡塔尔        101       40       13   1
</span></span><span class="line"><span class="cl">7      阿联酋         81       40        6   2
</span></span><span class="line"><span class="cl">8   乌兹别克斯坦         88       40        8   2
</span></span><span class="line"><span class="cl">9       泰国        122       40       17   1
</span></span><span class="line"><span class="cl">10      越南        102       50       17   1
</span></span><span class="line"><span class="cl">11      阿曼         87       50       12   1
</span></span><span class="line"><span class="cl">12      巴林        116       50       11   1
</span></span><span class="line"><span class="cl">13      朝鲜        110       50       14   1
</span></span><span class="line"><span class="cl">14      印尼        164       50       17   1
</span></span><span class="line"><span class="cl">15      澳洲         40       30        1   0
</span></span><span class="line"><span class="cl">16     叙利亚         76       40       17   1
</span></span><span class="line"><span class="cl">17      约旦        118       50        9   1
</span></span><span class="line"><span class="cl">18     科威特        160       50       15   1
</span></span><span class="line"><span class="cl">19    巴勒斯坦         96       50       16   1
</span></span></code></pre></td></tr></table>
</div>
</div><p>总结</p>
<p>今天我给你讲了 K-Means 算法原理，我们再来看下开篇我给你提的三个问题。</p>
<p>如何确定 K 类的中心点？其中包括了初始的设置，以及中间迭代过程中中心点的计算。在初始设置中，会进行 n_init 次的选择，然后选择初始中心点效果最好的为初始值。在每次分类更新后，你都需要重新确认每一类的中心点，一般采用均值的方式进行确认。</p>
<p>如何将其他点划分到 K 类中？这里实际上是关于距离的定义，我们知道距离有多种定义的方式，在 K-Means 和 KNN 中，我们都可以采用欧氏距离、曼哈顿距离、切比雪夫距离、余弦距离等。对于点的划分，就看它离哪个类的中心点的距离最近，就属于哪一类。</p>
<p>如何区分 K-Means 和 KNN 这两种算法呢？刚学过 K-Means 和 KNN 算法的同学应该能知道两者的区别，但往往过了一段时间，就容易混淆。所以我们可以从三个维度来区分 K-Means 和 KNN 这两个算法：</p>
<p>首先，这两个算法解决数据挖掘的两类问题。K-Means 是聚类算法，KNN 是分类算法。</p>
<p>这两个算法分别是两种不同的学习方式。K-Means 是非监督学习，也就是不需要事先给出分类标签，而 KNN 是有监督学习，需要我们给出训练数据的分类标识。</p>
<p>最后，K 值的含义不同。K-Means 中的 K 值代表 K 类。KNN 中的 K 值代表 K 个最接近的邻居。</p>
<p>那么学完了今天的内容后，你能说一下 K-Means 的算法原理吗？如果我们把上面的 20 支亚洲球队用 K-Means 划分成 5 类，在规范化数据的时候采用标准化的方式（即均值为 0，方差为 1），该如何编写程序呢？运行的结果又是如何？</p>
<p>欢迎你在评论区与我分享你的答案，也欢迎点击“请朋友读”，把这篇文章分享给你的朋友或者同事。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/">数据分析实战45讲</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%AE%9E%E6%88%9830%E8%AE%B2/2724%E4%B8%A8kafka%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E4%B9%8B%E9%98%9F%E5%88%97%E7%BA%A7%E7%9B%91%E6%8E%A7%E5%8F%8A%E5%B8%B8%E7%94%A8%E8%AE%A1%E6%95%B0%E5%99%A8%E8%A7%A3%E6%9E%90/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">2724丨Kafka性能监控工具之队列级监控及常用计数器解析</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/sql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/2726%E4%B8%A8%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%88%99%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E7%B4%A2%E5%BC%95%E8%AE%A9sql%E6%9F%A5%E8%AF%A2%E6%95%88%E7%8E%87%E6%9C%80%E5%A4%A7%E5%8C%96/">
            <span class="next-text nav-default">2726丨索引的使用原则如何通过索引让SQL查询效率最大化</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

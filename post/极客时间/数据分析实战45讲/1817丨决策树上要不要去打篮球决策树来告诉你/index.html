<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>1817丨决策树上要不要去打篮球决策树来告诉你 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="17 丨决策树（上）：要不要去打篮球？决策树来告诉你
想象一下一个女孩的妈妈给她介绍男朋友的场景：
女儿：长的帅不帅？
妈妈：挺帅的。
女儿：有没有房子？
妈妈：在老家有一个。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/1817%E4%B8%A8%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8A%E8%A6%81%E4%B8%8D%E8%A6%81%E5%8E%BB%E6%89%93%E7%AF%AE%E7%90%83%E5%86%B3%E7%AD%96%E6%A0%91%E6%9D%A5%E5%91%8A%E8%AF%89%E4%BD%A0/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/1817%E4%B8%A8%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8A%E8%A6%81%E4%B8%8D%E8%A6%81%E5%8E%BB%E6%89%93%E7%AF%AE%E7%90%83%E5%86%B3%E7%AD%96%E6%A0%91%E6%9D%A5%E5%91%8A%E8%AF%89%E4%BD%A0/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="1817丨决策树上要不要去打篮球决策树来告诉你">
  <meta property="og:description" content="17 丨决策树（上）：要不要去打篮球？决策树来告诉你
想象一下一个女孩的妈妈给她介绍男朋友的场景：
女儿：长的帅不帅？
妈妈：挺帅的。
女儿：有没有房子？
妈妈：在老家有一个。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="数据分析实战45讲">

  <meta itemprop="name" content="1817丨决策树上要不要去打篮球决策树来告诉你">
  <meta itemprop="description" content="17 丨决策树（上）：要不要去打篮球？决策树来告诉你
想象一下一个女孩的妈妈给她介绍男朋友的场景：
女儿：长的帅不帅？
妈妈：挺帅的。
女儿：有没有房子？
妈妈：在老家有一个。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="5509">
  <meta itemprop="keywords" content="数据分析实战45讲">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="1817丨决策树上要不要去打篮球决策树来告诉你">
  <meta name="twitter:description" content="17 丨决策树（上）：要不要去打篮球？决策树来告诉你
想象一下一个女孩的妈妈给她介绍男朋友的场景：
女儿：长的帅不帅？
妈妈：挺帅的。
女儿：有没有房子？
妈妈：在老家有一个。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">1817丨决策树上要不要去打篮球决策树来告诉你</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 5509 字 </span>
          <span class="more-meta"> 预计阅读 11 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents"></nav>
  </div>
</div>
    <div class="post-content">
      <p>17 丨决策树（上）：要不要去打篮球？决策树来告诉你</p>
<p>想象一下一个女孩的妈妈给她介绍男朋友的场景：</p>
<p>女儿：长的帅不帅？</p>
<p>妈妈：挺帅的。</p>
<p>女儿：有没有房子？</p>
<p>妈妈：在老家有一个。</p>
<p>女儿：收入高不高？</p>
<p>妈妈：还不错，年薪百万。</p>
<p>女儿：做什么工作的？</p>
<p>妈妈：IT 男，互联网公司做数据挖掘的。</p>
<p>女儿：好，那我见见。</p>
<p>在现实生活中，我们会遇到各种选择，不论是选择男女朋友，还是挑选水果，都是基于以往的经验来做判断。如果把判断背后的逻辑整理成一个结构图，你会发现它实际上是一个树状图，这就是我们今天要讲的决策树。</p>
<p>决策树的工作原理</p>
<p>决策树基本上就是把我们以前的经验总结出来。我给你准备了一个打篮球的训练集。如果我们要出门打篮球，一般会根据“天气”、“温度”、“湿度”、“刮风”这几个条件来判断，最后得到结果：去打篮球？还是不去？</p>
<p>上面这个图就是一棵典型的决策树。我们在做决策树的时候，会经历两个阶段：构造和剪枝。</p>
<p>构造</p>
<p>什么是构造呢？构造就是生成一棵完整的决策树。简单来说，构造的过程就是选择什么属性作为节点的过程，那么在构造过程中，会存在三种节点：</p>
<p>根节点：就是树的最顶端，最开始的那个节点。在上图中，“天气”就是一个根节点；</p>
<p>内部节点：就是树中间的那些节点，比如说“温度”、“湿度”、“刮风”；</p>
<p>叶节点：就是树最底部的节点，也就是决策结果。</p>
<p>节点之间存在父子关系。比如根节点会有子节点，子节点会有子子节点，但是到了叶节点就停止了，叶节点不存在子节点。那么在构造过程中，你要解决三个重要的问题：</p>
<p>选择哪个属性作为根节点；</p>
<p>选择哪些属性作为子节点；</p>
<p>什么时候停止并得到目标状态，即叶节点。</p>
<p>剪枝</p>
<p>决策树构造出来之后是不是就万事大吉了呢？也不尽然，我们可能还需要对决策树进行剪枝。剪枝就是给决策树瘦身，这一步想实现的目标就是，不需要太多的判断，同样可以得到不错的结果。之所以这么做，是为了防止“过拟合”（Overfitting）现象的发生。</p>
<p>“过拟合”这个概念你一定要理解，它指的就是模型的训练结果“太好了”，以至于在实际应用的过程中，会存在“死板”的情况，导致分类错误。</p>
<p>欠拟合，和过拟合就好比是下面这张图中的第一个和第三个情况一样，训练的结果“太好“，反而在实际应用过程中会导致分类错误。</p>
<p>造成过拟合的原因之一就是因为训练集中样本量较小。如果决策树选择的属性过多，构造出来的决策树一定能够“完美”地把训练集中的样本分类，但是这样就会把训练集中一些数据的特点当成所有数据的特点，但这个特点不一定是全部数据的特点，这就使得这个决策树在真实的数据分类中出现错误，也就是模型的“泛化能力”差。</p>
<p>泛化能力指的分类器是通过训练集抽象出来的分类能力，你也可以理解是举一反三的能力。如果我们太依赖于训练集的数据，那么得到的决策树容错率就会比较低，泛化能力差。因为训练集只是全部数据的抽样，并不能体现全部数据的特点。</p>
<p>既然要对决策树进行剪枝，具体有哪些方法呢？一般来说，剪枝可以分为“预剪枝”（Pre-Pruning）和“后剪枝”（Post-Pruning）。</p>
<p>预剪枝是在决策树构造时就进行剪枝。方法是在构造的过程中对节点进行评估，如果对某个节点进行划分，在验证集中不能带来准确性的提升，那么对这个节点进行划分就没有意义，这时就会把当前节点作为叶节点，不对其进行划分。</p>
<p>后剪枝就是在生成决策树之后再进行剪枝，通常会从决策树的叶节点开始，逐层向上对每个节点进行评估。如果剪掉这个节点子树，与保留该节点子树在分类准确性上差别不大，或者剪掉该节点子树，能在验证集中带来准确性的提升，那么就可以把该节点子树进行剪枝。方法是：用这个节点子树的叶子节点来替代该节点，类标记为这个节点子树中最频繁的那个类。</p>
<p>如何判断要不要去打篮球？</p>
<p>我给你准备了打篮球的数据集，训练数据如下：</p>
<p>我们该如何构造一个判断是否去打篮球的决策树呢？再回顾一下决策树的构造原理，在决策过程中有三个重要的问题：将哪个属性作为根节点？选择哪些属性作为后继节点？什么时候停止并得到目标值？</p>
<p>显然将哪个属性（天气、温度、湿度、刮风）作为根节点是个关键问题，在这里我们先介绍两个指标：纯度和信息熵。</p>
<p>先来说一下纯度。你可以把决策树的构造过程理解成为寻找纯净划分的过程。数学上，我们可以用纯度来表示，纯度换一种方式来解释就是让目标变量的分歧最小。</p>
<p>我在这里举个例子，假设有 3 个集合：</p>
<p>集合 1：6 次都去打篮球；</p>
<p>集合 2：4 次去打篮球，2 次不去打篮球；</p>
<p>集合 3：3 次去打篮球，3 次不去打篮球。</p>
<p>按照纯度指标来说，集合 1&gt; 集合 2&gt; 集合 3。因为集合 1 的分歧最小，集合 3 的分歧最大。</p>
<p>然后我们再来介绍信息熵（entropy）的概念，它表示了信息的不确定度。</p>
<p>在信息论中，随机离散事件出现的概率存在着不确定性。为了衡量这种信息的不确定性，信息学之父香农引入了信息熵的概念，并给出了计算信息熵的数学公式：</p>
<p>p(i|t) 代表了节点 t 为分类 i 的概率，其中 log2 为取以 2 为底的对数。这里我们不是来介绍公式的，而是说存在一种度量，它能帮我们反映出来这个信息的不确定度。当不确定性越大时，它所包含的信息量也就越大，信息熵也就越高。</p>
<p>我举个简单的例子，假设有 2 个集合</p>
<p>集合 1：5 次去打篮球，1 次不去打篮球；</p>
<p>集合 2：3 次去打篮球，3 次不去打篮球。</p>
<p>在集合 1 中，有 6 次决策，其中打篮球是 5 次，不打篮球是 1 次。那么假设：类别 1 为“打篮球”，即次数为 5；类别 2 为“不打篮球”，即次数为 1。那么节点划分为类别 1 的概率是 5/6，为类别 2 的概率是 1/6，带入上述信息熵公式可以计算得出：</p>
<p>同样，集合 2 中，也是一共 6 次决策，其中类别 1 中“打篮球”的次数是 3，类别 2“不打篮球”的次数也是 3，那么信息熵为多少呢？我们可以计算得出：</p>
<p>从上面的计算结果中可以看出，信息熵越大，纯度越低。当集合中的所有样本均匀混合时，信息熵最大，纯度最低。</p>
<p>我们在构造决策树的时候，会基于纯度来构建。而经典的 “不纯度”的指标有三种，分别是信息增益（ID3 算法）、信息增益率（C4.5 算法）以及基尼指数（Cart 算法）。</p>
<p>我们先看下 ID3 算法。ID3 算法计算的是信息增益，信息增益指的就是划分可以带来纯度的提高，信息熵的下降。它的计算公式，是父亲节点的信息熵减去所有子节点的信息熵。在计算的过程中，我们会计算每个子节点的归一化信息熵，即按照每个子节点在父节点中出现的概率，来计算这些子节点的信息熵。所以信息增益的公式可以表示为：</p>
<p>公式中 D 是父亲节点，Di 是子节点，Gain(D,a) 中的 a 作为 D 节点的属性选择。</p>
<p>假设天气 = 晴的时候，会有 5 次去打篮球，5 次不打篮球。其中 D1 刮风 = 是，有 2 次打篮球，1 次不打篮球。D2 刮风 = 否，有 3 次打篮球，4 次不打篮球。那么 a 代表节点的属性，即天气 = 晴。</p>
<p>你可以在下面的图例中直观地了解这几个概念。</p>
<p>比如针对图上这个例子，D 作为节点的信息增益为：</p>
<p>也就是 D 节点的信息熵 -2 个子节点的归一化信息熵。2 个子节点归一化信息熵 =3/10 的 D1 信息熵 +7/10 的 D2 信息熵。</p>
<p>我们基于 ID3 的算法规则，完整地计算下我们的训练集，训练集中一共有 7 条数据，3 个打篮球，4 个不打篮球，所以根节点的信息熵是：</p>
<p>如果你将天气作为属性的划分，会有三个叶子节点 D1、D2 和 D3，分别对应的是晴天、阴天和小雨。我们用 + 代表去打篮球，- 代表不去打篮球。那么第一条记录，晴天不去打篮球，可以记为 1-，于是我们可以用下面的方式来记录 D1，D2，D3：</p>
<p>D1(天气 = 晴天)={1-,2-,6+}</p>
<p>D2(天气 = 阴天)={3+,7-}</p>
<p>D3(天气 = 小雨)={4+,5-}</p>
<p>我们先分别计算三个叶子节点的信息熵：</p>
<p>因为 D1 有 3 个记录，D2 有 2 个记录，D3 有 2 个记录，所以 D 中的记录一共是 3+2+2=7，即总数为 7。所以 D1 在 D（父节点）中的概率是 3/7，D2 在父节点的概率是 2/7，D3 在父节点的概率是 2/7。那么作为子节点的归一化信息熵 = 3/7*0.918+2/7*1.0+2/7*1.0=0.965。</p>
<p>因为我们用 ID3 中的信息增益来构造决策树，所以要计算每个节点的信息增益。</p>
<p>天气作为属性节点的信息增益为，Gain(D , 天气)=0.985-0.965=0.020。。</p>
<p>同理我们可以计算出其他属性作为根节点的信息增益，它们分别为 ：</p>
<p>Gain(D , 温度)=0.128Gain(D , 湿度)=0.020Gain(D , 刮风)=0.020</p>
<p>我们能看出来温度作为属性的信息增益最大。因为 ID3 就是要将信息增益最大的节点作为父节点，这样可以得到纯度高的决策树，所以我们将温度作为根节点。其决策树状图分裂为下图所示：</p>
<p>然后我们要将上图中第一个叶节点，也就是 D1={1-,2-,3+,4+}进一步进行分裂，往下划分，计算其不同属性（天气、湿度、刮风）作为节点的信息增益，可以得到：</p>
<p>Gain(D , 天气)=0</p>
<p>Gain(D , 湿度)=0</p>
<p>Gain(D , 刮风)=0.0615</p>
<p>我们能看到刮风为 D1 的节点都可以得到最大的信息增益，这里我们选取刮风作为节点。同理，我们可以按照上面的计算步骤得到完整的决策树，结果如下：</p>
<p>于是我们通过 ID3 算法得到了一棵决策树。ID3 的算法规则相对简单，可解释性强。同样也存在缺陷，比如我们会发现 ID3 算法倾向于选择取值比较多的属性。这样，如果我们把“编号”作为一个属性（一般情况下不会这么做，这里只是举个例子），那么“编号”将会被选为最优属性 。但实际上“编号”是无关属性的，它对“打篮球”的分类并没有太大作用。</p>
<p>所以 ID3 有一个缺陷就是，有些属性可能对分类任务没有太大作用，但是他们仍然可能会被选为最优属性。这种缺陷不是每次都会发生，只是存在一定的概率。在大部分情况下，ID3 都能生成不错的决策树分类。针对可能发生的缺陷，后人提出了新的算法进行改进。</p>
<p>在 ID3 算法上进行改进的 C4.5 算法</p>
<p>那么 C4.5 都在哪些方面改进了 ID3 呢？</p>
<p>1. 采用信息增益率</p>
<p>因为 ID3 在计算的时候，倾向于选择取值多的属性。为了避免这个问题，C4.5 采用信息增益率的方式来选择属性。信息增益率 = 信息增益 / 属性熵，具体的计算公式这里省略。</p>
<p>当属性有很多值的时候，相当于被划分成了许多份，虽然信息增益变大了，但是对于 C4.5 来说，属性熵也会变大，所以整体的信息增益率并不大。</p>
<p>2. 采用悲观剪枝</p>
<p>ID3 构造决策树的时候，容易产生过拟合的情况。在 C4.5 中，会在决策树构造之后采用悲观剪枝（PEP），这样可以提升决策树的泛化能力。</p>
<p>悲观剪枝是后剪枝技术中的一种，通过递归估算每个内部节点的分类错误率，比较剪枝前后这个节点的分类错误率来决定是否对其进行剪枝。这种剪枝方法不再需要一个单独的测试数据集。</p>
<p>3. 离散化处理连续属性</p>
<p>C4.5 可以处理连续属性的情况，对连续的属性进行离散化的处理。比如打篮球存在的“湿度”属性，不按照“高、中”划分，而是按照湿度值进行计算，那么湿度取什么值都有可能。该怎么选择这个阈值呢，C4.5 选择具有最高信息增益的划分所对应的阈值。</p>
<p>4. 处理缺失值</p>
<p>针对数据集不完整的情况，C4.5 也可以进行处理。</p>
<p>假如我们得到的是如下的数据，你会发现这个数据中存在两点问题。第一个问题是，数据集中存在数值缺失的情况，如何进行属性选择？第二个问题是，假设已经做了属性划分，但是样本在这个属性上有缺失值，该如何对样本进行划分？</p>
<p>我们不考虑缺失的数值，可以得到温度 D={2-,3+,4+,5-,6+,7-}。温度 = 高：D1={2-,3+,4+} ；温度 = 中：D2={6+,7-}；温度 = 低：D3={5-} 。这里 + 号代表打篮球，- 号代表不打篮球。比如 ID=2 时，决策是不打篮球，我们可以记录为 2-。</p>
<p>所以三个叶节点的信息熵可以结算为：</p>
<p>这三个节点的归一化信息熵为 3/6*0.918+2/6*1.0+1/6*0=0.792。</p>
<p>针对将属性选择为温度的信息增益率为：</p>
<p>Gain(D′, 温度)=Ent(D′)-0.792=1.0-0.792=0.208</p>
<p>D′的样本个数为 6，而 D 的样本个数为 7，所以所占权重比例为 6/7，所以 Gain(D′，温度) 所占权重比例为 6/7，所以：</p>
<p>Gain(D, 温度)=6/7*0.208=0.178</p>
<p>这样即使在温度属性的数值有缺失的情况下，我们依然可以计算信息增益，并对属性进行选择。</p>
<p>Cart 算法在这里不做介绍，我会在下一讲给你讲解这个算法。现在我们总结下 ID3 和 C4.5 算法。首先 ID3 算法的优点是方法简单，缺点是对噪声敏感。训练数据如果有少量错误，可能会产生决策树分类错误。C4.5 在 ID3 的基础上，用信息增益率代替了信息增益，解决了噪声敏感的问题，并且可以对构造树进行剪枝、处理连续数值以及数值缺失等情况，但是由于 C4.5 需要对数据集进行多次扫描，算法效率相对较低。</p>
<p>总结</p>
<p>前面我们讲了两种决策树分类算法 ID3 和 C4.5，了解了它们的数学原理。你可能会问，公式这么多，在实际使用中该怎么办呢？实际上，我们可以使用一些数据挖掘工具使用它们，比如 Python 的 sklearn，或者是 Weka（一个免费的数据挖掘工作平台），它们已经集成了这两种算法。只是我们在了解了这两种算法之后，才能更加清楚这两种算法的优缺点。</p>
<p>我们总结下，这次都讲到了哪些知识点呢？</p>
<p>首先我们采用决策树分类，需要了解它的原理，包括它的构造原理、剪枝原理。另外在信息度量上，我们需要了解信息度量中的纯度和信息熵的概念。在决策树的构造中，一个决策树包括根节点、子节点、叶子节点。在属性选择的标准上，度量方法包括了信息增益和信息增益率。在算法上，我讲解了两种算法：ID3 和 C4.5，其中 ID3 是基础的决策树算法，C4.5 在它的基础上进行了改进，也是目前决策树中应用广泛的算法。然后在了解这些概念和原理后，强烈推荐你使用工具，具体工具的使用我会在后面进行介绍。</p>
<p>最后我们留一道思考题吧。请你用下面的例子来模拟下决策树的流程，假设好苹果的数据如下，请用 ID3 算法来给出好苹果的决策树。</p>
<p>如果你觉得这篇文章有所价值，欢迎点击“请朋友读”，把它分享给你的朋友或者同事。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/">数据分析实战45讲</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/python%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8A%9E%E5%85%AC%E5%AE%9E%E6%88%98%E8%AF%BE/1813excel%E6%8F%92%E4%BB%B6%E5%A6%82%E4%BD%95%E6%89%A9%E5%B1%95excel%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">1813｜Excel插件如何扩展Excel的基本功能</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/sql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/1817%E4%B8%A8%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8python%E6%93%8D%E4%BD%9Cmysql/">
            <span class="next-text nav-default">1817丨如何使用Python操作MySQL</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

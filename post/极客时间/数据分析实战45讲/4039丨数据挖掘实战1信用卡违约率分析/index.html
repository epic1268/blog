<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>4039丨数据挖掘实战（1）：信用卡违约率分析 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="39丨数据挖掘实战（1）：信用卡违约率分析
今天我来带你做一个数据挖掘的项目。在数据挖掘的过程中，我们经常会遇到一些问题，比如：如何选择各种分类器，到底选择哪个分类算法，是 SVM，决策树，还是 KNN？如何优化分类器的参数，以便得到更好的分类准确率？
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/4039%E4%B8%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%981%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%BF%9D%E7%BA%A6%E7%8E%87%E5%88%86%E6%9E%90/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/4039%E4%B8%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%981%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%BF%9D%E7%BA%A6%E7%8E%87%E5%88%86%E6%9E%90/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="4039丨数据挖掘实战（1）：信用卡违约率分析">
  <meta property="og:description" content="39丨数据挖掘实战（1）：信用卡违约率分析
今天我来带你做一个数据挖掘的项目。在数据挖掘的过程中，我们经常会遇到一些问题，比如：如何选择各种分类器，到底选择哪个分类算法，是 SVM，决策树，还是 KNN？如何优化分类器的参数，以便得到更好的分类准确率？">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="数据分析实战45讲">

  <meta itemprop="name" content="4039丨数据挖掘实战（1）：信用卡违约率分析">
  <meta itemprop="description" content="39丨数据挖掘实战（1）：信用卡违约率分析
今天我来带你做一个数据挖掘的项目。在数据挖掘的过程中，我们经常会遇到一些问题，比如：如何选择各种分类器，到底选择哪个分类算法，是 SVM，决策树，还是 KNN？如何优化分类器的参数，以便得到更好的分类准确率？">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="3454">
  <meta itemprop="keywords" content="数据分析实战45讲">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="4039丨数据挖掘实战（1）：信用卡违约率分析">
  <meta name="twitter:description" content="39丨数据挖掘实战（1）：信用卡违约率分析
今天我来带你做一个数据挖掘的项目。在数据挖掘的过程中，我们经常会遇到一些问题，比如：如何选择各种分类器，到底选择哪个分类算法，是 SVM，决策树，还是 KNN？如何优化分类器的参数，以便得到更好的分类准确率？">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">4039丨数据挖掘实战（1）：信用卡违约率分析</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 3454 字 </span>
          <span class="more-meta"> 预计阅读 7 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents"></nav>
  </div>
</div>
    <div class="post-content">
      <p>39丨数据挖掘实战（1）：信用卡违约率分析</p>
<p>今天我来带你做一个数据挖掘的项目。在数据挖掘的过程中，我们经常会遇到一些问题，比如：如何选择各种分类器，到底选择哪个分类算法，是 SVM，决策树，还是 KNN？如何优化分类器的参数，以便得到更好的分类准确率？</p>
<p>这两个问题，是数据挖掘核心的问题。当然对于一个新的项目，我们还有其他的问题需要了解，比如掌握数据探索和数据可视化的方式，还需要对数据的完整性和质量做评估。这些内容我在之前的课程中都有讲到过。</p>
<p>今天的学习主要围绕下面的三个目标，并通过它们完成信用卡违约率项目的实战，这三个目标分别是：</p>
<p>创建各种分类器，包括已经掌握的 SVM、决策树、KNN 分类器，以及随机森林分类器；</p>
<p>掌握 GridSearchCV 工具，优化算法模型的参数；</p>
<p>使用 Pipeline 管道机制进行流水线作业。因为在做分类之前，我们还需要一些准备过程，比如数据规范化，或者数据降维等。</p>
<p>构建随机森林分类器</p>
<p>在算法篇中，我主要讲了数据挖掘十大经典算法。实际工作中，你也可能会用到随机森林。</p>
<p>随机森林的英文是 Random Forest，英文简写是 RF。它实际上是一个包含多个决策树的分类器，每一个子分类器都是一棵 CART 分类回归树。所以随机森林既可以做分类，又可以做回归。当它做分类的时候，输出结果是每个子分类器的分类结果中最多的那个。你可以理解是每个分类器都做投票，取投票最多的那个结果。当它做回归的时候，输出结果是每棵 CART 树的回归结果的平均值。</p>
<p>在 sklearn 中，我们使用 RandomForestClassifier() 构造随机森林模型，函数里有一些常用的构造参数：</p>
<p>当我们创建好之后，就可以使用 fit 函数拟合，使用 predict 函数预测。</p>
<p>使用 GridSearchCV 工具对模型参数进行调优</p>
<p>在做分类算法的时候，我们需要经常调节网络参数（对应上面的构造参数），目的是得到更好的分类结果。实际上一个分类算法有很多参数，取值范围也比较广，那么该如何调优呢？</p>
<p>Python 给我们提供了一个很好用的工具 GridSearchCV，它是 Python 的参数自动搜索模块。我们只要告诉它想要调优的参数有哪些以及参数的取值范围，它就会把所有的情况都跑一遍，然后告诉我们哪个参数是最优的，结果如何。</p>
<p>使用 GridSearchCV 模块需要先引用工具包，方法如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">from sklearn.model_selection import GridSearchCV
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后我们使用 GridSearchCV(estimator, param_grid, cv=None, scoring=None) 构造参数的自动搜索模块，这里有一些主要的参数需要说明下：</p>
<p>构造完 GridSearchCV 之后，我们就可以使用 fit 函数拟合训练，使用 predict 函数预测，这时预测采用的是最优参数情况下的分类器。</p>
<p>这里举一个简单的例子，我们用 sklearn 自带的 IRIS 数据集，采用随机森林对 IRIS 数据分类。假设我们想知道 n_estimators 在 1-10 的范围内取哪个值的分类结果最好，可以编写代码：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># -*- coding: utf-8 -*-</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 RandomForest 对 IRIS 数据集进行分类</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 利用 GridSearchCV 寻找最优参数</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span> <span class="n">import</span> <span class="n">RandomForestClassifier</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span> <span class="n">import</span> <span class="n">GridSearchCV</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span> <span class="n">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl"><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;n_estimators&#34;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)}</span>
</span></span><span class="line"><span class="cl"><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 GridSearchCV 进行参数调优</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">rf</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 对 iris 数据集进行分类</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34; 最优分数： </span><span class="si">%.4lf</span><span class="s2">&#34;</span> <span class="o">%</span><span class="n">clf</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34; 最优参数：&#34;</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="err">运行结果如下：</span>
</span></span><span class="line"><span class="cl"><span class="err">最优分数：</span> <span class="mf">0.9667</span>
</span></span><span class="line"><span class="cl"><span class="err">最优参数：</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>你能看到当我们采用随机森林作为分类器的时候，最优准确率是 0.9667，当 n_estimators=6 的时候，是最优参数，也就是随机森林一共有 6 个子决策树。</p>
<p>使用 Pipeline 管道机制进行流水线作业</p>
<p>做分类的时候往往都是有步骤的，比如先对数据进行规范化处理，你也可以用 PCA 方法（一种常用的降维方法）对数据降维，最后使用分类器分类。</p>
<p>Python 有一种 Pipeline 管道机制。管道机制就是让我们把每一步都按顺序列下来，从而创建 Pipeline 流水线作业。每一步都采用 (‘名称’, 步骤) 的方式来表示。</p>
<p>我们需要先采用 StandardScaler 方法对数据规范化，即采用数据规范化为均值为 0，方差为 1 的正态分布，然后采用 PCA 方法对数据进行降维，最后采用随机森林进行分类。</p>
<p>具体代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">from sklearn.model_selection import GridSearchCV
</span></span><span class="line"><span class="cl">pipeline = Pipeline([
</span></span><span class="line"><span class="cl">        (&#39;scaler&#39;, StandardScaler()),
</span></span><span class="line"><span class="cl">        (&#39;pca&#39;, PCA()),
</span></span><span class="line"><span class="cl">        (&#39;randomforestclassifier&#39;, RandomForestClassifier())
</span></span><span class="line"><span class="cl">])
</span></span></code></pre></td></tr></table>
</div>
</div><p>那么我们现在采用 Pipeline 管道机制，用随机森林对 IRIS 数据集做一下分类。先用 StandardScaler 方法对数据规范化，然后再用随机森林分类，编写代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># -*- coding: utf-8 -*-</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 RandomForest 对 IRIS 数据集进行分类</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 利用 GridSearchCV 寻找最优参数, 使用 Pipeline 进行流水作业</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span> <span class="n">import</span> <span class="n">RandomForestClassifier</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span> <span class="n">import</span> <span class="n">GridSearchCV</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span> <span class="n">import</span> <span class="n">load_iris</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span> <span class="n">import</span> <span class="n">StandardScaler</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">pipeline</span> <span class="n">import</span> <span class="n">Pipeline</span>
</span></span><span class="line"><span class="cl"><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;randomforestclassifier__n_estimators&#34;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)}</span>
</span></span><span class="line"><span class="cl"><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
</span></span><span class="line"><span class="cl">        <span class="p">(</span><span class="s1">&#39;randomforestclassifier&#39;</span><span class="p">,</span> <span class="n">rf</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 GridSearchCV 进行参数调优</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 对 iris 数据集进行分类</span>
</span></span><span class="line"><span class="cl"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34; 最优分数： </span><span class="si">%.4lf</span><span class="s2">&#34;</span> <span class="o">%</span><span class="n">clf</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34; 最优参数：&#34;</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="err">运行结果：</span>
</span></span><span class="line"><span class="cl"><span class="err">最优分数：</span> <span class="mf">0.9667</span>
</span></span><span class="line"><span class="cl"><span class="err">最优参数：</span> <span class="p">{</span><span class="s1">&#39;randomforestclassifier__n_estimators&#39;</span><span class="p">:</span> <span class="mi">9</span><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>你能看到是否采用数据规范化对结果还是有一些影响的，有了 GridSearchCV 和 Pipeline 这两个工具之后，我们在使用分类器的时候就会方便很多。</p>
<p>对信用卡违约率进行分析</p>
<p>我们现在来做一个信用卡违约率的项目，这个数据集你可以从 GitHub 上下载：https://github.com/cystanford/credit_default。</p>
<p>这个数据集是台湾某银行 2005 年 4 月到 9 月的信用卡数据，数据集一共包括 25 个字段，具体含义如下：</p>
<p>现在我们的目标是要针对这个数据集构建一个分析信用卡违约率的分类器。具体选择哪个分类器，以及分类器的参数如何优化，我们可以用 GridSearchCV 这个工具跑一遍。</p>
<p>先梳理下整个项目的流程：</p>
<p>加载数据；</p>
<p>准备阶段：探索数据，采用数据可视化方式可以让我们对数据有更直观的了解，比如我们想要了解信用卡违约率和不违约率的人数。因为数据集没有专门的测试集，我们还需要使用 train_test_split 划分数据集。</p>
<p>分类阶段：之所以把数据规范化放到这个阶段，是因为我们可以使用 Pipeline 管道机制，将数据规范化设置为第一步，分类为第二步。因为我们不知道采用哪个分类器效果好，所以我们需要多用几个分类器，比如 SVM、决策树、随机森林和 KNN。然后通过 GridSearchCV 工具，找到每个分类器的最优参数和最优分数，最终找到最适合这个项目的分类器和该分类器的参数。</p>
<p>基于上面的流程，具体代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># -*- coding: utf-8 -*-
</span></span><span class="line"><span class="cl"># 信用卡违约率分析
</span></span><span class="line"><span class="cl">import pandas as pd
</span></span><span class="line"><span class="cl">from sklearn.model_selection import learning_curve, train_test_split,GridSearchCV
</span></span><span class="line"><span class="cl">from sklearn.preprocessing import StandardScaler
</span></span><span class="line"><span class="cl">from sklearn.pipeline import Pipeline
</span></span><span class="line"><span class="cl">from sklearn.metrics import accuracy_score
</span></span><span class="line"><span class="cl">from sklearn.svm import SVC
</span></span><span class="line"><span class="cl">from sklearn.tree import DecisionTreeClassifier
</span></span><span class="line"><span class="cl">from sklearn.ensemble import RandomForestClassifier
</span></span><span class="line"><span class="cl">from sklearn.neighbors import KNeighborsClassifier
</span></span><span class="line"><span class="cl">from matplotlib import pyplot as plt
</span></span><span class="line"><span class="cl">import seaborn as sns
</span></span><span class="line"><span class="cl"># 数据加载
</span></span><span class="line"><span class="cl">data = data = pd.read_csv(&#39;./UCI_Credit_Card.csv&#39;)
</span></span><span class="line"><span class="cl"># 数据探索
</span></span><span class="line"><span class="cl">print(data.shape) # 查看数据集大小
</span></span><span class="line"><span class="cl">print(data.describe()) # 数据集概览
</span></span><span class="line"><span class="cl"># 查看下一个月违约率的情况
</span></span><span class="line"><span class="cl">next_month = data[&#39;default.payment.next.month&#39;].value_counts()
</span></span><span class="line"><span class="cl">print(next_month)
</span></span><span class="line"><span class="cl">df = pd.DataFrame({&#39;default.payment.next.month&#39;: next_month.index,&#39;values&#39;: next_month.values})
</span></span><span class="line"><span class="cl">plt.rcParams[&#39;font.sans-serif&#39;]=[&#39;SimHei&#39;] # 用来正常显示中文标签
</span></span><span class="line"><span class="cl">plt.figure(figsize = (6,6))
</span></span><span class="line"><span class="cl">plt.title(&#39;信用卡违约率客户\n (违约：1，守约：0)&#39;)
</span></span><span class="line"><span class="cl">sns.set_color_codes(&#34;pastel&#34;)
</span></span><span class="line"><span class="cl">sns.barplot(x = &#39;default.payment.next.month&#39;, y=&#34;values&#34;, data=df)
</span></span><span class="line"><span class="cl">locs, labels = plt.xticks()
</span></span><span class="line"><span class="cl">plt.show()
</span></span><span class="line"><span class="cl"># 特征选择，去掉 ID 字段、最后一个结果字段即可
</span></span><span class="line"><span class="cl">data.drop([&#39;ID&#39;], inplace=True, axis =1) #ID 这个字段没有用
</span></span><span class="line"><span class="cl">target = data[&#39;default.payment.next.month&#39;].values
</span></span><span class="line"><span class="cl">columns = data.columns.tolist()
</span></span><span class="line"><span class="cl">columns.remove(&#39;default.payment.next.month&#39;)
</span></span><span class="line"><span class="cl">features = data[columns].values
</span></span><span class="line"><span class="cl"># 30% 作为测试集，其余作为训练集
</span></span><span class="line"><span class="cl">train_x, test_x, train_y, test_y = train_test_split(features, target, test_size=0.30, stratify = target, random_state = 1)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 构造各种分类器
</span></span><span class="line"><span class="cl">classifiers = [
</span></span><span class="line"><span class="cl">    SVC(random_state = 1, kernel = &#39;rbf&#39;),    
</span></span><span class="line"><span class="cl">    DecisionTreeClassifier(random_state = 1, criterion = &#39;gini&#39;),
</span></span><span class="line"><span class="cl">    RandomForestClassifier(random_state = 1, criterion = &#39;gini&#39;),
</span></span><span class="line"><span class="cl">    KNeighborsClassifier(metric = &#39;minkowski&#39;),
</span></span><span class="line"><span class="cl">]
</span></span><span class="line"><span class="cl"># 分类器名称
</span></span><span class="line"><span class="cl">classifier_names = [
</span></span><span class="line"><span class="cl">            &#39;svc&#39;, 
</span></span><span class="line"><span class="cl">            &#39;decisiontreeclassifier&#39;,
</span></span><span class="line"><span class="cl">            &#39;randomforestclassifier&#39;,
</span></span><span class="line"><span class="cl">            &#39;kneighborsclassifier&#39;,
</span></span><span class="line"><span class="cl">]
</span></span><span class="line"><span class="cl"># 分类器参数
</span></span><span class="line"><span class="cl">classifier_param_grid = [
</span></span><span class="line"><span class="cl">            {&#39;svc__C&#39;:[1], &#39;svc__gamma&#39;:[0.01]},
</span></span><span class="line"><span class="cl">            {&#39;decisiontreeclassifier__max_depth&#39;:[6,9,11]},
</span></span><span class="line"><span class="cl">            {&#39;randomforestclassifier__n_estimators&#39;:[3,5,6]} ,
</span></span><span class="line"><span class="cl">            {&#39;kneighborsclassifier__n_neighbors&#39;:[4,6,8]},
</span></span><span class="line"><span class="cl">]
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 对具体的分类器进行 GridSearchCV 参数调优
</span></span><span class="line"><span class="cl">def GridSearchCV_work(pipeline, train_x, train_y, test_x, test_y, param_grid, score = &#39;accuracy&#39;):
</span></span><span class="line"><span class="cl">    response = {}
</span></span><span class="line"><span class="cl">    gridsearch = GridSearchCV(estimator = pipeline, param_grid = param_grid, scoring = score)
</span></span><span class="line"><span class="cl">    # 寻找最优的参数 和最优的准确率分数
</span></span><span class="line"><span class="cl">    search = gridsearch.fit(train_x, train_y)
</span></span><span class="line"><span class="cl">    print(&#34;GridSearch 最优参数：&#34;, search.best_params_)
</span></span><span class="line"><span class="cl">    print(&#34;GridSearch 最优分数： %0.4lf&#34; %search.best_score_)
</span></span><span class="line"><span class="cl">	predict_y = gridsearch.predict(test_x)
</span></span><span class="line"><span class="cl">    print(&#34; 准确率 %0.4lf&#34; %accuracy_score(test_y, predict_y))
</span></span><span class="line"><span class="cl">    response[&#39;predict_y&#39;] = predict_y
</span></span><span class="line"><span class="cl">    response[&#39;accuracy_score&#39;] = accuracy_score(test_y,predict_y)
</span></span><span class="line"><span class="cl">    return response
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">for model, model_name, model_param_grid in zip(classifiers, classifier_names, classifier_param_grid):
</span></span><span class="line"><span class="cl">    pipeline = Pipeline([
</span></span><span class="line"><span class="cl">            (&#39;scaler&#39;, StandardScaler()),
</span></span><span class="line"><span class="cl">            (model_name, model)
</span></span><span class="line"><span class="cl">    ])
</span></span><span class="line"><span class="cl">    result = GridSearchCV_work(pipeline, train_x, train_y, test_x, test_y, model_param_grid , score = &#39;accuracy&#39;)
</span></span></code></pre></td></tr></table>
</div>
</div><p>运行结果：
(30000, 25)
                 ID             &hellip;              default.payment.next.month
count  30000.000000             &hellip;                            30000.000000
mean   15000.500000             &hellip;                                0.221200
std     8660.398374             &hellip;                                0.415062
min        1.000000             &hellip;                                0.000000
25%     7500.750000             &hellip;                                0.000000
50%    15000.500000             &hellip;                                0.000000
75%    22500.250000             &hellip;                                0.000000
max    30000.000000             &hellip;                                1.000000</p>
<p>[8 rows x 25 columns]</p>
<p>GridSearch 最优参数： {&lsquo;svc__C&rsquo;: 1, &lsquo;svc__gamma&rsquo;: 0.01}
GridSearch 最优分数： 0.8174
准确率 0.8172
GridSearch 最优参数： {&lsquo;decisiontreeclassifier__max_depth&rsquo;: 6}
GridSearch 最优分数： 0.8186
准确率 0.8113
GridSearch 最优参数： {&lsquo;randomforestclassifier__n_estimators&rsquo;: 6}
GridSearch 最优分数： 0.7998
准确率 0.7994
GridSearch 最优参数： {&lsquo;kneighborsclassifier__n_neighbors&rsquo;: 8}
GridSearch 最优分数： 0.8040
准确率 0.8036</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">从结果中，我们能看到 SVM 分类器的准确率最高，测试准确率为 0.8172。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">在决策树分类中，我设置了 3 种最大深度，当最大深度 =6 时结果最优，测试准确率为 0.8113；在随机森林分类中，我设置了 3 个决策树个数的取值，取值为 6 时结果最优，测试准确率为 0.7994；在 KNN 分类中，我设置了 3 个 n 的取值，取值为 8 时结果最优，测试准确率为 0.8036。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">总结
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">今天我给你讲了随机森林的概念及工具的使用，另外针对数据挖掘算法中经常采用的参数调优，也介绍了 GridSearchCV 工具这个利器。并将这两者结合起来，在信用卡违约分析这个项目中进行了使用。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">很多时候，我们不知道该采用哪种分类算法更适合。即便是对于一种分类算法，也有很多参数可以调优，每个参数都有一定的取值范围。我们可以把想要采用的分类器，以及这些参数的取值范围都设置到数组里，然后使用 GridSearchCV 工具进行调优。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">今天我们讲了如何使用 GridSearchCV 做参数调优，你可以说说你的理解，如果有使用的经验也可以分享下。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">另外针对信用卡违约率分析这个项目，我们使用了 SVM、决策树、随机森林和 KNN 分类器，你能不能编写代码使用 AdaBoost 分类器做分类呢？其中 n\_estimators 的取值有 10、50、100 三种可能，你可以使用 GridSearchCV 运行看看最优参数是多少，测试准确率是多少？
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">欢迎你在评论区与我分享你的答案，如果有问题也可以写在评论区。如果你觉得这篇文章有价值，欢迎把它分享给你的朋友或者同事。
</span></span></code></pre></td></tr></table>
</div>
</div>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/">数据分析实战45讲</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/sql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/4036%E4%B8%A8websql%E5%A6%82%E4%BD%95%E5%9C%A8h5%E4%B8%AD%E5%AD%98%E5%82%A8%E4%B8%80%E4%B8%AA%E6%9C%AC%E5%9C%B0%E6%95%B0%E6%8D%AE%E5%BA%93/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">4036丨WebSQL如何在H5中存储一个本地数据库</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/4039%E4%B8%A8%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%981%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%BF%9D%E7%BA%A6%E7%8E%87%E5%88%86%E6%9E%90/">
            <span class="next-text nav-default">4039丨数据挖掘实战（1）：信用卡违约率分析</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

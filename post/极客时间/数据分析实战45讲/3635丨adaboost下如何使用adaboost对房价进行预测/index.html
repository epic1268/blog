<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>3635丨AdaBoost下如何使用AdaBoost对房价进行预测 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="35丨AdaBoost（下）：如何使用AdaBoost对房价进行预测？
今天我带你用 AdaBoost 算法做一个实战项目。AdaBoost 不仅可以用于分类问题，还可以用于回归分析。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/3635%E4%B8%A8adaboost%E4%B8%8B%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8adaboost%E5%AF%B9%E6%88%BF%E4%BB%B7%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/3635%E4%B8%A8adaboost%E4%B8%8B%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8adaboost%E5%AF%B9%E6%88%BF%E4%BB%B7%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="3635丨AdaBoost下如何使用AdaBoost对房价进行预测">
  <meta property="og:description" content="35丨AdaBoost（下）：如何使用AdaBoost对房价进行预测？
今天我带你用 AdaBoost 算法做一个实战项目。AdaBoost 不仅可以用于分类问题，还可以用于回归分析。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="数据分析实战45讲">

  <meta itemprop="name" content="3635丨AdaBoost下如何使用AdaBoost对房价进行预测">
  <meta itemprop="description" content="35丨AdaBoost（下）：如何使用AdaBoost对房价进行预测？
今天我带你用 AdaBoost 算法做一个实战项目。AdaBoost 不仅可以用于分类问题，还可以用于回归分析。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="3321">
  <meta itemprop="keywords" content="数据分析实战45讲">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="3635丨AdaBoost下如何使用AdaBoost对房价进行预测">
  <meta name="twitter:description" content="35丨AdaBoost（下）：如何使用AdaBoost对房价进行预测？
今天我带你用 AdaBoost 算法做一个实战项目。AdaBoost 不仅可以用于分类问题，还可以用于回归分析。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">3635丨AdaBoost下如何使用AdaBoost对房价进行预测</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 3321 字 </span>
          <span class="more-meta"> 预计阅读 7 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents"></nav>
  </div>
</div>
    <div class="post-content">
      <p>35丨AdaBoost（下）：如何使用AdaBoost对房价进行预测？</p>
<p>今天我带你用 AdaBoost 算法做一个实战项目。AdaBoost 不仅可以用于分类问题，还可以用于回归分析。</p>
<p>我们先做个简单回忆，什么是分类，什么是回归呢？实际上分类和回归的本质是一样的，都是对未知事物做预测。不同之处在于输出结果的类型，分类输出的是一个离散值，因为物体的分类数有限的，而回归输出的是连续值，也就是在一个区间范围内任何取值都有可能。</p>
<p>这次我们的主要目标是使用 AdaBoost 预测房价，这是一个回归问题。除了对项目进行编码实战外，我希望你能掌握：</p>
<p>AdaBoost 工具的使用，包括使用 AdaBoost 进行分类，以及回归分析。</p>
<p>使用其他的回归工具，比如决策树回归，对比 AdaBoost 回归和决策树回归的结果。</p>
<p>如何使用 AdaBoost 工具</p>
<p>我们可以直接在 sklearn 中使用 AdaBoost。如果我们要用 AdaBoost 进行分类，需要在使用前引用代码：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">from sklearn.ensemble import AdaBoostClassifier
</span></span></code></pre></td></tr></table>
</div>
</div><p>我们之前讲到过，如果你看到了 Classifier 这个类，一般都会对应着 Regressor 类。AdaBoost 也不例外，回归工具包的引用代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">from sklearn.ensemble import AdaBoostRegressor
</span></span></code></pre></td></tr></table>
</div>
</div><p>我们先看下如何在 sklearn 中创建 AdaBoost 分类器。</p>
<p>我们需要使用 AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None) 这个函数，其中有几个比较主要的参数，我分别来讲解下：</p>
<p>base_estimator：代表的是弱分类器。在 AdaBoost 的分类器和回归器中都有这个参数，在 AdaBoost 中默认使用的是决策树，一般我们不需要修改这个参数，当然你也可以指定具体的分类器。</p>
<p>n_estimators：算法的最大迭代次数，也是分类器的个数，每一次迭代都会引入一个新的弱分类器来增加原有的分类器的组合能力。默认是 50。</p>
<p>learning_rate：代表学习率，取值在 0-1 之间，默认是 1.0。如果学习率较小，就需要比较多的迭代次数才能收敛，也就是说学习率和迭代次数是有相关性的。当你调整 learning_rate 的时候，往往也需要调整 n_estimators 这个参数。</p>
<p>algorithm：代表我们要采用哪种 boosting 算法，一共有两种选择：SAMME 和 SAMME.R。默认是 SAMME.R。这两者之间的区别在于对弱分类权重的计算方式不同。</p>
<p>random_state：代表随机数种子的设置，默认是 None。随机种子是用来控制随机模式的，当随机种子取了一个值，也就确定了一种随机规则，其他人取这个值可以得到同样的结果。如果不设置随机种子，每次得到的随机数也就不同。</p>
<p>那么如何创建 AdaBoost 回归呢？</p>
<p>我们可以使用 AdaBoostRegressor(base_estimator=None, n_estimators=50, learning_rate=1.0, loss=‘linear’, random_state=None) 这个函数。</p>
<p>你能看出来回归和分类的参数基本是一致的，不同点在于回归算法里没有 algorithm 这个参数，但多了一个 loss 参数。</p>
<p>loss 代表损失函数的设置，一共有 3 种选择，分别为 linear、square 和 exponential，它们的含义分别是线性、平方和指数。默认是线性。一般采用线性就可以得到不错的效果。</p>
<p>创建好 AdaBoost 分类器或回归器之后，我们就可以输入训练集对它进行训练。我们使用 fit 函数，传入训练集中的样本特征值 train_X 和结果 train_y，模型会自动拟合。使用 predict 函数进行预测，传入测试集中的样本特征值 test_X，然后就可以得到预测结果。</p>
<p>如何用 AdaBoost 对房价进行预测</p>
<p>了解了 AdaBoost 工具包之后，我们看下 sklearn 中自带的波士顿房价数据集。</p>
<p>这个数据集一共包括了 506 条房屋信息数据，每一条数据都包括了 13 个指标，以及一个房屋价位。</p>
<p>13 个指标的含义，可以参考下面的表格：</p>
<p>这些指标分析得还是挺细的，但实际上，我们不用关心具体的含义，要做的就是如何通过这 13 个指标推导出最终的房价结果。</p>
<p>如果你学习了之前的算法实战，这个数据集的预测并不复杂。</p>
<p>首先加载数据，将数据分割成训练集和测试集，然后创建 AdaBoost 回归模型，传入训练集数据进行拟合，再传入测试集数据进行预测，就可以得到预测结果。最后将预测的结果与实际结果进行对比，得到两者之间的误差。具体代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span> <span class="n">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span> <span class="n">import</span> <span class="n">mean_squared_error</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">datasets</span> <span class="n">import</span> <span class="n">load_boston</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span> <span class="n">import</span> <span class="n">AdaBoostRegressor</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 加载数据</span>
</span></span><span class="line"><span class="cl"><span class="n">data</span><span class="o">=</span><span class="n">load_boston</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 分割数据</span>
</span></span><span class="line"><span class="cl"><span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">33</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 使用 AdaBoost 回归模型</span>
</span></span><span class="line"><span class="cl"><span class="n">regressor</span><span class="o">=</span><span class="n">AdaBoostRegressor</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">pred_y</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="n">pred_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34; 房价预测结果 &#34;</span><span class="p">,</span> <span class="n">pred_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34; 均方误差 = &#34;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">mse</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>运行结果：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">房价预测结果  [20.2        10.4137931  14.63820225 17.80322581 24.58931298 21.25076923
</span></span><span class="line"><span class="cl"> 27.52222222 17.8372093  31.79642857 20.86428571 27.87431694 31.09142857
</span></span><span class="line"><span class="cl"> 12.81666667 24.13131313 12.81666667 24.58931298 17.80322581 17.66333333
</span></span><span class="line"><span class="cl"> 27.83       24.58931298 17.66333333 20.90823529 20.10555556 20.90823529
</span></span><span class="line"><span class="cl"> 28.20877193 20.10555556 21.16882129 24.58931298 13.27619048 31.09142857
</span></span><span class="line"><span class="cl"> 17.08095238 26.19217391  9.975      21.03404255 26.74583333 31.09142857
</span></span><span class="line"><span class="cl"> 25.83960396 11.859375   13.38235294 24.58931298 14.97931034 14.46699029
</span></span><span class="line"><span class="cl"> 30.12777778 17.66333333 26.19217391 20.10206186 17.70540541 18.45909091
</span></span><span class="line"><span class="cl"> 26.19217391 20.10555556 17.66333333 33.31025641 14.97931034 17.70540541
</span></span><span class="line"><span class="cl"> 24.64421053 20.90823529 25.83960396 17.08095238 24.58931298 21.43571429
</span></span><span class="line"><span class="cl"> 19.31617647 16.33733333 46.04888889 21.25076923 17.08095238 25.83960396
</span></span><span class="line"><span class="cl"> 24.64421053 11.81470588 17.80322581 27.63636364 23.59731183 17.94444444
</span></span><span class="line"><span class="cl"> 17.66333333 27.7253886  20.21465517 46.04888889 14.97931034  9.975
</span></span><span class="line"><span class="cl"> 17.08095238 24.13131313 21.03404255 13.4        11.859375   26.19214286
</span></span><span class="line"><span class="cl"> 21.25076923 21.03404255 47.11395349 16.33733333 43.21111111 31.65730337
</span></span><span class="line"><span class="cl"> 30.12777778 20.10555556 17.8372093  18.40833333 14.97931034 33.31025641
</span></span><span class="line"><span class="cl"> 24.58931298 22.88813559 18.27179487 17.80322581 14.63820225 21.16882129
</span></span><span class="line"><span class="cl"> 26.91538462 24.64421053 13.05       14.97931034  9.975      26.19217391
</span></span><span class="line"><span class="cl"> 12.81666667 26.19214286 49.46511628 13.27619048 17.70540541 25.83960396
</span></span><span class="line"><span class="cl"> 31.09142857 24.13131313 21.25076923 21.03404255 26.91538462 21.03404255
</span></span><span class="line"><span class="cl"> 21.16882129 17.8372093  12.81666667 21.03404255 21.03404255 17.08095238
</span></span><span class="line"><span class="cl"> 45.16666667]
</span></span><span class="line"><span class="cl">均方误差 =  18.05
</span></span></code></pre></td></tr></table>
</div>
</div><p>这个数据集是比较规范的，我们并不需要在数据清洗，数据规范化上花太多精力，代码编写起来比较简单。</p>
<p>同样，我们可以使用不同的回归分析模型分析这个数据集，比如使用决策树回归和 KNN 回归。</p>
<p>编写代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 使用决策树回归模型
</span></span><span class="line"><span class="cl">dec_regressor=DecisionTreeRegressor()
</span></span><span class="line"><span class="cl">dec_regressor.fit(train_x,train_y)
</span></span><span class="line"><span class="cl">pred_y = dec_regressor.predict(test_x)
</span></span><span class="line"><span class="cl">mse = mean_squared_error(test_y, pred_y)
</span></span><span class="line"><span class="cl">print(&#34; 决策树均方误差 = &#34;,round(mse,2))
</span></span><span class="line"><span class="cl"># 使用 KNN 回归模型
</span></span><span class="line"><span class="cl">knn_regressor=KNeighborsRegressor()
</span></span><span class="line"><span class="cl">knn_regressor.fit(train_x,train_y)
</span></span><span class="line"><span class="cl">pred_y = knn_regressor.predict(test_x)
</span></span><span class="line"><span class="cl">mse = mean_squared_error(test_y, pred_y)
</span></span><span class="line"><span class="cl">print(&#34;KNN 均方误差 = &#34;,round(mse,2))
</span></span></code></pre></td></tr></table>
</div>
</div><p>运行结果：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">决策树均方误差 =  23.84
</span></span><span class="line"><span class="cl">KNN 均方误差 =  27.87
</span></span></code></pre></td></tr></table>
</div>
</div><p>你能看到相比之下，AdaBoost 的均方误差更小，也就是结果更优。虽然 AdaBoost 使用了弱分类器，但是通过 50 个甚至更多的弱分类器组合起来而形成的强分类器，在很多情况下结果都优于其他算法。因此 AdaBoost 也是常用的分类和回归算法之一。</p>
<p>AdaBoost 与决策树模型的比较</p>
<p>在 sklearn 中 AdaBoost 默认采用的是决策树模型，我们可以随机生成一些数据，然后对比下 AdaBoost 中的弱分类器（也就是决策树弱分类器）、决策树分类器和 AdaBoost 模型在分类准确率上的表现。</p>
<p>如果想要随机生成数据，我们可以使用 sklearn 中的 make_hastie_10_2 函数生成二分类数据。假设我们生成 12000 个数据，取前 2000 个作为测试集，其余作为训练集。</p>
<p>有了数据和训练模型后，我们就可以编写代码。我设置了 AdaBoost 的迭代次数为 200，代表 AdaBoost 由 200 个弱分类器组成。针对训练集，我们用三种模型分别进行训练，然后用测试集进行预测，并将三个分类器的错误率进行可视化对比，可以看到这三者之间的区别：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
</span></span><span class="line"><span class="cl"><span class="n">import</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">pyplot</span> <span class="n">as</span> <span class="n">plt</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span> <span class="n">import</span> <span class="n">datasets</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span> <span class="n">import</span> <span class="n">zero_one_loss</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span> <span class="n">import</span> <span class="n">DecisionTreeClassifier</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span> <span class="n">import</span>  <span class="n">AdaBoostClassifier</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 设置 AdaBoost 迭代次数</span>
</span></span><span class="line"><span class="cl"><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 使用</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_hastie_10_2</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">12000</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 从 12000 个数据中取前 2000 行作为测试集，其余作为训练集</span>
</span></span><span class="line"><span class="cl"><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">2000</span><span class="p">:],</span><span class="n">y</span><span class="p">[</span><span class="mi">2000</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl"><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">2000</span><span class="p">],</span><span class="n">y</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 弱分类器</span>
</span></span><span class="line"><span class="cl"><span class="n">dt_stump</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dt_stump</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dt_stump_err</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">-</span><span class="n">dt_stump</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 决策树分类器</span>
</span></span><span class="line"><span class="cl"><span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span>  <span class="n">train_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dt_err</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">-</span><span class="n">dt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># AdaBoost 分类器</span>
</span></span><span class="line"><span class="cl"><span class="n">ada</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">dt_stump</span><span class="p">,</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ada</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span>  <span class="n">train_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 三个分类器的错误率可视化</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 设置 plt 正确显示中文</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SimHei&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="n">n_estimators</span><span class="p">],[</span><span class="n">dt_stump_err</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;决策树弱分类器 错误率&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="n">n_estimators</span><span class="p">],[</span><span class="n">dt_err</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span><span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;决策树模型 错误率&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ada_err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_estimators</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 遍历每次迭代的结果 i 为迭代次数, pred_y 为预测结果</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">pred_y</span> <span class="ow">in</span> <span class="n">enumerate</span><span class="p">(</span><span class="n">ada</span><span class="o">.</span><span class="n">staged_predict</span><span class="p">(</span><span class="n">test_x</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">     <span class="c1"># 统计错误率</span>
</span></span><span class="line"><span class="cl">    <span class="n">ada_err</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">pred_y</span><span class="p">,</span> <span class="n">test_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 绘制每次迭代的 AdaBoost 错误率 </span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">ada_err</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;AdaBoost Test 错误率&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;迭代次数&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;错误率&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">leg</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span><span class="n">fancybox</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>运行结果：</p>
<p>从图中你能看出来，弱分类器的错误率最高，只比随机分类结果略好，准确率稍微大于 50%。决策树模型的错误率明显要低很多。而 AdaBoost 模型在迭代次数超过 25 次之后，错误率有了明显下降，经过 125 次迭代之后错误率的变化形势趋于平缓。</p>
<p>因此我们能看出，虽然单独的一个决策树弱分类器效果不好，但是多个决策树弱分类器组合起来形成的 AdaBoost 分类器，分类效果要好于决策树模型。</p>
<p>总结</p>
<p>今天我带你用 AdaBoost 回归分析对波士顿房价进行了预测。因为这是个回归分析的问题，我们直接使用 sklearn 中的 AdaBoostRegressor 即可。如果是分类，我们使用 AdaBoostClassifier。</p>
<p>另外我们将 AdaBoost 分类器、弱分类器和决策树分类器做了对比，可以看出经过多个弱分类器组合形成的 AdaBoost 强分类器，准确率要明显高于决策树算法。所以 AdaBoost 的优势在于框架本身，它通过一种迭代机制让原本性能不强的分类器组合起来，形成一个强分类器。</p>
<p>其实在现实工作中，我们也能找到类似的案例。IBM 服务器追求的是单个服务器性能的强大，比如打造超级服务器。而 Google 在创建集群的时候，利用了很多 PC 级的服务器，将它们组成集群，整体性能远比一个超级服务器的性能强大。</p>
<p>再比如我们讲的“三个臭皮匠，顶个诸葛亮”，也就是 AdaBoost 的价值所在。</p>
<p>今天我们用 AdaBoost 分类器与决策树分类做对比的时候，使用到了 sklearn 中的 make_hastie_10_2 函数生成数据。实际上在第 19 篇，我们对泰坦尼克号的乘客做生存预测的时候，也讲到了决策树工具的使用。你能不能编写代码，使用 AdaBoost 算法对泰坦尼克号乘客的生存做预测，看看它和决策树模型，谁的准确率更高？</p>
<p>你也可以把这篇文章分享给你的朋友或者同事，一起切磋一下。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2/">数据分析实战45讲</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%AE%9E%E6%88%98/36-%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%AE%9E%E6%88%98/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">36-大规模数据处理实战</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/sql%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/3635%E4%B8%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF%E4%BB%80%E4%B9%88%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98/">
            <span class="next-text nav-default">3635丨数据库主从同步的作用是什么如何解决数据不一致问题</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

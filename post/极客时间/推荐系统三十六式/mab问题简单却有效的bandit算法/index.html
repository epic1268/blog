<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>【MAB问题】简单却有效的Bandit算法 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="我在之前的文章中表达过，推荐系统的使命就是在建立用户和物品之间的连接。建立连接可以理解成：为用户匹配到最佳的物品；但也有另一个理解就是，在某个时间某个位置为用户选择最好的物品。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/mab%E9%97%AE%E9%A2%98%E7%AE%80%E5%8D%95%E5%8D%B4%E6%9C%89%E6%95%88%E7%9A%84bandit%E7%AE%97%E6%B3%95/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/mab%E9%97%AE%E9%A2%98%E7%AE%80%E5%8D%95%E5%8D%B4%E6%9C%89%E6%95%88%E7%9A%84bandit%E7%AE%97%E6%B3%95/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="【MAB问题】简单却有效的Bandit算法">
  <meta property="og:description" content="我在之前的文章中表达过，推荐系统的使命就是在建立用户和物品之间的连接。建立连接可以理解成：为用户匹配到最佳的物品；但也有另一个理解就是，在某个时间某个位置为用户选择最好的物品。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="推荐系统三十六式">

  <meta itemprop="name" content="【MAB问题】简单却有效的Bandit算法">
  <meta itemprop="description" content="我在之前的文章中表达过，推荐系统的使命就是在建立用户和物品之间的连接。建立连接可以理解成：为用户匹配到最佳的物品；但也有另一个理解就是，在某个时间某个位置为用户选择最好的物品。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="4073">
  <meta itemprop="keywords" content="推荐系统三十六式">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="【MAB问题】简单却有效的Bandit算法">
  <meta name="twitter:description" content="我在之前的文章中表达过，推荐系统的使命就是在建立用户和物品之间的连接。建立连接可以理解成：为用户匹配到最佳的物品；但也有另一个理解就是，在某个时间某个位置为用户选择最好的物品。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">【MAB问题】简单却有效的Bandit算法</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 4073 字 </span>
          <span class="more-meta"> 预计阅读 9 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#推荐就是选择">推荐就是选择</a></li>
        <li><a href="#mab-问题">MAB 问题</a></li>
        <li><a href="#bandit-算法">Bandit 算法</a>
          <ul>
            <li><a href="#1-汤普森采样算法">1. 汤普森采样算法</a></li>
            <li><a href="#2ucb-算法">2.UCB 算法</a></li>
            <li><a href="#3-epsilon-贪婪算法">3. Epsilon 贪婪算法</a></li>
            <li><a href="#4-效果对比">4. 效果对比</a></li>
          </ul>
        </li>
        <li><a href="#冷启动">冷启动</a></li>
        <li><a href="#总结">总结</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>我在之前的文章中表达过，推荐系统的使命就是在建立用户和物品之间的连接。建立连接可以理解成：为用户匹配到最佳的物品；但也有另一个理解就是，在某个时间某个位置为用户选择最好的物品。</p>
<h2 id="推荐就是选择">推荐就是选择</h2>
<p>生活中，你我都会遇到很多要做选择的场景。上哪个大学，学什么专业，去哪家公司，中午吃什么等等。这些事情，都让选择困难症的我们头很大。头大在哪呢？主要是不知道每个选择会带来什么后果。</p>
<p>你仔细想一下，生活中为什么会害怕选择，究其原因是把每个选项看成独一无二的个体，一旦错过就不再来。推荐系统中一个一个单独的物品也如此，一旦选择呈现给用户，如果不能得到用户的青睐，就失去了一个展示机会。如果跳出来看这个问题，选择时不再聚焦到具体每个选项，而是去选择类别，这样压力是不是就小了很多？</p>
<p>比如说，把推荐选择具体物品，上升到选择策略。如果后台算法中有三种策略：按照内容相似推荐，按照相似好友推荐，按照热门推荐。每次选择一种策略，确定了策略后，再选择策略中的物品，这样两个步骤。</p>
<p>那么，是不是有办法来解决这个问题呢？当然有！那就是 Bandit 算法。</p>
<h2 id="mab-问题">MAB 问题</h2>
<p>Bandit 算法来源于人民群众喜闻乐见的赌博学，它要解决的问题是这样的。</p>
<p>一个赌徒，要去摇老虎机，走进赌场一看，一排老虎机，外表一模一样，但是每个老虎机吐钱的概率可不一样，他不知道每个老虎机吐钱的概率分布是什么，那么想最大化收益该怎么整？</p>
<p>这就是多臂赌博机问题 (Multi-armed bandit problem, K-armed bandit problem, MAB)，简称 MAB 问题。有很多相似问题都属于 MAB 问题。</p>
<ol>
<li>假设一个用户对不同类别的内容感兴趣程度不同，当推荐系统初次见到这个用户时，怎么快速地知道他对每类内容的感兴趣程度？这也是推荐系统常常面对的冷启动问题。</li>
<li>假设系统中有若干广告库存物料，该给每个用户展示哪个广告，才能获得最大的点击收益，是不是每次都挑收益最好那个呢？</li>
<li>算法工程师又设计出了新的策略或者模型，如何既能知道它和旧模型相比谁更靠谱又对风险可控呢？</li>
</ol>
<p>这些问题全都是关于选择的问题。只要是关于选择的问题，都可以简化成一个 MAB 问题。</p>
<p>我在前面的专栏中提过，推荐系统里面有两个顽疾，一个是冷启动，一个是探索利用问题，后者又称为 EE 问题：Exploit－Explore 问题。针对这两个顽疾，Bandit 算法可以入药。</p>
<p>冷启动问题好说，探索利用问题什么意思？</p>
<p>利用意思就是：比较确定的兴趣，当然要用啊。好比说我们已经挣到的钱，当然要花啊。</p>
<p>探索的意思就是：不断探索用户新的兴趣才行，不然很快就会出现一模一样的反复推荐。就好比我们虽然有一点钱可以花了，但是还得继续搬砖挣钱啊，要不然，花完了就要喝西北风了。</p>
<h2 id="bandit-算法">Bandit 算法</h2>
<p>Bandit 算法并不是指一个算法，而是一类算法。现在就来介绍一下 Bandit 算法家族怎么解决这类选择问题的。</p>
<p>首先，来定义一下，如何衡量选择的好坏？Bandit 算法的思想是：看看选择会带来多少遗憾，遗憾越少越好。在 MAB 问题里，用来量化选择好坏的指标就是累计遗憾，计算公式如图所示。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/9a618a2c3e836fb558089214e397ad6f.png" alt=""></p>
<p>简单描述一下这个公式。公式有两部分构成：一个是遗憾，一个是累积。求和符号内部就表示每次选择的遗憾多少。</p>
<p>Wopt 就表示，每次都运气好，选择了最好的选择，该得到多少收益，WBi 就表示每一次实际选择得到的收益，两者之差就是“遗憾”的量化，在 T 次选择后，就有了累积遗憾。</p>
<p>在这个公式中：为了简化 MAB 问题，每个臂的收益不是 0，就是 1，也就是伯努利收益。</p>
<p>这个公式可以用来对比不同 Bandit 算法的效果：对同样的多臂问题，用不同的 Bandit 算法模拟试验相同次数，比比看哪个 Bandit 算法的累积遗憾增长得慢，那就是效果较好的算法。</p>
<p>Bandit 算法的套路就是：小心翼翼地试，越确定某个选择好，就多选择它，越确定某个选择差，就越来越少选择它。</p>
<p>如果某个选择实验次数较少，导致不确定好坏，那么就多给一些被选择机会，直到确定了它是金子还是石头。简单说就是，把选择的机会给“确定好的”和“还不确定的”。</p>
<p>Bandit 算法中有几个关键元素：臂，回报，环境。</p>
<ol>
<li>臂：是每次选择的候选项，好比就是老虎机，有几个选项就有几个臂；</li>
<li>回报：就是选择一个臂之后得到的奖励，好比选择一个老虎机之后吐出来的金币；</li>
<li>环境：就是决定每个臂不同的那些因素，统称为环境。</li>
</ol>
<p>将这个几个关键元素对应到推荐系统中来。</p>
<ol>
<li>臂：每次推荐要选择候选池，可能是具体物品，也可能是推荐策略，也可能是物品类别；</li>
<li>回报：用户是否对推荐结果喜欢，喜欢了就是正面的回报，没有买账就是负面回报或者零回报；</li>
<li>环境：推荐系统面临的这个用户就是不可捉摸的环境。</li>
</ol>
<p>下面直接开始陈列出最常用的几个 Bandit 算法。</p>
<h3 id="1-汤普森采样算法">1. 汤普森采样算法</h3>
<p>第一个是汤普森采样算法。这个算法我个人很喜欢它，因为它只要一行代码就可以实现，并且数学的基础最简单。</p>
<p>简单介绍一下它的原理：假设每个臂是否产生收益，起决定作用的是背后有一个概率分布，产生收益的概率为 p。</p>
<p>每个臂背后绑定了一个概率分布；每次做选择时，让每个臂的概率分布各自独立产生一个随机数，按照这个随机数排序，输出产生最大随机数那个臂对应的物品。听上去很简单，为什么这个随机数这么神奇？</p>
<p>关键在于每个臂背后的概率分布，是一个贝塔分布，先看看贝塔分布的样子：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/9db6a3f0ef652319615f806cb143755a.png" alt=""></p>
<p>贝塔分布有 a 和 b 两个参数。这两个参数决定了分布的形状和位置：</p>
<ol>
<li>当 a+b 值越大，分布曲线就越窄，分布就越集中，这样的结果就是产生的随机数会容易靠近中心位置；</li>
<li>当 a/(a+b) 的值越大，分布的中心位置越靠近 1，反之就越靠近 0，这样产生的随机数也相应第更容易靠近 1 或者 0。</li>
</ol>
<p>贝塔分布的这两个特点，可以把它分成三种情况：</p>
<ol>
<li>曲线很窄，而且靠近 1；</li>
<li>曲线很窄，而且靠近 0；</li>
<li>曲线很宽。</li>
</ol>
<p>这和前面所讲的选择有什么关系呢？你把贝塔分布的 a 参数看成是推荐后得到用户点击的次数，把分布的 b 参数看成是没有得到用户点击的次数。按照这个对应，再来叙述一下汤普森采样的过程。</p>
<ol>
<li>取出每一个候选对应的参数 a 和 b；</li>
<li>为每个候选用 a 和 b 作为参数，用贝塔分布产生一个随机数；</li>
<li>按照随机数排序，输出最大值对应的候选；</li>
<li>观察用户反馈，如果用户点击则将对应候选的 a 加 1，否则 b 加 1；</li>
</ol>
<p>注意，实际上在推荐系统中，要为每一个用户都保存一套参数，比如候选有 m 个，用户有 n 个，那么就要保存 2   <em>m</em>  n 个参数。</p>
<p>汤普森采样为什么有效呢？解释一下。</p>
<ol>
<li>如果一个候选被选中的次数很多，也就是 a+b 很大了，它的分布会很窄，换句话说这个候选的收益已经非常确定了，用它产生随机数，基本上就在中心位置附近，接近平均收益。</li>
<li>如果一个候选不但 a+b 很大，即分布很窄，而且 a/(a+b) 也很大，接近 1，那就确定这是个好的候选项，平均收益很好，每次选择很占优势，就进入利用阶段，反之则几乎再无出头之日。</li>
<li>如果一个候选的 a+b 很小，分布很宽，也就是没有被选择太多次，说明这个候选是好是坏还不太确定，那么用它产生随机数就有可能得到一个较大的随机数，在排序时被优先输出，这就起到了前面说的探索作用。</li>
</ol>
<p>用 Python 实现汤普森采样就一行：</p>
<blockquote>
<p>choice = numpy.argmax(pymc.rbeta(1 + self.wins, 1 + self.trials - self.wins))</p>
</blockquote>
<h3 id="2ucb-算法">2.UCB 算法</h3>
<p>第二个常用的 Bandit 算法就是 UCB 算法，UCB 算法全称是 Upper Confidence Bound，即置信区间上界。它也为每个臂评分，每次选择评分最高的候选臂输出，每次输出后观察用户反馈，回来更新候选臂的参数。</p>
<p>每个臂的评分公式为.<img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/a07c0a4f26942c4f9bdce40e07e3e084.png" alt=""></p>
<p>公式有两部分，加号前面是这个候选臂到目前的平均收益，反应了它的效果，后面的叫做 Bonus，本质上是均值的标准差，反应了候选臂效果的不确定性，就是置信区间的上边界。t 是目前的总选择次数，Tjt 是每个臂被选择次数。</p>
<p>观察这个公式，如果一个候选的被选择次数很少，即 Tjt 很小，那么它的 Bonus 就会较大，在最后排序输出时有优势，这个 Bonus 反映了一个候选的收益置信区间宽度，Bonus 越大，候选的平均收益置信区间越宽，越不确定，越需要更多的选择机会。</p>
<p>反之如果平均收益很大，就是说加号左边很大，也会在被选择时有优势。</p>
<p>这个评分公式也和汤普森采样是一样的思想：</p>
<ol>
<li>以每个候选的平均收益为基准线进行选择；</li>
<li>对于被选择次数不足的给予照顾；</li>
<li>选择倾向的是那些确定收益较好的候选。</li>
</ol>
<h3 id="3-epsilon-贪婪算法">3. Epsilon 贪婪算法</h3>
<p>这是一个朴素的算法，也很简单有效，思想有点类似模拟退火，做法如下。</p>
<ol>
<li>先选一个 (0,1) 之间较小的数，叫做 Epsilon，也是这个算法名字来历。</li>
<li>每次以概率 Epsilon 做一件事：所有候选臂中随机选一个，以 1-Epsilon 的概率去选择平均收益最大的那个臂。</li>
</ol>
<p>是不是简单粗暴？Epsilon 的值可以控制对探索和利用的权衡程度。这个值越接近 0，在探索上就越保守。</p>
<p>和这种做法相似，还有一个更朴素的做法：先试几次，等每个臂都统计到收益之后，就一直选均值最大那个臂。</p>
<h3 id="4-效果对比">4. 效果对比</h3>
<p>以上几个算法，可以简单用模拟试验的方式对比其效果，如图所示。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/f17061f32c15c2c9f378242389a1eb65.png" alt=""></p>
<p>横坐标是模拟次数增加，可以看成随着时间推移，纵坐标就是累积遗憾，越高说明搞砸的次数越多。在模拟后期，基本上各种算法优劣一目了然。从上到下分别是下面几种。</p>
<ol>
<li>完全随机：就是不顾用户反馈的做法。</li>
<li>朴素选择：就是认准一个效果好的，一直推。</li>
<li>Epsilon 贪婪算法：每次以小概率尝试新的，大概率选择效果好的。</li>
<li>UCB：每次都会给予机会较少的候选一些倾向。</li>
<li>汤普森采样：用贝塔分布管理每一个候选的效果。</li>
</ol>
<p>UCB 算法和汤普森采样都显著优秀很多。</p>
<h2 id="冷启动">冷启动</h2>
<p>我想，你已经想到了，推荐系统冷启动问题可以用 Bandit 算法来解决一部分。</p>
<p>大致思路如下：</p>
<ol>
<li>用分类或者 Topic 来表示每个用户兴趣，我们可以通过几次试验，来刻画出新用户心目中对每个 Topic 的感兴趣概率。</li>
<li>这里，如果用户对某个 Topic 感兴趣，就表示我们得到了收益，如果推给了它不感兴趣的 Topic，推荐系统就表示很遗憾 (regret) 了。</li>
<li>当一个新用户来了，针对这个用户，我们用汤普森采样为每一个 Topic 采样一个随机数，排序后，输出采样值 Top N 的推荐 Item。注意，这里一次选择了 Top N 个候选臂。</li>
<li>等着获取用户的反馈，没有反馈则更新对应 Topic 的 b 值，点击了则更新对应 Topic 的 a 值。</li>
</ol>
<h2 id="总结">总结</h2>
<p>今天给你介绍了一种走一步看一步的推荐算法，叫做 Bandit 算法。Bandit 算法把每个用户看成一个多变的环境，待推荐的物品就如同赌场里老虎机的摇臂，如果推荐了符合用户心目中喜欢的，就好比是从一台老虎机中摇出了金币一样。</p>
<p>今天重点介绍的 Bandit 算法有汤普森采样，UCB 算法，Epsilon 贪婪，并且用模拟的方式对比了它们的效果，汤普森采样以实现简单和效果显著而被人民群众爱戴，你需要时不妨首先试试它。</p>
<p>同时，这里留下一个问题给你，今天讲到的 Bandit 算法有哪些不足？欢迎留言和我一起讨论。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/d3b48a2755db0a3707ef37007c2179c8.png" alt=""></p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/">推荐系统三十六式</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%AF%BC%E6%89%8B%E5%86%8C/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">《数据结构与算法之美》学习指导手册</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/mab%E9%97%AE%E9%A2%98%E7%BB%93%E5%90%88%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF%E7%9A%84bandit%E7%AE%97%E6%B3%95/">
            <span class="next-text nav-default">【MAB问题】结合上下文信息的Bandit算法</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>推荐系统的参考阅读 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="专栏主体内容已经结束了，在专栏写作的过程中，我阅读了很多业界公开的资料，我觉得有必要整理出来，供想深入阅读的人继续去找虐。
整体来说，在选择参考文献时，我偏爱那些由公司发表的。因为推荐系统本质上还是一种非常依赖实践的算法应用方向，并且，这些商业公司论文中的技术内容也在他们实际的场景中经过了检验。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%82%E8%80%83%E9%98%85%E8%AF%BB/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%82%E8%80%83%E9%98%85%E8%AF%BB/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="推荐系统的参考阅读">
  <meta property="og:description" content="专栏主体内容已经结束了，在专栏写作的过程中，我阅读了很多业界公开的资料，我觉得有必要整理出来，供想深入阅读的人继续去找虐。
整体来说，在选择参考文献时，我偏爱那些由公司发表的。因为推荐系统本质上还是一种非常依赖实践的算法应用方向，并且，这些商业公司论文中的技术内容也在他们实际的场景中经过了检验。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="推荐系统三十六式">

  <meta itemprop="name" content="推荐系统的参考阅读">
  <meta itemprop="description" content="专栏主体内容已经结束了，在专栏写作的过程中，我阅读了很多业界公开的资料，我觉得有必要整理出来，供想深入阅读的人继续去找虐。
整体来说，在选择参考文献时，我偏爱那些由公司发表的。因为推荐系统本质上还是一种非常依赖实践的算法应用方向，并且，这些商业公司论文中的技术内容也在他们实际的场景中经过了检验。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="3846">
  <meta itemprop="keywords" content="推荐系统三十六式">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="推荐系统的参考阅读">
  <meta name="twitter:description" content="专栏主体内容已经结束了，在专栏写作的过程中，我阅读了很多业界公开的资料，我觉得有必要整理出来，供想深入阅读的人继续去找虐。
整体来说，在选择参考文献时，我偏爱那些由公司发表的。因为推荐系统本质上还是一种非常依赖实践的算法应用方向，并且，这些商业公司论文中的技术内容也在他们实际的场景中经过了检验。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">推荐系统的参考阅读</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 3846 字 </span>
          <span class="more-meta"> 预计阅读 8 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#原理篇">原理篇</a></li>
        <li><a href="#1-内容推荐">1. 内容推荐</a>
          <ul>
            <li><a href="#题目bag-of-tricks-for-efficient-text-classification">题目：Bag of Tricks for Efficient Text Classification</a></li>
            <li><a href="#类型论文"><strong>类型</strong>：论文</a></li>
            <li><a href="#作者facebook"><strong>作者</strong>：Facebook</a></li>
            <li><a href="#说明"><strong>说明</strong>：</a></li>
            <li><a href="#题目the-learning-behind-gmail-priority-inbox"><strong>题目</strong>：The Learning Behind Gmail Priority Inbox</a></li>
            <li><a href="#类型论文-1"><strong>类型</strong>：论文</a></li>
            <li><a href="#作者google"><strong>作者</strong>：Google</a></li>
            <li><a href="#说明-1"><strong>说明</strong>：</a></li>
            <li><a href="#题目recommender-systems-handbook第三章第九章"><strong>题目</strong>：Recommender Systems Handbook(第三章，第九章)</a></li>
            <li><a href="#类型书"><strong>类型</strong>：书</a></li>
            <li><a href="#作者francesco-ricci-等"><strong>作者</strong>：Francesco Ricci 等</a></li>
            <li><a href="#说明-2"><strong>说明</strong>：</a></li>
            <li><a href="#题目文本上的算法"><strong>题目</strong>：文本上的算法</a></li>
            <li><a href="#类型网络文章-网络免费版已有成书文本上的算法深入浅出自然语言处理内容更丰富"><strong>类型</strong>：网络文章 (网络免费版，已有成书《文本上的算法：深入浅出自然语言处理》，内容更丰富)</a></li>
            <li><a href="#作者路彦雄"><strong>作者</strong>：路彦雄</a></li>
            <li><a href="#说明-3"><strong>说明</strong>：</a></li>
            <li><a href="#题目lda-数学八卦">题目：LDA 数学八卦</a></li>
            <li><a href="#类型网络文章">类型：网络文章</a></li>
            <li><a href="#作者rickjin靳志辉">作者：Rickjin(@靳志辉)</a></li>
            <li><a href="#说明-4">说明：</a></li>
          </ul>
        </li>
        <li><a href="#2-近邻推荐">2. 近邻推荐</a>
          <ul>
            <li><a href="#题目amazoncom-recommendations-item-to-item-collaborative-filtering">题目：Amazon.com recommendations: item-to-item collaborative filtering</a></li>
            <li><a href="#类型论文-2">类型：论文</a></li>
            <li><a href="#作者amazon">作者：Amazon</a></li>
            <li><a href="#说明-5">说明：</a></li>
            <li><a href="#题目slope-one-predictors-for-online-rating-based-collaborative-filtering">题目：Slope One Predictors for Online Rating-Based Collaborative Filtering</a></li>
            <li><a href="#类型论文-3">类型：论文</a></li>
            <li><a href="#作者daniel-lemire-等">作者：Daniel Lemire 等</a></li>
            <li><a href="#说明-6">说明：</a></li>
            <li><a href="#题目item-based-collaborative-filtering-recommendation-algorithms">题目：Item-Based Collaborative Filtering Recommendation Algorithms</a></li>
            <li><a href="#类型论文-4">类型：论文</a></li>
            <li><a href="#作者badrul-sarwar-等">作者：Badrul Sarwar 等</a></li>
            <li><a href="#说明-7">说明：</a></li>
            <li><a href="#题目collaborative-recommendations-using-item-to-item-similarity-mappings">题目：Collaborative Recommendations Using Item-to-Item Similarity Mappings</a></li>
            <li><a href="#类型专利">类型：专利</a></li>
            <li><a href="#作者amazon-1">作者：Amazon</a></li>
            <li><a href="#说明-8">说明：</a></li>
            <li><a href="#题目recommender-systems-handbook第-4-章">题目：Recommender Systems Handbook（第 4 章）</a></li>
            <li><a href="#类型书-1">类型：书</a></li>
            <li><a href="#作者francesco-ricci-等-1">作者：Francesco Ricci 等</a></li>
            <li><a href="#说明-9">说明：</a></li>
          </ul>
        </li>
        <li><a href="#3-矩阵分解">3. 矩阵分解</a>
          <ul>
            <li><a href="#题目matrix-factorization-and-collaborative-filtering">题目：Matrix Factorization and Collaborative Filtering</a></li>
            <li><a href="#类型演示文稿">类型：演示文稿</a></li>
            <li><a href="#作者daryl-lim">作者：Daryl Lim</a></li>
            <li><a href="#说明-10">说明：</a></li>
            <li><a href="#题目factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model">题目：Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model</a></li>
            <li><a href="#类型论文-5">类型：论文</a></li>
            <li><a href="#作者yehuda-koren">作者：Yehuda Koren</a></li>
            <li><a href="#说明-11">说明：</a></li>
            <li><a href="#题目bpr--bayesian-personalized-ranking-from-implicit-feedback">题目：BPR- Bayesian Personalized Ranking from Implicit Feedback</a></li>
            <li><a href="#类型论文-6">类型：论文</a></li>
            <li><a href="#作者steffen-rendle-等">作者：Steffen Rendle 等</a></li>
            <li><a href="#说明-12">说明：</a></li>
            <li><a href="#题目collaborative-filtering-for-implicit-feedback-datasets">题目：Collaborative Filtering for Implicit Feedback Datasets</a></li>
            <li><a href="#类型论文-7">类型：论文</a></li>
            <li><a href="#作者yifan-hu-等">作者：Yifan Hu 等</a></li>
            <li><a href="#说明-13">说明：</a></li>
            <li><a href="#题目matrix-factorization-techniques-for-recommender-systems">题目：Matrix Factorization Techniques For Recommender Systems</a></li>
            <li><a href="#类型论文-8">类型：论文</a></li>
            <li><a href="#作者yehuda-koren-等">作者：Yehuda Koren 等</a></li>
            <li><a href="#说明-14">说明：</a></li>
            <li><a href="#题目the-bellkor-solution-to-the-netflix-grand-prize">题目：The BellKor Solution to the Netflix Grand Prize</a></li>
            <li><a href="#类型论文-9">类型：论文</a></li>
            <li><a href="#作者yehuda-koren-1">作者：Yehuda Koren</a></li>
            <li><a href="#说明-15">说明：</a></li>
          </ul>
        </li>
        <li><a href="#4-模型融合">4. 模型融合</a>
          <ul>
            <li><a href="#题目adaptive-bound-optimization-for-online-convex-optimization">题目：Adaptive Bound Optimization for Online Convex Optimization</a></li>
            <li><a href="#类型论文-10">类型：论文</a></li>
            <li><a href="#作者google-1">作者：Google</a></li>
            <li><a href="#说明-16">说明：</a></li>
            <li><a href="#题目在线最优化求解">题目：在线最优化求解</a></li>
            <li><a href="#类型网络文章-1">类型：网络文章</a></li>
            <li><a href="#作者冯扬">作者：冯扬</a></li>
            <li><a href="#说明-17">说明：</a></li>
            <li><a href="#题目ad-click-prediction-a-view-from-the-trenches">题目：Ad Click Prediction: a View from the Trenches</a></li>
            <li><a href="#类型论文-11">类型：论文</a></li>
            <li><a href="#作者google-2">作者：Google</a></li>
            <li><a href="#说明-18">说明：</a></li>
            <li><a href="#题目factorization-machines">题目：Factorization Machines</a></li>
            <li><a href="#类型论文-12">类型：论文</a></li>
            <li><a href="#作者steffen-rendle">作者：Steffen Rendle</a></li>
            <li><a href="#说明-19">说明：</a></li>
            <li><a href="#题目field-aware-factorization-machines-for-ctr-prediction">题目：Field-aware Factorization Machines for CTR Prediction</a></li>
            <li><a href="#类型论文-13">类型：论文</a></li>
            <li><a href="#作者yuchin-juan">作者：Yuchin Juan</a></li>
            <li><a href="#说明-20">说明：</a></li>
            <li><a href="#题目practical-lessons-from-predicting-clicks-on-ads-at-facebook">题目：Practical Lessons from Predicting Clicks on Ads at Facebook</a></li>
            <li><a href="#类型论文-14">类型：论文</a></li>
            <li><a href="#说明-21">说明：</a></li>
            <li><a href="#题目wide--deep-learning-for-recommender-systems">题目：Wide &amp; Deep Learning for Recommender Systems</a></li>
            <li><a href="#类型论文-15">类型：论文</a></li>
            <li><a href="#作者google-3">作者：Google</a></li>
            <li><a href="#说明-22">说明：</a></li>
          </ul>
        </li>
        <li><a href="#5bandit-算法">5.Bandit 算法</a>
          <ul>
            <li><a href="#题目introduction-to-bandits--algorithms-and-theory-part-1--bandits-with-small-sets-of-actions">题目：Introduction to Bandits- Algorithms and Theory Part 1- Bandits with small sets of actions</a></li>
            <li><a href="#类型演示文稿-1">类型：演示文稿</a></li>
            <li><a href="#作者jean-yves-audibert-等">作者：Jean-Yves Audibert 等</a></li>
            <li><a href="#说明-23">说明：</a></li>
            <li><a href="#题目introduction-to-bandits--algorithms-and-theory-part-2--bandits-with-large-sets-of-actions">题目：Introduction to Bandits- Algorithms and Theory Part 2- Bandits with large sets of actions</a></li>
            <li><a href="#类型演示文稿-2">类型：演示文稿</a></li>
            <li><a href="#作者jean-yves-audibert-等-1">作者：Jean-Yves Audibert 等</a></li>
            <li><a href="#说明-24">说明：</a></li>
            <li><a href="#题目a-contextual-bandit-approach-to-personalized-news-article-recommendation">题目：A Contextual-Bandit Approach to Personalized News Article Recommendation</a></li>
            <li><a href="#类型论文-16">类型：论文</a></li>
            <li><a href="#作者yahoo">作者：Yahoo</a></li>
            <li><a href="#说明-25">说明：</a></li>
            <li><a href="#题目collaborative-filtering-bandits">题目：Collaborative Filtering Bandits</a></li>
            <li><a href="#类型论文-17">类型：论文</a></li>
            <li><a href="#作者shuai-li-等">作者：Shuai Li 等</a></li>
            <li><a href="#说明-26">说明：</a></li>
          </ul>
        </li>
        <li><a href="#6-深度学习">6. 深度学习</a>
          <ul>
            <li><a href="#题目deep-neural-networks-for-youtube-recommendations">题目：Deep Neural Networks for YouTube Recommendations</a></li>
            <li><a href="#类型论文-18">类型：论文</a></li>
            <li><a href="#作者google-4">作者：Google</a></li>
            <li><a href="#说明-27">说明：</a></li>
            <li><a href="#题目efficient-estimation-of-word-representations-in-vector-space">题目：Efficient Estimation of Word Representations in Vector Space</a></li>
            <li><a href="#类型论文-19">类型：论文</a></li>
            <li><a href="#作者google-5">作者：Google</a></li>
            <li><a href="#说明-28">说明：</a></li>
            <li><a href="#题目item2vec-neural-item-embedding-for-collaborative-filtering">题目：Item2Vec: Neural Item Embedding for Collaborative Filtering</a></li>
            <li><a href="#类型论文-20">类型：论文</a></li>
            <li><a href="#作者microsoft">作者：Microsoft</a></li>
            <li><a href="#说明-29">说明：</a></li>
            <li><a href="#题目learning-representations-of-text-using-neural-networks">题目：Learning Representations of Text using Neural Networks</a></li>
            <li><a href="#类型演示文稿-3">类型：演示文稿</a></li>
            <li><a href="#作者google-6">作者：Google</a></li>
            <li><a href="#说明-30">说明：</a></li>
            <li><a href="#题目long-short-term-memory">题目：Long Short-Term Memory</a></li>
            <li><a href="#类型论文-21">类型：论文</a></li>
            <li><a href="#作者sepp-hochreiter-等">作者：Sepp Hochreiter 等</a></li>
            <li><a href="#说明-31">说明：</a></li>
            <li><a href="#题目an-empirical-exploration-of-recurrent-network-architectures">题目：An Empirical Exploration of Recurrent Network Architectures</a></li>
            <li><a href="#类型论文-22">类型：论文</a></li>
            <li><a href="#作者google-7">作者：Google</a></li>
            <li><a href="#说明-32">说明：</a></li>
            <li><a href="#题目recurrent-neural-networks-for-collaborative-filtering">题目：Recurrent Neural Networks for Collaborative Filtering</a></li>
            <li><a href="#类型网络文章-2">类型：网络文章</a></li>
            <li><a href="#作者erik-bernhardsson">作者：Erik Bernhardsson</a></li>
            <li><a href="#说明-33">说明：</a></li>
          </ul>
        </li>
        <li><a href="#7-其他实用算法">7. 其他实用算法</a>
          <ul>
            <li><a href="#题目detecting-near-duplicates-for-web-crawling">题目：Detecting Near-Duplicates for Web Crawling</a></li>
            <li><a href="#类型论文-23">类型：论文</a></li>
            <li><a href="#作者google-8">作者：Google</a></li>
            <li><a href="#说明-34">说明：</a></li>
            <li><a href="#题目weighted-random-sampling-over-data-streams">题目：Weighted Random Sampling over Data Streams</a></li>
            <li><a href="#类型论文-24">类型：论文</a></li>
            <li><a href="#作者pavlos-s-efraimidis">作者：Pavlos S. Efraimidis</a></li>
            <li><a href="#说明-35">说明：</a></li>
            <li><a href="#题目weighted-sampling-without-replacement-from-data-streams">题目：Weighted Sampling Without Replacement from Data Streams</a></li>
            <li><a href="#类型论文-25">类型：论文：</a></li>
            <li><a href="#作者vladimir-braverman-等">作者：Vladimir Braverman 等</a></li>
            <li><a href="#说明-36">说明：</a></li>
          </ul>
        </li>
        <li><a href="#工程篇">工程篇</a></li>
        <li><a href="#1-常见架构">1. 常见架构</a>
          <ul>
            <li><a href="#题目activity-feeds-architecture">题目：Activity Feeds Architecture</a></li>
            <li><a href="#类型演示文稿-4">类型：演示文稿</a></li>
            <li><a href="#作者etsy">作者：Etsy</a></li>
            <li><a href="#说明-37">说明：</a></li>
            <li><a href="#题目atom-activity-streams-10">题目：Atom Activity Streams 1.0</a></li>
            <li><a href="#类型规范文档">类型：规范文档</a></li>
            <li><a href="#作者activity-streams-working-group">作者：Activity Streams Working Group</a></li>
            <li><a href="#说明-38">说明：</a></li>
            <li><a href="#题目beyond-the-5-starsnetflix-recommendations">题目：Beyond the 5 stars（Netflix Recommendations）</a></li>
            <li><a href="#类型网络文章-3">类型：网络文章</a></li>
            <li><a href="#作者netflix">作者：Netflix</a></li>
            <li><a href="#说明-39">说明：</a></li>
            <li><a href="#题目system-architectures-for-personalization-and-recommendation">题目：System Architectures for Personalization and Recommendation</a></li>
            <li><a href="#类型网络文章-4">类型：网络文章</a></li>
            <li><a href="#作者netflix-1">作者：Netflix</a></li>
            <li><a href="#说明-40">说明：</a></li>
            <li><a href="#题目information-seeking-convergence-of-search-recommendations-and-advertising">题目：Information Seeking-Convergence of Search, Recommendations and Advertising</a></li>
            <li><a href="#类型论文-26">类型：论文</a></li>
            <li><a href="#作者h-garcia-molina-等">作者：H Garcia-Molina 等</a></li>
            <li><a href="#说明-41">说明：</a></li>
          </ul>
        </li>
        <li><a href="#2-关键模块">2. 关键模块</a>
          <ul>
            <li><a href="#题目overlapping-experiment-infrastructure--more-better-faster-experimentation">题目：Overlapping Experiment Infrastructure- More, Better, Faster Experimentation</a></li>
            <li><a href="#类型论文-27">类型：论文</a></li>
            <li><a href="#作者google-9">作者：Google</a></li>
            <li><a href="#说明-42">说明：</a></li>
            <li><a href="#题目tencentrecreal-time-stream-recommendation-in-practice">题目：TencentRec：Real-time Stream Recommendation in Practice</a></li>
            <li><a href="#类型论文-28">类型：论文</a></li>
            <li><a href="#作者腾讯">作者：腾讯</a></li>
            <li><a href="#说明-43">说明：</a></li>
            <li><a href="#题目personalization-at-spotify-using-cassandra">题目：Personalization at Spotify using Cassandra</a></li>
            <li><a href="#类型网络文章-5">类型：网络文章</a></li>
            <li><a href="#作者spotify">作者：Spotify</a></li>
            <li><a href="#说明-44">说明：</a></li>
          </ul>
        </li>
        <li><a href="#3-效果保证">3. 效果保证</a>
          <ul>
            <li><a href="#题目tutorial-on-robustness-of-recommender-systems">题目：Tutorial on Robustness of Recommender Systems</a></li>
            <li><a href="#类型演示文稿-5">类型：演示文稿</a></li>
            <li><a href="#作者neil-hurley">作者：Neil Hurley</a></li>
            <li><a href="#说明-45">说明：</a></li>
            <li><a href="#题目recommender-systems-handbook第八章">题目：Recommender Systems Handbook(第八章)</a></li>
            <li><a href="#类型书-2">类型：书</a></li>
            <li><a href="#作者francesco-ricci-等-2">作者：Francesco Ricci 等</a></li>
            <li><a href="#说明-46">说明：</a></li>
          </ul>
        </li>
        <li><a href="#其他书目">其他书目</a>
          <ul>
            <li><a href="#打包资料下载地址">打包资料下载地址：</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>专栏主体内容已经结束了，在专栏写作的过程中，我阅读了很多业界公开的资料，我觉得有必要整理出来，供想深入阅读的人继续去找虐。</p>
<p>整体来说，在选择参考文献时，我偏爱那些由公司发表的。因为推荐系统本质上还是一种非常依赖实践的算法应用方向，并且，这些商业公司论文中的技术内容也在他们实际的场景中经过了检验。</p>
<p>另外，更多的内容是来自我自己的大脑中，所以我在下面列出来的只是一部分，在经过反复删减之后，保留了这些，有中文有英文，一般来说英文居多。有较理论化的，如优化理论，更多的是较实践派，可以学完即用。这些资料分成这么几个类型。</p>
<ol>
<li>论文：以论文形式发表的，期刊数据库中可以下载到。</li>
<li>网络文章：就是在网上自由流传的内容或者博客，为了方便阅读，我将它们保存为 PDF 格式。</li>
<li>演示文稿：就是作者曾公开演讲过的内容，相对来说不是那么严谨，但是更容易理解。</li>
<li>书：推荐系统相关的书较少，我在专栏中参考过的书只有一本（附件中不提供书的电子文档）。</li>
</ol>
<p>以上的参考文献我按照章节顺序列在了下面，我还在后面附上一个推荐书单。你可以点击查看。</p>
<h2 id="原理篇">原理篇</h2>
<h2 id="1-内容推荐">1. 内容推荐</h2>
<ul>
<li>
<h3 id="题目bag-of-tricks-for-efficient-text-classification">题目：Bag of Tricks for Efficient Text Classification</h3>
</li>
</ul>
<h3 id="类型论文"><strong>类型</strong>：论文</h3>
<h3 id="作者facebook"><strong>作者</strong>：Facebook</h3>
<h3 id="说明"><strong>说明</strong>：</h3>
<p>Facebook 开源的文本处理工具 fastText 背后原理。可以训练词嵌入向量，文本多分类，效率和线性模型一样，效果和深度学习一样，值得拥有。</p>
<ul>
<li>
<h3 id="题目the-learning-behind-gmail-priority-inbox"><strong>题目</strong>：The Learning Behind Gmail Priority Inbox</h3>
</li>
</ul>
<h3 id="类型论文-1"><strong>类型</strong>：论文</h3>
<h3 id="作者google"><strong>作者</strong>：Google</h3>
<h3 id="说明-1"><strong>说明</strong>：</h3>
<p>介绍了一种基于文本和行为给用户建模的思路，是信息流推荐的早期探索，Gmail 智能邮箱背后的原理。</p>
<ul>
<li>
<h3 id="题目recommender-systems-handbook第三章第九章"><strong>题目</strong>：Recommender Systems Handbook(第三章，第九章)</h3>
</li>
</ul>
<h3 id="类型书"><strong>类型</strong>：书</h3>
<h3 id="作者francesco-ricci-等"><strong>作者</strong>：Francesco Ricci 等</h3>
<h3 id="说明-2"><strong>说明</strong>：</h3>
<p>这本书收录了推荐系统很多经典论文，话题涵盖非常广，第三章专门讲内容推荐的基本原理，第九章是一个具体的基于内容推荐系统的案例。</p>
<ul>
<li>
<h3 id="题目文本上的算法"><strong>题目</strong>：文本上的算法</h3>
</li>
</ul>
<h3 id="类型网络文章-网络免费版已有成书文本上的算法深入浅出自然语言处理内容更丰富"><strong>类型</strong>：网络文章 (网络免费版，已有成书《文本上的算法：深入浅出自然语言处理》，内容更丰富)</h3>
<h3 id="作者路彦雄"><strong>作者</strong>：路彦雄</h3>
<h3 id="说明-3"><strong>说明</strong>：</h3>
<p>介绍了文本挖掘中常用的算法，及基础概念。内容涉及概率论，信息论，文本分类，聚类，深度学习，推荐系统等。</p>
<ul>
<li>
<h3 id="题目lda-数学八卦">题目：LDA 数学八卦</h3>
</li>
</ul>
<h3 id="类型网络文章">类型：网络文章</h3>
<h3 id="作者rickjin靳志辉">作者：Rickjin(@靳志辉)</h3>
<h3 id="说明-4">说明：</h3>
<p>由浅入深地讲解 LDA 原理，对于实际 LDA 工具的使用有非常大的帮助。</p>
<h2 id="2-近邻推荐">2. 近邻推荐</h2>
<ul>
<li>
<h3 id="题目amazoncom-recommendations-item-to-item-collaborative-filtering">题目：Amazon.com recommendations: item-to-item collaborative filtering</h3>
</li>
</ul>
<h3 id="类型论文-2">类型：论文</h3>
<h3 id="作者amazon">作者：Amazon</h3>
<h3 id="说明-5">说明：</h3>
<p>介绍 Amazon 的推荐系统原理，主要是介绍 Item-Based 协同过滤算法。</p>
<ul>
<li>
<h3 id="题目slope-one-predictors-for-online-rating-based-collaborative-filtering">题目：Slope One Predictors for Online Rating-Based Collaborative Filtering</h3>
</li>
</ul>
<h3 id="类型论文-3">类型：论文</h3>
<h3 id="作者daniel-lemire-等">作者：Daniel Lemire 等</h3>
<h3 id="说明-6">说明：</h3>
<p>Slope One 算法。</p>
<ul>
<li>
<h3 id="题目item-based-collaborative-filtering-recommendation-algorithms">题目：Item-Based Collaborative Filtering Recommendation Algorithms</h3>
</li>
</ul>
<h3 id="类型论文-4">类型：论文</h3>
<h3 id="作者badrul-sarwar-等">作者：Badrul Sarwar 等</h3>
<h3 id="说明-7">说明：</h3>
<p>GroupLens 的研究团队对比了不同的 Item-to-Item 的推荐算法。</p>
<ul>
<li>
<h3 id="题目collaborative-recommendations-using-item-to-item-similarity-mappings">题目：Collaborative Recommendations Using Item-to-Item Similarity Mappings</h3>
</li>
</ul>
<h3 id="类型专利">类型：专利</h3>
<h3 id="作者amazon-1">作者：Amazon</h3>
<h3 id="说明-8">说明：</h3>
<p>是的，Amazon 申请了 Item-Based 算法的专利，所以如果在美上市企业，小心用这个算法。</p>
<ul>
<li>
<h3 id="题目recommender-systems-handbook第-4-章">题目：Recommender Systems Handbook（第 4 章）</h3>
</li>
</ul>
<h3 id="类型书-1">类型：书</h3>
<h3 id="作者francesco-ricci-等-1">作者：Francesco Ricci 等</h3>
<h3 id="说明-9">说明：</h3>
<p>第四章综述性地讲了近邻推荐，也就是基础协同过滤算法。</p>
<h2 id="3-矩阵分解">3. 矩阵分解</h2>
<ul>
<li>
<h3 id="题目matrix-factorization-and-collaborative-filtering">题目：Matrix Factorization and Collaborative Filtering</h3>
</li>
</ul>
<h3 id="类型演示文稿">类型：演示文稿</h3>
<h3 id="作者daryl-lim">作者：Daryl Lim</h3>
<h3 id="说明-10">说明：</h3>
<p>从 PCA 这种传统的数据降维方法讲起，综述了矩阵分解和协同过滤算法。矩阵分解也是一种降维方法。</p>
<ul>
<li>
<h3 id="题目factorization-meets-the-neighborhood-a-multifaceted-collaborative-filtering-model">题目：Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model</h3>
</li>
</ul>
<h3 id="类型论文-5">类型：论文</h3>
<h3 id="作者yehuda-koren">作者：Yehuda Koren</h3>
<h3 id="说明-11">说明：</h3>
<p>把矩阵分解和近邻模型融合在一起。</p>
<ul>
<li>
<h3 id="题目bpr--bayesian-personalized-ranking-from-implicit-feedback">题目：BPR- Bayesian Personalized Ranking from Implicit Feedback</h3>
</li>
</ul>
<h3 id="类型论文-6">类型：论文</h3>
<h3 id="作者steffen-rendle-等">作者：Steffen Rendle 等</h3>
<h3 id="说明-12">说明：</h3>
<p>更关注推荐结果的排序好坏，而不是评分预测精度，那么 BPR 模型可能是首选，本篇是出处。</p>
<ul>
<li>
<h3 id="题目collaborative-filtering-for-implicit-feedback-datasets">题目：Collaborative Filtering for Implicit Feedback Datasets</h3>
</li>
</ul>
<h3 id="类型论文-7">类型：论文</h3>
<h3 id="作者yifan-hu-等">作者：Yifan Hu 等</h3>
<h3 id="说明-13">说明：</h3>
<p>不同于通常矩阵分解处理的都是评分数据这样的显式反馈，本文介绍一种处理点击等隐式反馈数据的矩阵分解模型。</p>
<ul>
<li>
<h3 id="题目matrix-factorization-techniques-for-recommender-systems">题目：Matrix Factorization Techniques For Recommender Systems</h3>
</li>
</ul>
<h3 id="类型论文-8">类型：论文</h3>
<h3 id="作者yehuda-koren-等">作者：Yehuda Koren 等</h3>
<h3 id="说明-14">说明：</h3>
<p>本文是大神 Yehuda Koren 对矩阵分解在推荐系统中的应用做的一个普及性介绍，值得一读。</p>
<ul>
<li>
<h3 id="题目the-bellkor-solution-to-the-netflix-grand-prize">题目：The BellKor Solution to the Netflix Grand Prize</h3>
</li>
</ul>
<h3 id="类型论文-9">类型：论文</h3>
<h3 id="作者yehuda-koren-1">作者：Yehuda Koren</h3>
<h3 id="说明-15">说明：</h3>
<p>也是一篇综述，或者说教程，针对 Netflix Prize 的。</p>
<h2 id="4-模型融合">4. 模型融合</h2>
<ul>
<li>
<h3 id="题目adaptive-bound-optimization-for-online-convex-optimization">题目：Adaptive Bound Optimization for Online Convex Optimization</h3>
</li>
</ul>
<h3 id="类型论文-10">类型：论文</h3>
<h3 id="作者google-1">作者：Google</h3>
<h3 id="说明-16">说明：</h3>
<p>FTRL 是 CTR 预估常用的优化算法，本文介绍 FTRL 算法原理。</p>
<ul>
<li>
<h3 id="题目在线最优化求解">题目：在线最优化求解</h3>
</li>
</ul>
<h3 id="类型网络文章-1">类型：网络文章</h3>
<h3 id="作者冯扬">作者：冯扬</h3>
<h3 id="说明-17">说明：</h3>
<p>是对 FTRL 的通俗版解说。</p>
<ul>
<li>
<h3 id="题目ad-click-prediction-a-view-from-the-trenches">题目：Ad Click Prediction: a View from the Trenches</h3>
</li>
</ul>
<h3 id="类型论文-11">类型：论文</h3>
<h3 id="作者google-2">作者：Google</h3>
<h3 id="说明-18">说明：</h3>
<p>FTRL 工程实现解读。</p>
<ul>
<li>
<h3 id="题目factorization-machines">题目：Factorization Machines</h3>
</li>
</ul>
<h3 id="类型论文-12">类型：论文</h3>
<h3 id="作者steffen-rendle">作者：Steffen Rendle</h3>
<h3 id="说明-19">说明：</h3>
<p>提出 FM 模型的论文，FM 用于 CTR 预估。</p>
<ul>
<li>
<h3 id="题目field-aware-factorization-machines-for-ctr-prediction">题目：Field-aware Factorization Machines for CTR Prediction</h3>
</li>
</ul>
<h3 id="类型论文-13">类型：论文</h3>
<h3 id="作者yuchin-juan">作者：Yuchin Juan</h3>
<h3 id="说明-20">说明：</h3>
<p>FFM 模型，用于 CTR 预估。</p>
<ul>
<li>
<h3 id="题目practical-lessons-from-predicting-clicks-on-ads-at-facebook">题目：Practical Lessons from Predicting Clicks on Ads at Facebook</h3>
</li>
</ul>
<h3 id="类型论文-14">类型：论文</h3>
<h3 id="说明-21">说明：</h3>
<p>提出了 LR + GBDT 的 CTR 预估模型。</p>
<ul>
<li>
<h3 id="题目wide--deep-learning-for-recommender-systems">题目：Wide &amp; Deep Learning for Recommender Systems</h3>
</li>
</ul>
<h3 id="类型论文-15">类型：论文</h3>
<h3 id="作者google-3">作者：Google</h3>
<h3 id="说明-22">说明：</h3>
<p>提出融合深度和宽度模型的Wide&amp;Deep 模型，用于 CTR 预估。</p>
<h2 id="5bandit-算法">5.Bandit 算法</h2>
<ul>
<li>
<h3 id="题目introduction-to-bandits--algorithms-and-theory-part-1--bandits-with-small-sets-of-actions">题目：Introduction to Bandits- Algorithms and Theory Part 1- Bandits with small sets of actions</h3>
</li>
</ul>
<h3 id="类型演示文稿-1">类型：演示文稿</h3>
<h3 id="作者jean-yves-audibert-等">作者：Jean-Yves Audibert 等</h3>
<h3 id="说明-23">说明：</h3>
<p>介绍 bandit 算法概念，理论和算法，这部分主要针对小的选项候选集。</p>
<ul>
<li>
<h3 id="题目introduction-to-bandits--algorithms-and-theory-part-2--bandits-with-large-sets-of-actions">题目：Introduction to Bandits- Algorithms and Theory Part 2- Bandits with large sets of actions</h3>
</li>
</ul>
<h3 id="类型演示文稿-2">类型：演示文稿</h3>
<h3 id="作者jean-yves-audibert-等-1">作者：Jean-Yves Audibert 等</h3>
<h3 id="说明-24">说明：</h3>
<p>介绍 Bandit 算法概念，理论和算法，这部分主要针对较大的选项候选集。</p>
<ul>
<li>
<h3 id="题目a-contextual-bandit-approach-to-personalized-news-article-recommendation">题目：A Contextual-Bandit Approach to Personalized News Article Recommendation</h3>
</li>
</ul>
<h3 id="类型论文-16">类型：论文</h3>
<h3 id="作者yahoo">作者：Yahoo</h3>
<h3 id="说明-25">说明：</h3>
<p>Linucb 的原始论文，考虑上下文的 Bandit 算法。</p>
<ul>
<li>
<h3 id="题目collaborative-filtering-bandits">题目：Collaborative Filtering Bandits</h3>
</li>
</ul>
<h3 id="类型论文-17">类型：论文</h3>
<h3 id="作者shuai-li-等">作者：Shuai Li 等</h3>
<h3 id="说明-26">说明：</h3>
<p>Bandit 算法与协同过滤结合，提出 COFIBA 算法。</p>
<h2 id="6-深度学习">6. 深度学习</h2>
<ul>
<li>
<h3 id="题目deep-neural-networks-for-youtube-recommendations">题目：Deep Neural Networks for YouTube Recommendations</h3>
</li>
</ul>
<h3 id="类型论文-18">类型：论文</h3>
<h3 id="作者google-4">作者：Google</h3>
<h3 id="说明-27">说明：</h3>
<p>介绍 YouTube 视频推荐系统在深度神经网络上的尝试。能从中看到 wide&amp;deep 模型的影子。</p>
<ul>
<li>
<h3 id="题目efficient-estimation-of-word-representations-in-vector-space">题目：Efficient Estimation of Word Representations in Vector Space</h3>
</li>
</ul>
<h3 id="类型论文-19">类型：论文</h3>
<h3 id="作者google-5">作者：Google</h3>
<h3 id="说明-28">说明：</h3>
<p>Word2Vec 的作者在这篇文章中提出了一种词嵌入向量学习方法，也就是把开源工具包 Word2Vec 背后的模型详细介绍了一次。理论上很简单，更多是一些工程技巧的分享。Word2Vec 给推荐系统带来了一种新的隐因子向量学习方法，深陷评分预测泥潭的矩阵分解被开拓了思路。</p>
<ul>
<li>
<h3 id="题目item2vec-neural-item-embedding-for-collaborative-filtering">题目：Item2Vec: Neural Item Embedding for Collaborative Filtering</h3>
</li>
</ul>
<h3 id="类型论文-20">类型：论文</h3>
<h3 id="作者microsoft">作者：Microsoft</h3>
<h3 id="说明-29">说明：</h3>
<p>这篇就是借鉴了 word2vec 在语言建模中的思路，为推荐系统的行为建模，从中为物品学习嵌入向量。</p>
<ul>
<li>
<h3 id="题目learning-representations-of-text-using-neural-networks">题目：Learning Representations of Text using Neural Networks</h3>
</li>
</ul>
<h3 id="类型演示文稿-3">类型：演示文稿</h3>
<h3 id="作者google-6">作者：Google</h3>
<h3 id="说明-30">说明：</h3>
<p>理解为 word2vec 作者写一个教程。</p>
<ul>
<li>
<h3 id="题目long-short-term-memory">题目：Long Short-Term Memory</h3>
</li>
</ul>
<h3 id="类型论文-21">类型：论文</h3>
<h3 id="作者sepp-hochreiter-等">作者：Sepp Hochreiter 等</h3>
<h3 id="说明-31">说明：</h3>
<p>可以用来为序列建模的 LSTM，实际上在 1997 年就发表论文了，只是在十几年后才大火。</p>
<ul>
<li>
<h3 id="题目an-empirical-exploration-of-recurrent-network-architectures">题目：An Empirical Exploration of Recurrent Network Architectures</h3>
</li>
</ul>
<h3 id="类型论文-22">类型：论文</h3>
<h3 id="作者google-7">作者：Google</h3>
<h3 id="说明-32">说明：</h3>
<p>Google 在 RNN 模型使用上的经验分享。</p>
<ul>
<li>
<h3 id="题目recurrent-neural-networks-for-collaborative-filtering">题目：Recurrent Neural Networks for Collaborative Filtering</h3>
</li>
</ul>
<h3 id="类型网络文章-2">类型：网络文章</h3>
<h3 id="作者erik-bernhardsson">作者：Erik Bernhardsson</h3>
<h3 id="说明-33">说明：</h3>
<p>这是 Erik Bernhardsson 在 Spotify 期间所做的尝试，用 RNN 自动构建音乐播单。Erik Bernhardsson 还有一项开源项目 Annoy，用于稠密向量的近邻搜索，在推荐系统中也用得较多。</p>
<h2 id="7-其他实用算法">7. 其他实用算法</h2>
<ul>
<li>
<h3 id="题目detecting-near-duplicates-for-web-crawling">题目：Detecting Near-Duplicates for Web Crawling</h3>
</li>
</ul>
<h3 id="类型论文-23">类型：论文</h3>
<h3 id="作者google-8">作者：Google</h3>
<h3 id="说明-34">说明：</h3>
<p>在这篇论文中提出了 simhash 算法，用于大规模网页去重。</p>
<ul>
<li>
<h3 id="题目weighted-random-sampling-over-data-streams">题目：Weighted Random Sampling over Data Streams</h3>
</li>
</ul>
<h3 id="类型论文-24">类型：论文</h3>
<h3 id="作者pavlos-s-efraimidis">作者：Pavlos S. Efraimidis</h3>
<h3 id="说明-35">说明：</h3>
<p>对流式数据的加权采样。</p>
<ul>
<li>
<h3 id="题目weighted-sampling-without-replacement-from-data-streams">题目：Weighted Sampling Without Replacement from Data Streams</h3>
</li>
</ul>
<h3 id="类型论文-25">类型：论文：</h3>
<h3 id="作者vladimir-braverman-等">作者：Vladimir Braverman 等</h3>
<h3 id="说明-36">说明：</h3>
<p>介绍了两种对流式数据的加权采样。</p>
<h2 id="工程篇">工程篇</h2>
<h2 id="1-常见架构">1. 常见架构</h2>
<ul>
<li>
<h3 id="题目activity-feeds-architecture">题目：Activity Feeds Architecture</h3>
</li>
</ul>
<h3 id="类型演示文稿-4">类型：演示文稿</h3>
<h3 id="作者etsy">作者：Etsy</h3>
<h3 id="说明-37">说明：</h3>
<p>本文非常详细地介绍了社交动态信息流的架构设计细节。</p>
<ul>
<li>
<h3 id="题目atom-activity-streams-10">题目：Atom Activity Streams 1.0</h3>
</li>
</ul>
<h3 id="类型规范文档">类型：规范文档</h3>
<h3 id="作者activity-streams-working-group">作者：Activity Streams Working Group</h3>
<h3 id="说明-38">说明：</h3>
<p>这是一份动态信息流数据模型的协议规范文档，由 Activity Streams Working Group 共同发出，这个组织包含 Google 和 Microsoft。</p>
<ul>
<li>
<h3 id="题目beyond-the-5-starsnetflix-recommendations">题目：Beyond the 5 stars（Netflix Recommendations）</h3>
</li>
</ul>
<h3 id="类型网络文章-3">类型：网络文章</h3>
<h3 id="作者netflix">作者：Netflix</h3>
<h3 id="说明-39">说明：</h3>
<p>Netflix 详细宏观上介绍了自家推荐系统的产品形态，不只是比赛中的评分预测那么简单的。</p>
<ul>
<li>
<h3 id="题目system-architectures-for-personalization-and-recommendation">题目：System Architectures for Personalization and Recommendation</h3>
</li>
</ul>
<h3 id="类型网络文章-4">类型：网络文章</h3>
<h3 id="作者netflix-1">作者：Netflix</h3>
<h3 id="说明-40">说明：</h3>
<p>Netflix 推荐系统的架构介绍。</p>
<ul>
<li>
<h3 id="题目information-seeking-convergence-of-search-recommendations-and-advertising">题目：Information Seeking-Convergence of Search, Recommendations and Advertising</h3>
</li>
</ul>
<h3 id="类型论文-26">类型：论文</h3>
<h3 id="作者h-garcia-molina-等">作者：H Garcia-Molina 等</h3>
<h3 id="说明-41">说明：</h3>
<p>探讨搜索、推荐、广告三者架构统一。</p>
<h2 id="2-关键模块">2. 关键模块</h2>
<ul>
<li>
<h3 id="题目overlapping-experiment-infrastructure--more-better-faster-experimentation">题目：Overlapping Experiment Infrastructure- More, Better, Faster Experimentation</h3>
</li>
</ul>
<h3 id="类型论文-27">类型：论文</h3>
<h3 id="作者google-9">作者：Google</h3>
<h3 id="说明-42">说明：</h3>
<p>ABTest 实验平台的扛鼎之作，Google 出品，值得拥有。</p>
<ul>
<li>
<h3 id="题目tencentrecreal-time-stream-recommendation-in-practice">题目：TencentRec：Real-time Stream Recommendation in Practice</h3>
</li>
</ul>
<h3 id="类型论文-28">类型：论文</h3>
<h3 id="作者腾讯">作者：腾讯</h3>
<h3 id="说明-43">说明：</h3>
<p>介绍了腾讯内部的实时推荐系统架构。</p>
<ul>
<li>
<h3 id="题目personalization-at-spotify-using-cassandra">题目：Personalization at Spotify using Cassandra</h3>
</li>
</ul>
<h3 id="类型网络文章-5">类型：网络文章</h3>
<h3 id="作者spotify">作者：Spotify</h3>
<h3 id="说明-44">说明：</h3>
<p>介绍了 Spotify 在推荐系统所用到的数据存储中间件。</p>
<h2 id="3-效果保证">3. 效果保证</h2>
<ul>
<li>
<h3 id="题目tutorial-on-robustness-of-recommender-systems">题目：Tutorial on Robustness of Recommender Systems</h3>
</li>
</ul>
<h3 id="类型演示文稿-5">类型：演示文稿</h3>
<h3 id="作者neil-hurley">作者：Neil Hurley</h3>
<h3 id="说明-45">说明：</h3>
<p>本文非常详细讨论了对推荐系统的攻击和防护，并有实验模拟。</p>
<ul>
<li>
<h3 id="题目recommender-systems-handbook第八章">题目：Recommender Systems Handbook(第八章)</h3>
</li>
</ul>
<h3 id="类型书-2">类型：书</h3>
<h3 id="作者francesco-ricci-等-2">作者：Francesco Ricci 等</h3>
<h3 id="说明-46">说明：</h3>
<p>该书第八章介绍了能见到的几乎所有推荐系统评价指标，只是实际上用不到这么多指标。</p>
<h2 id="其他书目">其他书目</h2>
<ol>
<li>Pattern Recognization and Machine Learning（机器学习基础，有此一本足够了）。</li>
<li>推荐系统实践（国内唯一一本非翻译的推荐系统书籍，入门必选）。</li>
<li>信号与噪声（介绍贝叶斯统计的一本科普书）。</li>
<li>复杂（推荐系统面对的是复杂网络，了解复杂系统和复杂网络的特点，有助于开脑洞）。</li>
<li>信息简史（既然是信息经济，当然要读一本关于信息的历史）。</li>
</ol>
<p>知道你们不会读的，所以就不推荐太多了。但愿我这个激将法有助于你学习进步。</p>
<h3 id="打包资料下载地址">打包资料下载地址：</h3>
<ul>
<li><a href="https://pan.baidu.com/s/1pbjQ94QBcRerv6ZW3-sopg">https://pan.baidu.com/s/1pbjQ94QBcRerv6ZW3-sopg</a></li>
<li>密码:6mds</li>
</ul>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/d3b48a2755db0a3707ef37007c2179c8.png" alt=""></p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F/">推荐系统三十六式</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E7%89%B9%E5%88%AB%E5%8A%A0%E9%A4%90__%E6%88%91%E5%9C%A82019%E5%B9%B4f8%E5%A4%A7%E4%BC%9A%E7%9A%84%E4%B8%A4%E6%97%A5%E8%A7%81%E9%97%BB%E5%BD%95/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">特别加餐__我在2019年F8大会的两日见闻录</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB__%E6%88%91%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E6%95%85%E4%BA%8B/">
            <span class="next-text nav-default">推荐阅读__我与人工智能的故事</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

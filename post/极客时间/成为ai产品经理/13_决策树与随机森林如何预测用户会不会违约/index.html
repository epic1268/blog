<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>13_决策树与随机森林：如何预测用户会不会违约？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是海丰。
今天，我们要讲决策树与随机森林。决策树是一种基础的分类和回归算法，随机森林是由多棵决策树集成在一起的集成学习算法，它们都非常常用。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/13_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%A6%82%E4%BD%95%E9%A2%84%E6%B5%8B%E7%94%A8%E6%88%B7%E4%BC%9A%E4%B8%8D%E4%BC%9A%E8%BF%9D%E7%BA%A6/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/13_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%A6%82%E4%BD%95%E9%A2%84%E6%B5%8B%E7%94%A8%E6%88%B7%E4%BC%9A%E4%B8%8D%E4%BC%9A%E8%BF%9D%E7%BA%A6/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="13_决策树与随机森林：如何预测用户会不会违约？">
  <meta property="og:description" content="你好，我是海丰。
今天，我们要讲决策树与随机森林。决策树是一种基础的分类和回归算法，随机森林是由多棵决策树集成在一起的集成学习算法，它们都非常常用。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="成为AI产品经理">

  <meta itemprop="name" content="13_决策树与随机森林：如何预测用户会不会违约？">
  <meta itemprop="description" content="你好，我是海丰。
今天，我们要讲决策树与随机森林。决策树是一种基础的分类和回归算法，随机森林是由多棵决策树集成在一起的集成学习算法，它们都非常常用。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="4748">
  <meta itemprop="keywords" content="成为AI产品经理">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="13_决策树与随机森林：如何预测用户会不会违约？">
  <meta name="twitter:description" content="你好，我是海丰。
今天，我们要讲决策树与随机森林。决策树是一种基础的分类和回归算法，随机森林是由多棵决策树集成在一起的集成学习算法，它们都非常常用。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">13_决策树与随机森林：如何预测用户会不会违约？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 4748 字 </span>
          <span class="more-meta"> 预计阅读 10 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#如何理解决策树">如何理解决策树？</a>
          <ul>
            <li><a href="#决策树的生成">决策树的生成</a></li>
            <li><a href="#信息熵">信息熵</a></li>
            <li><a href="#剪枝操作">剪枝操作</a></li>
          </ul>
        </li>
        <li><a href="#决策树的应用案例预测用户违约">决策树的应用案例：预测用户违约</a></li>
        <li><a href="#决策树的优缺点">决策树的优缺点</a></li>
        <li><a href="#随机森林集体的力量">随机森林：集体的力量</a></li>
        <li><a href="#总结">总结</a></li>
        <li><a href="#课后讨论">课后讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是海丰。</p>
<p>今天，我们要讲决策树与随机森林。决策树是一种基础的分类和回归算法，随机森林是由多棵决策树集成在一起的集成学习算法，它们都非常常用。</p>
<p>这节课，我就通过决策树预测用户会不会违约的例子，来给你讲讲决策树和随机森林的原理和应用。</p>
<h2 id="如何理解决策树">如何理解决策树？</h2>
<p>很多人都有过租房子的经历，那你是怎么决定要不要租一个房子的呢？你可以先想一想，我先把我的做法说一下，我会先判断房子的位置，再看价格，最后看装修。</p>
<p>更具体点来说，我只会选择离公司近的房子，比如说 5 公里以内的或者通勤时间在 40 分钟以内的。其次，如果价格便宜，不管装修得好不好我都租，如果价格贵那我就要看装修情况，装修好就租，装修不好就不租。</p>
<p>这就是一棵典型的决策树：对于租房子这个问题，我根据距离、价格、装修这几个条件，对一个房子进行了判断，最后得到一个解决结果，就是这个房子我是租或者不租。下图就是这棵决策树的示意图。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/f0d7b9fedf46a192f78437ead4fa09e1.png" alt=""></p>
<p>我们可以看到，决策树（Decision Tree）就是一种树形结构的算法，上面的节点代表算法的某一个<strong>特征（如距离、价格），节点上可能存在多个分支，每一个分支代表的是这个特征的不同种类（如距离远、距离近），最后的叶子节点代表最终的决策结果（如租、不租）</strong>。</p>
<h3 id="决策树的生成">决策树的生成</h3>
<p>知道了决策树的形式和原理，我们再来看看决策树的生成过程，它是决策树的核心。不过，对于产品经理来说，更重要的还是掌握决策树的原理、形式、优缺点。那我把它的详细过程写在下面，就是让你在工作中遇到类似问题的时候，能直接回来补充必要的知识，所以今天我们先对整体过程有个大致了解就可以了。</p>
<p>**决策树生成的过程包括三个部分，分别是特征选择、决策树生成、决策树剪枝。**下面，我们还是拿上面租房子的例子，来说一说这个决策树生成的过程。假设现在有如下条件的一个房子，根据我上面定下的规则，你觉得这个房子我会不会租呢？</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/f15356a9abc2e3260e17023b7a752e73.png" alt=""></p>
<p>我们先看距离，因为这个房子距离公司远，所以根据上面的决策树，我们就能直接得出结论：不租。但是，假设我们的决策树不是用距离作为根节点，而是用价格作为根节点的话，结果会不会不一样呢？</p>
<p>这个时候，决策棵树可能会变成下面的样子：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/211c7e8a9c708c1282ca17609246b59f.png" alt=""></p>
<p>你会发现，我们的决策树一下子变“大”了，判断这个房子的过程就变成了，先看价格，再看装修，最后看距离。我们发现，即使决策树的结构发生了变化，可我们还是会得到之前的结论：不租，所以，决策树的构造只会影响到算法的复杂度和计算的时间，而不会影响决策的结果。</p>
<p>因此，在实际工作中，我们就需要优化决策树的结构，让它的效率更高，但这具体该怎么做呢？</p>
<h3 id="信息熵">信息熵</h3>
<p>我们一般会在特征选择和决策树的生成阶段，通过<strong>信息熵</strong>来决定哪些特征重要以及它们应该放到哪个节点上，因为信息熵是用来衡量<strong>一个节点内信息的不确定性的</strong>。一个系统中信息熵越大，这个系统的不确定性就越大，样本就越多样，你也可以理解成是样本的<strong>纯度越低</strong>，信息熵越小，系统的不确定性就越小，样本越趋于一致，那样本的<strong>纯度就越高</strong>。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/3f24ff59a41ec148ece9094106f7261f.png" alt=""></p>
<p>我们肯定是希望决策树在每次划分的时候，每个条件分支都能够最大化地去划分这些样本，让每个节点的信息熵更低，样本一致性更高。所以，决策树会计算每一个特征划分后样本的“<strong>纯度</strong>”，纯度越高的特征越接近根节点。这样一来，决策树的复杂度和计算时间肯定就会越少，也就不会出现我们刚才说的那种“很大”的决策树。这就是实际工作中我们构造决策树的思路了。</p>
<p>实际上，决策树的算法有很多，最典型的三种分别是 ID3（Iterative Dichotomiser 3，迭代二叉树 3 代）、C4.5 和 CART（Classification and Regression Trees，分类与回归树）。ID3 是最初代的决策树算法，它使用的计算指标是信息增益；C4.5 是在 ID3 基础上改进后的算法，它使用的计算指标是信息增益率；CART 分类与回归树，做分类问题时使用的是 Gini 系数（Gini Coefficient，基尼系数），做回归问题的时候使用的是偏差值。</p>
<p>作为产品经理，我们简单了解这三种算法的特点就可以了，我在下面对它们进行了总结，你可以参考一下。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/91e975a2273bc5708c080413f30e83ef.png" alt=""></p>
<h3 id="剪枝操作">剪枝操作</h3>
<p>最后，因为决策树很容易出现过拟合情况，所以我们还会引入剪枝操作这个环节。剪枝就是我们对一棵树进行简化，减少它的复杂程度，提高模型的泛化能力。剪枝的原理很好理解，主要就是判断把某个节点去掉之后，模型的准确度会不会降低了，如果没有降低，就可以减掉这个节点。</p>
<p>剪枝的操作还分为预剪枝和后剪枝，它们的区别是剪枝发生的阶段不同。预剪枝在决策树生成时候同步进行。而后剪枝是决策树生成之后，再对决策树的叶子节点开始一步一步地向根方向剪枝。</p>
<h2 id="决策树的应用案例预测用户违约">决策树的应用案例：预测用户违约</h2>
<p>决策树的生成讲完了，我们重点来看看决策树的应用。在金融风控场景下，我们经常需要判断用户的违约风险。</p>
<p>最早的风控模型都是使用逻辑回归来做的，因为它相对简单而且可解释性强。但逻辑回归属于线性模型，不能很好处理非线性特征，所以决策树算法也慢慢用于违约风险的预测。接下来，我们就来看看决策树是怎么预测违约风险的。</p>
<p>决策树预测用户违约的核心思想是：<strong>先获取部分用户的历史数据，历史数据中包括过去的信贷数据和还款结果；然后将贷款客户不断进行分类，直到某个节点的样本用户都是同一个类型为止；最后，再对决策树进行剪枝，简化树的复杂度。</strong></p>
<p>假设我们得到的用户历史数据如下所示。对于这个表格，我再补充解释一下，过去的信贷数据应该包括申请数据、金融产品相关数据等等。年龄，是否有房这些都属于申请数据，是包括在信贷数据里的。</p>
<p>还款结果指的是什么时候还款，还了多少，但是做模型设计，定义模型目标变量的时候，我们不可能直接用还款数据，所以我们定义是否逾期作为目标值，也就是 Y 值。1 代表逾期，0 代表不逾期。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/d4b690f7d0bf10bf541ad09482e7be40.png" alt=""></p>
<p>因为目前决策树算法中，使用比较多的是 CART 算法，所以我们也选择它进行模型构建，而特征选择阶段会使用 Gini 系数。CART 算法选择 Gini 系数，是因为信息熵模型使用了大量的对数计算导致效率很低，而 Gini 系统可以避免这个问题，从而提升计算效率。</p>
<p>从上面的历史数据中，我们可以提取出三个特征，分别是性别、年龄和是否有房。接下来，我们就分别计算一下这三个特征的 Gini 系数。</p>
<p>首先，性别特征的 Gini 系数直接根据公式计算就可以了，我们假设它就是 0.412。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/bc44258ab7a50eeb95b7d1c47b33ec88.png" alt=""></p>
<p>我们重点来看第二个特征：年龄。年龄是一个连续的值，我们的历史数据中一共有 4 种数值，每两个相邻值之间都可以是一个特征分类的点（比如说，年龄 22 和年龄 24 的分类点就是 23），所以对于年龄这个特征，我们一共有 3 种不同的分类方式。因为分类方式比较多，相对应的，Gini 的计算方式就会比较复杂，我们需要分别计算 3 种不同分类方式时的 Gini 系数，选出 Gini 最小的分类方式，把它作为年龄的分类。</p>
<p>假设年龄在 37 的时候 Gini 系数最小，等于 0.511，那么年龄这个特征的条件分支就是小于 37 和大于 37。</p>
<p>相同的，我们可以再计算是否有房的 Gini 系数。假设这个特征的 Gini 系数为 0.113，最后，根据 Gini 排序我们就能得到如下的决策树结构。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/eaa3cdf5d55902b8413ea58178c23819.png" alt=""></p>
<p>但是，这个决策树还不是最终的结构，因为有些节点我们是可以去掉的。比如说，我们发现有房产这个条件下面的所有节点，去掉和不去掉的时候模型准确性没有变化，那我们就可以把有房产下面的所有节点裁剪掉，从而得到新的决策树。</p>
<p>这就是剪枝操作，在我们实际工作中通常采取后剪枝的操作，从叶子节点逐步向上判断哪些节点是可以去掉的，剪枝后的决策树如下所示。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/f1c71e7939357b5b523aceacd0faf611.png" alt=""></p>
<p>以上就是决策树创建的过程，因为没有进行实际计算，实际结果可能有偏差，你只要理解这个过程就可以了。</p>
<h2 id="决策树的优缺点">决策树的优缺点</h2>
<p>通过上面的学习我们可以发现，决策树的优点和缺点都很明显。由于具有树形结构所以决策树的可解释性强，直观好理解，而且我们还可以从结果向上去追溯原因。采用决策树，我们可以很方便地和领导、业务方、甲方去解释我们的模型是什么，以及有哪些因素影响了模型的结果。</p>
<p>不过，决策树的缺点也非常明显。当数据量大，数据维度（样本具有的特征或者属性，如价格、位置）很多的时候，决策树会变得非常复杂，训练时间会很久。</p>
<p>另外，决策树还有一个很明显的缺点就是，需要算法同学手工设置决策树的深度（决策树要分多少层），如果设置了不合适的参数，就很可能造成欠拟合或者过拟合的情况。比如说，深度太浅就意味着你的叶子节点分得不干净，很容易造成欠拟合的情况，深度太深也会导致决策树训练时间太久，复杂度太高，很容易造成过拟合的情况。</p>
<h2 id="随机森林集体的力量">随机森林：集体的力量</h2>
<p>在实际工作中，我们既可以只使用一棵决策树来解决问题，也可以使用多棵决策树来共同解决问题，也就是随机森林。</p>
<p>随机森林（Random Forest）指的是由多棵决策树组成，随机指的是每一个决策树的样本是随机从数据集中采样得到的。假设，模型由三个决策树 A、B、C 组成，我们给每棵决策树都随机抽取样本进行训练，由于这三棵树的训练样本不一样，因此它们最后得到的决策结果有可能不同。最后，我们再把这三棵树得到的结果做一个综合，就能得到最终的决策结果了。</p>
<p>随机森林的原理很好理解，那我们再来说说它的优缺点。因为这个算法是随机从数据集中进行采样的，所以模型的随机性很强，不容易产生过拟合的情况，但正因为样本是随机的，所以模型对于样本数据的异常值也不太敏感。</p>
<p>其次，因为算法采样的时候，是从整个数据集中抽取其中一部分进行采样，而且随机森林是由多棵树组合而成的，所以模型中的每一棵决策树都可以并行训练和计算，这样一来，在面向大数据量的情况下，随机森林的运行效率更高。</p>
<p>也正是因为这样，随机森林在训练时候需要的计算成本会更高，而且，就算它们整合之后会比之前单一模型表现好，但在面对复杂样本的时候，它们仍然没有办法很好区分，所以模型上限很低。</p>
<p>随机森林属于集成学习中的一种。集成学习（Ensemble Learning）可以理解为，不是通过某一个单独的机器学习算法解决问题，而是通过多个机器学习算法结合使用来完成最终的算法，最终达到 1+1&gt;2 的效果。核心原理你可以记成是我们常说的“三个臭皮匠赛过一个诸葛亮”。</p>
<p>集成学习的内部由很多弱监督模型组成，某一个弱监督模型只在某一个方向上表现比较好，当我们把这些算法合而为一的时候，就会得到一个各方面都会表现较好的模型。集成学习的算法有很多，随机森林是其中比较有代表性的一种。我在下面整理了一个集成学习的思维导图，你可以了解一下。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/9a8b3c5810b68daf60d79c80f1f52ce8.png" alt=""></p>
<h2 id="总结">总结</h2>
<p>今天，我们讲了决策树、随机森林的原理、应用和优缺点。理解决策树是理解随机森林和集成学习的基础，不过，作为产品经理，我们的重点不在于理解决策树的生成过程，只是借着它的生成加深对决策树原理和应用的理解。</p>
<p>总的来说，关于决策树和随机森林，我希望你重点记住这 5 点：</p>
<ol>
<li>决策树就是一种树形结构的算法，它很直观，可视化很强，但也容易过拟合；</li>
<li>决策树特征选择是生成决策树的基础，不同的算法对应了不同的特征选择方式；</li>
<li>集成学习是多个机器学习算法的结合；</li>
<li>随机森林是集成学习中的一种，由多棵决策树组成；</li>
<li>随机森林的原理你可以记成：三个臭皮匠赛过一个诸葛亮，它的特点你可以记成：模型起点高、天花板低。</li>
</ol>
<p>除此之外，关于决策树和随机森林的应用场景我还想再强调一下。决策树和随机森林模型的可解释度都很高，这就意味着我们可以轻松地把模型的计算逻辑介绍清楚。</p>
<p>实际上，这一点对于咨询、金融、医疗领域的公司来说非常重要，因为你的客户往往不懂你的模型内部在做什么，但如果你的模型结构清晰，你就能在最短的时间内介绍出模型的优势。而且，因为随机森林这样的集成学习算法融合了多个模型的优点，所以对于解决分类问题来说，决策树和随机森林是当今的机器学习算法的首选，就比如你可能听过的 GBDT、XGBoost 就是决策树的升级版。</p>
<h2 id="课后讨论">课后讨论</h2>
<p>因为产品经理不需要实际进行模型的构建，所以我不会让你去构建一棵决策树，我想请你来梳理一下，你所在的团队中有哪些项目是基于决策树、随机森林或者是升级算法解决的呢？</p>
<p>欢迎在留言区分享你的经验，我们下节课见！</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%88%90%E4%B8%BAai%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/">成为AI产品经理</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%AD%A6%E6%9E%B6%E6%9E%84/13_%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B%E8%AF%A6%E7%BB%86%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">13_架构设计流程：详细方案设计</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%AD%A6%E5%BE%AE%E6%9C%8D%E5%8A%A1/13_%E5%BC%80%E6%BA%90%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%A6%82%E4%BD%95%E9%80%89%E5%9E%8B/">
            <span class="next-text nav-default">13_开源服务注册中心如何选型？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

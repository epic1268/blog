<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>09__视听触的协同性：从人感知世界的时间延迟去理解协同 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是 Rocky。
在前面几节课里我们分别谈了视觉、听觉和触觉。今天我们来聊聊视听触的协同。
视听触协同相当于是一种进阶的体验设计，它在生活中无处不在。毕竟人是有着复杂感官通道的动物，对自然的认知本来就是多通道、多感官的。我下面描述一个场景，你可以尝试从多感官协同体验维度理解一下。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%9B%A0%E7%9A%84%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E8%AF%BE/09__%E8%A7%86%E5%90%AC%E8%A7%A6%E7%9A%84%E5%8D%8F%E5%90%8C%E6%80%A7%E4%BB%8E%E4%BA%BA%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E7%9A%84%E6%97%B6%E9%97%B4%E5%BB%B6%E8%BF%9F%E5%8E%BB%E7%90%86%E8%A7%A3%E5%8D%8F%E5%90%8C/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%9B%A0%E7%9A%84%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E8%AF%BE/09__%E8%A7%86%E5%90%AC%E8%A7%A6%E7%9A%84%E5%8D%8F%E5%90%8C%E6%80%A7%E4%BB%8E%E4%BA%BA%E6%84%9F%E7%9F%A5%E4%B8%96%E7%95%8C%E7%9A%84%E6%97%B6%E9%97%B4%E5%BB%B6%E8%BF%9F%E5%8E%BB%E7%90%86%E8%A7%A3%E5%8D%8F%E5%90%8C/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="09__视听触的协同性：从人感知世界的时间延迟去理解协同">
  <meta property="og:description" content="你好，我是 Rocky。
在前面几节课里我们分别谈了视觉、听觉和触觉。今天我们来聊聊视听触的协同。
视听触协同相当于是一种进阶的体验设计，它在生活中无处不在。毕竟人是有着复杂感官通道的动物，对自然的认知本来就是多通道、多感官的。我下面描述一个场景，你可以尝试从多感官协同体验维度理解一下。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="基于人因的用户体验设计课">

  <meta itemprop="name" content="09__视听触的协同性：从人感知世界的时间延迟去理解协同">
  <meta itemprop="description" content="你好，我是 Rocky。
在前面几节课里我们分别谈了视觉、听觉和触觉。今天我们来聊聊视听触的协同。
视听触协同相当于是一种进阶的体验设计，它在生活中无处不在。毕竟人是有着复杂感官通道的动物，对自然的认知本来就是多通道、多感官的。我下面描述一个场景，你可以尝试从多感官协同体验维度理解一下。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="3628">
  <meta itemprop="keywords" content="基于人因的用户体验设计课">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="09__视听触的协同性：从人感知世界的时间延迟去理解协同">
  <meta name="twitter:description" content="你好，我是 Rocky。
在前面几节课里我们分别谈了视觉、听觉和触觉。今天我们来聊聊视听触的协同。
视听触协同相当于是一种进阶的体验设计，它在生活中无处不在。毕竟人是有着复杂感官通道的动物，对自然的认知本来就是多通道、多感官的。我下面描述一个场景，你可以尝试从多感官协同体验维度理解一下。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">09__视听触的协同性：从人感知世界的时间延迟去理解协同</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 3628 字 </span>
          <span class="more-meta"> 预计阅读 8 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#视听协同">视听协同</a></li>
        <li><a href="#视触协同">视触协同</a></li>
        <li><a href="#声触协同">声触协同</a></li>
        <li><a href="#视听触综合协同">视听触综合协同</a></li>
        <li><a href="#总结"><strong>总结</strong></a></li>
        <li><a href="#作业">作业</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是 Rocky。</p>
<p>在前面几节课里我们分别谈了视觉、听觉和触觉。今天我们来聊聊视听触的协同。</p>
<p>视听触协同相当于是一种进阶的体验设计，它在生活中无处不在。毕竟人是有着复杂感官通道的动物，对自然的认知本来就是多通道、多感官的。我下面描述一个场景，你可以尝试从多感官协同体验维度理解一下。</p>
<p>你赤着脚走在热带小岛软软的金色沙滩上，海滩的细沙按摩着脚底。余晖洒满天空，也让海面泛起闪闪金光。带有一丝咸涩的海风吹来，吹散了你的头发，也带来丝丝的清凉。海浪拍打着海岸，哗哗的海浪声伴随着海鸟的欢歌。你随手捡起一个贝壳，抚摸它多彩的纹路……</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%9B%A0%E7%9A%84%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E8%AF%BE/076a31a63fc7770a75839aa3f370caff.png" alt=""></p>
<p>上面的描述有视觉、听觉、触觉甚至嗅觉。这就是人与自然的多感交互。那现在我们要设计一个人造物、一个电子产品、一个 App，一样需要考虑，如何在设计中能带给人自然的交互体验。那么自然的视听触协同体验有哪些考虑点呢？我们可以大致拆解为几种协同：视听协同、视触协同和声触协同。</p>
<h2 id="视听协同">视听协同</h2>
<p>我们首先来看视听协同。我们都知道声音的传播速度远小于光速，但对于大脑而言，只要声音和图像信号之间的延迟小到一定的范围，人就根本感觉不到它们的不同步，甚至就直接把看到的和听到的自然结合到一起。</p>
<p>国际标准组织已经做过实验，并将声画不同步的定义做成了标准。在视频领域：</p>
<ol>
<li>如果声音比图像延迟不到 100ms，或者说声音比图像提前不超过 25ms，人是感知不到的；</li>
<li>如果说声音比图像延迟超过 125ms，或者声音比图像提前超过 45ms，人就会比较明显地察觉到了；</li>
<li>如果声音比图像延迟超过 185ms，或者声音比图像提前超过 90ms，人就已经不可接受了。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%9B%A0%E7%9A%84%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E8%AF%BE/51e78335d007f5a0bf97e0e2f0868e7d.png" alt=""></p>
<p>这就意味着，如果我们设计一个好的动效，再配上音效，那么<strong>动效与音效之间的时延要控制在 -100ms~25ms 之间，用户才会获得良好的视听协同体验。</strong></p>
<p>iMassage 发送烟花的全屏特效是一个非常棒的视听协同案例。这些烟花是随机播放出来的，背后是图形计算的算法。当烟花在屏幕上播放的时候，你能完美感受到烟花炸开和对应声音的协同匹配。短促的烟花、大个的烟花，不同烟花对应的音效都有差别。整个烟花绽放的过程接近自然，彷佛是自己身临其境在现场看烟花一样。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%9B%A0%E7%9A%84%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E8%AF%BE/6ff0d5167373f5f982a30f862e175a11.png" alt=""></p>
<p>声画同步仅仅是视听协同的第一步。好的音效设计，还要符合物理世界的隐喻。这个我在 07 中讲过一部分。</p>
<p>声音也有一部分视觉属性。这也属于感官的联觉部分。从色相上的理解来看，不同的人对不同频率的声音，或者不同的乐器会有不同的色彩联想，可以讲是仁者见仁智者见智。</p>
<p>但是音调和色彩的明度是有很明显的联觉的。以下是不同的音调对应的色彩明度：</p>
<ol>
<li>高音区：明朗、响亮，对应的色彩明度高；</li>
<li>中音区：梦幻、辉煌，对应色彩明度适中；</li>
<li>低音区：苍老、深沉、悲哀，对应色彩的明度低，色彩偏暗。</li>
</ol>
<p>另外声音的大小和视觉物体的大小（或者重量感）也是有很明显的联觉的。我们在考虑视听协同的设计时，需要考虑声音的视觉属性。</p>
<p>举个例子，比如对于音乐播放界面来说，你需要考虑如何通过视觉动效的运动变化，去适配音乐的律动。现在很多音乐 App 播放界面上用模拟黑胶的旋转，或者单纯在音乐播放背景用静态的音乐专辑封面图片。应该说这样做在简约设计的同时，也放弃了视觉声音的联觉设计，有些可惜。</p>
<h2 id="视触协同">视触协同</h2>
<p>以人的视角来看，视触协同分为两种。一种是主动的视触协同，也就是人主动触控设备，然后设备产生动效变化来给用户清晰的视觉反馈。一种是被动的视触协同，也就是设备主动出现视觉的变化（比如通知），然后会产生振动反馈以提醒人的注意。我们主要来看看主动的视触协同。</p>
<p>什么样的动效反馈我们不会感觉到卡顿？可见并能对我们产生影响的视觉刺激最短时长是 5ms，对应的帧率是 200 帧。</p>
<p>很多人说是不是 60 帧的游戏画面就不卡顿了？我要说这还远远没有达到人的流畅视觉体验极限。之所以很多人都会说 60 帧，是因为提这个概念的时候，屏幕刷新频率就是 60hz。所以 60 帧就是这种屏幕动效处理的极限了。</p>
<p>那究竟什么样的动效才是真的流畅体验？在我们屏幕刷新率技术没有达到 5ms 这个极限的时候，屏幕刷新率越高动效就越流畅。</p>
<p>而达到了 200hz 的刷新率后，屏幕刷新率再往上做就已经没有太大意义了。因为这个时候人的肉眼已经根本分辨不出来区别了。</p>
<p>现在很多手机屏幕的刷新率已经达到了 120hz。这对应的每两帧之间的间隔是 8.33ms，还没有接近人能感知的极限。现在有的屏幕厂家已经提出要做 240hz 的刷新率，那真的超过人的流畅性认知极限了。</p>
<p>当我们的手指在屏幕上产生交互动作，比如滑动、点击、捏合时，屏幕上的交互动效以一个什么样的延时，我们是可以接受的？答案是越快越好。</p>
<p>在屏幕刷新频率没有达到 200hz 之前，最优秀的动效产生的时延，就是在手指触到屏幕的下一帧间隔内。当然这个是最优的处理。从人因角度上来看，有没有一个忍受的极限呢？答案也是有的。</p>
<p>**人的大脑能感知到的因果关系的最长时延是 140ms。**这就意味着如果你的手指点击屏幕上的一个按钮，结果交互反馈动效在 140ms 后才体现出来，你就会觉得这个动效和刚才那个点击没有直接的因果关系。或者说这个动效的延迟过于明显，以至于你不可接受。</p>
<p>合理的时延，仅仅是视触协同的第一步。好的触控视觉反馈绝不仅仅是唯快不破这么简单。为了让触控视觉反馈更符合物理世界的规律，触控的很多参数都可以作为变量来使视觉反馈看起来更加自然。</p>
<p>对于滑动的手势来说，这个手势滑动的方向、距离、速度，手指离开屏幕的时机，都可以作为动效曲线生成的参数。</p>
<p>比如下面这个华为的返回动效，如果你是左手握持向上滑动，那么应用界面缩小，最后返回到对应桌面图标的动效就是向左上的一个抛物曲线。如果你是右手做类似的滑动，就会是一个向右上的抛物曲线。后来，我们把这一系列拟合物理规律的动效曲线做成了动效引擎，集成在华为的 EMUI 里。所以你会在华为的各种交互动效场景里感受到这种自然。</p>
<h2 id="声触协同">声触协同</h2>
<p>接下来我们谈谈声触协同。和视听、视触协同不同，在声触协同体验中，触控反馈的表现力远远低于听觉，所以如果你想通过触觉模拟声音的频率、音色的话，在很多时候是困难且没有必要的。</p>
<p>对于什么样的音效应该适配什么样的振动反馈，这就不仅仅是保持同步那么简单了。</p>
<p>振动反馈由于表现力弱，非常容易被声音掩盖住，所以它在使用过程中应该适量使用，不必完美去复制声波的频率和振幅。比如下图，触控反馈仅仅是选择了声音振幅的几个高点做了脉冲映射。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%9B%A0%E7%9A%84%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E8%AF%BE/79ce78df35b63d734f8b67ab97d39ca1.png" alt=""></p>
<p>甚至我们可以考虑让触控反馈与声音去按照某些因果关系错开播放，这样人的体验会更加明显。比如在声音真正开始前就启动振动，让声音成为振动的一个果。这在体验上也是自然的交互。苹果支付（Apple Pay）的音效和触控就是先有的振动，才开始有声音。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%9B%A0%E7%9A%84%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E8%AF%BE/1206662fee5165bbeee4ff1cf20b07d0.png" alt=""></p>
<h2 id="视听触综合协同">视听触综合协同</h2>
<p>最后，我们来看看视听触的综合协同。在某些交互场景下，视听触协同要是同时发生，那么用户体验会更加自然。比如弹性模拟、机械齿轮模拟、阻尼模拟、气泡模拟等。</p>
<p>我拿机械齿轮模拟为例，给你简要分析一下。对于拨盘界面而言，比如手机时间应用里面调整时间的拨盘界面，又或者手机相机里面调整参数的拨盘界面，但凡涉及到拨盘，就应该有一定的动效和音效去完美配合。</p>
<p>早些年华为的拨盘音效是不管你如何拨动拨盘，对应的音效和触控反馈都是均匀的。这样的交互反馈对用户而言非常不自然。后面我们更改了算法，跟踪用户滑动拨盘的速度，然后在视觉反馈上通过阻尼的方式模拟拨盘慢下来的过程。随着拨盘减速，音效的哒哒声和对应的振动反馈也同步减速，这样在视听触上完美拟合了整个过程。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%9B%A0%E7%9A%84%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E8%AF%BE/5a8e6887f093b7d27e6cbb4d265e6a06.png" alt=""></p>
<p>好的视听触协同的体验，会将生活中的“自然流畅”体现为：**人眼看到的视觉感知流畅、大脑认知理解的流畅以及手触控操作的流畅。**这样才能为用户提供极致流畅的综合体验。</p>
<h2 id="总结"><strong>总结</strong></h2>
<p>好了，讲到这里，今天的内容也就基本结束了。最后我来给你总结一下今天讲的要点。</p>
<p>今天我们聊的是相对高阶的视听触协同设计背后人因。我们可以把视听触协同拆解为三种协同：视听协同、视触协同和声触协同。</p>
<p>如果你将动效与音效之间的时延控制在 -100ms~25ms 之间，人会获得良好的视听协同体验。除了和物理世界接近之外，你还要注意声音的视觉属性。比如音调和色彩明度之间的对应，音量大小和视觉物体的大小（或者重量感）的对应。这些都是联觉体验的重要部分。</p>
<p>在视触协同体验上，5ms 是人能感觉到视觉刺激的最短时长，对应的是 200hz 的屏幕刷新率。触控屏幕与动效响应的时间最迟不要超过 140ms，否则会脱离因果关系的认知。好的触控设计不仅仅体现在时延控制上，同时还应该考虑物理世界规律的遵循，比如针对滑动方向、距离、速度，用算法去生成不同的动效曲线。</p>
<p>声触协同的处理要兼顾振动反馈的硬件技术瓶颈，选用声音振幅的高点做脉冲映射，又或者是调整振动和声音的因果关系，让振动成为声音的因。这些做法都会让两者协同更加自然。</p>
<p>对视听触协同同时发生的交互场景来说，用户的体验会更加自然。比如弹性模拟、机械齿轮模拟、阻尼模拟、气泡模拟等。</p>
<h2 id="作业">作业</h2>
<p>最后，我给你留了一个小作业，从今天我讲的内容，你能找到你的产品中哪个交互体验会用到视听触协同吗？如果能，根据今天的学习，你准备如何优化它？</p>
<p>以及有没有什么你觉得视听触协同做得非常好的 App？欢迎分享。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E5%9F%BA%E4%BA%8E%E4%BA%BA%E5%9B%A0%E7%9A%84%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E8%AF%BE/">基于人因的用户体验设计课</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/etcd%E5%AE%9E%E6%88%98%E8%AF%BE/09__%E4%BA%8B%E5%8A%A1%E5%A6%82%E4%BD%95%E5%AE%89%E5%85%A8%E5%9C%B0%E5%AE%9E%E7%8E%B0%E5%A4%9Akey%E6%93%8D%E4%BD%9C/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">09__事务：如何安全地实现多key操作？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%A1%85%E8%B0%B7%E4%BA%A7%E5%93%81%E5%AE%9E%E6%88%9836%E8%AE%B2/09__%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99%E7%94%A8%E4%BE%8B_%E4%BC%98%E5%8C%96%E5%BE%AE%E4%BF%A1%E5%8A%A0%E5%A5%BD%E5%8F%8B%E7%9A%84%E5%8A%9F%E8%83%BD/">
            <span class="next-text nav-default">09__手把手教你写用例：_优化微信加好友的功能</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

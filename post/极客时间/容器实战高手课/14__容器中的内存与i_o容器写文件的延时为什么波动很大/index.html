<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>14__容器中的内存与I_O：容器写文件的延时为什么波动很大？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是程远。这一讲，我们继续聊一聊容器中写文件性能波动的问题。
你应该还记得，我们上一讲中讲过 Linux 中的两种 I/O 模式，Direct I/O 和 Buffered I/O。
对于 Linux 的系统调用 write() 来说，Buffered I/O 是缺省模式，使用起来比较方便，而且从用户角度看，在大多数的应用场景下，用 Buffered I/O 的 write() 函数调用返回要快一些。所以，Buffered I/O 在程序中使用得更普遍一些。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE/14__%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9A%84%E5%86%85%E5%AD%98%E4%B8%8Ei_o%E5%AE%B9%E5%99%A8%E5%86%99%E6%96%87%E4%BB%B6%E7%9A%84%E5%BB%B6%E6%97%B6%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B3%A2%E5%8A%A8%E5%BE%88%E5%A4%A7/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE/14__%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9A%84%E5%86%85%E5%AD%98%E4%B8%8Ei_o%E5%AE%B9%E5%99%A8%E5%86%99%E6%96%87%E4%BB%B6%E7%9A%84%E5%BB%B6%E6%97%B6%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B3%A2%E5%8A%A8%E5%BE%88%E5%A4%A7/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="14__容器中的内存与I_O：容器写文件的延时为什么波动很大？">
  <meta property="og:description" content="你好，我是程远。这一讲，我们继续聊一聊容器中写文件性能波动的问题。
你应该还记得，我们上一讲中讲过 Linux 中的两种 I/O 模式，Direct I/O 和 Buffered I/O。
对于 Linux 的系统调用 write() 来说，Buffered I/O 是缺省模式，使用起来比较方便，而且从用户角度看，在大多数的应用场景下，用 Buffered I/O 的 write() 函数调用返回要快一些。所以，Buffered I/O 在程序中使用得更普遍一些。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="容器实战高手课">

  <meta itemprop="name" content="14__容器中的内存与I_O：容器写文件的延时为什么波动很大？">
  <meta itemprop="description" content="你好，我是程远。这一讲，我们继续聊一聊容器中写文件性能波动的问题。
你应该还记得，我们上一讲中讲过 Linux 中的两种 I/O 模式，Direct I/O 和 Buffered I/O。
对于 Linux 的系统调用 write() 来说，Buffered I/O 是缺省模式，使用起来比较方便，而且从用户角度看，在大多数的应用场景下，用 Buffered I/O 的 write() 函数调用返回要快一些。所以，Buffered I/O 在程序中使用得更普遍一些。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="4050">
  <meta itemprop="keywords" content="容器实战高手课">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="14__容器中的内存与I_O：容器写文件的延时为什么波动很大？">
  <meta name="twitter:description" content="你好，我是程远。这一讲，我们继续聊一聊容器中写文件性能波动的问题。
你应该还记得，我们上一讲中讲过 Linux 中的两种 I/O 模式，Direct I/O 和 Buffered I/O。
对于 Linux 的系统调用 write() 来说，Buffered I/O 是缺省模式，使用起来比较方便，而且从用户角度看，在大多数的应用场景下，用 Buffered I/O 的 write() 函数调用返回要快一些。所以，Buffered I/O 在程序中使用得更普遍一些。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">14__容器中的内存与I_O：容器写文件的延时为什么波动很大？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 4050 字 </span>
          <span class="more-meta"> 预计阅读 9 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#问题再现">问题再现</a></li>
        <li><a href="#时间波动是因为-dirty-pages-的影响么">时间波动是因为 Dirty Pages 的影响么？</a></li>
        <li><a href="#调试问题">调试问题</a></li>
      </ul>
    </li>
    <li><a href="#cd-syskerneldebugtracing">cd /sys/kernel/debug/tracing</a></li>
    <li><a href="#echo-vfs_write--set_ftrace_filter">echo vfs_write &raquo; set_ftrace_filter</a></li>
    <li><a href="#echo-xfs_file_write_iter--set_ftrace_filter">echo xfs_file_write_iter &raquo; set_ftrace_filter</a></li>
    <li><a href="#echo-xfs_file_buffered_aio_write--set_ftrace_filter">echo xfs_file_buffered_aio_write &raquo; set_ftrace_filter</a></li>
    <li><a href="#echo-iomap_file_buffered_write">echo iomap_file_buffered_write</a></li>
    <li><a href="#echo-iomap_file_buffered_write--set_ftrace_filter">echo iomap_file_buffered_write &raquo; set_ftrace_filter</a></li>
    <li><a href="#echo-pagecache_get_page--set_ftrace_filter">echo pagecache_get_page &raquo; set_ftrace_filter</a></li>
    <li><a href="#echo-try_to_free_mem_cgroup_pages--set_ftrace_filter">echo try_to_free_mem_cgroup_pages &raquo; set_ftrace_filter</a></li>
    <li><a href="#echo-try_charge--set_ftrace_filter">echo try_charge &raquo; set_ftrace_filter</a></li>
    <li><a href="#echo-mem_cgroup_try_charge--set_ftrace_filter">echo mem_cgroup_try_charge &raquo; set_ftrace_filter</a></li>
    <li><a href="#echo-function_graph--current_tracer">echo function_graph &gt; current_tracer</a></li>
    <li><a href="#echo-1--tracing_on">echo 1 &gt; tracing_on</a>
      <ul>
        <li><a href="#重点总结">重点总结</a></li>
        <li><a href="#思考题">思考题</a></li>
      </ul>
    </li>
    <li><a href="#fio--direct1--iodepth64--rwwrite--ioenginelibaio--bs4k--size10g--numjobs1---namefiotest">fio -direct=1 -iodepth=64 -rw=write -ioengine=libaio -bs=4k -size=10G -numjobs=1  -name=./fio.test</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是程远。这一讲，我们继续聊一聊容器中写文件性能波动的问题。</p>
<p>你应该还记得，我们上一讲中讲过 Linux 中的两种 I/O 模式，Direct I/O 和 Buffered I/O。</p>
<p>对于 Linux 的系统调用 write() 来说，Buffered I/O 是缺省模式，使用起来比较方便，而且从用户角度看，在大多数的应用场景下，用 Buffered I/O 的 write() 函数调用返回要快一些。所以，Buffered I/O 在程序中使用得更普遍一些。</p>
<p>当使用 Buffered I/O 的应用程序从虚拟机迁移到容器，这时我们就会发现多了 Memory Cgroup 的限制之后，write() 写相同大小的数据块花费的时间，延时波动会比较大。</p>
<p>这是怎么回事呢？接下来我们就带着问题开始今天的学习。</p>
<h2 id="问题再现">问题再现</h2>
<p>我们可以先动手写一个小程序，用来模拟刚刚说的现象。</p>
<p>这个小程序我们这样来设计：从一个文件中每次读取一个 64KB 大小的数据块，然后写到一个新文件中，它可以不断读写 10GB 大小的数据。同时我们在这个小程序中做个记录，记录写每个 64KB 的数据块需要花费的时间。</p>
<p>我们可以先在虚拟机里直接运行，虚拟机里内存大小是大于 10GB 的。接着，我们把这个程序放到容器中运行，因为这个程序本身并不需要很多的内存，我们给它做了一个 Memory Cgroup 的内存限制，设置为 1GB。</p>
<p>运行结束后，我们比较一下程序写数据块的时间。我把结果画了一张图，图里的纵轴是时间，单位 us；横轴是次数，在这里我们记录了 96 次。图中橘红色的线是在容器里运行的结果，蓝色的线是在虚拟机上运行的结果。</p>
<p>结果很明显，在容器中写入数据块的时间会时不时地增高到 200us；而在虚拟机里的写入数据块时间就比较平稳，一直在 30～50us 这个范围内。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE/dc4bc8ed6423f45da1f32e0d257684ef.png" alt=""></p>
<p>通过这个小程序，我们再现了问题，那我们就来分析一下，为什么会产生这样的结果。</p>
<h2 id="时间波动是因为-dirty-pages-的影响么">时间波动是因为 Dirty Pages 的影响么？</h2>
<p>我们对文件的写入操作是 Buffered I/O。在前一讲中，我们其实已经知道了，对于 Buffer I/O，用户的数据是先写入到 Page Cache 里的。而这些写入了数据的内存页面，在它们没有被写入到磁盘文件之前，就被叫作 dirty pages。</p>
<p>Linux 内核会有专门的内核线程（每个磁盘设备对应的 kworker/flush 线程）把 dirty pages 写入到磁盘中。那我们自然会这样猜测，也许是 Linux 内核对 dirty pages 的操作影响了 Buffered I/O 的写操作？</p>
<p>想要验证这个想法，我们需要先来看看 dirty pages 是在什么时候被写入到磁盘的。这里就要用到 <strong>/proc/sys/vm 里和 dirty page 相关的内核参数</strong>了，我们需要知道所有相关参数的含义，才能判断出最后真正导致问题发生的原因。</p>
<p>现在我们挨个来看一下。为了方便后面的讲述，我们可以设定一个比值 A，<strong>A 等于 dirty pages 的内存 / 节点可用内存 *100%</strong>。</p>
<p>第一个参数，dirty_background_ratio，这个参数里的数值是一个百分比值，缺省是 10%。如果比值 A 大于 dirty_background_ratio 的话，比如大于默认的 10%，内核 flush 线程就会把 dirty pages 刷到磁盘里。</p>
<p>第二个参数，是和 dirty_background_ratio 相对应一个参数，也就是 dirty_background_bytes，它和 dirty_background_ratio 作用相同。区别只是 dirty_background_bytes 是具体的字节数，它用来定义的是 dirty pages 内存的临界值，而不是比例值。</p>
<p>这里你还要注意，dirty_background_ratio 和 dirty_background_bytes 只有一个可以起作用，如果你给其中一个赋值之后，另外一个参数就归 0 了。</p>
<p>接下来我们看第三个参数，dirty_ratio，这个参数的数值也是一个百分比值，缺省是 20%。</p>
<p>如果比值 A，大于参数 dirty_ratio 的值，比如大于默认设置的 20%，这时候正在执行 Buffered I/O 写文件的进程就会被阻塞住，直到它写的数据页面都写到磁盘为止。</p>
<p>同样，第四个参数 dirty_bytes 与 dirty_ratio 相对应，它们的关系和 dirty_background_ratio 与 dirty_background_bytes 一样。我们给其中一个赋值后，另一个就会归零。</p>
<p>然后我们来看 dirty_writeback_centisecs，这个参数的值是个时间值，以百分之一秒为单位，缺省值是 500，也就是 5 秒钟。它表示每 5 秒钟会唤醒内核的 flush 线程来处理 dirty pages。</p>
<p>最后还有 dirty_expire_centisecs，这个参数的值也是一个时间值，以百分之一秒为单位，缺省值是 3000，也就是 30 秒钟。它定义了 dirty page 在内存中存放的最长时间，如果一个 dirty page 超过这里定义的时间，那么内核的 flush 线程也会把这个页面写入磁盘。</p>
<p>好了，从这些 dirty pages 相关的参数定义，你会想到些什么呢？</p>
<p>进程写操作上的时间波动，只有可能是因为 dirty pages 的数量很多，已经达到了第三个参数 dirty_ratio 的值。这时执行写文件功能的进程就会被暂停，直到写文件的操作将数据页面写入磁盘，写文件的进程才能继续运行，所以进程里一次写文件数据块的操作时间会增加。</p>
<p>刚刚说的是我们的推理，那情况真的会是这样吗？其实我们可以在容器中进程不断写入数据的时候，查看节点上 dirty pages 的实时数目。具体操作如下：</p>
<p>watch -n 1 &ldquo;cat /proc/vmstat | grep dirty&rdquo;</p>
<p>当我们的节点可用内存是 12GB 的时候，假设 dirty_ratio 是 20%，dirty_background_ratio 是 10%，那么我们在 1GB memory 容器中写 10GB 的数据，就会看到它实时的 dirty pages 数目，也就是 / proc/vmstat 里的 nr_dirty 的数值，这个数值对应的内存并不能达到 dirty_ratio 所占的内存值。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE/ffa122a6dc84d8093e2f84a08bdfdddb.png" alt=""></p>
<p>其实我们还可以再做个实验，就是在 dirty_bytes 和 dirty_background_bytes 里写入一个很小的值。</p>
<p>echo 8192 &gt; /proc/sys/vm/dirty_bytes<br>
echo 4096 &gt; /proc/sys/vm/dirty_background_bytes</p>
<p>然后再记录一下容器程序里每写入 64KB 数据块的时间，这时候，我们就会看到，时不时一次写入的时间就会达到 9ms，这已经远远高于我们之前看到的 200us 了。</p>
<p>因此，我们知道了这个时间的波动，并不是强制把 dirty page 写入到磁盘引起的。</p>
<h2 id="调试问题">调试问题</h2>
<p>那接下来，我们还能怎么分析这个问题呢？</p>
<p>我们可以用 perf 和 ftrace 这两个工具，对容器里写数据块的进程做个 profile，看看到底是调用哪个函数花费了比较长的时间。顺便说一下，我们在专题加餐里会专门介绍如何使用 perf、ftrace 等工具以及它们的工作原理，在这里你只要了解我们的调试思路就行。</p>
<p>怎么使用这两个工具去定位耗时高的函数呢？我大致思路是这样的：我们发现容器中的进程用到了 write() 这个函数调用，然后写 64KB 数据块的时间增加了，而 write() 是一个系统调用，那我们需要进行下面这两步操作。</p>
<p>**第一步，我们要找到内核中 write() 这个系统调用函数下，又调用了哪些子函数。**想找出主要的子函数我们可以查看代码，也可以用 perf 这个工具来得到。</p>
<p>然后是<strong>第二步，得到了 write() 的主要子函数之后，我们可以用 ftrace 这个工具来 trace 这些函数的执行时间，这样就可以找到花费时间最长的函数了。</strong></p>
<p>好，下面我们就按照刚才梳理的思路来做一下。首先是第一步，我们在容器启动写磁盘的进程后，在宿主机上得到这个进程的 pid，然后运行下面的 perf 命令。</p>
<p>perf record -a -g -p <pid></p>
<p>等写磁盘的进程退出之后，这个 perf record 也就停止了。</p>
<p>这时我们再执行 <code>perf report</code> 查看结果。把 vfs_write() 函数展开之后，我们就可以看到，write() 这个系统调用下面的调用到了哪些主要的子函数，到这里第一步就完成了。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE/4a756f36dd2c4a4ee4829e5d66835a8e.png" alt=""></p>
<p>下面再来做第二步，我们把主要的函数写入到 ftrace 的 set_ftrace_filter 里，然后把 ftrace 的 tracer 设置为 function_graph，并且打开 tracing_on 开启追踪。</p>
<h1 id="cd-syskerneldebugtracing">cd /sys/kernel/debug/tracing</h1>
<h1 id="echo-vfs_write--set_ftrace_filter">echo vfs_write &raquo; set_ftrace_filter</h1>
<h1 id="echo-xfs_file_write_iter--set_ftrace_filter">echo xfs_file_write_iter &raquo; set_ftrace_filter</h1>
<h1 id="echo-xfs_file_buffered_aio_write--set_ftrace_filter">echo xfs_file_buffered_aio_write &raquo; set_ftrace_filter</h1>
<h1 id="echo-iomap_file_buffered_write">echo iomap_file_buffered_write</h1>
<h1 id="echo-iomap_file_buffered_write--set_ftrace_filter">echo iomap_file_buffered_write &raquo; set_ftrace_filter</h1>
<h1 id="echo-pagecache_get_page--set_ftrace_filter">echo pagecache_get_page &raquo; set_ftrace_filter</h1>
<h1 id="echo-try_to_free_mem_cgroup_pages--set_ftrace_filter">echo try_to_free_mem_cgroup_pages &raquo; set_ftrace_filter</h1>
<h1 id="echo-try_charge--set_ftrace_filter">echo try_charge &raquo; set_ftrace_filter</h1>
<h1 id="echo-mem_cgroup_try_charge--set_ftrace_filter">echo mem_cgroup_try_charge &raquo; set_ftrace_filter</h1>
<h1 id="echo-function_graph--current_tracer">echo function_graph &gt; current_tracer</h1>
<h1 id="echo-1--tracing_on">echo 1 &gt; tracing_on</h1>
<p>这些设置完成之后，我们再运行一下容器中的写磁盘程序，同时从 ftrace 的 trace_pipe 中读取出追踪到的这些函数。</p>
<p>这时我们可以看到，当需要申请 Page Cache 页面的时候，write() 系统调用会反复地调用 mem_cgroup_try_charge()，并且在释放页面的时候，函数 do_try_to_free_pages() 花费的时间特别长，有 50+us（时间单位，micro-seconds）这么多。</p>
<ol>
<li>
<pre><code>          |  vfs_write() {  
</code></pre>
</li>
<li>
<pre><code>          |    xfs_file_write_iter [xfs]() {  
</code></pre>
</li>
<li>
<pre><code>          |      xfs_file_buffered_aio_write [xfs]() {  
</code></pre>
</li>
<li>
<pre><code>          |        iomap_file_buffered_write() {  
</code></pre>
</li>
<li>
<pre><code>          |          pagecache_get_page() {  
</code></pre>
</li>
<li>
<pre><code>          |            mem_cgroup_try_charge() {  
</code></pre>
</li>
<li>
<p>0.338 us    |              try_charge();</p>
</li>
<li>
<p>0.791 us    |            }</p>
</li>
<li>
<p>4.127 us    |          }<br>
…</p>
</li>
<li>
<pre><code>          |          pagecache_get_page() {  
</code></pre>
</li>
<li>
<pre><code>          |            mem_cgroup_try_charge() {  
</code></pre>
</li>
<li>
<pre><code>          |              try_charge() {  
</code></pre>
</li>
<li>
<pre><code>          |                try_to_free_mem_cgroup_pages() {  
</code></pre>
</li>
<li>
<ul>
<li>52.798 us   |                  do_try_to_free_pages();</li>
</ul>
</li>
<li>
<ul>
<li>53.958 us   |                }</li>
</ul>
</li>
<li>
<ul>
<li>54.751 us   |              }</li>
</ul>
</li>
<li>
<ul>
<li>55.188 us   |            }</li>
</ul>
</li>
<li>
<ul>
<li>56.742 us   |          }<br>
…</li>
</ul>
</li>
<li>
<p>! 109.925 us  |        }</p>
</li>
<li>
<p>! 110.558 us  |      }</p>
</li>
<li>
<p>! 110.984 us  |    }</p>
</li>
<li>
<p>! 111.515 us  |  }</p>
</li>
</ol>
<p>看到这个 ftrace 的结果，你是不是会想到，我们在容器内存那一讲中提到的 Page Cahe 呢？</p>
<p>是的，这个问题的确和 Page Cache 有关，Linux 会把所有的空闲内存利用起来，一旦有 Buffered I/O，这些内存都会被用作 Page Cache。</p>
<p>当容器加了 Memory Cgroup 限制了内存之后，对于容器里的 Buffered I/O，就只能使用容器中允许使用的最大内存来做 Page Cache。</p>
<p><strong>那么如果容器在做内存限制的时候，Cgroup 中 memory.limit_in_bytes 设置得比较小，而容器中的进程又有很大量的 I/O，这样申请新的 Page Cache 内存的时候，又会不断释放老的内存页面，这些操作就会带来额外的系统开销了。</strong></p>
<h2 id="重点总结">重点总结</h2>
<p>我们今天讨论的问题是在容器中用 Buffered I/O 方式写文件的时候，会出现写入时间波动的问题。</p>
<p>由于这是 Buffered I/O 方式，对于写入文件会先写到内存里，这样就产生了 dirty pages，所以我们先研究了一下 Linux 对 dirty pages 的回收机制是否会影响到容器中写入数据的波动。</p>
<p>在这里我们最主要的是理解这两个参数，<strong>dirty_background_ratio 和 dirty_ratio</strong>，这两个值都是相对于节点可用内存的百分比值。</p>
<p><strong>当 dirty pages 数量超过 dirty_background_ratio 对应的内存量的时候，内核 flush 线程就会开始把 dirty pages 写入磁盘 ; 当 dirty pages 数量超过 dirty_ratio 对应的内存量，这时候程序写文件的函数调用 write() 就会被阻塞住，直到这次调用的 dirty pages 全部写入到磁盘。</strong></p>
<p>在节点是大内存容量，并且 dirty_ratio 为系统缺省值 20%，dirty_background_ratio 是系统缺省值 10% 的情况下，我们通过观察 /proc/vmstat 中的 nr_dirty 数值可以发现，dirty pages 不会阻塞进程的 Buffered I/O 写文件操作。</p>
<p>所以我们做了另一种尝试，使用 perf 和 ftrace 工具对容器中的写文件进程进行 profile。我们用 perf 得到了系统调用 write() 在内核中的一系列子函数调用，再用 ftrace 来查看这些子函数的调用时间。</p>
<p><strong>根据 ftrace 的结果，我们发现写数据到 Page Cache 的时候，需要不断地去释放原有的页面，这个时间开销是最大的。造成容器中 Buffered I/O write() 不稳定的原因，正是容器在限制内存之后，Page Cache 的数量较小并且不断申请释放。</strong></p>
<p>其实这个问题也提醒了我们：在对容器做 Memory Cgroup 限制内存大小的时候，不仅要考虑容器中进程实际使用的内存量，还要考虑容器中程序 I/O 的量，合理预留足够的内存作为 Buffered I/O 的 Page Cache。</p>
<p>比如，如果知道需要反复读写文件的大小，并且在内存足够的情况下，那么 Memory Cgroup 的内存限制可以超过这个文件的大小。</p>
<p>还有一个解决思路是，我们在程序中自己管理文件的 cache 并且调用 Direct I/O 来读写文件，这样才会对应用程序的性能有一个更好的预期。</p>
<h2 id="思考题">思考题</h2>
<p>我们对 dirty_bytes 和 dirty_background_bytes 做下面的设置：</p>
<p>-bash-4.2# echo 8192 &gt; /proc/sys/vm/dirty_bytes<br>
-bash-4.2# echo 4096 &gt; /proc/sys/vm/dirty_background_bytes</p>
<p>然后再运行下面的 fio 测试，得到的结果和缺省 dirty_* 配置的时候会有差别吗？</p>
<h1 id="fio--direct1--iodepth64--rwwrite--ioenginelibaio--bs4k--size10g--numjobs1---namefiotest">fio -direct=1 -iodepth=64 -rw=write -ioengine=libaio -bs=4k -size=10G -numjobs=1  -name=./fio.test</h1>
<p>欢迎你在留言区提出你的思考或是疑问。如果这篇文章对你有帮助的话，也欢迎你分享给你的朋友、同事，一起学习进步。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE/">容器实战高手课</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%AE%B9%E9%87%8F%E4%BF%9D%E9%9A%9C%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/14__%E5%AE%B9%E9%87%8F%E4%BF%9D%E9%9A%9C%E7%BB%84%E7%BB%87%E5%BB%BA%E8%AE%BE%E5%AE%B9%E9%87%8F%E4%BF%9D%E9%9A%9C%E9%9C%80%E8%A6%81%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E5%9B%A2%E9%98%9F/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">14__容量保障组织建设：容量保障需要什么样的团队？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%8A%80%E6%9C%AF%E7%AE%A1%E7%90%86%E5%AE%9E%E6%88%9836%E8%AE%B2/14__%E5%A6%82%E4%BD%95%E6%9D%A5%E8%A7%84%E5%88%92%E5%9B%A2%E9%98%9F%E7%9A%84%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84%E5%91%A2/">
            <span class="next-text nav-default">14__如何来规划团队的组织结构呢？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

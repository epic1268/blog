<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>14__文件IO：实现高效正确的文件读写并非易事 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是朱晔。今天，我们来聊聊如何实现高效、正确的文件操作。
随着数据库系统的成熟和普及，需要直接做文件 IO 操作的需求越来越少，这就导致我们对相关 API 不够熟悉，以至于遇到类似文件导出、三方文件对账等需求时，只能临时抱佛脚，随意搜索一些代码完成需求，出现性能问题或者 Bug 后不知从何处入手。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/14__%E6%96%87%E4%BB%B6io%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%B9%B6%E9%9D%9E%E6%98%93%E4%BA%8B/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/14__%E6%96%87%E4%BB%B6io%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E5%B9%B6%E9%9D%9E%E6%98%93%E4%BA%8B/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="14__文件IO：实现高效正确的文件读写并非易事">
  <meta property="og:description" content="你好，我是朱晔。今天，我们来聊聊如何实现高效、正确的文件操作。
随着数据库系统的成熟和普及，需要直接做文件 IO 操作的需求越来越少，这就导致我们对相关 API 不够熟悉，以至于遇到类似文件导出、三方文件对账等需求时，只能临时抱佛脚，随意搜索一些代码完成需求，出现性能问题或者 Bug 后不知从何处入手。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Java业务开发常见错误100例">

  <meta itemprop="name" content="14__文件IO：实现高效正确的文件读写并非易事">
  <meta itemprop="description" content="你好，我是朱晔。今天，我们来聊聊如何实现高效、正确的文件操作。
随着数据库系统的成熟和普及，需要直接做文件 IO 操作的需求越来越少，这就导致我们对相关 API 不够熟悉，以至于遇到类似文件导出、三方文件对账等需求时，只能临时抱佛脚，随意搜索一些代码完成需求，出现性能问题或者 Bug 后不知从何处入手。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="5252">
  <meta itemprop="keywords" content="Java业务开发常见错误100例">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="14__文件IO：实现高效正确的文件读写并非易事">
  <meta name="twitter:description" content="你好，我是朱晔。今天，我们来聊聊如何实现高效、正确的文件操作。
随着数据库系统的成熟和普及，需要直接做文件 IO 操作的需求越来越少，这就导致我们对相关 API 不够熟悉，以至于遇到类似文件导出、三方文件对账等需求时，只能临时抱佛脚，随意搜索一些代码完成需求，出现性能问题或者 Bug 后不知从何处入手。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">14__文件IO：实现高效正确的文件读写并非易事</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 5252 字 </span>
          <span class="more-meta"> 预计阅读 11 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#文件读写需要确保字符编码一致">文件读写需要确保字符编码一致</a></li>
        <li><a href="#使用-files-类静态方法进行文件操作注意释放文件句柄">使用 Files 类静态方法进行文件操作注意释放文件句柄</a></li>
        <li><a href="#注意读写文件要考虑设置缓冲区">注意读写文件要考虑设置缓冲区</a></li>
        <li><a href="#ns--------------task-name">ns         %     Task name</a></li>
        <li><a href="#ns--------------task-name-1">ns         %     Task name</a></li>
        <li><a href="#重点回顾">重点回顾</a></li>
        <li><a href="#思考与讨论">思考与讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是朱晔。今天，我们来聊聊如何实现高效、正确的文件操作。</p>
<p>随着数据库系统的成熟和普及，需要直接做文件 IO 操作的需求越来越少，这就导致我们对相关 API 不够熟悉，以至于遇到类似文件导出、三方文件对账等需求时，只能临时抱佛脚，随意搜索一些代码完成需求，出现性能问题或者 Bug 后不知从何处入手。</p>
<p>今天这篇文章，我就会从字符编码、缓冲区和文件句柄释放这 3 个常见问题出发，和你分享如何解决与文件操作相关的性能问题或者 Bug。如果你对文件操作相关的 API 不够熟悉，可以查看Oracle 官网的介绍。</p>
<h2 id="文件读写需要确保字符编码一致">文件读写需要确保字符编码一致</h2>
<p>有一个项目需要读取三方的对账文件定时对账，原先一直是单机处理的，没什么问题。后来为了提升性能，使用双节点同时处理对账，每一个节点处理部分对账数据，但新增的节点在处理文件中中文的时候总是读取到乱码。</p>
<p>程序代码都是一致的，为什么老节点就不会有问题呢？我们知道，这很可能是写代码时没有注意编码问题导致的。接下来，我们就分析下这个问题吧。</p>
<p>为模拟这个场景，我们使用 GBK 编码把“你好 hi”写入一个名为 hello.txt 的文本文件，然后直接以字节数组形式读取文件内容，转换为十六进制字符串输出到日志中：</p>
<p>Files.deleteIfExists(Paths.get(&ldquo;hello.txt&rdquo;));<br>
Files.write(Paths.get(&ldquo;hello.txt&rdquo;), &ldquo;你好 hi&rdquo;.getBytes(Charset.forName(&ldquo;GBK&rdquo;)));<br>
log.info(&ldquo;bytes:{}&rdquo;, Hex.encodeHexString(Files.readAllBytes(Paths.get(&ldquo;hello.txt&rdquo;))).toUpperCase());</p>
<p>输出如下：</p>
<p>13:06:28.955 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - bytes:C4E3BAC36869</p>
<p>虽然我们打开文本文件时看到的是“你好 hi”，但不管是什么文字，计算机中都是按照一定的规则将其以二进制保存的。这个规则就是字符集，字符集枚举了所有支持的字符映射成二进制的映射表。在处理文件读写的时候，如果是在字节层面进行操作，那么不会涉及字符编码问题；而如果需要在字符层面进行读写的话，就需要明确字符的编码方式也就是字符集了。</p>
<p>当时出现问题的文件读取代码是这样的：</p>
<p>char[] chars = new char[10];<br>
String content = &ldquo;&rdquo;;<br>
try (FileReader fileReader = new FileReader(&ldquo;hello.txt&rdquo;)) {<br>
int count;<br>
while ((count = fileReader.read(chars)) != -1) {<br>
content += new String(chars, 0, count);<br>
}<br>
}<br>
log.info(&ldquo;result:{}&rdquo;, content);</p>
<p>可以看到，是使用了 FileReader 类以字符方式进行文件读取，日志中读取出来的“你好”变为了乱码：</p>
<p>13:06:28.961 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - result:���hi</p>
<p>显然，这里并没有指定以什么字符集来读取文件中的字符。查看JDK 文档可以发现，<strong>FileReader 是以当前机器的默认字符集来读取文件的</strong>，如果希望指定字符集的话，需要直接使用 InputStreamReader 和 FileInputStream。</p>
<p>到这里我们就明白了，FileReader 虽然方便但因为使用了默认字符集对环境产生了依赖，这就是为什么老的机器上程序可以正常运作，在新节点上读取中文时却产生了乱码。</p>
<p>那，怎么确定当前机器的默认字符集呢？写一段代码输出当前机器的默认字符集，以及 UTF-8 方式编码的“你好 hi”的十六进制字符串：</p>
<p>log.info(&ldquo;charset: {}&rdquo;, Charset.defaultCharset());<br>
Files.write(Paths.get(&ldquo;hello2.txt&rdquo;), &ldquo;你好 hi&rdquo;.getBytes(Charsets.UTF_8));<br>
log.info(&ldquo;bytes:{}&rdquo;, Hex.encodeHexString(Files.readAllBytes(Paths.get(&ldquo;hello2.txt&rdquo;))).toUpperCase());</p>
<p>输出结果如下：</p>
<p>13:06:28.961 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - charset: UTF-8<br>
13:06:28.962 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - bytes:E4BDA0E5A5BD6869</p>
<p>可以看到，当前机器默认字符集是 UTF-8，当然无法读取 GBK 编码的汉字。UTF-8 编码的“你好”的十六进制是 E4BDA0E5A5BD，每一个汉字需要三个字节；而 GBK 编码的汉字，每一个汉字两个字节。字节长度都不一样，以 GBK 编码后保存的汉字，以 UTF8 进行解码读取，必然不会成功。</p>
<p>定位到问题后，修复就很简单了。按照文档所说，直接使用 FileInputStream 拿文件流，然后使用 InputStreamReader 读取字符流，并指定字符集为 GBK：</p>
<p>private static void right1() throws IOException {<br>
char[] chars = new char[10];<br>
String content = &ldquo;&rdquo;;<br>
try (FileInputStream fileInputStream = new FileInputStream(&ldquo;hello.txt&rdquo;);<br>
InputStreamReader inputStreamReader = new InputStreamReader(fileInputStream, Charset.forName(&ldquo;GBK&rdquo;))) {<br>
int count;<br>
while ((count = inputStreamReader.read(chars)) != -1) {<br>
content += new String(chars, 0, count);<br>
}<br>
}<br>
log.info(&ldquo;result: {}&rdquo;, content);<br>
}</p>
<p>从日志中看到，修复后的代码正确读取到了“你好 Hi”。</p>
<p>13:06:28.963 [main] INFO org.geekbang.time.commonmistakes.io.demo3.FileBadEncodingIssueApplication - result: 你好 hi</p>
<p>如果你觉得这种方式比较麻烦的话，使用 JDK1.7 推出的 Files 类的 readAllLines 方法，可以很方便地用一行代码完成文件内容读取：</p>
<p>log.info(&ldquo;result: {}&rdquo;, Files.readAllLines(Paths.get(&ldquo;hello.txt&rdquo;), Charset.forName(&ldquo;GBK&rdquo;)).stream().findFirst().orElse(&quot;&quot;));</p>
<p><strong>但这种方式有个问题是，读取超出内存大小的大文件时会出现 OOM</strong>。为什么呢？</p>
<p>打开 readAllLines 方法的源码可以看到，readAllLines 读取文件所有内容后，放到一个 List<String> 中返回，如果内存无法容纳这个 List，就会 OOM：</p>
<p>public static List<String> readAllLines(Path path, Charset cs) throws IOException {<br>
try (BufferedReader reader = newBufferedReader(path, cs)) {<br>
List<String> result = new ArrayList&lt;&gt;();<br>
for (;;) {<br>
String line = reader.readLine();<br>
if (line == null)<br>
break;<br>
result.add(line);<br>
}<br>
return result;<br>
}<br>
}</p>
<p>那么，有没有办法实现按需的流式读取呢？比如，需要消费某行数据时再读取，而不是把整个文件一次性读取到内存？</p>
<p>当然有，解决方案就是 File 类的 lines 方法。接下来，我就与你说说使用 lines 方法时需要注意的一些问题。</p>
<h2 id="使用-files-类静态方法进行文件操作注意释放文件句柄">使用 Files 类静态方法进行文件操作注意释放文件句柄</h2>
<p>与 readAllLines 方法返回 List<String> 不同，lines 方法返回的是 Stream<String>。这，使得我们在需要时可以不断读取、使用文件中的内容，而不是一次性地把所有内容都读取到内存中，因此避免了 OOM。</p>
<p>接下来，我通过一段代码测试一下。我们尝试读取一个 1 亿 1 万行的文件，文件占用磁盘空间超过 4GB。如果使用 -Xmx512m -Xms512m 启动 JVM 控制最大堆内存为 512M 的话，肯定无法一次性读取这样的大文件，但通过 Files.lines 方法就没问题。</p>
<p>在下面的代码中，首先输出这个文件的大小，然后计算读取 20 万行数据和 200 万行数据的耗时差异，最后逐行读取文件，统计文件的总行数：</p>
<p>//输出文件大小<br>
log.info(&ldquo;file size:{}&rdquo;, Files.size(Paths.get(&ldquo;test.txt&rdquo;)));<br>
StopWatch stopWatch = new StopWatch();<br>
stopWatch.start(&ldquo;read 200000 lines&rdquo;);<br>
//使用 Files.lines 方法读取 20 万行数据<br>
log.info(&ldquo;lines {}&rdquo;, Files.lines(Paths.get(&ldquo;test.txt&rdquo;)).limit(200000).collect(Collectors.toList()).size());<br>
stopWatch.stop();<br>
stopWatch.start(&ldquo;read 2000000 lines&rdquo;);<br>
//使用 Files.lines 方法读取 200 万行数据<br>
log.info(&ldquo;lines {}&rdquo;, Files.lines(Paths.get(&ldquo;test.txt&rdquo;)).limit(2000000).collect(Collectors.toList()).size());<br>
stopWatch.stop();<br>
log.info(stopWatch.prettyPrint());<br>
AtomicLong atomicLong = new AtomicLong();<br>
//使用 Files.lines 方法统计文件总行数<br>
Files.lines(Paths.get(&ldquo;test.txt&rdquo;)).forEach(line-&gt;atomicLong.incrementAndGet());<br>
log.info(&ldquo;total lines {}&rdquo;, atomicLong.get());</p>
<p>输出结果如下：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/2fd09a66fbdc5631a69377f6e8ee02e8.png" alt=""></p>
<p>可以看到，实现了全文件的读取、统计了整个文件的行数，并没有出现 OOM；读取 200 万行数据耗时 760ms，读取 20 万行数据仅需 267ms。这些都可以说明，File.lines 方法并不是一次性读取整个文件的，而是按需读取。</p>
<p>到这里，你觉得这段代码有什么问题吗？</p>
<p>问题在于读取完文件后没有关闭。我们通常会认为静态方法的调用不涉及资源释放，因为方法调用结束自然代表资源使用完成，由 API 释放资源，但对于 Files 类的一些返回 Stream 的方法并不是这样。这，是一个很容易被忽略的严重问题。</p>
<p>我就曾遇到过一个案例：程序在生产上运行一段时间后就会出现 too many files 的错误，我们想当然地认为是 OS 设置的最大文件句柄太小了，就让运维放开这个限制，但放开后还是会出现这样的问题。经排查发现，其实是文件句柄没有释放导致的，问题就出在 Files.lines 方法上。</p>
<p>我们来重现一下这个问题，随便写入 10 行数据到一个 demo.txt 文件中：</p>
<p>Files.write(Paths.get(&ldquo;demo.txt&rdquo;),<br>
IntStream.rangeClosed(1, 10).mapToObj(i -&gt; UUID.randomUUID().toString()).collect(Collectors.toList())<br>
, UTF_8, CREATE, TRUNCATE_EXISTING);</p>
<p>然后使用 Files.lines 方法读取这个文件 100 万次，每读取一行计数器 +1：</p>
<p>LongAdder longAdder = new LongAdder();<br>
IntStream.rangeClosed(1, 1000000).forEach(i -&gt; {<br>
try {<br>
Files.lines(Paths.get(&ldquo;demo.txt&rdquo;)).forEach(line -&gt; longAdder.increment());<br>
} catch (IOException e) {<br>
e.printStackTrace();<br>
}<br>
});<br>
log.info(&ldquo;total : {}&rdquo;, longAdder.longValue());</p>
<p>运行后马上可以在日志中看到如下错误：</p>
<p>java.nio.file.FileSystemException: demo.txt: Too many open files<br>
at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)<br>
at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)<br>
at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)</p>
<p>使用 lsof 命令查看进程打开的文件，可以看到打开了 1 万多个 demo.txt：</p>
<p>lsof -p 63937<br>
&hellip;<br>
java    63902 zhuye *238r   REG                1,4      370         12934160647 /Users/zhuye/Documents/common-mistakes/demo.txt<br>
java    63902 zhuye *239r   REG                1,4      370         12934160647 /Users/zhuye/Documents/common-mistakes/demo.txt<br>
&hellip;</p>
<p>lsof -p 63937 | grep demo.txt | wc -l<br>
10007</p>
<p><strong>其实，在</strong> <strong>JDK 文档</strong> <strong>中有提到，注意使用 try-with-resources 方式来配合，确保流的 close 方法可以调用释放资源。</strong></p>
<p>这也很容易理解，使用流式处理，如果不显式地告诉程序什么时候用完了流，程序又如何知道呢，它也不能帮我们做主何时关闭文件。</p>
<p>修复方式很简单，使用 try 来包裹 Stream 即可：</p>
<p>LongAdder longAdder = new LongAdder();<br>
IntStream.rangeClosed(1, 1000000).forEach(i -&gt; {<br>
try (Stream<String> lines = Files.lines(Paths.get(&ldquo;demo.txt&rdquo;))) {<br>
lines.forEach(line -&gt; longAdder.increment());<br>
} catch (IOException e) {<br>
e.printStackTrace();<br>
}<br>
});<br>
log.info(&ldquo;total : {}&rdquo;, longAdder.longValue());</p>
<p>修改后的代码不再出现错误日志，因为读取了 100 万次包含 10 行数据的文件，所以最终正确输出了 1000 万：</p>
<p>14:19:29.410 [main] INFO org.geekbang.time.commonmistakes.io.demo2.FilesStreamOperationNeedCloseApplication - total : 10000000</p>
<p>查看 lines 方法源码可以发现，Stream 的 close 注册了一个回调，来关闭 BufferedReader 进行资源释放：</p>
<p>public static Stream<String> lines(Path path, Charset cs) throws IOException {<br>
BufferedReader br = Files.newBufferedReader(path, cs);<br>
try {<br>
return br.lines().onClose(asUncheckedRunnable(br));<br>
} catch (Error|RuntimeException e) {<br>
try {<br>
br.close();<br>
} catch (IOException ex) {<br>
try {<br>
e.addSuppressed(ex);<br>
} catch (Throwable ignore) {}<br>
}<br>
throw e;<br>
}<br>
}</p>
<p>private static Runnable asUncheckedRunnable(Closeable c) {<br>
return () -&gt; {<br>
try {<br>
c.close();<br>
} catch (IOException e) {<br>
throw new UncheckedIOException(e);<br>
}<br>
};<br>
}</p>
<p>从命名上可以看出，使用 BufferedReader 进行字符流读取时，用到了缓冲。这里缓冲 Buffer 的意思是，使用一块内存区域作为直接操作的中转。</p>
<p>比如，读取文件操作就是一次性读取一大块数据（比如 8KB）到缓冲区，后续的读取可以直接从缓冲区返回数据，而不是每次都直接对应文件 IO。写操作也是类似。如果每次写几十字节到文件都对应一次 IO 操作，那么写一个几百兆的大文件可能就需要千万次的 IO 操作，耗时会非常久。</p>
<p>接下来，我就通过几个实验，和你说明使用缓冲 Buffer 的重要性，并对比下不同使用方式的文件读写性能，来帮助你用对、用好 Buffer。</p>
<h2 id="注意读写文件要考虑设置缓冲区">注意读写文件要考虑设置缓冲区</h2>
<p>我曾遇到过这么一个案例，一段先进行文件读入再简单处理后写入另一个文件的业务代码，由于开发人员使用了单字节的读取写入方式，导致执行得巨慢，业务量上来后需要数小时才能完成。</p>
<p>我们来模拟一下相关实现。创建一个文件随机写入 100 万行数据，文件大小在 35MB 左右：</p>
<p>Files.write(Paths.get(&ldquo;src.txt&rdquo;),<br>
IntStream.rangeClosed(1, 1000000).mapToObj(i -&gt; UUID.randomUUID().toString()).collect(Collectors.toList())<br>
, UTF_8, CREATE, TRUNCATE_EXISTING);</p>
<p>当时开发人员写的文件处理代码大概是这样的：使用 FileInputStream 获得一个文件输入流，然后调用其 read 方法每次读取一个字节，最后通过一个 FileOutputStream 文件输出流把处理后的结果写入另一个文件。</p>
<p>为了简化逻辑便于理解，这里我们不对数据进行处理，直接把原文件数据写入目标文件，相当于文件复制：</p>
<p>private static void perByteOperation() throws IOException {<br>
try (FileInputStream fileInputStream = new FileInputStream(&ldquo;src.txt&rdquo;);<br>
FileOutputStream fileOutputStream = new FileOutputStream(&ldquo;dest.txt&rdquo;)) {<br>
int i;<br>
while ((i = fileInputStream.read()) != -1) {<br>
fileOutputStream.write(i);<br>
}<br>
}<br>
}</p>
<p>这样的实现，复制一个 35MB 的文件居然耗时 190 秒。</p>
<p><strong>显然，每读取一个字节、每写入一个字节都进行一次 IO 操作，代价太大了</strong>。解决方案就是，考虑使用缓冲区作为过渡，一次性从原文件读取一定数量的数据到缓冲区，一次性写入一定数量的数据到目标文件。</p>
<p>改良后，使用 100 字节作为缓冲区，使用 FileInputStream 的 byte[] 的重载来一次性读取一定字节的数据，同时使用 FileOutputStream 的 byte[] 的重载实现一次性从缓冲区写入一定字节的数据到文件：</p>
<p>private static void bufferOperationWith100Buffer() throws IOException {<br>
try (FileInputStream fileInputStream = new FileInputStream(&ldquo;src.txt&rdquo;);<br>
FileOutputStream fileOutputStream = new FileOutputStream(&ldquo;dest.txt&rdquo;)) {<br>
byte[] buffer = new byte[100];<br>
int len = 0;<br>
while ((len = fileInputStream.read(buffer)) != -1) {<br>
fileOutputStream.write(buffer, 0, len);<br>
}<br>
}<br>
}</p>
<p>仅仅使用了 100 个字节的缓冲区作为过渡，完成 35M 文件的复制耗时缩短到了 26 秒，是无缓冲时性能的 7 倍；如果把缓冲区放大到 1000 字节，耗时可以进一步缩短到 342 毫秒。可以看到，<strong>在进行文件 IO 处理的时候，使用合适的缓冲区可以明显提高性能</strong>。</p>
<p>你可能会说，实现文件读写还要自己 new 一个缓冲区出来，太麻烦了，不是有一个 BufferedInputStream 和 BufferedOutputStream 可以实现输入输出流的缓冲处理吗？</p>
<p>是的，它们在内部实现了一个默认 8KB 大小的缓冲区。但是，在使用 BufferedInputStream 和 BufferedOutputStream 时，我还是建议你再使用一个缓冲进行读写，不要因为它们实现了内部缓冲就进行逐字节的操作。</p>
<p>接下来，我写一段代码比较下使用下面三种方式读写一个字节的性能：</p>
<ol>
<li>直接使用 BufferedInputStream 和 BufferedOutputStream；</li>
<li>额外使用一个 8KB 缓冲，使用 BufferedInputStream 和 BufferedOutputStream；</li>
<li>直接使用 FileInputStream 和 FileOutputStream，再使用一个 8KB 的缓冲。</li>
</ol>
<p>//使用 BufferedInputStream 和 BufferedOutputStream<br>
private static void bufferedStreamByteOperation() throws IOException {<br>
try (BufferedInputStream bufferedInputStream = new BufferedInputStream(new FileInputStream(&ldquo;src.txt&rdquo;));<br>
BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(new FileOutputStream(&ldquo;dest.txt&rdquo;))) {<br>
int i;<br>
while ((i = bufferedInputStream.read()) != -1) {<br>
bufferedOutputStream.write(i);<br>
}<br>
}<br>
}<br>
//额外使用一个 8KB 缓冲，再使用 BufferedInputStream 和 BufferedOutputStream<br>
private static void bufferedStreamBufferOperation() throws IOException {<br>
try (BufferedInputStream bufferedInputStream = new BufferedInputStream(new FileInputStream(&ldquo;src.txt&rdquo;));<br>
BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(new FileOutputStream(&ldquo;dest.txt&rdquo;))) {<br>
byte[] buffer = new byte[8192];<br>
int len = 0;<br>
while ((len = bufferedInputStream.read(buffer)) != -1) {<br>
bufferedOutputStream.write(buffer, 0, len);<br>
}<br>
}<br>
}<br>
//直接使用 FileInputStream 和 FileOutputStream，再使用一个 8KB 的缓冲<br>
private static void largerBufferOperation() throws IOException {<br>
try (FileInputStream fileInputStream = new FileInputStream(&ldquo;src.txt&rdquo;);<br>
FileOutputStream fileOutputStream = new FileOutputStream(&ldquo;dest.txt&rdquo;)) {<br>
byte[] buffer = new byte[8192];<br>
int len = 0;<br>
while ((len = fileInputStream.read(buffer)) != -1) {<br>
fileOutputStream.write(buffer, 0, len);<br>
}<br>
}<br>
}</p>
<p>结果如下：</p>
<hr>
<h2 id="ns--------------task-name">ns         %     Task name</h2>
<p>1424649223  086%  bufferedStreamByteOperation<br>
117807808  007%  bufferedStreamBufferOperation<br>
112153174  007%  largerBufferOperation</p>
<p>可以看到，第一种方式虽然使用了缓冲流，但逐字节的操作因为方法调用次数实在太多还是慢，耗时 1.4 秒；后面两种方式的性能差不多，耗时 110 毫秒左右。虽然第三种方式没有使用缓冲流，但使用了 8KB 大小的缓冲区，和缓冲流默认的缓冲区大小相同。</p>
<p>看到这里，你可能会疑惑了，既然这样使用 BufferedInputStream 和 BufferedOutputStream 有什么意义呢？</p>
<p>其实，这里我是为了演示所以示例三使用了固定大小的缓冲区，但在实际代码中每次需要读取的字节数很可能不是固定的，有的时候读取几个字节，有的时候读取几百字节，这个时候有一个固定大小较大的缓冲，也就是使用 BufferedInputStream 和 BufferedOutputStream 做为后备的稳定的二次缓冲，就非常有意义了。</p>
<p>最后我要补充说明的是，对于类似的文件复制操作，如果希望有更高性能，可以使用 FileChannel 的 transfreTo 方法进行流的复制。在一些操作系统（比如高版本的 Linux 和 UNIX）上可以实现 DMA（直接内存访问），也就是数据从磁盘经过总线直接发送到目标文件，无需经过内存和 CPU 进行数据中转：</p>
<p>private static void fileChannelOperation() throws IOException {<br>
FileChannel in = FileChannel.open(Paths.get(&ldquo;src.txt&rdquo;), StandardOpenOption.READ);<br>
FileChannel out = FileChannel.open(Paths.get(&ldquo;dest.txt&rdquo;), CREATE, WRITE);<br>
in.transferTo(0, in.size(), out);<br>
}</p>
<p>你可以通过这篇文章，了解 transferTo 方法的更多细节。</p>
<p>在测试 FileChannel 性能的同时，我再运行一下这一小节中的所有实现，比较一下读写 35MB 文件的耗时。</p>
<hr>
<h2 id="ns--------------task-name-1">ns         %     Task name</h2>
<p>183673362265  098%  perByteOperation<br>
2034504694  001%  bufferOperationWith100Buffer<br>
749967898  000%  bufferedStreamByteOperation<br>
110602155  000%  bufferedStreamBufferOperation<br>
114542834  000%  largerBufferOperation<br>
050068602  000%  fileChannelOperation</p>
<p>可以看到，最慢的是单字节读写文件流的方式，耗时 183 秒，最快的是 FileChannel.transferTo 方式进行流转发的方式，耗时 50 毫秒。两者耗时相差达到 3600 倍！</p>
<h2 id="重点回顾">重点回顾</h2>
<p>今天，我通过三个案例和你分享了文件读写操作中最重要的几个方面。</p>
<p>第一，如果需要读写字符流，那么需要确保文件中字符的字符集和字符流的字符集是一致的，否则可能产生乱码。</p>
<p>第二，使用 Files 类的一些流式处理操作，注意使用 try-with-resources 包装 Stream，确保底层文件资源可以释放，避免产生 too many open files 的问题。</p>
<p>第三，进行文件字节流操作的时候，一般情况下不考虑进行逐字节操作，使用缓冲区进行批量读写减少 IO 次数，性能会好很多。一般可以考虑直接使用缓冲输入输出流 BufferedXXXStream，追求极限性能的话可以考虑使用 FileChannel 进行流转发。</p>
<p>最后我要强调的是，文件操作因为涉及操作系统和文件系统的实现，JDK 并不能确保所有 IO API 在所有平台的逻辑一致性，代码迁移到新的操作系统或文件系统时，要重新进行功能测试和性能测试。</p>
<p>今天用到的代码，我都放在了 GitHub 上，你可以点击这个链接查看。</p>
<h2 id="思考与讨论">思考与讨论</h2>
<ol>
<li>Files.lines 方法进行流式处理，需要使用 try-with-resources 进行资源释放。那么，使用 Files 类中其他返回 Stream 包装对象的方法进行流式处理，比如 newDirectoryStream 方法返回 DirectoryStream<Path>，list、walk 和 find 方法返回 Stream<Path>，也同样有资源释放问题吗？</li>
<li>Java 的 File 类和 Files 类提供的文件复制、重命名、删除等操作，是原子性的吗？</li>
</ol>
<p>对于文件操作，你还遇到过什么坑吗？我是朱晔，欢迎在评论区与我留言分享你的想法，也欢迎你把这篇文章分享给你的朋友或同事，一起交流。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/">Java业务开发常见错误100例</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%A6%82%E4%BD%95%E7%9C%8B%E6%87%82%E4%B8%80%E5%B9%85%E7%94%BB/14__%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AF%95%E5%8A%A0%E7%B4%A2%E7%94%BB%E7%9A%84%E6%83%85%E4%BA%BA%E9%83%BD%E6%98%AF%E5%A4%A9%E4%BB%B7%E5%90%8D%E7%94%BB/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">14__为什么毕加索画的情人都是天价名画？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E/14__%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%E4%B8%80%E5%88%87%E7%AE%A1%E7%90%86%E9%97%AE%E9%A2%98%E9%83%BD%E5%BA%94%E6%80%9D%E8%80%83%E8%83%BD%E5%90%A6%E9%80%9A%E8%BF%87%E5%B7%A5%E5%85%B7%E8%A7%A3%E5%86%B3/">
            <span class="next-text nav-default">14__项目管理工具：一切管理问题，都应思考能否通过工具解决</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>26__数据存储：NoSQL与RDBMS如何取长补短、相辅相成？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是朱晔。今天，我来和你聊聊数据存储的常见错误。
近几年，各种非关系型数据库，也就是 NoSQL 发展迅猛，在项目中也非常常见。其中不乏一些使用上的极端情况，比如直接把关系型数据库（RDBMS）全部替换为 NoSQL，或是在不合适的场景下错误地使用 NoSQL。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/26__%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8nosql%E4%B8%8Erdbms%E5%A6%82%E4%BD%95%E5%8F%96%E9%95%BF%E8%A1%A5%E7%9F%AD%E7%9B%B8%E8%BE%85%E7%9B%B8%E6%88%90/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/26__%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8nosql%E4%B8%8Erdbms%E5%A6%82%E4%BD%95%E5%8F%96%E9%95%BF%E8%A1%A5%E7%9F%AD%E7%9B%B8%E8%BE%85%E7%9B%B8%E6%88%90/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="26__数据存储：NoSQL与RDBMS如何取长补短、相辅相成？">
  <meta property="og:description" content="你好，我是朱晔。今天，我来和你聊聊数据存储的常见错误。
近几年，各种非关系型数据库，也就是 NoSQL 发展迅猛，在项目中也非常常见。其中不乏一些使用上的极端情况，比如直接把关系型数据库（RDBMS）全部替换为 NoSQL，或是在不合适的场景下错误地使用 NoSQL。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Java业务开发常见错误100例">

  <meta itemprop="name" content="26__数据存储：NoSQL与RDBMS如何取长补短、相辅相成？">
  <meta itemprop="description" content="你好，我是朱晔。今天，我来和你聊聊数据存储的常见错误。
近几年，各种非关系型数据库，也就是 NoSQL 发展迅猛，在项目中也非常常见。其中不乏一些使用上的极端情况，比如直接把关系型数据库（RDBMS）全部替换为 NoSQL，或是在不合适的场景下错误地使用 NoSQL。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="8028">
  <meta itemprop="keywords" content="Java业务开发常见错误100例">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="26__数据存储：NoSQL与RDBMS如何取长补短、相辅相成？">
  <meta name="twitter:description" content="你好，我是朱晔。今天，我来和你聊聊数据存储的常见错误。
近几年，各种非关系型数据库，也就是 NoSQL 发展迅猛，在项目中也非常常见。其中不乏一些使用上的极端情况，比如直接把关系型数据库（RDBMS）全部替换为 NoSQL，或是在不合适的场景下错误地使用 NoSQL。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">26__数据存储：NoSQL与RDBMS如何取长补短、相辅相成？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 8028 字 </span>
          <span class="more-meta"> 预计阅读 17 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#取长补短之-redis-vs-mysql">取长补短之 Redis vs MySQL</a></li>
        <li><a href="#取长补短之-influxdb-vs-mysql">取长补短之 InfluxDB vs MySQL</a></li>
        <li><a href="#取长补短之-elasticsearch-vs-mysql">取长补短之 Elasticsearch vs MySQL</a></li>
        <li><a href="#结合-nosql-和-mysql-应对高并发的复合数据库架构">结合 NoSQL 和 MySQL 应对高并发的复合数据库架构</a></li>
        <li><a href="#重点回顾">重点回顾</a></li>
        <li><a href="#思考与讨论">思考与讨论</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是朱晔。今天，我来和你聊聊数据存储的常见错误。</p>
<p>近几年，各种非关系型数据库，也就是 NoSQL 发展迅猛，在项目中也非常常见。其中不乏一些使用上的极端情况，比如直接把关系型数据库（RDBMS）全部替换为 NoSQL，或是在不合适的场景下错误地使用 NoSQL。</p>
<p>其实，每种 NoSQL 的特点不同，都有其要着重解决的某一方面的问题。因此，我们在使用 NoSQL 的时候，要尽量让它去处理擅长的场景，否则不但发挥不出它的功能和优势，还可能会导致性能问题。</p>
<p>NoSQL 一般可以分为缓存数据库、时间序列数据库、全文搜索数据库、文档数据库、图数据库等。今天，我会以缓存数据库 Redis、时间序列数据库 InfluxDB、全文搜索数据库 ElasticSearch 为例，通过一些测试案例，和你聊聊这些常见 NoSQL 的特点，以及它们擅长和不擅长的地方。最后，我也还会和你说说 NoSQL 如何与 RDBMS 相辅相成，来构成一套可以应对高并发的复合数据库体系。</p>
<h2 id="取长补短之-redis-vs-mysql">取长补短之 Redis vs MySQL</h2>
<p>Redis 是一款设计简洁的缓存数据库，数据都保存在内存中，所以读写单一 Key 的性能非常高。</p>
<p>我们来做一个简单测试，分别填充 10 万条数据到 Redis 和 MySQL 中。MySQL 中的 name 字段做了索引，相当于 Redis 的 Key，data 字段为 100 字节的数据，相当于 Redis 的 Value：</p>
<p>@SpringBootApplication<br>
@Slf4j<br>
public class CommonMistakesApplication {</p>
<pre><code>//模拟 10 万条数据存到 Redis 和 MySQL  
public static final int ROWS = 100000;  
public static final String PAYLOAD = IntStream.rangeClosed(1, 100).mapToObj(__ -&gt; &quot;a&quot;).collect(Collectors.joining(&quot;&quot;));  
@Autowired  
private StringRedisTemplate stringRedisTemplate;  
@Autowired  
private JdbcTemplate jdbcTemplate;  
@Autowired  
private StandardEnvironment standardEnvironment;  


public static void main(String[] args) {  
    SpringApplication.run(CommonMistakesApplication.class, args);  
}  

@PostConstruct  
public void init() {  
    //使用-Dspring.profiles.active=init 启动程序进行初始化  
    if (Arrays.stream(standardEnvironment.getActiveProfiles()).anyMatch(s -&gt; s.equalsIgnoreCase(&quot;init&quot;))) {  
        initRedis();  
        initMySQL();  
    }  
}  

//填充数据到 MySQL  
private void initMySQL() {  
    //删除表  
    jdbcTemplate.execute(&quot;DROP TABLE IF EXISTS `r`;&quot;);  
    //新建表，name 字段做了索引  
    jdbcTemplate.execute(&quot;CREATE TABLE `r` (\n&quot; +  
            &quot;  `id` bigint(20) NOT NULL AUTO_INCREMENT,\n&quot; +  
            &quot;  `data` varchar(2000) NOT NULL,\n&quot; +  
            &quot;  `name` varchar(20) NOT NULL,\n&quot; +  
            &quot;  PRIMARY KEY (`id`),\n&quot; +  
            &quot;  KEY `name` (`name`) USING BTREE\n&quot; +  
            &quot;) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;&quot;);  

    //批量插入数据  
    String sql = &quot;INSERT INTO `r` (`data`,`name`) VALUES (?,?)&quot;;  
    jdbcTemplate.batchUpdate(sql, new BatchPreparedStatementSetter() {  
        @Override  
        public void setValues(PreparedStatement preparedStatement, int i) throws SQLException {  
            preparedStatement.setString(1, PAYLOAD);  
            preparedStatement.setString(2, &quot;item&quot; + i);  
        }  

        @Override  
        public int getBatchSize() {  
            return ROWS;  
        }  
    });  
    log.info(&quot;init mysql finished with count {}&quot;, jdbcTemplate.queryForObject(&quot;SELECT COUNT(*) FROM `r`&quot;, Long.class));  
}  

//填充数据到 Redis  
private void initRedis() {  
    IntStream.rangeClosed(1, ROWS).forEach(i -&gt; stringRedisTemplate.opsForValue().set(&quot;item&quot; + i, PAYLOAD));  
    log.info(&quot;init redis finished with count {}&quot;, stringRedisTemplate.keys(&quot;item*&quot;));  
}  
</code></pre>
<p>}</p>
<p>启动程序后，输出了如下日志，数据全部填充完毕：</p>
<p>[14:22:47.195] [main] [INFO ] [o.g.t.c.n.r.CommonMistakesApplication:80  ] - init redis finished with count 100000<br>
[14:22:50.030] [main] [INFO ] [o.g.t.c.n.r.CommonMistakesApplication:74  ] - init mysql finished with count 100000</p>
<p>然后，比较一下从 MySQL 和 Redis 随机读取单条数据的性能。“公平”起见，像 Redis 那样，我们使用 MySQL 时也根据 Key 来查 Value，也就是根据 name 字段来查 data 字段，并且我们给 name 字段做了索引：</p>
<p>@Autowired<br>
private JdbcTemplate jdbcTemplate;<br>
@Autowired<br>
private StringRedisTemplate stringRedisTemplate;</p>
<p>@GetMapping(&ldquo;redis&rdquo;)<br>
public void redis() {<br>
//使用随机的 Key 来查询 Value，结果应该等于 PAYLOAD<br>
Assert.assertTrue(stringRedisTemplate.opsForValue().get(&ldquo;item&rdquo; + (ThreadLocalRandom.current().nextInt(CommonMistakesApplication.ROWS) + 1)).equals(CommonMistakesApplication.PAYLOAD));<br>
}</p>
<p>@GetMapping(&ldquo;mysql&rdquo;)<br>
public void mysql() {<br>
//根据随机 name 来查 data，name 字段有索引，结果应该等于 PAYLOAD<br>
Assert.assertTrue(jdbcTemplate.queryForObject(&ldquo;SELECT data FROM <code>r</code> WHERE name=?&rdquo;, new Object[]{(&ldquo;item&rdquo; + (ThreadLocalRandom.current().nextInt(CommonMistakesApplication.ROWS) + 1))}, String.class)<br>
.equals(CommonMistakesApplication.PAYLOAD));<br>
}</p>
<p>在我的电脑上，使用 wrk 加 10 个线程 50 个并发连接做压测。可以看到，MySQL 90% 的请求需要 61ms，QPS 为 1460；<strong>而 Redis 90% 的请求在 5ms 左右，QPS 达到了 14008，几乎是 MySQL 的十倍</strong>：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/4d106f70f6cf72df29a5dfbee4601055.png" alt=""></p>
<p>但 Redis 薄弱的地方是，不擅长做 Key 的搜索。对 MySQL，我们可以使用 LIKE 操作前匹配走 B+ 树索引实现快速搜索；但对 Redis，我们使用 Keys 命令对 Key 的搜索，其实相当于在 MySQL 里做全表扫描。</p>
<p>我写一段代码来对比一下性能：</p>
<p>@GetMapping(&ldquo;redis2&rdquo;)<br>
public void redis2() {<br>
Assert.assertTrue(stringRedisTemplate.keys(&ldquo;item71*&rdquo;).size() == 1111);<br>
}<br>
@GetMapping(&ldquo;mysql2&rdquo;)<br>
public void mysql2() {<br>
Assert.assertTrue(jdbcTemplate.queryForList(&ldquo;SELECT name FROM <code>r</code> WHERE name LIKE &lsquo;item71%&rsquo;&rdquo;, String.class).size() == 1111);<br>
}</p>
<p>可以看到，在 QPS 方面，<strong>MySQL 的 QPS 达到了 Redis 的 157 倍；在延迟方面，MySQL 的延迟只有 Redis 的十分之一。</strong></p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/3f89b11667e648be76f41622b0f22f66.png" alt=""></p>
<p>Redis 慢的原因有两个：</p>
<ol>
<li>Redis 的 Keys 命令是 O(n) 时间复杂度。如果数据库中 Key 的数量很多，就会非常慢。</li>
<li>Redis 是单线程的，对于慢的命令如果有并发，串行执行就会非常耗时。</li>
</ol>
<p>一般而言，我们使用 Redis 都是针对某一个 Key 来使用，而不能在业务代码中使用 Keys 命令从 Redis 中“搜索数据”，因为这不是 Redis 的擅长。对于 Key 的搜索，我们可以先通过关系型数据库进行，然后再从 Redis 存取数据（如果实在需要搜索 Key 可以使用 SCAN 命令）。在生产环境中，我们一般也会配置 Redis 禁用类似 Keys 这种比较危险的命令，你可以参考这里。</p>
<p>总结一下，正如“缓存设计”一讲中提到的，对于业务开发来说，大多数业务场景下 Redis 是作为关系型数据库的辅助用于缓存的，我们一般不会把它当作数据库独立使用。</p>
<p>此外值得一提的是，Redis 提供了丰富的数据结构（Set、SortedSet、Hash、List），并围绕这些数据结构提供了丰富的 API。如果我们好好利用这个特点的话，可以直接在 Redis 中完成一部分服务端计算，避免“读取缓存 -&gt; 计算数据 -&gt; 保存缓存”三部曲中的读取和保存缓存的开销，进一步提高性能。</p>
<h2 id="取长补短之-influxdb-vs-mysql">取长补短之 InfluxDB vs MySQL</h2>
<p>InfluxDB 是一款优秀的时序数据库。在“生产就绪”这一讲中，我们就是使用 InfluxDB 来做的 Metrics 打点。时序数据库的优势，在于处理指标数据的聚合，并且读写效率非常高。</p>
<p>同样的，我们使用一些测试来对比下 InfluxDB 和 MySQL 的性能。</p>
<p>在如下代码中，我们分别填充了 1000 万条数据到 MySQL 和 InfluxDB 中。其中，每条数据只有 ID、时间戳、10000 以内的随机值这 3 列信息，对于 MySQL 我们把时间戳列做了索引：</p>
<p>@SpringBootApplication<br>
@Slf4j<br>
public class CommonMistakesApplication {</p>
<pre><code>public static void main(String[] args) {  
    SpringApplication.run(CommonMistakesApplication.class, args);  
}  

//测试数据量  
public static final int ROWS = 10000000;  

@Autowired  
private JdbcTemplate jdbcTemplate;  
@Autowired  
private StandardEnvironment standardEnvironment;  

@PostConstruct  
public void init() {  
    //使用-Dspring.profiles.active=init 启动程序进行初始化  
    if (Arrays.stream(standardEnvironment.getActiveProfiles()).anyMatch(s -&gt; s.equalsIgnoreCase(&quot;init&quot;))) {  
        initInfluxDB();  
        initMySQL();  
    }  
}  

//初始化 MySQL  
private void initMySQL() {  
    long begin = System.currentTimeMillis();  
    jdbcTemplate.execute(&quot;DROP TABLE IF EXISTS `m`;&quot;);  
    //只有 ID、值和时间戳三列  
    jdbcTemplate.execute(&quot;CREATE TABLE `m` (\n&quot; +  
            &quot;  `id` bigint(20) NOT NULL AUTO_INCREMENT,\n&quot; +  
            &quot;  `value` bigint NOT NULL,\n&quot; +  
            &quot;  `time` timestamp NOT NULL,\n&quot; +  
            &quot;  PRIMARY KEY (`id`),\n&quot; +  
            &quot;  KEY `time` (`time`) USING BTREE\n&quot; +  
            &quot;) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;&quot;);  

    String sql = &quot;INSERT INTO `m` (`value`,`time`) VALUES (?,?)&quot;;  
    //批量插入数据  
    jdbcTemplate.batchUpdate(sql, new BatchPreparedStatementSetter() {  
        @Override  
        public void setValues(PreparedStatement preparedStatement, int i) throws SQLException {  
            preparedStatement.setLong(1, ThreadLocalRandom.current().nextInt(10000));  
            preparedStatement.setTimestamp(2, Timestamp.valueOf(LocalDateTime.now().minusSeconds(5 * i)));  
        }  

        @Override  
        public int getBatchSize() {  
            return ROWS;  
        }  
    });  
    log.info(&quot;init mysql finished with count {} took {}ms&quot;, jdbcTemplate.queryForObject(&quot;SELECT COUNT(*) FROM `m`&quot;, Long.class), System.currentTimeMillis()-begin);  
}  

//初始化 InfluxDB  
private void initInfluxDB() {  
    long begin = System.currentTimeMillis();  
    OkHttpClient.Builder okHttpClientBuilder = new OkHttpClient().newBuilder()  
            .connectTimeout(1, TimeUnit.SECONDS)  
            .readTimeout(10, TimeUnit.SECONDS)  
            .writeTimeout(10, TimeUnit.SECONDS);  
    try (InfluxDB influxDB = InfluxDBFactory.connect(&quot;http://127.0.0.1:8086&quot;, &quot;root&quot;, &quot;root&quot;, okHttpClientBuilder)) {  
        String db = &quot;performance&quot;;  
        influxDB.query(new Query(&quot;DROP DATABASE &quot; + db));  
        influxDB.query(new Query(&quot;CREATE DATABASE &quot; + db));  
        //设置数据库  
        influxDB.setDatabase(db);  
        //批量插入，10000 条数据刷一次，或 1 秒刷一次  
        influxDB.enableBatch(BatchOptions.DEFAULTS.actions(10000).flushDuration(1000));  
        IntStream.rangeClosed(1, ROWS).mapToObj(i -&gt; Point  
                .measurement(&quot;m&quot;)  
                .addField(&quot;value&quot;, ThreadLocalRandom.current().nextInt(10000))  
                .time(LocalDateTime.now().minusSeconds(5 * i).toInstant(ZoneOffset.UTC).toEpochMilli(), TimeUnit.MILLISECONDS).build())  
                .forEach(influxDB::write);  
        influxDB.flush();  
        log.info(&quot;init influxdb finished with count {} took {}ms&quot;, influxDB.query(new Query(&quot;SELECT COUNT(*) FROM m&quot;)).getResults().get(0).getSeries().get(0).getValues().get(0).get(1), System.currentTimeMillis()-begin);  
    }  
}  
</code></pre>
<p>}</p>
<p>启动后，程序输出了如下日志：</p>
<p>[16:08:25.062] [main] [INFO ] [o.g.t.c.n.i.CommonMistakesApplication:104 ] - init influxdb finished with count 1.0E7 took 54280ms<br>
[16:11:50.462] [main] [INFO ] [o.g.t.c.n.i.CommonMistakesApplication:80  ] - init mysql finished with count 10000000 took 205394ms</p>
<p>InfluxDB 批量插入 1000 万条数据仅用了 54 秒，相当于每秒插入 18 万条数据，速度相当快；MySQL 的批量插入，速度也挺快达到了每秒 4.8 万。</p>
<p>接下来，我们测试一下。</p>
<p>对这 1000 万数据进行一个统计，查询最近 60 天的数据，按照 1 小时的时间粒度聚合，统计 value 列的最大值、最小值和平均值，并将统计结果绘制成曲线图：</p>
<p>@Autowired<br>
private JdbcTemplate jdbcTemplate;<br>
@GetMapping(&ldquo;mysql&rdquo;)<br>
public void mysql() {<br>
long begin = System.currentTimeMillis();<br>
//使用 SQL 从 MySQL 查询，按照小时分组<br>
Object result = jdbcTemplate.queryForList(&ldquo;SELECT date_format(time,&rsquo;%Y%m%d%H&rsquo;),max(value),min(value),avg(value) FROM m WHERE time&gt;now()- INTERVAL 60 DAY GROUP BY date_format(time,&rsquo;%Y%m%d%H&rsquo;)&rdquo;);<br>
log.info(&ldquo;took {} ms result {}&rdquo;, System.currentTimeMillis() - begin, result);<br>
}</p>
<p>@GetMapping(&ldquo;influxdb&rdquo;)<br>
public void influxdb() {<br>
long begin = System.currentTimeMillis();<br>
try (InfluxDB influxDB = InfluxDBFactory.connect(&ldquo;http://127.0.0.1:8086&rdquo;, &ldquo;root&rdquo;, &ldquo;root&rdquo;)) {<br>
//切换数据库<br>
influxDB.setDatabase(&ldquo;performance&rdquo;);<br>
//InfluxDB 的查询语法 InfluxQL 类似 SQL<br>
Object result = influxDB.query(new Query(&ldquo;SELECT MEAN(value),MIN(value),MAX(value) FROM m WHERE time &gt; now() - 60d GROUP BY TIME(1h)&rdquo;));<br>
log.info(&ldquo;took {} ms result {}&rdquo;, System.currentTimeMillis() - begin, result);<br>
}<br>
}</p>
<p>因为数据量非常大，单次查询就已经很慢了，所以这次我们不进行压测。分别调用两个接口，可以看到 <strong>MySQL 查询一次耗时 29 秒左右，而 InfluxDB 耗时 980ms</strong>：</p>
<p>[16:19:26.562] [http-nio-45678-exec-1] [INFO ] [o.g.t.c.n.i.PerformanceController:31  ] - took 28919 ms result [{date_format(time,&rsquo;%Y%m%d%H&rsquo;)=2019121308, max(value)=9993, min(value)=4, avg(value)=5129.5639}, {date_format(time,&rsquo;%Y%m%d%H&rsquo;)=2019121309, max(value)=9990, min(value)=12, avg(value)=4856.0556}, {date_format(time,&rsquo;%Y%m%d%H&rsquo;)=2019121310, max(value)=9998, min(value)=8, avg(value)=4948.9347}, {date_format(time,&rsquo;%Y%m%d%H&rsquo;)&hellip;<br>
[16:20:08.170] [http-nio-45678-exec-6] [INFO ] [o.g.t.c.n.i.PerformanceController:40  ] - took 981 ms result QueryResult [results=[Result [series=[Series [name=m, tags=null, columns=[time, mean, min, max], values=[[2019-12-13T08:00:00Z, 5249.2468619246865, 21.0, 9992.0],&hellip;</p>
<p>在按照时间区间聚合的案例上，我们看到了 InfluxDB 的性能优势。但，我们<strong>肯定不能把 InfluxDB 当作普通数据库</strong>，原因是：</p>
<ol>
<li>InfluxDB 不支持数据更新操作，毕竟时间数据只能随着时间产生新数据，肯定无法对过去的数据做修改；</li>
<li>从数据结构上说，时间序列数据数据没有单一的主键标识，必须包含时间戳，数据只能和时间戳进行关联，不适合普通业务数据。</li>
</ol>
<p><strong>此外需要注意，即便只是使用 InfluxDB 保存和时间相关的指标数据，我们也要注意不能滥用 tag</strong>。</p>
<p>InfluxDB 提供的 tag 功能，可以为每一个指标设置多个标签，并且 tag 有索引，可以对 tag 进行条件搜索或分组。但是，tag 只能保存有限的、可枚举的标签，不能保存 URL 等信息，否则可能会出现high series cardinality 问题，导致占用大量内存，甚至是 OOM。你可以点击这里，查看 series 和内存占用的关系。对于 InfluxDB，我们无法把 URL 这种原始数据保存到数据库中，只能把数据进行归类，形成有限的 tag 进行保存。</p>
<p>总结一下，对于 MySQL 而言，针对大量的数据使用全表扫描的方式来聚合统计指标数据，性能非常差，一般只能作为临时方案来使用。此时，引入 InfluxDB 之类的时间序列数据库，就很有必要了。时间序列数据库可以作为特定场景（比如监控、统计）的主存储，也可以和关系型数据库搭配使用，作为一个辅助数据源，保存业务系统的指标数据。</p>
<h2 id="取长补短之-elasticsearch-vs-mysql">取长补短之 Elasticsearch vs MySQL</h2>
<p>Elasticsearch（以下简称 ES），是目前非常流行的分布式搜索和分析数据库，独特的倒排索引结构尤其适合进行全文搜索。</p>
<p>简单来讲，倒排索引可以认为是一个 Map，其 Key 是分词之后的关键字，Value 是文档 ID/ 片段 ID 的列表。我们只要输入需要搜索的单词，就可以直接在这个 Map 中得到所有包含这个单词的文档 ID/ 片段 ID 列表，然后再根据其中的文档 ID/ 片段 ID 查询出实际的文档内容。</p>
<p>我们来测试一下，对比下使用 ES 进行关键字全文搜索、在 MySQL 中使用 LIKE 进行搜索的效率差距。</p>
<p>首先，定义一个实体 News，包含新闻分类、标题、内容等字段。这个实体同时会用作 Spring Data JPA 和 Spring Data Elasticsearch 的实体：</p>
<p>@Entity<br>
@Document(indexName = &ldquo;news&rdquo;, replicas = 0) //@Document 注解定义了这是一个 ES 的索引，索引名称 news，数据不需要冗余<br>
@Table(name = &ldquo;news&rdquo;, indexes = {@Index(columnList = &ldquo;cateid&rdquo;)}) //@Table 注解定义了这是一个 MySQL 表，表名 news，对 cateid 列做索引<br>
@Data<br>
@AllArgsConstructor<br>
@NoArgsConstructor<br>
@DynamicUpdate<br>
public class News {<br>
@Id<br>
private long id;<br>
@Field(type = FieldType.Keyword)<br>
private String category;//新闻分类名称<br>
private int cateid;//新闻分类 ID<br>
@Column(columnDefinition = &ldquo;varchar(500)&rdquo;)//@Column 注解定义了在 MySQL 中字段，比如这里定义 title 列的类型是 varchar(500)<br>
@Field(type = FieldType.Text, analyzer = &ldquo;ik_max_word&rdquo;, searchAnalyzer = &ldquo;ik_smart&rdquo;)//@Field 注解定义了 ES 字段的格式，使用 ik 分词器进行分词<br>
private String title;//新闻标题<br>
@Column(columnDefinition = &ldquo;text&rdquo;)<br>
@Field(type = FieldType.Text, analyzer = &ldquo;ik_max_word&rdquo;, searchAnalyzer = &ldquo;ik_smart&rdquo;)<br>
private String content;//新闻内容<br>
}</p>
<p>接下来，我们实现主程序。在启动时，我们会从一个 csv 文件中加载 4000 条新闻数据，然后复制 100 份，拼成 40 万条数据，分别写入 MySQL 和 ES：</p>
<p>@SpringBootApplication<br>
@Slf4j<br>
@EnableElasticsearchRepositories(includeFilters = @ComponentScan.Filter(type = FilterType.ASSIGNABLE_TYPE, value = NewsESRepository.class)) //明确设置哪个是 ES 的 Repository<br>
@EnableJpaRepositories(excludeFilters = @ComponentScan.Filter(type = FilterType.ASSIGNABLE_TYPE, value = NewsESRepository.class)) //其他的是 MySQL 的 Repository<br>
public class CommonMistakesApplication {</p>
<pre><code>public static void main(String[] args) {  
    Utils.loadPropertySource(CommonMistakesApplication.class, &quot;es.properties&quot;);  
    SpringApplication.run(CommonMistakesApplication.class, args);  
}  

@Autowired  
private StandardEnvironment standardEnvironment;  
@Autowired  
private NewsESRepository newsESRepository;  
@Autowired  
private NewsMySQLRepository newsMySQLRepository;  

@PostConstruct  
public void init() {  
    //使用-Dspring.profiles.active=init 启动程序进行初始化  
    if (Arrays.stream(standardEnvironment.getActiveProfiles()).anyMatch(s -&gt; s.equalsIgnoreCase(&quot;init&quot;))) {  
        //csv 中的原始数据只有 4000 条  
        List&lt;News&gt; news = loadData();  
        AtomicLong atomicLong = new AtomicLong();  
        news.forEach(item -&gt; item.setTitle(&quot;%%&quot; + item.getTitle()));  
        //我们模拟 100 倍的数据量，也就是 40 万条  
        IntStream.rangeClosed(1, 100).forEach(repeat -&gt; {  
            news.forEach(item -&gt; {  
                //重新设置主键 ID  
                item.setId(atomicLong.incrementAndGet());  
                //每次复制数据稍微改一下 title 字段，在前面加上一个数字，代表这是第几次复制  
                item.setTitle(item.getTitle().replaceFirst(&quot;%%&quot;, String.valueOf(repeat)));  
            });  
            initMySQL(news, repeat == 1);  
            log.info(&quot;init MySQL finished for {}&quot;, repeat);  
            initES(news, repeat == 1);  
            log.info(&quot;init ES finished for {}&quot;, repeat);  
        });  

    }  
}  

//从 news.csv 中解析得到原始数据  
private List&lt;News&gt; loadData() {  
    //使用 jackson-dataformat-csv 实现 csv 到 POJO 的转换  
    CsvMapper csvMapper = new CsvMapper();  
    CsvSchema schema = CsvSchema.emptySchema().withHeader();  
    ObjectReader objectReader = csvMapper.readerFor(News.class).with(schema);  
    ClassLoader classLoader = getClass().getClassLoader();  
    File file = new File(classLoader.getResource(&quot;news.csv&quot;).getFile());  
    try (Reader reader = new FileReader(file)) {  
        return objectReader.&lt;News&gt;readValues(reader).readAll();  
    } catch (Exception e) {  
        e.printStackTrace();  
    }  
    return null;  
}  

//把数据保存到 ES 中  
private void initES(List&lt;News&gt; news, boolean clear) {  
    if (clear) {  
        //首次调用的时候先删除历史数据  
        newsESRepository.deleteAll();  
    }  
    newsESRepository.saveAll(news);  
}  

//把数据保存到 MySQL 中  
private void initMySQL(List&lt;News&gt; news, boolean clear) {  
    if (clear) {  
        //首次调用的时候先删除历史数据  
        newsMySQLRepository.deleteAll();  
    }  
    newsMySQLRepository.saveAll(news);  
}  
</code></pre>
<p>}</p>
<p>由于我们使用了 Spring Data，直接定义两个 Repository，然后直接定义查询方法，无需实现任何逻辑即可实现查询，Spring Data 会根据方法名生成相应的 SQL 语句和 ES 查询 DSL，其中 ES 的翻译逻辑详见这里。</p>
<p>在这里，我们定义一个 countByCateidAndContentContainingAndContentContaining 方法，代表查询条件是：搜索分类等于 cateid 参数，且内容同时包含关键字 keyword1 和 keyword2，计算符合条件的新闻总数量：</p>
<p>@Repository<br>
public interface NewsMySQLRepository extends JpaRepository&lt;News, Long&gt; {<br>
//JPA：搜索分类等于 cateid 参数，且内容同时包含关键字 keyword1 和 keyword2，计算符合条件的新闻总数量<br>
long countByCateidAndContentContainingAndContentContaining(int cateid, String keyword1, String keyword2);<br>
}</p>
<p>@Repository<br>
public interface NewsESRepository extends ElasticsearchRepository&lt;News, Long&gt; {<br>
//ES：搜索分类等于 cateid 参数，且内容同时包含关键字 keyword1 和 keyword2，计算符合条件的新闻总数量<br>
long countByCateidAndContentContainingAndContentContaining(int cateid, String keyword1, String keyword2);<br>
}</p>
<p>对于 ES 和 MySQL，我们使用相同的条件进行搜索，搜素分类是 1，关键字是社会和苹果，然后输出搜索结果和耗时：</p>
<p>//测试 MySQL 搜索，最后输出耗时和结果<br>
@GetMapping(&ldquo;mysql&rdquo;)<br>
public void mysql(@RequestParam(value = &ldquo;cateid&rdquo;, defaultValue = &ldquo;1&rdquo;) int cateid,<br>
@RequestParam(value = &ldquo;keyword1&rdquo;, defaultValue = &ldquo;社会&rdquo;) String keyword1,<br>
@RequestParam(value = &ldquo;keyword2&rdquo;, defaultValue = &ldquo;苹果&rdquo;) String keyword2) {<br>
long begin = System.currentTimeMillis();<br>
Object result = newsMySQLRepository.countByCateidAndContentContainingAndContentContaining(cateid, keyword1, keyword2);<br>
log.info(&ldquo;took {} ms result {}&rdquo;, System.currentTimeMillis() - begin, result);<br>
}<br>
//测试 ES 搜索，最后输出耗时和结果<br>
@GetMapping(&ldquo;es&rdquo;)<br>
public void es(@RequestParam(value = &ldquo;cateid&rdquo;, defaultValue = &ldquo;1&rdquo;) int cateid,<br>
@RequestParam(value = &ldquo;keyword1&rdquo;, defaultValue = &ldquo;社会&rdquo;) String keyword1,<br>
@RequestParam(value = &ldquo;keyword2&rdquo;, defaultValue = &ldquo;苹果&rdquo;) String keyword2) {<br>
long begin = System.currentTimeMillis();<br>
Object result = newsESRepository.countByCateidAndContentContainingAndContentContaining(cateid, keyword1, keyword2);<br>
log.info(&ldquo;took {} ms result {}&rdquo;, System.currentTimeMillis() - begin, result);<br>
}</p>
<p>分别调用接口可以看到，<strong>ES 耗时仅仅 48ms，MySQL 耗时 6 秒多是 ES 的 100 倍</strong>。很遗憾，虽然新闻分类 ID 已经建了索引，但是这个索引只能起到加速过滤分类 ID 这一单一条件的作用，对于文本内容的全文搜索，B+ 树索引无能为力。</p>
<p>[22:04:00.951] [http-nio-45678-exec-6] [INFO ] [o.g.t.c.n.esvsmyql.PerformanceController:48  ] - took 48 ms result 2100<br>
Hibernate: select count(news0_.id) as col_0_0_ from news news0_ where news0_.cateid=? and (news0_.content like ? escape ?) and (news0_.content like ? escape ?)<br>
[22:04:11.946] [http-nio-45678-exec-7] [INFO ] [o.g.t.c.n.esvsmyql.PerformanceController:39  ] - took 6637 ms result 2100</p>
<p>但 ES 这种以索引为核心的数据库，也不是万能的，频繁更新就是一个大问题。</p>
<p>MySQL 可以做到仅更新某行数据的某个字段，但 ES 里每次数据字段更新都相当于整个文档索引重建。即便 ES 提供了文档部分更新的功能，但本质上只是节省了提交文档的网络流量，以及减少了更新冲突，其内部实现还是文档删除后重新构建索引。因此，如果要在 ES 中保存一个类似计数器的值，要实现不断更新，其执行效率会非常低。</p>
<p>我们来验证下，分别使用 JdbcTemplate+SQL 语句、ElasticsearchTemplate+ 自定义 UpdateQuery，实现部分更新 MySQL 表和 ES 索引的一个字段，每个方法都是循环更新 1000 次：</p>
<p>@GetMapping(&ldquo;mysql2&rdquo;)<br>
public void mysql2(@RequestParam(value = &ldquo;id&rdquo;, defaultValue = &ldquo;400000&rdquo;) long id) {<br>
long begin = System.currentTimeMillis();<br>
//对于 MySQL，使用 JdbcTemplate+SQL 语句，实现直接更新某个 category 字段，更新 1000 次<br>
IntStream.rangeClosed(1, 1000).forEach(i -&gt; {<br>
jdbcTemplate.update(&ldquo;UPDATE <code>news</code> SET category=? WHERE id=?&rdquo;, new Object[]{&ldquo;test&rdquo; + i, id});<br>
});<br>
log.info(&ldquo;mysql took {} ms result {}&rdquo;, System.currentTimeMillis() - begin, newsMySQLRepository.findById(id));<br>
}</p>
<p>@GetMapping(&ldquo;es2&rdquo;)<br>
public void es(@RequestParam(value = &ldquo;id&rdquo;, defaultValue = &ldquo;400000&rdquo;) long id) {<br>
long begin = System.currentTimeMillis();<br>
IntStream.rangeClosed(1, 1000).forEach(i -&gt; {<br>
//对于 ES，通过 ElasticsearchTemplate+ 自定义 UpdateQuery，实现文档的部分更新<br>
UpdateQuery updateQuery = null;<br>
try {<br>
updateQuery = new UpdateQueryBuilder()<br>
.withIndexName(&ldquo;news&rdquo;)<br>
.withId(String.valueOf(id))<br>
.withType(&quot;_doc&quot;)<br>
.withUpdateRequest(new UpdateRequest().doc(<br>
jsonBuilder()<br>
.startObject()<br>
.field(&ldquo;category&rdquo;, &ldquo;test&rdquo; + i)<br>
.endObject()))<br>
.build();<br>
} catch (IOException e) {<br>
e.printStackTrace();<br>
}<br>
elasticsearchTemplate.update(updateQuery);<br>
});<br>
log.info(&ldquo;es took {} ms result {}&rdquo;, System.currentTimeMillis() - begin, newsESRepository.findById(id).get());<br>
}</p>
<p>可以看到，<strong>MySQL 耗时仅仅 1.5 秒，而 ES 耗时 6.8 秒</strong>：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/ba91c530741d0e6fc0b3b08ea3351de2.png" alt=""></p>
<p>ES 是一个分布式的全文搜索数据库，所以与 MySQL 相比的优势在于文本搜索，而且因为其分布式的特性，可以使用一个大 ES 集群处理大规模数据的内容搜索。但，由于 ES 的索引是文档维度的，所以不适用于频繁更新的 OLTP 业务。</p>
<p>一般而言，我们会把 ES 和 MySQL 结合使用，MySQL 直接承担业务系统的增删改操作，而 ES 作为辅助数据库，直接扁平化保存一份业务数据，用于复杂查询、全文搜索和统计。接下来，我也会继续和你分析这一点。</p>
<h2 id="结合-nosql-和-mysql-应对高并发的复合数据库架构">结合 NoSQL 和 MySQL 应对高并发的复合数据库架构</h2>
<p>现在，我们通过一些案例看到了 Redis、InfluxDB、ES 这些 NoSQL 数据库，都有擅长和不擅长的场景。那么，有没有全能的数据库呢？</p>
<p>我认为没有。每一个存储系统都有其独特的数据结构，数据结构的设计就决定了其擅长和不擅长的场景。</p>
<p>比如，MySQL InnoDB 引擎的 B+ 树对排序和范围查询友好，频繁数据更新的代价不是太大，因此适合 OLTP（On-Line Transaction Processing）。</p>
<p>又比如，ES 的 Lucene 采用了 FST（Finite State Transducer）索引 + 倒排索引，空间效率高，适合对变动不频繁的数据做索引，实现全文搜索。存储系统本身不可能对一份数据使用多种数据结构保存，因此不可能适用于所有场景。</p>
<p>虽然在大多数业务场景下，MySQL 的性能都不算太差，但对于数据量大、访问量大、业务复杂的互联网应用来说，MySQL 因为实现了 ACID（原子性、一致性、隔离性、持久性）会比较重，而且横向扩展能力较差、功能单一，无法扛下所有数据量和流量，无法应对所有功能需求。因此，我们需要通过架构手段，来组合使用多种存储系统，取长补短，实现 1+1&gt;2 的效果。</p>
<p>我来举个例子。我们设计了一个<strong>包含多个数据库系统的、能应对各种高并发场景的一套数据服务的系统架构</strong>，其中包含了同步写服务、异步写服务和查询服务三部分，分别实现主数据库写入、辅助数据库写入和查询路由。</p>
<p>我们按照服务来依次分析下这个架构。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/a14b086fe9232b29e5dd7b4f658c73af.png" alt=""></p>
<p>首先要明确的是，重要的业务主数据只能保存在 MySQL 这样的关系型数据库中，原因有三点：</p>
<ol>
<li>RDBMS 经过了几十年的验证，已经非常成熟；</li>
<li>RDBMS 的用户数量众多，Bug 修复快、版本稳定、可靠性很高；</li>
<li>RDBMS 强调 ACID，能确保数据完整。</li>
</ol>
<p>有两种类型的查询任务可以交给 MySQL 来做，性能会比较好，这也是 MySQL 擅长的地方：</p>
<ol>
<li>按照主键 ID 的查询。直接查询聚簇索引，其性能会很高。但是单表数据量超过亿级后，性能也会衰退，而且单个数据库无法承受超大的查询并发，因此我们可以把数据表进行 Sharding 操作，均匀拆分到多个数据库实例中保存。我们把这套数据库集群称作 Sharding 集群。</li>
<li>按照各种条件进行范围查询，查出主键 ID。对二级索引进行查询得到主键，只需要查询一棵 B+ 树，效率同样很高。但索引的值不宜过大，比如对 varchar(1000) 进行索引不太合适，而索引外键（一般是 int 或 bigint 类型）性能就会比较好。因此，我们可以在 MySQL 中建立一张“索引表”，除了保存主键外，主要是保存各种关联表的外键，以及尽可能少的 varchar 类型的字段。这张索引表的大部分列都可以建上二级索引，用于进行简单搜索，搜索的结果是主键的列表，而不是完整的数据。由于索引表字段轻量并且数量不多（一般控制在 10 个以内），所以即便索引表没有进行 Sharding 拆分，问题也不会很大。</li>
</ol>
<p>如图上蓝色线所示，写入两种 MySQL 数据表和发送 MQ 消息的这三步，我们用一个<strong>同步写服务</strong>完成了。我在“异步处理”中提到，所有异步流程都需要补偿，这里的异步流程同样需要。只不过为了简洁，我在这里省略了补偿流程。</p>
<p>然后，如图中绿色线所示，有一个<strong>异步写服务</strong>，监听 MQ 的消息，继续完成辅助数据的更新操作。这里我们选用了 ES 和 InfluxDB 这两种辅助数据库，因此整个异步写数据操作有三步：</p>
<ol>
<li>MQ 消息不一定包含完整的数据，甚至可能只包含一个最新数据的主键 ID，我们需要根据 ID 从查询服务查询到完整的数据。</li>
<li>写入 InfluxDB 的数据一般可以按时间间隔进行简单聚合，定时写入 InfluxDB。因此，这里会进行简单的客户端聚合，然后写入 InfluxDB。</li>
<li>ES 不适合在各索引之间做连接（Join）操作，适合保存扁平化的数据。比如，我们可以把订单下的用户、商户、商品列表等信息，作为内嵌对象嵌入整个订单 JSON，然后把整个扁平化的 JSON 直接存入 ES。</li>
</ol>
<p>对于数据写入操作，我们认为操作返回的时候同步数据一定是写入成功的，但是由于各种原因，异步数据写入无法确保立即成功，会有一定延迟，比如：</p>
<ol>
<li>异步消息丢失的情况，需要补偿处理；</li>
<li>写入 ES 的索引操作本身就会比较慢；</li>
<li>写入 InfluxDB 的数据需要客户端定时聚合。</li>
</ol>
<p>因此，对于<strong>查询服务</strong>，如图中红色线所示，我们需要根据一定的上下文条件（比如查询一致性要求、时效性要求、搜索的条件、需要返回的数据字段、搜索时间区间等）来把请求路由到合适的数据库，并且做一些聚合处理：</p>
<ol>
<li>需要根据主键查询单条数据，可以从 MySQL Sharding 集群或 Redis 查询，如果对实时性要求不高也可以从 ES 查询。</li>
<li>按照多个条件搜索订单的场景，可以从 MySQL 索引表查询出主键列表，然后再根据主键从 MySQL Sharding 集群或 Redis 获取数据详情。</li>
<li>各种后台系统需要使用比较复杂的搜索条件，甚至全文搜索来查询订单数据，或是定时分析任务需要一次查询大量数据，这些场景对数据实时性要求都不高，可以到 ES 进行搜索。此外，MySQL 中的数据可以归档，我们可以在 ES 中保留更久的数据，而且查询历史数据一般并发不会很大，可以统一路由到 ES 查询。</li>
<li>监控系统或后台报表系统需要呈现业务监控图表或表格，可以把请求路由到 InfluxDB 查询。</li>
</ol>
<h2 id="重点回顾">重点回顾</h2>
<p>今天，我通过三个案例分别对比了缓存数据库 Redis、时间序列数据库 InfluxDB、搜索数据库 ES 和 MySQL 的性能。我们看到：</p>
<ol>
<li>Redis 对单条数据的读取性能远远高于 MySQL，但不适合进行范围搜索。</li>
<li>InfluxDB 对于时间序列数据的聚合效率远远高于 MySQL，但因为没有主键，所以不是一个通用数据库。</li>
<li>ES 对关键字的全文搜索能力远远高于 MySQL，但是字段的更新效率较低，不适合保存频繁更新的数据。</li>
</ol>
<p>最后，我们给出了一个混合使用 MySQL + Redis + InfluxDB + ES 的架构方案，充分发挥了各种数据库的特长，相互配合构成了一个可以应对各种复杂查询，以及高并发读写的存储架构。</p>
<ol>
<li>主数据由两种 MySQL 数据表构成，其中索引表承担简单条件的搜索来得到主键，Sharding 表承担大并发的主键查询。主数据由同步写服务写入，写入后发出 MQ 消息。</li>
<li>辅助数据可以根据需求选用合适的 NoSQL，由单独一个或多个异步写服务监听 MQ 后异步写入。</li>
<li>由统一的查询服务，对接所有查询需求，根据不同的查询需求路由查询到合适的存储，确保每一个存储系统可以根据场景发挥所长，并分散各数据库系统的查询压力。</li>
</ol>
<p>今天用到的代码，我都放在了 GitHub 上，你可以点击这个链接查看。</p>
<h2 id="思考与讨论">思考与讨论</h2>
<ol>
<li>我们提到，InfluxDB 不能包含太多 tag。你能写一段测试代码，来模拟这个问题，并观察下 InfluxDB 的内存使用情况吗？</li>
<li>文档数据库 MongoDB，也是一种常用的 NoSQL。你觉得 MongoDB 的优势和劣势是什么呢？它适合用在什么场景下呢？</li>
</ol>
<p>关于数据存储，你还有其他心得吗？我是朱晔，欢迎在评论区与我留言分享你的想法，也欢迎你把今天的内容分享给你的朋友或同事，一起交流。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF100%E4%BE%8B/">Java业务开发常见错误100例</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/26__%E4%BD%BF%E7%94%A8%E9%98%BB%E5%A1%9Ei_o%E5%92%8C%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E6%8D%A2%E4%B8%80%E7%A7%8D%E8%BD%BB%E9%87%8F%E7%9A%84%E6%96%B9%E5%BC%8F/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">26__使用阻塞I_O和线程模型：换一种轻量的方式</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2/26__%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E5%A6%82%E4%BD%95%E7%9E%AC%E9%97%B4%E5%AE%8C%E6%88%90%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%A3%80%E7%B4%A2/">
            <span class="next-text nav-default">26__搜索引擎架构：如何瞬间完成海量数据检索？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

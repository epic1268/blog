<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>11jieba分词如何基于感情色彩进行单词数量统计 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="06 | jieba分词：如何基于感情色彩进行单词数量统计？
你好，我是尹会生。
在涉及运营、市场的工作中，我们经常需要根据产品评论的情感分析，来了解某一产品的口碑。所谓的情感分析，就是指根据用户对产品的评论，分析出用户对产品的喜好程度。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/python%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8A%9E%E5%85%AC%E5%AE%9E%E6%88%98%E8%AF%BE/11jieba%E5%88%86%E8%AF%8D%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8E%E6%84%9F%E6%83%85%E8%89%B2%E5%BD%A9%E8%BF%9B%E8%A1%8C%E5%8D%95%E8%AF%8D%E6%95%B0%E9%87%8F%E7%BB%9F%E8%AE%A1/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/python%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8A%9E%E5%85%AC%E5%AE%9E%E6%88%98%E8%AF%BE/11jieba%E5%88%86%E8%AF%8D%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8E%E6%84%9F%E6%83%85%E8%89%B2%E5%BD%A9%E8%BF%9B%E8%A1%8C%E5%8D%95%E8%AF%8D%E6%95%B0%E9%87%8F%E7%BB%9F%E8%AE%A1/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="11jieba分词如何基于感情色彩进行单词数量统计">
  <meta property="og:description" content="06 | jieba分词：如何基于感情色彩进行单词数量统计？
你好，我是尹会生。
在涉及运营、市场的工作中，我们经常需要根据产品评论的情感分析，来了解某一产品的口碑。所谓的情感分析，就是指根据用户对产品的评论，分析出用户对产品的喜好程度。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Python自动化办公实战课">

  <meta itemprop="name" content="11jieba分词如何基于感情色彩进行单词数量统计">
  <meta itemprop="description" content="06 | jieba分词：如何基于感情色彩进行单词数量统计？
你好，我是尹会生。
在涉及运营、市场的工作中，我们经常需要根据产品评论的情感分析，来了解某一产品的口碑。所谓的情感分析，就是指根据用户对产品的评论，分析出用户对产品的喜好程度。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="4177">
  <meta itemprop="keywords" content="Python自动化办公实战课">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="11jieba分词如何基于感情色彩进行单词数量统计">
  <meta name="twitter:description" content="06 | jieba分词：如何基于感情色彩进行单词数量统计？
你好，我是尹会生。
在涉及运营、市场的工作中，我们经常需要根据产品评论的情感分析，来了解某一产品的口碑。所谓的情感分析，就是指根据用户对产品的评论，分析出用户对产品的喜好程度。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">11jieba分词如何基于感情色彩进行单词数量统计</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 4177 字 </span>
          <span class="more-meta"> 预计阅读 9 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents"></nav>
  </div>
</div>
    <div class="post-content">
      <p>06 | jieba分词：如何基于感情色彩进行单词数量统计？</p>
<p>你好，我是尹会生。</p>
<p>在涉及运营、市场的工作中，我们经常需要根据产品评论的情感分析，来了解某一产品的口碑。所谓的情感分析，就是指根据用户对产品的评论，分析出用户对产品的喜好程度。</p>
<p>最简单的，我们会区分产品的评价是正向还是负向的，然后根据反馈结果改变产品的特性。稍微复杂一点的，我们会根据情感色彩将产品的评价关键词提取出来，进行统计和分类（用于更深入的分析产品）。</p>
<p>如果靠人工对产品评价进行辨析，有很大的局限性：一个是不够公平，因为每个人对词语感情色彩的理解并不是完全一致的；另一个是产品评价有很多，而且还会不定期增加，人工分析很难保证及时性。</p>
<p>因此，在进行词语的情感分析时，我通常都会使用 Python 的 jieba 库，来自动化实现文本情感分析功能。一般需要经过三个步骤，分别是分词、优化分词结果和情感分析。</p>
<p>那我就先带你看看为什么要进行分词，以及如何进行分词操作。</p>
<p>如何分词？</p>
<p>要想判断一段话表达的情感是正向还是负向，就需要根据这句话中的关键词来得到情感的倾向。例如一段话中出现了“开心”“高兴”“物超所值”等正向的词语，我们就可以认定这条产品的评价是偏正向的。相反，出现“不喜欢”“差”等词语，评价就是偏负向的。</p>
<p>但是，要想从一句话中将这些表达情感的词一个一个找出来，就需要依靠专业的工具把一句话根据语义划分成多个词，再把表达情感的词语提取出来，进行情感分析。</p>
<p>为什么要先根据语义来划分词呢？这主要是因为中文句子里的每个词中间没有用空格进行分隔，没有分隔就没法进行之后的情感分析。而对中文句子按照语义进行切割的这种操作，我们就称为“分词”。</p>
<p>Python 中有非常成熟的分词库，其中最流行的库是 jieba 库。在计算机中，实现语义分割的技术有两种，一种是从统计学的角度分词，另一种是从词库的角度基于 TF-IDF 算法实现分词。jieba 就是采用第二种，基于词库的角度对文章进行自动分词的。</p>
<p>那我就以电商网站上的一段商品评论为例，给你演示一下 jieba 库是如何实现分词的。</p>
<p><code>import jiebawords1=&quot;速度快，包装好，看着特别好，喝着肯定不错！价廉物美&quot;words2 = jieba.cut(words1)print(&quot;/&quot;.join(words2))\# 速度/快/，/包装/好/，/看着/特别/好/，/喝/着/肯定/不错/！/价廉物美</code></p>
<p>在这段代码中，我利用 jieba 库的 cut() 函数实现了自动分词功能。我刚才讲了，jieba 分词是依靠词库实现的，词库里包含了提前准备好的词和词性。下图就是 jieba 词库的内容：</p>
<p><code>一鼓 ru一鼓作气 ru一马当先 ru... ...</code></p>
<p>这些词库中的词，jieba 是怎么识别的呢？</p>
<p>在你使用 pip 命令安装了 jieba 库之后，它会附带一个默认的词库。在官方文档中，将这个词库称作“字典”文件。这个文件包含了日常汉语的词语、词性。jieba 库会先基于“字典”对文章中所有可能出现的词进行匹配。匹配之后，会生成句子中的汉字所有可能形成的词。然后再将这些词构成的有向无环图（DAG），并采用动态规划算法查找最大概率路径，尽可能不会将一个词拆分成单个汉字。最后再从“字典”找出基于词频的最大切分组合，把这分词的组合从句子中找出来，形成一个一个的词。</p>
<p>而且，为了提高分词的准确率，jieba 对没有记录在字典的词（称作未登录词）也使用了分词的模型，它就是大名鼎鼎的基于汉字成词能力的 HMM 模型（隐马尔可夫模型）。对词库中的词和未登录词进行处理之后，jieba 就可以实现自动化分词了。</p>
<p>不过，分词之后，我们还需要对分词结果进行优化。因为在分词结果中存在着大量的标点符号，还有“看着”“喝着”“包装” 等和表达产品评价的情感无关的词语，为了加快计算词语的情感速度、避免无关词语影响情感倾向判断，我们就要优化分词的结果。</p>
<p>优化分词结果</p>
<p>优化分词结果主要从两个方面进行优化：一方面是移除标点符号；一方面是删除和情感无关的助词、名词等。</p>
<p>我先来带你学习下怎么从分词结果中移除标点符号。</p>
<p>移除标点符号一般有两种方法：</p>
<p>删除停止词（Stop Words）；</p>
<p>根据词性提取关键词。</p>
<p>先来看看第一种，删除停止词。</p>
<p>所谓的停止词，就是指为了节省空间和提高匹配词语情感倾向的效率，在进 **** 行情感分析前自动过滤掉的某些字或词。</p>
<p>停止词主要是标点符号，也可以是“啊呀呢”等语气助词。把标点符号写入停止词列表后，再使用 for 循环功能，将 jieba 分好的词和停止词列表依次匹配。如果 jieba 分好的词出现在列表中，就将这些词删掉。如果没有出现在列表中，就把这些词再组合成一个新的列表，后续就可以对新的列表进行情感分析。</p>
<p>删除停止词的代码如下。通过删除停止词，我们就可以得到只有汉字的分词结果。</p>
<p><code>words2 = jieba.cut(words1)words3 = list(words2)print(&quot;/&quot;.join(words3))\# 速度/快/，/包装/好/，/看着/特别/好/，/喝/着/肯定/不错/！/价廉物美stop\_words = \[&quot;，&quot;, &quot;！&quot;\]words4 =\[x for x in words3 if x not in stop\_words\]print(words4)\# \['速度', '快', '包装', '好', '看着', '特别', '好', '喝', '着', '肯定', '不错', '价廉物美'\]</code></p>
<p>另一种优化分词结果的方式叫做根据词性提取关键词。这种方式的优点在于不用事先准备停用词列表，jieba 库就能够根据每个词的词性对其进行标注。</p>
<p>我这里为你提供了一张 paddle（paddle 是百度开源的深度学习平台，jieba 使用了 paddle 的模型库）模式词性表作为参考，你可以根据 jieba 自动分析得到的词性结果，手动将助词、虚词（标点符号）移除。</p>
<p>我把这个基于词性移除标点符号的代码也提供给你：</p>
<p><code>\# words5 基于词性移除标点符号import jieba.posseg as psg  words5 = \[ (w.word, w.flag) for w in psg.cut(words1) \]\# 保留形容词saved = \['a',\]words5 =\[x for x in words5 if x\[1\] in saved\]print(words5)\# \[('快', 'a'), ('好', 'a'), ('好', 'a'), ('不错', 'a')\]</code></p>
<p>在这段代码中，我在使用 jieba 库的 posseg 类实现分词的同时，也对词性进行了标注。为了让你看到更直接的结果，我只保留了形容词，因此，变量 saved 的列表参数就只有一个‘a’，表示保留的词类型为形容词。</p>
<p>如果你希望保留更多的词性，可以将词性表中代表每种词的英文缩写写入 saved 列表中，其中，我建议你在处理之后把形容词、副词、动词都保留下来，这些都有助于你进行下一步的语义情感分析。</p>
<p>在优化分词结果之后，我们就得到了只有形容词的处理结果。那么，接下来，我们需要基于这些形容词来获取产品评价的正向或负向结果，以及基于词语的情感色彩来统计单词的数量。</p>
<p>语义情感分析</p>
<p>对于已经分好词的语句，我们需要使用另一个库统计词的正向、负向情感倾向，这个库就是 snownlp 库。</p>
<p>snownlp 库既能实现分词，也能计算词出现频率，以及进行情感分析。那你可能就发出疑问了：为什么不直接使用 snownlp 进行分词，而要使用 jieba 分词呢？</p>
<p>原因就在于，snownlp 的算法问题，会让它对否定词划分得不够准确。例如“不喜欢”，snownlp 会把这个词划分为两个独立的词，分别是“不”和“喜欢”。那么，在计算语义情感时，就会产生较大的误差。所以我们会先采用 jieba 进行分词，分词之后再采用 snownlp 来实现语义情感分析功能。</p>
<p>接下来，我带你看一下如何使用 snownlp 得到完成分词之后的情感分析结果。代码如下：</p>
<p><code>from snownlp import SnowNLPwords6 = \[ x\[0\] for x in words5 \]s1 = SnowNLP(&quot; &quot;.join(words3))print(s1.sentiments)\# 0.99583439264303 </code></p>
<p>这段代码通过 snownlp 的 Bayes（贝叶斯）模型训练方法，将模块自带的正样本和负样本读入内存之后，再使用 Bayes 模型中的 classify() 函数进行分类，这样就得到了 sentiments 属性的值，sentiments 的值表示情感倾向的方向。在 snownlp 中：</p>
<p>如果情感倾向是正向的，sentiments 的结果会接近 1。</p>
<p>如果情感倾向是负向的，结果会接近 0。</p>
<p>可以看到，我们在刚刚的代码中得到的情感分析的结果是 0.9958，非常接近 1，因此这条产品的评价就是正向的。</p>
<p>情感倾向结果趋近于 1 或者趋近于 0 都是非常理想的情况，可以直接得到感情色彩比较强烈的产品评价。但是，有时候感情色彩不太强烈，在这种情况下，我们就需要根据评价的数值范围对评论进行分组，统计每组包含多少个评价。</p>
<p>这个功能也可以通过 snownlp 实现，我把代码写在这里，你可以参考：</p>
<p><code>positive = 0negtive = 0for word in words6:    s2 = SnowNLP(word)    if s2.sentiments &gt; 0.7:        positive+=1    else:        negtive+=1    print(word,str(s2.sentiments))print(f&quot;正向评价数量:{positive}&quot;)print(f&quot;负向评价数量:{negtive}&quot;)\# 快 0.7164835164835165\# 好 0.6558628208940429\# 好 0.6558628208940429\# 不错 0.8612132352941176\# 价廉物美 0.7777777777777779\# 正向评价数量:3\# 负向评价数量:2</code></p>
<p>通过 snownlp 库配合 jieba 分词的结果，你就可以实现批量产品评论的自动语义情感分析了。同时，你还可以根据不断累积产品的评价，来持续优化你的产品。</p>
<p>小结</p>
<p>最后，我来为你总结一下对文件进行情感倾向分析的关键步骤和注意事项。实现语义情感分析功能，你必须掌握分词、优化分词结果、语义情感分析这三个步骤。</p>
<p>其中分词是实现中文语义分析的第一步，也是最基础的部分。分词的好坏决定了对每个词的情感进行标注的准确程度。如果默认的 jieba 分词没有正确地把词语划分，你也可以使用 jieba 自带的 suggest_freq() 函数进行词频调节。</p>
<p>举个小例子，“中”“将”两个字可以组成“中将”的词语，也可以拆开来用“我们中 / 将有人成功考上北大”。在不同的语言环境中，我们要通过词频调节来让它们以词的形式出现，还是以两个字的方式出现。调整的方法是：</p>
<p><code>jieba.suggest\_freq((&quot;中&quot;, &quot;将&quot;), tune = True)</code></p>
<p>可以看到，利用调节词频使“中”“将”都能被分出来，而不会被错误地识别为一个词“中将”，通过这种方式，就可以提升 jieba 的识别正确率。</p>
<p>在优化分词结果这一步，你可以通过减少虚词和标点符号，通过停止词、词性的选择，来降低它们对情感分析结果的干扰。</p>
<p>最后，你还可以为 snownlp 增加新的流行词和网络用语，帮你更准确地分析用户对产品的喜好程度，从而提高产品定位的精确度。</p>
<p>在 snownlp 中，通过 train() 和 save() 两个函数把模型训练和保存之后，就能实现扩展默认字典的功能了。此外，我在工作中还会利用这种方式增加 emoji 表情对应的情感倾向分析功能，以此来进一步提升 snownlp 分析情感倾向的准确度。</p>
<p>我将训练模型和保存训练后的模型的函数也写在这里供你参考，希望通过训练自己的模型，能够让你的产品分析更加准确。</p>
<p><code>sentiment.train(neg2.txt,pos2.txt);  #   训练用户自定义正负情感数据集sentiment.save('sentiment2.marshal');  # 保存训练模型</code></p>
<p>今天用到的代码，我都放在了 GitHub 上，你可以点击这个链接查看。</p>
<p>思考题</p>
<p>我给你留一道思考题，我在最后一段代码分别统计了正向和负向评价的数量，你能否根据这段代码统计一段文字中包含了多少个动词、多少个名词和多少个形容词呢？欢迎你在课程评论区留言，和我一起讨论。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/python%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8A%9E%E5%85%AC%E5%AE%9E%E6%88%98%E8%AF%BE/">Python自动化办公实战课</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E5%AD%A6%E4%B9%A0%E9%AB%98%E6%89%8B/1111%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%AE%8C%E6%88%90%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%B7%A5%E4%BD%9C%E4%BB%BB%E5%8A%A1%E4%BB%A5%E5%8F%8A%E5%BF%AB%E9%80%9F%E5%AD%A6%E4%BC%9A%E6%96%B0%E6%8A%80%E8%83%BD/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">1111｜如何快速完成学习和工作任务以及快速学会新技能</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97/11p8%E6%8F%90%E5%8D%87%E6%94%BB%E7%95%A5%E6%80%8E%E4%B9%88%E6%88%90%E4%B8%BA%E6%9C%89%E5%BD%B1%E5%93%8D%E5%8A%9B%E7%9A%84%E9%A2%86%E5%9F%9F%E4%B8%93%E5%AE%B6/">
            <span class="next-text nav-default">11P8提升攻略怎么成为有影响力的领域专家</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>21揭秘Python协程 - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="20 | 揭秘 Python 协程
你好，我是景霄。
上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。
那么首先你要明白，什么是协程？
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/21%E6%8F%AD%E7%A7%98python%E5%8D%8F%E7%A8%8B/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/21%E6%8F%AD%E7%A7%98python%E5%8D%8F%E7%A8%8B/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="21揭秘Python协程">
  <meta property="og:description" content="20 | 揭秘 Python 协程
你好，我是景霄。
上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。
那么首先你要明白，什么是协程？">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Python核心技术与实战">

  <meta itemprop="name" content="21揭秘Python协程">
  <meta itemprop="description" content="20 | 揭秘 Python 协程
你好，我是景霄。
上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。
那么首先你要明白，什么是协程？">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="4844">
  <meta itemprop="keywords" content="Python核心技术与实战">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="21揭秘Python协程">
  <meta name="twitter:description" content="20 | 揭秘 Python 协程
你好，我是景霄。
上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。
那么首先你要明白，什么是协程？">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">21揭秘Python协程</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 4844 字 </span>
          <span class="more-meta"> 预计阅读 10 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents"></nav>
  </div>
</div>
    <div class="post-content">
      <p>20 | 揭秘 Python 协程</p>
<p>你好，我是景霄。</p>
<p>上一节课的最后，我们留下一个小小的悬念：生成器在 Python 2 中还扮演了一个重要角色，就是用来实现 Python 协程。</p>
<p>那么首先你要明白，什么是协程？</p>
<p>协程是实现并发编程的一种方式。一说并发，你肯定想到了多线程 / 多进程模型，没错，多线程 / 多进程，正是解决并发问题的经典模型之一。最初的互联网世界，多线程 / 多进程在服务器并发中，起到举足轻重的作用。</p>
<p>随着互联网的快速发展，你逐渐遇到了 C10K 瓶颈，也就是同时连接到服务器的客户达到了一万个。于是很多代码跑崩了，进程上下文切换占用了大量的资源，线程也顶不住如此巨大的压力，这时， NGINX 带着事件循环出来拯救世界了。</p>
<p>如果将多进程 / 多线程类比为起源于唐朝的藩镇割据，那么事件循环，就是宋朝加强的中央集权制。事件循环启动一个统一的调度器，让调度器来决定一个时刻去运行哪个任务，于是省却了多线程中启动线程、管理线程、同步锁等各种开销。同一时期的 NGINX，在高并发下能保持低资源低消耗高性能，相比 Apache 也支持更多的并发连接。</p>
<p>再到后来，出现了一个很有名的名词，叫做回调地狱（callback hell），手撸过 JavaScript 的朋友肯定知道我在说什么。我们大家惊喜地发现，这种工具完美地继承了事件循环的优越性，同时还能提供 async / await 语法糖，解决了执行性和可读性共存的难题。于是，协程逐渐被更多人发现并看好，也有越来越多的人尝试用 Node.js 做起了后端开发。（讲个笑话，JavaScript 是一门编程语言。）</p>
<p>回到我们的 Python。使用生成器，是 Python 2 开头的时代实现协程的老方法了，Python 3.7 提供了新的基于 asyncio 和 async / await 的方法。我们这节课，同样的，跟随时代，抛弃掉不容易理解、也不容易写的旧的基于生成器的方法，直接来讲新方法。</p>
<p>我们先从一个爬虫实例出发，用清晰的讲解思路，带你结合实战来搞懂这个不算特别容易理解的概念。之后，我们再由浅入深，直击协程的核心。</p>
<p>从一个爬虫说起</p>
<p>爬虫，就是互联网的蜘蛛，在搜索引擎诞生之时，与其一同来到世上。爬虫每秒钟都会爬取大量的网页，提取关键信息后存储在数据库中，以便日后分析。爬虫有非常简单的 Python 十行代码实现，也有 Google 那样的全球分布式爬虫的上百万行代码，分布在内部上万台服务器上，对全世界的信息进行嗅探。</p>
<p>话不多说，我们先看一个简单的爬虫例子：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import time
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">def crawl_page(url):
</span></span><span class="line"><span class="cl">    print(&#39;crawling {}&#39;.format(url))
</span></span><span class="line"><span class="cl">    sleep_time = int(url.split(&#39;_&#39;)[-1])
</span></span><span class="line"><span class="cl">    time.sleep(sleep_time)
</span></span><span class="line"><span class="cl">    print(&#39;OK {}&#39;.format(url))
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">def main(urls):
</span></span><span class="line"><span class="cl">    for url in urls:
</span></span><span class="line"><span class="cl">        crawl_page(url)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">%time main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;])
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">########## 输出 ##########
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">crawling url_1
</span></span><span class="line"><span class="cl">OK url_1
</span></span><span class="line"><span class="cl">crawling url_2
</span></span><span class="line"><span class="cl">OK url_2
</span></span><span class="line"><span class="cl">crawling url_3
</span></span><span class="line"><span class="cl">OK url_3
</span></span><span class="line"><span class="cl">crawling url_4
</span></span><span class="line"><span class="cl">OK url_4
</span></span><span class="line"><span class="cl">Wall time: 10 s
</span></span></code></pre></td></tr></table>
</div>
</div><p>（注意：本节的主要目的是协程的基础概念，因此我们简化爬虫的 scrawl_page 函数为休眠数秒，休眠时间取决于 url 最后的那个数字。）</p>
<p>这是一个很简单的爬虫，main() 函数执行时，调取 crawl_page() 函数进行网络通信，经过若干秒等待后收到结果，然后执行下一个。</p>
<p>看起来很简单，但你仔细一算，它也占用了不少时间，五个页面分别用了 1 秒到 4 秒的时间，加起来一共用了 10 秒。这显然效率低下，该怎么优化呢？</p>
<p>于是，一个很简单的思路出现了——我们这种爬取操作，完全可以并发化。我们就来看看使用协程怎么写。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import asyncio
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def crawl_page(url):
</span></span><span class="line"><span class="cl">    print(&#39;crawling {}&#39;.format(url))
</span></span><span class="line"><span class="cl">    sleep_time = int(url.split(&#39;_&#39;)[-1])
</span></span><span class="line"><span class="cl">    await asyncio.sleep(sleep_time)
</span></span><span class="line"><span class="cl">    print(&#39;OK {}&#39;.format(url))
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def main(urls):
</span></span><span class="line"><span class="cl">    for url in urls:
</span></span><span class="line"><span class="cl">        await crawl_page(url)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">%time asyncio.run(main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;]))
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">########## 输出 ##########
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">crawling url_1
</span></span><span class="line"><span class="cl">OK url_1
</span></span><span class="line"><span class="cl">crawling url_2
</span></span><span class="line"><span class="cl">OK url_2
</span></span><span class="line"><span class="cl">crawling url_3
</span></span><span class="line"><span class="cl">OK url_3
</span></span><span class="line"><span class="cl">crawling url_4
</span></span><span class="line"><span class="cl">OK url_4
</span></span><span class="line"><span class="cl">Wall time: 10 s
</span></span></code></pre></td></tr></table>
</div>
</div><p>看到这段代码，你应该发现了，在 Python 3.7 以上版本中，使用协程写异步程序非常简单。</p>
<p>首先来看 import asyncio，这个库包含了大部分我们实现协程所需的魔法工具。</p>
<p>async 修饰词声明异步函数，于是，这里的 crawl_page 和 main 都变成了异步函数。而调用异步函数，我们便可得到一个协程对象（coroutine object）。</p>
<p>举个例子，如果你
print(crawl_page(&rsquo;&rsquo;))
，便会输出
&lt;coroutine object crawl_page at 0x000002BEDF141148&gt;
，提示你这是一个 Python 的协程对象，而并不会真正执行这个函数。</p>
<p>再来说说协程的执行。执行协程有多种方法，这里我介绍一下常用的三种。</p>
<p>首先，我们可以通过 await 来调用。await 执行的效果，和 Python 正常执行是一样的，也就是说程序会阻塞在这里，进入被调用的协程函数，执行完毕返回后再继续，而这也是 await 的字面意思。代码中
await asyncio.sleep(sleep_time)
会在这里休息若干秒，
await crawl_page(url)
则会执行 crawl_page() 函数。</p>
<p>其次，我们可以通过 asyncio.create_task() 来创建任务，这个我们下节课会详细讲一下，你先简单知道即可。</p>
<p>最后，我们需要 asyncio.run 来触发运行。asyncio.run 这个函数是 Python 3.7 之后才有的特性，可以让 Python 的协程接口变得非常简单，你不用去理会事件循环怎么定义和怎么使用的问题（我们会在下面讲）。一个非常好的编程规范是，asyncio.run(main()) 作为主程序的入口函数，在程序运行周期内，只调用一次 asyncio.run。</p>
<p>这样，你就大概看懂了协程是怎么用的吧。不妨试着跑一下代码，欸，怎么还是 10 秒？</p>
<p>10 秒就对了，还记得上面所说的，await 是同步调用，因此， crawl_page(url) 在当前的调用结束之前，是不会触发下一次调用的。于是，这个代码效果就和上面完全一样了，相当于我们用异步接口写了个同步代码。</p>
<p>现在又该怎么办呢？</p>
<p>其实很简单，也正是我接下来要讲的协程中的一个重要概念，任务（Task）。老规矩，先看代码。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import asyncio
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def crawl_page(url):
</span></span><span class="line"><span class="cl">    print(&#39;crawling {}&#39;.format(url))
</span></span><span class="line"><span class="cl">    sleep_time = int(url.split(&#39;_&#39;)[-1])
</span></span><span class="line"><span class="cl">    await asyncio.sleep(sleep_time)
</span></span><span class="line"><span class="cl">    print(&#39;OK {}&#39;.format(url))
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def main(urls):
</span></span><span class="line"><span class="cl">    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
</span></span><span class="line"><span class="cl">    for task in tasks:
</span></span><span class="line"><span class="cl">        await task
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">%time asyncio.run(main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;]))
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">########## 输出 ##########
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">crawling url_1
</span></span><span class="line"><span class="cl">crawling url_2
</span></span><span class="line"><span class="cl">crawling url_3
</span></span><span class="line"><span class="cl">crawling url_4
</span></span><span class="line"><span class="cl">OK url_1
</span></span><span class="line"><span class="cl">OK url_2
</span></span><span class="line"><span class="cl">OK url_3
</span></span><span class="line"><span class="cl">OK url_4
</span></span><span class="line"><span class="cl">Wall time: 3.99 s
</span></span></code></pre></td></tr></table>
</div>
</div><p>你可以看到，我们有了协程对象后，便可以通过
asyncio.create_task
来创建任务。任务创建后很快就会被调度执行，这样，我们的代码也不会阻塞在任务这里。所以，我们要等所有任务都结束才行，用
for task in tasks: await task
即可。</p>
<p>这次，你就看到效果了吧，结果显示，运行总时长等于运行时间最长的爬虫。</p>
<p>当然，你也可以想一想，这里用多线程应该怎么写？而如果需要爬取的页面有上万个又该怎么办呢？再对比下协程的写法，谁更清晰自是一目了然。</p>
<p>其实，对于执行 tasks，还有另一种做法：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import asyncio
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def crawl_page(url):
</span></span><span class="line"><span class="cl">    print(&#39;crawling {}&#39;.format(url))
</span></span><span class="line"><span class="cl">    sleep_time = int(url.split(&#39;_&#39;)[-1])
</span></span><span class="line"><span class="cl">    await asyncio.sleep(sleep_time)
</span></span><span class="line"><span class="cl">    print(&#39;OK {}&#39;.format(url))
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def main(urls):
</span></span><span class="line"><span class="cl">    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
</span></span><span class="line"><span class="cl">    await asyncio.gather(*tasks)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">%time asyncio.run(main([&#39;url_1&#39;, &#39;url_2&#39;, &#39;url_3&#39;, &#39;url_4&#39;]))
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">########## 输出 ##########
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">crawling url_1
</span></span><span class="line"><span class="cl">crawling url_2
</span></span><span class="line"><span class="cl">crawling url_3
</span></span><span class="line"><span class="cl">crawling url_4
</span></span><span class="line"><span class="cl">OK url_1
</span></span><span class="line"><span class="cl">OK url_2
</span></span><span class="line"><span class="cl">OK url_3
</span></span><span class="line"><span class="cl">OK url_4
</span></span><span class="line"><span class="cl">Wall time: 4.01 s
</span></span></code></pre></td></tr></table>
</div>
</div><p>这里的代码也很好理解。唯一要注意的是，
*tasks
解包列表，将列表变成了函数的参数；与之对应的是，
** dict
将字典变成了函数的参数。</p>
<p>另外，
asyncio.create_task
，
asyncio.run
这些函数都是 Python 3.7 以上的版本才提供的，自然，相比于旧接口它们也更容易理解和阅读。</p>
<p>解密协程运行时</p>
<p>说了这么多，现在，我们不妨来深入代码底层看看。有了前面的知识做基础，你应该很容易理解这两段代码。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import asyncio
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def worker_1():
</span></span><span class="line"><span class="cl">    print(&#39;worker_1 start&#39;)
</span></span><span class="line"><span class="cl">    await asyncio.sleep(1)
</span></span><span class="line"><span class="cl">    print(&#39;worker_1 done&#39;)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def worker_2():
</span></span><span class="line"><span class="cl">    print(&#39;worker_2 start&#39;)
</span></span><span class="line"><span class="cl">    await asyncio.sleep(2)
</span></span><span class="line"><span class="cl">    print(&#39;worker_2 done&#39;)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def main():
</span></span><span class="line"><span class="cl">    print(&#39;before await&#39;)
</span></span><span class="line"><span class="cl">    await worker_1()
</span></span><span class="line"><span class="cl">    print(&#39;awaited worker_1&#39;)
</span></span><span class="line"><span class="cl">    await worker_2()
</span></span><span class="line"><span class="cl">    print(&#39;awaited worker_2&#39;)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">%time asyncio.run(main())
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">########## 输出 ##########
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">before await
</span></span><span class="line"><span class="cl">worker_1 start
</span></span><span class="line"><span class="cl">worker_1 done
</span></span><span class="line"><span class="cl">awaited worker_1
</span></span><span class="line"><span class="cl">worker_2 start
</span></span><span class="line"><span class="cl">worker_2 done
</span></span><span class="line"><span class="cl">awaited worker_2
</span></span><span class="line"><span class="cl">Wall time: 3 s
</span></span></code></pre></td></tr></table>
</div>
</div><p>import asyncio</p>
<p>async def worker_1():
    print(&lsquo;worker_1 start&rsquo;)
    await asyncio.sleep(1)
    print(&lsquo;worker_1 done&rsquo;)</p>
<p>async def worker_2():
    print(&lsquo;worker_2 start&rsquo;)
    await asyncio.sleep(2)
    print(&lsquo;worker_2 done&rsquo;)</p>
<p>async def main():
    task1 = asyncio.create_task(worker_1())
    task2 = asyncio.create_task(worker_2())
    print(&lsquo;before await&rsquo;)
    await task1
    print(&lsquo;awaited worker_1&rsquo;)
    await task2
    print(&lsquo;awaited worker_2&rsquo;)</p>
<p>%time asyncio.run(main())</p>
<p>########## 输出 ##########</p>
<p>before await
worker_1 start
worker_2 start
worker_1 done
awaited worker_1
worker_2 done
awaited worker_2
Wall time: 2.01 s</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">不过，第二个代码，到底发生了什么呢？为了让你更详细了解到协程和线程的具体区别，这里我详细地分析了整个过程。步骤有点多，别着急，我们慢慢来看。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">asyncio.run(main())
</span></span><span class="line"><span class="cl">，程序进入 main() 函数，事件循环开启；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">task1 和 task2 任务被创建，并进入事件循环等待运行；运行到 print，输出 
</span></span><span class="line"><span class="cl">&#39;before await&#39;
</span></span><span class="line"><span class="cl">；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">await task1 执行，用户选择从当前的主任务中切出，事件调度器开始调度 worker\_1；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">worker\_1 开始运行，运行 print 输出
</span></span><span class="line"><span class="cl">&#39;worker_1 start&#39;
</span></span><span class="line"><span class="cl">，然后运行到 
</span></span><span class="line"><span class="cl">await asyncio.sleep(1)
</span></span><span class="line"><span class="cl">， 从当前任务切出，事件调度器开始调度 worker\_2；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">worker\_2 开始运行，运行 print 输出 
</span></span><span class="line"><span class="cl">&#39;worker_2 start&#39;
</span></span><span class="line"><span class="cl">，然后运行 
</span></span><span class="line"><span class="cl">await asyncio.sleep(2)
</span></span><span class="line"><span class="cl"> 从当前任务切出；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">以上所有事件的运行时间，都应该在 1ms 到 10ms 之间，甚至可能更短，事件调度器从这个时候开始暂停调度；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">一秒钟后，worker\_1 的 sleep 完成，事件调度器将控制权重新传给 task\_1，输出 
</span></span><span class="line"><span class="cl">&#39;worker_1 done&#39;
</span></span><span class="line"><span class="cl">，task\_1 完成任务，从事件循环中退出；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">await task1 完成，事件调度器将控制器传给主任务，输出 
</span></span><span class="line"><span class="cl">&#39;awaited worker_1&#39;
</span></span><span class="line"><span class="cl">，·然后在 await task2 处继续等待；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">两秒钟后，worker\_2 的 sleep 完成，事件调度器将控制权重新传给 task\_2，输出 
</span></span><span class="line"><span class="cl">&#39;worker_2 done&#39;
</span></span><span class="line"><span class="cl">，task\_2 完成任务，从事件循环中退出；
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">主任务输出 
</span></span><span class="line"><span class="cl">&#39;awaited worker_2&#39;
</span></span><span class="line"><span class="cl">，协程全任务结束，事件循环结束。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">接下来，我们进阶一下。如果我们想给某些协程任务限定运行时间，一旦超时就取消，又该怎么做呢？再进一步，如果某些协程运行时出现错误，又该怎么处理呢？同样的，来看代码。
</span></span></code></pre></td></tr></table>
</div>
</div><p>import asyncio</p>
<p>async def worker_1():
    await asyncio.sleep(1)
    return 1</p>
<p>async def worker_2():
    await asyncio.sleep(2)
    return 2 / 0</p>
<p>async def worker_3():
    await asyncio.sleep(3)
    return 3</p>
<p>async def main():
    task_1 = asyncio.create_task(worker_1())
    task_2 = asyncio.create_task(worker_2())
    task_3 = asyncio.create_task(worker_3())</p>
<p>    await asyncio.sleep(2)
    task_3.cancel()</p>
<p>    res = await asyncio.gather(task_1, task_2, task_3, return_exceptions=True)
    print(res)</p>
<p>%time asyncio.run(main())</p>
<p>########## 输出 ##########</p>
<p>[1, ZeroDivisionError(&lsquo;division by zero&rsquo;), CancelledError()]
Wall time: 2 s</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">你可以看到，worker\_1 正常运行，worker\_2 运行中出现错误，worker\_3 执行时间过长被我们 cancel 掉了，这些信息会全部体现在最终的返回结果 res 中。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">不过要注意
</span></span><span class="line"><span class="cl">return_exceptions=True
</span></span><span class="line"><span class="cl">这行代码。如果不设置这个参数，错误就会完整地 throw 到我们这个执行层，从而需要 try except 来捕捉，这也就意味着其他还没被执行的任务会被全部取消掉。为了避免这个局面，我们将 return\_exceptions 设置为 True 即可。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">到这里，发现了没，线程能实现的，协程都能做到。那就让我们温习一下这些知识点，用协程来实现一个经典的生产者消费者模型吧。
</span></span></code></pre></td></tr></table>
</div>
</div><p>import asyncio
import random</p>
<p>async def consumer(queue, id):
    while True:
        val = await queue.get()
        print(&rsquo;{} get a val: {}&rsquo;.format(id, val))
        await asyncio.sleep(1)</p>
<p>async def producer(queue, id):
    for i in range(5):
        val = random.randint(1, 10)
        await queue.put(val)
        print(&rsquo;{} put a val: {}&rsquo;.format(id, val))
        await asyncio.sleep(1)</p>
<p>async def main():
    queue = asyncio.Queue()</p>
<p>    consumer_1 = asyncio.create_task(consumer(queue, &lsquo;consumer_1&rsquo;))
    consumer_2 = asyncio.create_task(consumer(queue, &lsquo;consumer_2&rsquo;))</p>
<p>    producer_1 = asyncio.create_task(producer(queue, &lsquo;producer_1&rsquo;))
    producer_2 = asyncio.create_task(producer(queue, &lsquo;producer_2&rsquo;))</p>
<p>    await asyncio.sleep(10)
    consumer_1.cancel()
    consumer_2.cancel()</p>
<p>    await asyncio.gather(consumer_1, consumer_2, producer_1, producer_2, return_exceptions=True)</p>
<p>%time asyncio.run(main())</p>
<p>########## 输出 ##########</p>
<p>producer_1 put a val: 5
producer_2 put a val: 3
consumer_1 get a val: 5
consumer_2 get a val: 3
producer_1 put a val: 1
producer_2 put a val: 3
consumer_2 get a val: 1
consumer_1 get a val: 3
producer_1 put a val: 6
producer_2 put a val: 10
consumer_1 get a val: 6
consumer_2 get a val: 10
producer_1 put a val: 4
producer_2 put a val: 5
consumer_2 get a val: 4
consumer_1 get a val: 5
producer_1 put a val: 2
producer_2 put a val: 8
consumer_1 get a val: 2
consumer_2 get a val: 8
Wall time: 10 s</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">实战：豆瓣近日推荐电影爬虫
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">最后，进入今天的实战环节——实现一个完整的协程爬虫。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">任务描述：https://movie.douban.com/cinema/later/beijing/ 这个页面描述了北京最近上映的电影，你能否通过 Python 得到这些电影的名称、上映时间和海报呢？这个页面的海报是缩小版的，我希望你能从具体的电影描述页面中抓取到海报。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">听起来难度不是很大吧？我在下面给出了同步版本的代码和协程版本的代码，通过运行时间和代码写法的对比，希望你能对协程有更深的了解。（注意：为了突出重点、简化代码，这里我省略了异常处理。）
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">不过，在参考我给出的代码之前，你是不是可以自己先动手写一下、跑一下呢？
</span></span></code></pre></td></tr></table>
</div>
</div><p>import requests
from bs4 import BeautifulSoup</p>
<p>def main():
    url = &ldquo;<a href="https://movie.douban.com/cinema/later/beijing/%22">https://movie.douban.com/cinema/later/beijing/&quot;</a>
    init_page = requests.get(url).content
    init_soup = BeautifulSoup(init_page, &rsquo;lxml&rsquo;)</p>
<p>    all_movies = init_soup.find(&lsquo;div&rsquo;, id=&ldquo;showing-soon&rdquo;)
    for each_movie in all_movies.find_all(&lsquo;div&rsquo;, class_=&ldquo;item&rdquo;):
        all_a_tag = each_movie.find_all(&lsquo;a&rsquo;)
        all_li_tag = each_movie.find_all(&rsquo;li&rsquo;)</p>
<p>        movie_name = all_a_tag[1].text
        url_to_fetch = all_a_tag[1][&lsquo;href&rsquo;]
        movie_date = all_li_tag[0].text</p>
<p>        response_item = requests.get(url_to_fetch).content
        soup_item = BeautifulSoup(response_item, &rsquo;lxml&rsquo;)
        img_tag = soup_item.find(&lsquo;img&rsquo;)</p>
<p>        print(&rsquo;{} {} {}&rsquo;.format(movie_name, movie_date, img_tag[&lsquo;src&rsquo;]))</p>
<p>%time main()</p>
<p>########## 输出 ##########</p>
<p>阿拉丁 05 月 24 日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2553992741.jpg
龙珠超：布罗利 05 月 24 日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2557371503.jpg
五月天人生无限公司 05 月 24 日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554324453.jpg
&hellip; &hellip;
直播攻略 06 月 04 日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2555957974.jpg
Wall time: 56.6 s</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import asyncio
</span></span><span class="line"><span class="cl">import aiohttp
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">from bs4 import BeautifulSoup
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def fetch_content(url):
</span></span><span class="line"><span class="cl">    async with aiohttp.ClientSession(
</span></span><span class="line"><span class="cl">        headers=header, connector=aiohttp.TCPConnector(ssl=False)
</span></span><span class="line"><span class="cl">    ) as session:
</span></span><span class="line"><span class="cl">        async with session.get(url) as response:
</span></span><span class="line"><span class="cl">            return await response.text()
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">async def main():
</span></span><span class="line"><span class="cl">    url = &#34;https://movie.douban.com/cinema/later/beijing/&#34;
</span></span><span class="line"><span class="cl">    init_page = await fetch_content(url)
</span></span><span class="line"><span class="cl">    init_soup = BeautifulSoup(init_page, &#39;lxml&#39;)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    movie_names, urls_to_fetch, movie_dates = [], [], []
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    all_movies = init_soup.find(&#39;div&#39;, id=&#34;showing-soon&#34;)
</span></span><span class="line"><span class="cl">    for each_movie in all_movies.find_all(&#39;div&#39;, class_=&#34;item&#34;):
</span></span><span class="line"><span class="cl">        all_a_tag = each_movie.find_all(&#39;a&#39;)
</span></span><span class="line"><span class="cl">        all_li_tag = each_movie.find_all(&#39;li&#39;)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        movie_names.append(all_a_tag[1].text)
</span></span><span class="line"><span class="cl">        urls_to_fetch.append(all_a_tag[1][&#39;href&#39;])
</span></span><span class="line"><span class="cl">        movie_dates.append(all_li_tag[0].text)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    tasks = [fetch_content(url) for url in urls_to_fetch]
</span></span><span class="line"><span class="cl">    pages = await asyncio.gather(*tasks)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    for movie_name, movie_date, page in zip(movie_names, movie_dates, pages):
</span></span><span class="line"><span class="cl">        soup_item = BeautifulSoup(page, &#39;lxml&#39;)
</span></span><span class="line"><span class="cl">        img_tag = soup_item.find(&#39;img&#39;)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        print(&#39;{} {} {}&#39;.format(movie_name, movie_date, img_tag[&#39;src&#39;]))
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">%time asyncio.run(main())
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">########## 输出 ##########
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">阿拉丁 05 月 24 日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2553992741.jpg
</span></span><span class="line"><span class="cl">龙珠超：布罗利 05 月 24 日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2557371503.jpg
</span></span><span class="line"><span class="cl">五月天人生无限公司 05 月 24 日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2554324453.jpg
</span></span><span class="line"><span class="cl">... ...
</span></span><span class="line"><span class="cl">直播攻略 06 月 04 日 https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2555957974.jpg
</span></span><span class="line"><span class="cl">Wall time: 4.98 s
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">```
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">总结
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">到这里，今天的主要内容就讲完了。今天我用了较长的篇幅，从一个简单的爬虫开始，到一个真正的爬虫结束，在中间穿插讲解了 Python 协程最新的基本概念和用法。这里带你简单复习一下。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">协程和多线程的区别，主要在于两点，一是协程为单线程；二是协程由用户决定，在哪些地方交出控制权，切换到下一个任务。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">协程的写法更加简洁清晰，把 async / await 语法和 create\_task 结合来用，对于中小级别的并发需求已经毫无压力。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">写协程程序的时候，你的脑海中要有清晰的事件循环概念，知道程序在什么时候需要暂停、等待 I/O，什么时候需要一并执行到底。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">最后的最后，请一定不要轻易炫技。多线程模型也一定有其优点，一个真正牛逼的程序员，应该懂得，在什么时候用什么模型能达到工程上的最优，而不是自觉某个技术非常牛逼，所有项目创造条件也要上。技术是工程，而工程则是时间、资源、人力等纷繁复杂的事情的折衷。
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">思考题
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">最后给你留一个思考题。协程怎么实现回调函数呢？欢迎留言和我讨论，也欢迎你把这篇文章分享给你的同事朋友，我们一起交流，一起进步。
</span></span></code></pre></td></tr></table>
</div>
</div>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/python%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/">Python核心技术与实战</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF/21%E7%AE%80%E5%8D%95%E5%92%8C%E7%9B%B4%E8%A7%82%E6%98%AF%E6%B0%B8%E6%81%92%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">21简单和直观是永恒的解决方案</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98/21%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A9%E5%91%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E7%9A%84%E6%95%B4%E4%BD%93%E8%84%89%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84/">
            <span class="next-text nav-default">21深度学习革命深度学习推荐模型发展的整体脉络是怎样的</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>22_瞧一瞧Linux：伙伴系统如何分配内存？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是 LMOS。
前面我们实现了 Cosmos 的内存管理组件，相信你对计算机内存管理已经有了相当深刻的认识和见解。那么，像 Linux 这样的成熟操作系统，又是怎样实现内存管理的呢？
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%9845%E8%AE%B2/22_%E7%9E%A7%E4%B8%80%E7%9E%A7linux%E4%BC%99%E4%BC%B4%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D%E5%86%85%E5%AD%98/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%9845%E8%AE%B2/22_%E7%9E%A7%E4%B8%80%E7%9E%A7linux%E4%BC%99%E4%BC%B4%E7%B3%BB%E7%BB%9F%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D%E5%86%85%E5%AD%98/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="22_瞧一瞧Linux：伙伴系统如何分配内存？">
  <meta property="og:description" content="你好，我是 LMOS。
前面我们实现了 Cosmos 的内存管理组件，相信你对计算机内存管理已经有了相当深刻的认识和见解。那么，像 Linux 这样的成熟操作系统，又是怎样实现内存管理的呢？">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="操作系统实战45讲">

  <meta itemprop="name" content="22_瞧一瞧Linux：伙伴系统如何分配内存？">
  <meta itemprop="description" content="你好，我是 LMOS。
前面我们实现了 Cosmos 的内存管理组件，相信你对计算机内存管理已经有了相当深刻的认识和见解。那么，像 Linux 这样的成熟操作系统，又是怎样实现内存管理的呢？">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="7572">
  <meta itemprop="keywords" content="操作系统实战45讲">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="22_瞧一瞧Linux：伙伴系统如何分配内存？">
  <meta name="twitter:description" content="你好，我是 LMOS。
前面我们实现了 Cosmos 的内存管理组件，相信你对计算机内存管理已经有了相当深刻的认识和见解。那么，像 Linux 这样的成熟操作系统，又是怎样实现内存管理的呢？">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">22_瞧一瞧Linux：伙伴系统如何分配内存？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 7572 字 </span>
          <span class="more-meta"> 预计阅读 16 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#伙伴系统">伙伴系统</a>
          <ul>
            <li><a href="#怎样表示一个页">怎样表示一个页</a></li>
            <li><a href="#怎样表示一个区">怎样表示一个区</a></li>
            <li><a href="#怎样表示一个内存节点">怎样表示一个内存节点</a></li>
            <li><a href="#数据结构之间的关系">数据结构之间的关系</a></li>
            <li><a href="#何为伙伴">何为伙伴</a></li>
          </ul>
        </li>
        <li><a href="#分配页面">分配页面</a>
          <ul>
            <li><a href="#通过接口找到内存节点">通过接口找到内存节点</a></li>
            <li><a href="#开始分配">开始分配</a></li>
            <li><a href="#准备分配页面的参数">准备分配页面的参数</a></li>
            <li><a href="#plan-a快速分配路径">Plan A：快速分配路径</a></li>
            <li><a href="#plan-b慢速分配路径">Plan B：慢速分配路径</a></li>
            <li><a href="#如何分配内存页面">如何分配内存页面</a></li>
          </ul>
        </li>
        <li><a href="#重点回顾">重点回顾</a></li>
        <li><a href="#思考题">思考题</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是 LMOS。</p>
<p>前面我们实现了 Cosmos 的内存管理组件，相信你对计算机内存管理已经有了相当深刻的认识和见解。那么，像 Linux 这样的成熟操作系统，又是怎样实现内存管理的呢？</p>
<p>这就要说到 Linux 系统中，用来管理物理内存页面的<strong>伙伴系统</strong>，以及负责分配比页更小的内存对象的 <strong>SLAB 分配器</strong>了。</p>
<p>我会通过两节课给你理清这两种内存管理技术，这节课我们先来说说伙伴系统，下节课再讲 SLAB。只要你紧跟我的思路，再加上前面的学习，真正理解这两种技术也并不难。</p>
<h2 id="伙伴系统">伙伴系统</h2>
<p>伙伴系统源于 Sun 公司的 Solaris 操作系统，是 Solaris 操作系统上极为优秀的物理内存页面管理算法。</p>
<p>但是，好东西总是容易被别人窃取或者效仿，伙伴系统也成了 Linux 的物理内存管理算法。由于 Linux 的开放和非赢利，这自然无可厚非，这不得不让我们想起了鲁迅《孔乙己》中的：“窃书不算偷”。</p>
<p>那 Linux 上伙伴系统算法是怎样实现的呢？我们不妨从一些重要的数据结构开始入手。</p>
<h3 id="怎样表示一个页">怎样表示一个页</h3>
<p>Linux 也是使用分页机制管理物理内存的，即 Linux 把物理内存分成 4KB 大小的页面进行管理。那 Linux 用了一个什么样的数据结构，表示一个页呢？</p>
<p>早期 Linux 使用了位图，后来使用了字节数组，但是现在 Linux 定义了一个 page 结构体来表示一个页，代码如下所示。</p>
<p>struct page {<br>
//page 结构体的标志，它决定页面是什么状态<br>
unsigned long flags;<br>
union {<br>
struct {<br>
//挂载上级结构的链表<br>
struct list_head lru;<br>
//用于文件系统，address_space 结构描述上文件占用了哪些内存页面<br>
struct address_space *mapping;<br>
pgoff_t index; <br>
unsigned long private;<br>
};<br>
//DMA 设备的地址<br>
struct {<br>
dma_addr_t dma_addr;<br>
};<br>
//当页面用于内存对象时指向相关的数据结构<br>
struct {  <br>
union {<br>
struct list_head slab_list;<br>
struct { <br>
struct page *next;<br>
#ifdef CONFIG_64BIT<br>
int pages;<br>
int pobjects;<br>
#else<br>
short int pages;<br>
short int pobjects;<br>
#endif<br>
};<br>
};<br>
//指向管理 SLAB 的结构 kmem_cache<br>
struct kmem_cache *slab_cache;<br>
//指向 SLAB 的第一个对象<br>
void *freelist;  <br>
union {<br>
void *s_mem; <br>
unsigned long counters;  <br>
struct {           <br>
unsigned inuse:16;<br>
unsigned objects:15;<br>
unsigned frozen:1;<br>
};<br>
};<br>
};<br>
//用于页表映射相关的字段<br>
struct {<br>
unsigned long _pt_pad_1;  <br>
pgtable_t pmd_huge_pte;<br>
unsigned long _pt_pad_2;<br>
union {<br>
struct mm_struct *pt_mm;<br>
atomic_t pt_frag_refcount;<br>
};<br>
//自旋锁<br>
#if ALLOC_SPLIT_PTLOCKS<br>
spinlock_t *ptl;<br>
#else<br>
spinlock_t ptl;<br>
#endif<br>
};<br>
//用于设备映射<br>
struct {<br>
struct dev_pagemap *pgmap;<br>
void *zone_device_data;<br>
};<br>
struct rcu_head rcu_head;<br>
};<br>
//页面引用计数<br>
atomic_t _refcount;</p>
<p>#ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS<br>
int _last_cpupid;<br>
#endif<br>
} _struct_page_alignment;</p>
<p>这个 page 结构看上去非常巨大，信息量很多，但其实它占用的内存很少，根据 Linux 内核配置选项不同，占用 20～40 个字节空间。page 结构大量使用了 C 语言 union 联合体定义结构字段，这个联合体的大小，要根据它里面占用内存最大的变量来决定。</p>
<p>不难猜出，使用过程中，page 结构正是<strong>通过 flags</strong> 表示它处于哪种状态，根据不同的状态来使用 union 联合体的变量表示的数据信息。如果 page 处于空闲状态，它就会使用 union 联合体中的 lru 字段，挂载到对应空闲链表中。</p>
<p>一“页”障目，不见泰山，这里我们不需要了解 page 结构的所有细节，我们只需要知道 <strong>Linux 内核中，一个 page 结构表示一个物理内存页面就行了。</strong></p>
<h3 id="怎样表示一个区">怎样表示一个区</h3>
<p>Linux 内核中也有区的逻辑概念，因为硬件的限制，Linux 内核不能对所有的物理内存页统一对待，所以就把属性相同物理内存页面，归结到了一个区中。</p>
<p>不同硬件平台，区的划分也不一样。比如在 32 位的 x86 平台中，一些使用 DMA 的设备只能访问 0~16MB 的物理空间，因此将 0~16MB 划分为 DMA 区。</p>
<p>高内存区则适用于要访问的物理地址空间大于虚拟地址空间，Linux 内核不能建立直接映射的情况。除开这两个内存区，物理内存中剩余的页面就划分到常规内存区了。有的平台没有 DMA 区，64 位的 x86 平台则没有高内存区。</p>
<p>在 Linux 里可以查看自己机器上的内存区，指令如下图所示。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%9845%E8%AE%B2/5ccea32e3efbaed48bfc32c5e92560f8.png" alt=""></p>
<p>PS：在我的系统上还有防止内存碎片化的 MOVABLE 区和支持设备热插拔的 DEVICE 区</p>
<p>Linux 内核用 zone 数据结构表示一个区，代码如下所示。</p>
<p>enum migratetype {<br>
MIGRATE_UNMOVABLE, //不能移动的<br>
MIGRATE_MOVABLE,   //可移动和<br>
MIGRATE_RECLAIMABLE,<br>
MIGRATE_PCPTYPES,  //属于 pcp list 的<br>
MIGRATE_HIGHATOMIC = MIGRATE_PCPTYPES,<br>
#ifdef CONFIG_CMA<br>
MIGRATE_CMA,   //属于 CMA 区的<br>
#endif<br>
#ifdef CONFIG_MEMORY_ISOLATION<br>
MIGRATE_ISOLATE,  <br>
#endif<br>
MIGRATE_TYPES<br>
};<br>
//页面空闲链表头<br>
struct free_area {<br>
struct list_head    free_list[MIGRATE_TYPES];<br>
unsigned long       nr_free;<br>
};</p>
<p>struct zone {<br>
unsigned long _watermark[NR_WMARK];<br>
unsigned long watermark_boost;<br>
//预留的内存页面数<br>
unsigned long nr_reserved_highatomic;<br>
//内存区属于哪个内存节点<br>
#ifdef CONFIG_NUMA<br>
int node;<br>
#endif<br>
struct pglist_data  *zone_pgdat;<br>
//内存区开始的 page 结构数组的开始下标<br>
unsigned long       zone_start_pfn;</p>
<pre><code>atomic_long_t       managed_pages;  
//内存区总的页面数  
unsigned long       spanned_pages;  
//内存区存在的页面数  
unsigned long       present_pages;  
//内存区名字  
const char      *name;  
//挂载页面 page 结构的链表  
struct free_area    free_area[MAX_ORDER];  
//内存区的标志  
unsigned long       flags;  
/*保护 free_area 的自旋锁*/  
spinlock_t      lock;  
</code></pre>
<p>};</p>
<p>为了节约你的时间，我只列出了需要我们关注的字段。其中 _watermark 表示内存页面总量的水位线有 min, low, high 三种状态，可以作为启动内存页面回收的判断标准。spanned_pages 是该内存区总的页面数。</p>
<p>为什么要有个 present_pages 字段表示页面真正存在呢？那是因为一些内存区中存在内存空洞，空洞对应的 page 结构不能用。你可以做个对比，我们的 Cosmos 不会对内存空洞建立 msadsc_t，避免浪费内存。</p>
<p>在 zone 结构中我们真正要关注的是 <strong>free_area 结构的数组</strong>，这个数组就是用于实现伙伴系统的。其中 MAX_ORDER 的值默认为 11，分别表示挂载地址连续的 page 结构数目为 1，2，4，8，16，32……最大为 1024。</p>
<p>而 free_area 结构中又是一个 list_head 链表数组，该数组将具有相同迁移类型的 page 结构尽可能地分组，有的页面可以迁移，有的不可以迁移，同一类型的所有相同 order 的 page 结构，就构成了一组 page 结构块。</p>
<p>分配的时候，会先按请求的 migratetype 从对应的 page 结构块中寻找，如果不成功，才会从其他 migratetype 的 page 结构块中分配。这样做是为了<strong>让内存页迁移更加高效，可以有效降低内存碎片。</strong></p>
<p>zone 结构中还有一个指针，指向 pglist_data 结构，这个结构也很重要，下面我们一起去研究它。</p>
<h3 id="怎样表示一个内存节点">怎样表示一个内存节点</h3>
<p>在了解 Linux 内存节点数据结构之前，我们先要了解 <strong>NUMA</strong>。</p>
<p>在很多服务器和大型计算机上，如果物理内存是分布式的，由多个计算节点组成，那么每个 CPU 核都会有自己的本地内存，CPU 在访问它的本地内存的时候就比较快，访问其他 CPU 核内存的时候就比较慢，这种体系结构被称为 Non-Uniform Memory Access（NUMA）。</p>
<p>逻辑如下图所示。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%9845%E8%AE%B2/eae95a7c5fd5f2802508cfbf595ef039.png" alt=""></p>
<p>NUMA 架构</p>
<p>Linux 对 NUMA 进行了抽象，它可以将一整块连续物理内存的划分成几个内存节点，也可以把不是连续的物理内存当成真正的 NUMA。</p>
<p>那么 Linux 使用什么数据结构表示一个内存节点呢？请看代码，如下所示。</p>
<p>enum {<br>
ZONELIST_FALLBACK,<br>
#ifdef CONFIG_NUMA<br>
ZONELIST_NOFALLBACK,<br>
#endif<br>
MAX_ZONELISTS<br>
};<br>
struct zoneref {<br>
struct zone *zone;//内存区指针<br>
int zone_idx;     //内存区对应的索引<br>
};<br>
struct zonelist {<br>
struct zoneref _zonerefs[MAX_ZONES_PER_ZONELIST + 1];<br>
};<br>
//zone 枚举类型 从 0 开始<br>
enum zone_type {<br>
#ifdef CONFIG_ZONE_DMA<br>
ZONE_DMA,<br>
#endif<br>
#ifdef CONFIG_ZONE_DMA32<br>
ZONE_DMA32,<br>
#endif<br>
ZONE_NORMAL,<br>
#ifdef CONFIG_HIGHMEM<br>
ZONE_HIGHMEM,<br>
#endif<br>
ZONE_MOVABLE,<br>
#ifdef CONFIG_ZONE_DEVICE<br>
ZONE_DEVICE,<br>
#endif<br>
__MAX_NR_ZONES</p>
<p>};<br>
//定义 MAX_NR_ZONES 为__MAX_NR_ZONES 最大为 6<br>
DEFINE(MAX_NR_ZONES, __MAX_NR_ZONES);<br>
//内存节点<br>
typedef struct pglist_data {<br>
//定一个内存区数组，最大为 6 个 zone 元素<br>
struct zone node_zones[MAX_NR_ZONES];<br>
//两个 zonelist，一个是指向本节点的的内存区，另一个指向由本节点分配不到内存时可选的备用内存区。<br>
struct zonelist node_zonelists[MAX_ZONELISTS];<br>
//本节点有多少个内存区<br>
int nr_zones;<br>
//本节点开始的 page 索引号<br>
unsigned long node_start_pfn;<br>
//本节点有多少个可用的页面<br>
unsigned long node_present_pages;<br>
//本节点有多少个可用的页面包含内存空洞<br>
unsigned long node_spanned_pages;<br>
//节点 id<br>
int node_id;<br>
//交换内存页面相关的字段<br>
wait_queue_head_t kswapd_wait;<br>
wait_queue_head_t pfmemalloc_wait;<br>
struct task_struct *kswapd;<br>
//本节点保留的内存页面<br>
unsigned long       totalreserve_pages;<br>
//自旋锁<br>
spinlock_t      lru_lock;<br>
} pg_data_t;</p>
<p>可以发现，pglist_data 结构中包含了 zonelist 数组。第一个 zonelist 类型的元素指向本节点内的 zone 数组，第二个 zonelist 类型的元素指向其它节点的 zone 数组，而一个 zone 结构中的 free_area 数组中又挂载着 page 结构。</p>
<p>这样在本节点中分配不到内存页面的时候，就会到其它节点中分配内存页面。当计算机不是 NUMA 时，这时 Linux 就只创建一个节点。</p>
<h3 id="数据结构之间的关系">数据结构之间的关系</h3>
<p>现在，我们已经了解了 pglist_data、zonelist、zone、page 这些数据结构的核心内容。</p>
<p>有了这些必要的知识积累，我再带你从宏观上梳理一下这些结构的关系，只有搞清楚了它们之间的关系，你才能清楚伙伴系统的核心算法的实现。</p>
<p>根据前面的描述，我们来画张图就清晰了。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%9845%E8%AE%B2/5302bcb26cdf2b5c06ba0c5fd56fcce5.png" alt=""></p>
<p>Linux 内存数据结构关系</p>
<p>我相信你看了这张图，再结合上节课 Cosmos 的物理内存管理器的内容，Linux 的伙伴系统算法，你就已经心中有数了。下面，我们去看看何为伙伴。</p>
<h3 id="何为伙伴">何为伙伴</h3>
<p>我们一直在说伙伴系统，但是我们还不清楚何为伙伴？</p>
<p>在我们现实世界中，伙伴就是好朋友，而在 Linux 物理内存页面管理中，连续且相同大小的 pages 就可以表示成伙伴。</p>
<p>比如，第 0 个 page 和第 1 个 page 是伙伴，但是和第 2 个 page 不是伙伴，第 2 个 page 和第 3 个 page 是伙伴。同时，第 0 个 page 和第 1 个 page 连续起来作为一个整体 pages，这和第 2 个 page 和第 3 个 page 连续起来作为一个整体 pages，它们又是伙伴，依次类推。</p>
<p>我们还是来画幅图吧，如下所示。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%9845%E8%AE%B2/0d7bd60d9b7076d7ab29194000325d83.png" alt=""></p>
<p>伙伴系统示意图</p>
<p>上图中，首先最小的 page（0,1）是伙伴，page（2,3）是伙伴，page（4,5）是伙伴，page（6,7）是伙伴，然后 A 与 B 是伙伴，C 与 D 是伙伴，最后 E 与 F 是伙伴。有了图解，你是不是瞬间明白伙伴系统的伙伴了呢？</p>
<h2 id="分配页面">分配页面</h2>
<p>下面，我们开始研究 Linux 下怎样分配物理内存页面，看过前面的数据结构和它们之间的关系，分配物理内存页面的过程很好推理：<strong>首先要找到内存节点，接着找到内存区，然后合适的空闲链表，最后在其中找到页的 page 结构，完成物理内存页面的分配。</strong></p>
<h3 id="通过接口找到内存节点">通过接口找到内存节点</h3>
<p>我们先来了解一下分配内存页面的接口，我用一幅图来表示接口以及它们调用关系。我相信图解是理解接口函数的最佳方式，如下所示。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%9845%E8%AE%B2/e14e8358f3401a33cb0b734b5ebc7b00.png" alt=""></p>
<p>分配内存页面接口</p>
<p>上图中，虚线框中为接口函数，下面则是分配内存页面的核心实现，所有的接口函数都会调用到 alloc_pages 函数，而这个函数最终会调用 __alloc_pages_nodemask 函数完成内存页面的分配。</p>
<p>下面我们来看看 alloc_pages 函数的形式，代码如下。</p>
<p>struct page *alloc_pages_current(gfp_t gfp, unsigned order)<br>
{<br>
struct mempolicy *pol = &amp;default_policy;<br>
struct page *page;<br>
if (!in_interrupt() &amp;&amp; !(gfp &amp; __GFP_THISNODE))<br>
pol = get_task_policy(current);<br>
if (pol-&gt;mode == MPOL_INTERLEAVE)<br>
page = alloc_page_interleave(gfp, order, interleave_nodes(pol));<br>
else<br>
page = __alloc_pages_nodemask(gfp, order,<br>
policy_node(gfp, pol, numa_node_id()),<br>
policy_nodemask(gfp, pol));</p>
<pre><code>return page;  
</code></pre>
<p>}</p>
<p>static inline struct page * alloc_pages(gfp_t gfp_mask, unsigned int order)<br>
{<br>
return alloc_pages_current(gfp_mask, order);<br>
}</p>
<p>我们这里不需要关注 alloc_pages_current 函数的其它细节，<strong>只要知道它最终要调用 __alloc_pages_nodemask 函数</strong>，而且我们还要搞清楚它的参数，order 很好理解，它表示请求分配 2 的 order 次方个页面，<strong>重点是 gfp_t 类型的 gfp_mask</strong>。</p>
<p>gfp_mask 的类型和取值如下所示。</p>
<p>typedef unsigned int __bitwise gfp_t;<br>
#define ___GFP_DMA      0x01u<br>
#define ___GFP_HIGHMEM      0x02u<br>
#define ___GFP_DMA32        0x04u<br>
#define ___GFP_MOVABLE      0x08u<br>
#define ___GFP_RECLAIMABLE  0x10u<br>
#define ___GFP_HIGH     0x20u<br>
#define ___GFP_IO       0x40u<br>
#define ___GFP_FS       0x80u<br>
#define ___GFP_ZERO     0x100u<br>
#define ___GFP_ATOMIC       0x200u<br>
#define ___GFP_DIRECT_RECLAIM   0x400u<br>
#define ___GFP_KSWAPD_RECLAIM   0x800u<br>
#define ___GFP_WRITE        0x1000u<br>
#define ___GFP_NOWARN       0x2000u<br>
#define ___GFP_RETRY_MAYFAIL    0x4000u<br>
#define ___GFP_NOFAIL       0x8000u<br>
#define ___GFP_NORETRY      0x10000u<br>
#define ___GFP_MEMALLOC     0x20000u<br>
#define ___GFP_COMP     0x40000u<br>
#define ___GFP_NOMEMALLOC   0x80000u<br>
#define ___GFP_HARDWALL     0x100000u<br>
#define ___GFP_THISNODE     0x200000u<br>
#define ___GFP_ACCOUNT      0x400000u<br>
//需要原子分配内存不得让请求者进入睡眠<br>
#define GFP_ATOMIC  (__GFP_HIGH|__GFP_ATOMIC|__GFP_KSWAPD_RECLAIM)<br>
//分配用于内核自己使用的内存，可以有 IO 和文件系统相关的操作<br>
#define GFP_KERNEL  (__GFP_RECLAIM | __GFP_IO | __GFP_FS)<br>
#define GFP_KERNEL_ACCOUNT (GFP_KERNEL | __GFP_ACCOUNT)<br>
//分配内存不能睡眠，不能有 I/O 和文件系统相关的操作<br>
#define GFP_NOWAIT  (__GFP_KSWAPD_RECLAIM)<br>
#define GFP_NOIO    (__GFP_RECLAIM)<br>
#define GFP_NOFS    (__GFP_RECLAIM | __GFP_IO)<br>
//分配用于用户进程的内存<br>
#define GFP_USER    (__GFP_RECLAIM | __GFP_IO | __GFP_FS | __GFP_HARDWALL)<br>
//用于 DMA 设备的内存<br>
#define GFP_DMA     __GFP_DMA<br>
#define GFP_DMA32   __GFP_DMA32<br>
//把高端内存区的内存分配给用户进程<br>
#define GFP_HIGHUSER    (GFP_USER | __GFP_HIGHMEM)<br>
#define GFP_HIGHUSER_MOVABLE    (GFP_HIGHUSER | __GFP_MOVABLE)<br>
#define GFP_TRANSHUGE_LIGHT ((GFP_HIGHUSER_MOVABLE | __GFP_COMP | __GFP_NOMEMALLOC | __GFP_NOWARN) &amp; ~__GFP_RECLAIM)<br>
#define GFP_TRANSHUGE   (GFP_TRANSHUGE_LIGHT | __GFP_DIRECT_RECLAIM)</p>
<p>不难发现，gfp_t 类型就是 int 类型，用其中位的状态表示请求分配不同的内存区的内存页面，以及分配内存页面的不同方式。</p>
<h3 id="开始分配">开始分配</h3>
<p>前面我们已经搞清楚了，内存页面分配接口的参数。下面我们进入分配内存页面的主要函数，这个 <strong>__alloc_pages_nodemask 函数</strong>主要干了三件事。</p>
<p>1. 准备分配页面的参数；</p>
<p>2. 进入快速分配路径；</p>
<p>3. 若快速分配路径没有分配到页面，就进入慢速分配路径。</p>
<p>让我们来看看它的代码实现。</p>
<p>struct page *__alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, int preferred_nid,  nodemask_t *nodemask)<br>
{<br>
struct page *page;<br>
unsigned int alloc_flags = ALLOC_WMARK_LOW;<br>
gfp_t alloc_mask;<br>
struct alloc_context ac = { };<br>
//分配页面的 order 大于等于最大的 order 直接返回 NULL<br>
if (unlikely(order &gt;= MAX_ORDER)) {<br>
WARN_ON_ONCE(!(gfp_mask &amp; __GFP_NOWARN));<br>
return NULL;<br>
}<br>
gfp_mask &amp;= gfp_allowed_mask;<br>
alloc_mask = gfp_mask;<br>
//准备分配页面的参数放在 ac 变量中<br>
if (!prepare_alloc_pages(gfp_mask, order, preferred_nid, nodemask, &amp;ac, &amp;alloc_mask, &amp;alloc_flags))<br>
return NULL;<br>
alloc_flags |= alloc_flags_nofragment(ac.preferred_zoneref-&gt;zone, gfp_mask);<br>
//进入快速分配路径<br>
page = get_page_from_freelist(alloc_mask, order, alloc_flags, &amp;ac);<br>
if (likely(page))<br>
goto out;<br>
alloc_mask = current_gfp_context(gfp_mask);<br>
ac.spread_dirty_pages = false;<br>
ac.nodemask = nodemask;<br>
//进入慢速分配路径<br>
page = __alloc_pages_slowpath(alloc_mask, order, &amp;ac);<br>
out:<br>
return page;<br>
}</p>
<h3 id="准备分配页面的参数">准备分配页面的参数</h3>
<p>我想你在 __alloc_pages_nodemask 函数中，一定看到了一个变量 ac 是 alloc_context 类型的，顾名思义，分配参数就保存在了 ac 这个分配上下文的变量中。</p>
<p>prepare_alloc_pages 函数根据传递进来的参数，还会对 ac 变量做进一步处理，代码如下。</p>
<p>struct alloc_context {<br>
struct zonelist *zonelist;<br>
nodemask_t *nodemask;<br>
struct zoneref *preferred_zoneref;<br>
int migratetype;<br>
enum zone_type highest_zoneidx;<br>
bool spread_dirty_pages;<br>
};</p>
<p>static inline bool prepare_alloc_pages(gfp_t gfp_mask, unsigned int order,<br>
int preferred_nid, nodemask_t *nodemask,<br>
struct alloc_context *ac, gfp_t *alloc_mask,<br>
unsigned int *alloc_flags)<br>
{<br>
//从哪个内存区分配内存<br>
ac-&gt;highest_zoneidx = gfp_zone(gfp_mask);<br>
//根据节点 id 计算出 zone 的指针<br>
ac-&gt;zonelist = node_zonelist(preferred_nid, gfp_mask);<br>
ac-&gt;nodemask = nodemask;<br>
//计算出 free_area 中的 migratetype 值，比如如分配的掩码为 GFP_KERNEL，那么其类型为 MIGRATE_UNMOVABLE；<br>
ac-&gt;migratetype = gfp_migratetype(gfp_mask);<br>
//处理 CMA 相关的分配选项<br>
*alloc_flags = current_alloc_flags(gfp_mask, *alloc_flags);<br>
ac-&gt;spread_dirty_pages = (gfp_mask &amp; __GFP_WRITE);<br>
//搜索 nodemask 表示的节点中可用的 zone 保存在 preferred_zoneref<br>
ac-&gt;preferred_zoneref = first_zones_zonelist(ac-&gt;zonelist,<br>
ac-&gt;highest_zoneidx, ac-&gt;nodemask);<br>
return true;<br>
}</p>
<p>可以看到，prepare_alloc_pages 函数根据传递进入的参数，就能找出要分配内存区、候选内存区以及内存区中空闲链表的 migratetype 类型。它把这些全部收集到 ac 结构中，只要它返回 true，就说明分配内存页面的参数已经准备好了。</p>
<h3 id="plan-a快速分配路径">Plan A：快速分配路径</h3>
<p>为了优化内存页面的分配性能，在一定情况下可以进入快速分配路径，请注意**快速分配路径不会处理内存页面合并和回收。**我们一起来看看代码，如下所示。</p>
<p>static struct page *<br>
get_page_from_freelist(gfp_t gfp_mask, unsigned int order, int alloc_flags,<br>
const struct alloc_context *ac)<br>
{<br>
struct zoneref *z;<br>
struct zone *zone;<br>
struct pglist_data *last_pgdat_dirty_limit = NULL;<br>
bool no_fallback;<br>
retry:<br>
no_fallback = alloc_flags &amp; ALLOC_NOFRAGMENT;<br>
z = ac-&gt;preferred_zoneref;<br>
//遍历 ac-&gt;preferred_zoneref 中每个内存区<br>
for_next_zone_zonelist_nodemask(zone, z, ac-&gt;highest_zoneidx,<br>
ac-&gt;nodemask) {<br>
struct page *page;<br>
unsigned long mark;<br>
//查看内存水位线<br>
mark = wmark_pages(zone, alloc_flags &amp; ALLOC_WMARK_MASK);<br>
//检查内存区中空闲内存是否在水印之上<br>
if (!zone_watermark_fast(zone, order, mark,<br>
ac-&gt;highest_zoneidx, alloc_flags,<br>
gfp_mask)) {<br>
int ret;<br>
//当前内存区的内存结点需要做内存回收吗<br>
ret = node_reclaim(zone-&gt;zone_pgdat, gfp_mask, order);<br>
switch (ret) {<br>
//快速分配路径不处理页面回收的问题<br>
case NODE_RECLAIM_NOSCAN:<br>
continue;<br>
case NODE_RECLAIM_FULL:<br>
continue;<br>
default:<br>
//根据分配的 order 数量判断内存区的水位线是否满足要求<br>
if (zone_watermark_ok(zone, order, mark,<br>
ac-&gt;highest_zoneidx, alloc_flags))<br>
//如果可以可就从这个内存区开始分配<br>
goto try_this_zone;<br>
continue;<br>
}<br>
}</p>
<p>try_this_zone:<br>
//真正分配内存页面<br>
page = rmqueue(ac-&gt;preferred_zoneref-&gt;zone, zone, order,<br>
gfp_mask, alloc_flags, ac-&gt;migratetype);<br>
if (page) {<br>
//清除一些标志或者设置联合页等等<br>
prep_new_page(page, order, gfp_mask, alloc_flags);<br>
return page;<br>
}<br>
}<br>
if (no_fallback) {<br>
alloc_flags &amp;= ~ALLOC_NOFRAGMENT;<br>
goto retry;<br>
}<br>
return NULL;<br>
}</p>
<p>上述这段代码中，我删除了一部分非核心代码，如果你有兴趣深入了解请看这里。这个函数的逻辑就是<strong>遍历所有的候选内存区，然后针对每个内存区检查水位线，是不是执行内存回收机制，当一切检查通过之后，就开始调用 rmqueue 函数执行内存页面分配。</strong></p>
<h3 id="plan-b慢速分配路径">Plan B：慢速分配路径</h3>
<p>当快速分配路径没有分配到页面的时候，就会进入慢速分配路径。跟快速路径相比，慢速路径最主要的不同是它会<strong>执行页面回收</strong>，回收页面之后会进行多次重复分配，直到最后分配到内存页面，或者分配失败，具体代码如下。</p>
<p>static inline struct page *<br>
__alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,<br>
struct alloc_context *ac)<br>
{<br>
bool can_direct_reclaim = gfp_mask &amp; __GFP_DIRECT_RECLAIM;<br>
const bool costly_order = order &gt; PAGE_ALLOC_COSTLY_ORDER;<br>
struct page *page = NULL;<br>
unsigned int alloc_flags;<br>
unsigned long did_some_progress;<br>
enum compact_priority compact_priority;<br>
enum compact_result compact_result;<br>
int compaction_retries;<br>
int no_progress_loops;<br>
unsigned int cpuset_mems_cookie;<br>
int reserve_flags;</p>
<p>retry:<br>
//唤醒所有交换内存的线程<br>
if (alloc_flags &amp; ALLOC_KSWAPD)<br>
wake_all_kswapds(order, gfp_mask, ac);<br>
//依然调用快速分配路径入口函数尝试分配内存页面<br>
page = get_page_from_freelist(gfp_mask, order, alloc_flags, ac);<br>
if (page)<br>
goto got_pg;</p>
<pre><code>//尝试直接回收内存并且再分配内存页面      
page = __alloc_pages_direct_reclaim(gfp_mask, order, alloc_flags, ac,  
                        &amp;did_some_progress);  
if (page)  
    goto got_pg;  

//尝试直接压缩内存并且再分配内存页面  
page = __alloc_pages_direct_compact(gfp_mask, order, alloc_flags, ac,  
                compact_priority, &amp;compact_result);  
if (page)  
    goto got_pg;  
//检查对于给定的分配请求，重试回收是否有意义  
if (should_reclaim_retry(gfp_mask, order, ac, alloc_flags,  
             did_some_progress &gt; 0, &amp;no_progress_loops))  
    goto retry;  
//检查对于给定的分配请求，重试压缩是否有意义  
if (did_some_progress &gt; 0 &amp;&amp;  
        should_compact_retry(ac, order, alloc_flags,  
            compact_result, &amp;compact_priority,  
            &amp;compaction_retries))  
    goto retry;  
//回收、压缩内存已经失败了，开始尝试杀死进程，回收内存页面   
page = __alloc_pages_may_oom(gfp_mask, order, ac, &amp;did_some_progress);  
if (page)  
    goto got_pg;  
</code></pre>
<p>got_pg:<br>
return page;<br>
}</p>
<p>上述代码中，依然会调用快速分配路径入口函数进行分配，不过到这里大概率会分配失败，如果能成功分配，也就不会进入到 __alloc_pages_slowpath 函数中。</p>
<p>__alloc_pages_slowpath 函数一开始会唤醒所有用于内存交换回收的线程 get_page_from_freelist 函数分配失败了就会进行内存回收，内存回收主要是释放一些文件占用的内存页面。如果内存回收不行，就会就进入到内存压缩环节。</p>
<p>这里有一个常见的误区你要留意，<strong>内存压缩不是指压缩内存中的数据，而是指移动内存页面，进行内存碎片整理</strong>，**腾出更大的连续的内存空间。**如果内存碎片整理了，还是不能成功分配内存，就要杀死进程以便释放更多内存页面了。</p>
<p>因为回收内存的机制不是重点，我们主要关注的是伙伴系统的实现，这里你只要明白它们工作流程就好了。</p>
<h3 id="如何分配内存页面">如何分配内存页面</h3>
<p>无论快速分配路径还是慢速分配路径，最终执行内存页面分配动作的始终是 get_page_from_freelist 函数，更准确地说，实际完成分配任务的是 <strong>rmqueue 函数</strong>。</p>
<p>我们弄懂了这个函数，才能真正搞清楚伙伴系统的核心原理，后面这段是它的代码。</p>
<p>static inline struct page *rmqueue(struct zone *preferred_zone,<br>
struct zone *zone, unsigned int order,<br>
gfp_t gfp_flags, unsigned int alloc_flags,<br>
int migratetype)<br>
{<br>
unsigned long flags;<br>
struct page *page;<br>
if (likely(order == 0)) {<br>
if (!IS_ENABLED(CONFIG_CMA) || alloc_flags &amp; ALLOC_CMA ||<br>
migratetype != MIGRATE_MOVABLE) {<br>
//如果 order 等于 0，就说明是分配一个页面，说就从 pcplist 中分配<br>
page = rmqueue_pcplist(preferred_zone, zone, gfp_flags,<br>
migratetype, alloc_flags);<br>
goto out;<br>
}<br>
}<br>
//加锁并关中断<br>
spin_lock_irqsave(&amp;zone-&gt;lock, flags);<br>
do {<br>
page = NULL;<br>
if (order &gt; 0 &amp;&amp; alloc_flags &amp; ALLOC_HARDER) {<br>
//从 free_area 中分配<br>
page = __rmqueue_smallest(zone, order, MIGRATE_HIGHATOMIC);<br>
}<br>
if (!page)<br>
//它最后也是调用__rmqueue_smallest 函数<br>
page = __rmqueue(zone, order, migratetype, alloc_flags);<br>
} while (page &amp;&amp; check_new_pages(page, order));<br>
spin_unlock(&amp;zone-&gt;lock);<br>
zone_statistics(preferred_zone, zone);<br>
local_irq_restore(flags);<br>
out:<br>
return page;<br>
}</p>
<p>这段代码中，我们只需要关注两个函数 rmqueue_pcplist 和 __rmqueue_smallest，这是分配内存页面的核心函数。</p>
<p>先来看看 rmqueue_pcplist 函数，在请求分配一个页面的时候，就是用它从 pcplist 中分配页面的。所谓的 pcp 是指，每个 CPU 都有一个内存页面高速缓冲，由数据结构 per_cpu_pageset 描述，包含在内存区中。</p>
<p>在 Linux 内核中，系统会经常请求和释放单个页面。如果针对每个 CPU，都建立出预先分配了单个内存页面的链表，用于满足本地 CPU 发出的单一内存请求，就能提升系统的性能，代码如下所示。</p>
<p>struct per_cpu_pages {<br>
int count;      //列表中的页面数<br>
int high;       //页面数高于水位线，需要清空<br>
int batch;      //从伙伴系统增加/删除的块数<br>
//页面列表，每个迁移类型一个。<br>
struct list_head lists[MIGRATE_PCPTYPES];<br>
};<br>
struct per_cpu_pageset {<br>
struct per_cpu_pages pcp;<br>
#ifdef CONFIG_NUMA<br>
s8 expire;<br>
u16 vm_numa_stat_diff[NR_VM_NUMA_STAT_ITEMS];<br>
#endif<br>
#ifdef CONFIG_SMP<br>
s8 stat_threshold;<br>
s8 vm_stat_diff[NR_VM_ZONE_STAT_ITEMS];<br>
#endif<br>
};<br>
static struct page *__rmqueue_pcplist(struct zone *zone, int migratetype,unsigned int alloc_flags,struct per_cpu_pages *pcp,<br>
struct list_head *list)<br>
{<br>
struct page *page;<br>
do {<br>
if (list_empty(list)) {<br>
//如果 list 为空，就从这个内存区中分配一部分页面到 pcp 中来<br>
pcp-&gt;count += rmqueue_bulk(zone, 0,<br>
pcp-&gt;batch, list,<br>
migratetype, alloc_flags);<br>
if (unlikely(list_empty(list)))<br>
return NULL;<br>
}<br>
//获取 list 上第一个 page 结构<br>
page = list_first_entry(list, struct page, lru);<br>
//脱链<br>
list_del(&amp;page-&gt;lru);<br>
//减少 pcp 页面计数<br>
pcp-&gt;count&ndash;;<br>
} while (check_new_pcp(page));<br>
return page;<br>
}<br>
static struct page *rmqueue_pcplist(struct zone *preferred_zone,<br>
struct zone *zone, gfp_t gfp_flags,int migratetype, unsigned int alloc_flags)<br>
{<br>
struct per_cpu_pages *pcp;<br>
struct list_head *list;<br>
struct page *page;<br>
unsigned long flags;<br>
//关中断<br>
local_irq_save(flags);<br>
//获取当前 CPU 下的 pcp<br>
pcp = &amp;this_cpu_ptr(zone-&gt;pageset)-&gt;pcp;<br>
//获取 pcp 下迁移的 list 链表<br>
list = &amp;pcp-&gt;lists[migratetype];<br>
//摘取 list 上的 page 结构<br>
page = __rmqueue_pcplist(zone,  migratetype, alloc_flags, pcp, list);<br>
//开中断<br>
local_irq_restore(flags);<br>
return page;<br>
}</p>
<p>上述代码的注释已经很清楚了，它主要是优化了请求分配单个内存页面的性能。但是遇到多个内存页面的分配请求，就会调用 __rmqueue_smallest 函数，从 free_area 数组中分配。</p>
<p>我们一起来看看 __rmqueue_smallest 函数的代码。</p>
<p>static inline struct page *get_page_from_free_area(struct free_area *area,int migratetype)<br>
{//返回 free_list[migratetype] 中的第一个 page 若没有就返回 NULL<br>
return list_first_entry_or_null(&amp;area-&gt;free_list[migratetype],<br>
struct page, lru);<br>
}<br>
static inline void del_page_from_free_list(struct page *page, struct zone *zone,unsigned int order)<br>
{<br>
if (page_reported(page))<br>
__ClearPageReported(page);<br>
//脱链<br>
list_del(&amp;page-&gt;lru);<br>
//清除 page 中伙伴系统的标志<br>
__ClearPageBuddy(page);<br>
set_page_private(page, 0);<br>
//减少 free_area 中页面计数<br>
zone-&gt;free_area[order].nr_free&ndash;;<br>
}</p>
<p>static inline void add_to_free_list(struct page *page, struct zone *zone,<br>
unsigned int order, int migratetype)<br>
{<br>
struct free_area *area = &amp;zone-&gt;free_area[order];<br>
//把一组 page 的首个 page 加入对应的 free_area 中<br>
list_add(&amp;page-&gt;lru, &amp;area-&gt;free_list[migratetype]);<br>
area-&gt;nr_free++;<br>
}<br>
//分割一组页<br>
static inline void expand(struct zone *zone, struct page *page,<br>
int low, int high, int migratetype)<br>
{<br>
//最高 order 下连续的 page 数 比如 high = 3 size=8<br>
unsigned long size = 1 &laquo; high;<br>
while (high &gt; low) {<br>
high&ndash;;<br>
size &raquo;= 1;//每次循环左移一位 4,2,1<br>
//标记为保护页，当其伙伴被释放时，允许合并<br>
if (set_page_guard(zone, &amp;page[size], high, migratetype))<br>
continue;<br>
//把另一半 pages 加入对应的 free_area 中<br>
add_to_free_list(&amp;page[size], zone, high, migratetype);<br>
//设置伙伴<br>
set_buddy_order(&amp;page[size], high);<br>
}<br>
}</p>
<p>static __always_inline struct page *__rmqueue_smallest(struct zone *zone, unsigned int order,int migratetype)<br>
{<br>
unsigned int current_order;<br>
struct free_area *area;<br>
struct page *page;<br>
for (current_order = order; current_order &lt; MAX_ORDER; ++current_order) {<br>
//获取 current_order 对应的 free_area<br>
area = &amp;(zone-&gt;free_area[current_order]);<br>
//获取 free_area 中对应 migratetype 为下标的 free_list 中的 page<br>
page = get_page_from_free_area(area, migratetype);<br>
if (!page)<br>
continue;<br>
//脱链 page<br>
del_page_from_free_list(page, zone, current_order);<br>
//分割伙伴<br>
expand(zone, page, order, current_order, migratetype);<br>
set_pcppage_migratetype(page, migratetype);<br>
return page;<br>
}<br>
return NULL;<br>
}</p>
<p>可以看到，在 __rmqueue_smallest 函数中，首先要取得 current_order 对应的 free_area 区中 page，若没有，就继续增加 current_order，直到最大的 MAX_ORDER。要是得到一组连续 page 的首地址，就对其脱链，然后调用 expand 函数分割伙伴。</p>
<p>可以说 <strong>expand 函数是完成伙伴算法的核心</strong>，结合注释你有没有发现，它和我们 Cosmos 物理内存分配算法有点类似呢？好，伙伴系统算法的核心，我们现在已经搞清楚了，下节课我再跟你说说 SLAB。</p>
<h2 id="重点回顾">重点回顾</h2>
<p>至此，伙伴系统我们就介绍完了，我来帮你梳理一下本课程的重点，主要有两个方面。</p>
<p>首先，我们学习了伙伴系统的数据结构，我们从页开始，Linux 用 page 结构代表一个物理内存页面，接着在 page 上层定义了内存区 zone，这是为了不同的地址空间的分配要求。然后 Linux 为了支持 NUMA 体系的计算机，而定义了**节点 pglist_data，**每个节点中包含了多个 zone，我们一起理清了这些数据结构之间的关系。</p>
<p>之后，我们进入到分配页面这一步，为了理解伙伴系统的内存分配的原理，我们研究了伙伴系统的分配接口，然后重点分析了它的快速分配路径和慢速分配路径。</p>
<p>只有在快速分配路径失败之后，才会进入慢速分配路径，慢速分配路径中会进行内存回收相关的工作。最后，我们一起了解了 expand 函数是如何分割伙伴，完成页面分配的。</p>
<h2 id="思考题">思考题</h2>
<p>在默认配置下，Linux 伙伴系统能分配多大的连续物理内存？</p>
<p>欢迎你在留言区跟我交流互动，也欢迎你把这节课转给对 Linux 伙伴系统感兴趣的朋友，一去学习进步。</p>
<p>好，我是 LMOS，我们下节课见！</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%9845%E8%AE%B2/">操作系统实战45讲</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E8%AF%BE/22_%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%A6%82%E4%BD%95%E8%AE%A9%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E4%BC%9A%E8%87%AA%E5%8A%A8%E5%88%86%E7%B1%BB/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">22_朴素贝叶斯：如何让计算机学会自动分类？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/10x%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95/22_%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%B2%9F%E9%80%9A%E4%BD%A0%E6%80%BB%E6%98%AF%E5%9C%A8%E5%BC%80%E4%BC%9A%E5%90%97/">
            <span class="next-text nav-default">22_轻量级沟通：你总是在开会吗？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

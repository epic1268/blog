<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>40__案例篇：网络请求延迟变大了，我该怎么办？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是倪朋飞。
上一节，我们学习了碰到分布式拒绝服务（DDoS）的缓解方法。简单回顾一下，DDoS 利用大量的伪造请求，导致目标服务要耗费大量资源，来处理这些无效请求，进而无法正常响应正常用户的请求。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/40__%E6%A1%88%E4%BE%8B%E7%AF%87%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F%E5%8F%98%E5%A4%A7%E4%BA%86%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/40__%E6%A1%88%E4%BE%8B%E7%AF%87%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F%E5%8F%98%E5%A4%A7%E4%BA%86%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="40__案例篇：网络请求延迟变大了，我该怎么办？">
  <meta property="og:description" content="你好，我是倪朋飞。
上一节，我们学习了碰到分布式拒绝服务（DDoS）的缓解方法。简单回顾一下，DDoS 利用大量的伪造请求，导致目标服务要耗费大量资源，来处理这些无效请求，进而无法正常响应正常用户的请求。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Linux性能优化实战">

  <meta itemprop="name" content="40__案例篇：网络请求延迟变大了，我该怎么办？">
  <meta itemprop="description" content="你好，我是倪朋飞。
上一节，我们学习了碰到分布式拒绝服务（DDoS）的缓解方法。简单回顾一下，DDoS 利用大量的伪造请求，导致目标服务要耗费大量资源，来处理这些无效请求，进而无法正常响应正常用户的请求。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="6096">
  <meta itemprop="keywords" content="Linux性能优化实战">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="40__案例篇：网络请求延迟变大了，我该怎么办？">
  <meta name="twitter:description" content="你好，我是倪朋飞。
上一节，我们学习了碰到分布式拒绝服务（DDoS）的缓解方法。简单回顾一下，DDoS 利用大量的伪造请求，导致目标服务要耗费大量资源，来处理这些无效请求，进而无法正常响应正常用户的请求。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">40__案例篇：网络请求延迟变大了，我该怎么办？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 6096 字 </span>
          <span class="more-meta"> 预计阅读 13 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#网络延迟">网络延迟</a></li>
        <li><a href="#案例准备">案例准备</a></li>
        <li><a href="#案例分析">案例分析</a></li>
        <li><a href="#小结">小结</a></li>
        <li><a href="#思考">思考</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是倪朋飞。</p>
<p>上一节，我们学习了碰到分布式拒绝服务（DDoS）的缓解方法。简单回顾一下，DDoS 利用大量的伪造请求，导致目标服务要耗费大量资源，来处理这些无效请求，进而无法正常响应正常用户的请求。</p>
<p>由于 DDoS 的分布式、大流量、难追踪等特点，目前确实还没有方法，能够完全防御 DDoS 带来的问题，我们只能设法缓解 DDoS 带来的影响。</p>
<p>比如，你可以购买专业的流量清洗设备和网络防火墙，在网络入口处阻断恶意流量，只保留正常流量进入数据中心的服务器。</p>
<p>在 Linux 服务器中，你可以通过内核调优、DPDK、XDP 等多种方法，增大服务器的抗攻击能力，降低 DDoS 对正常服务的影响。而在应用程序中，你可以利用各级缓存、WAF、CDN 等方式，缓解 DDoS 对应用程序的影响。</p>
<p>不过要注意，如果 DDoS 的流量，已经到了 Linux 服务器中，那么，即使应用层做了各种优化，网络服务的延迟一般还是会比正常情况大很多。</p>
<p>所以，在实际应用中，我们通常要让 Linux 服务器，配合专业的流量清洗以及网络防火墙设备，一起来缓解这一问题。</p>
<p>除了 DDoS 会带来网络延迟增大外，我想，你肯定见到过不少其他原因导致的网络延迟，比如</p>
<ul>
<li>网络传输慢，导致延迟；</li>
<li>Linux 内核协议栈报文处理慢，导致延迟；</li>
<li>应用程序数据处理慢，导致延迟等等。</li>
</ul>
<p>那么，当碰到这些原因的延迟时，我们该怎么办呢？又该如何定位网络延迟的根源呢？今天，我就通过一个案例，带你一起看看这些问题。</p>
<h2 id="网络延迟">网络延迟</h2>
<p>我相信，提到<strong>网络延迟</strong>时，你可能轻松想起它的含义——网络数据传输所用的时间。不过要注意，这个时间可能是单向的，指从源地址发送到目的地址的单程时间；也可能是双向的，即从源地址发送到目的地址，然后又从目的地址发回响应，这个往返全程所用的时间。</p>
<p>通常，我们更常用的是双向的往返通信延迟，比如 ping 测试的结果，就是往返延时 RTT（Round-Trip Time）。</p>
<p>除了网络延迟外，另一个常用的指标是<strong>应用程序延迟</strong>，它是指，从应用程序接收到请求，再到发回响应，全程所用的时间。通常，应用程序延迟也指的是往返延迟，是网络数据传输时间加上数据处理时间的和。</p>
<p>在 <a href="./81057.md">Linux 网络基础篇</a> 中，我曾经介绍到，你可以用 ping 来测试网络延迟。ping 基于 ICMP 协议，它通过计算 ICMP 回显响应报文与 ICMP 回显请求报文的时间差，来获得往返延时。这个过程并不需要特殊认证，常被很多网络攻击利用，比如端口扫描工具 nmap、组包工具 hping3 等等。</p>
<p>所以，为了避免这些问题，很多网络服务会把 ICMP 禁止掉，这也就导致我们无法用 ping，来测试网络服务的可用性和往返延时。这时，你可以用 traceroute 或 hping3 的 TCP 和 UDP 模式，来获取网络延迟。</p>
<p>比如，以 baidu.com 为例，你可以执行下面的 hping3 命令，测试你的机器到百度搜索服务器的网络延迟：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># -c 表示发送 3 次请求，-S 表示设置 TCP SYN，-p 表示端口号为 80
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ hping3 -c 3 -S -p 80 baidu.com
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">HPING baidu.com (eth0 123.125.115.110): S set, 40 headers + 0 data bytes
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=46 ip=123.125.115.110 ttl=51 id=47908 sport=80 flags=SA seq=0 win=8192 rtt=20.9 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=46 ip=123.125.115.110 ttl=51 id=6788  sport=80 flags=SA seq=1 win=8192 rtt=20.9 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=46 ip=123.125.115.110 ttl=51 id=37699 sport=80 flags=SA seq=2 win=8192 rtt=20.9 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> --- baidu.com hping statistic ---
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">3 packets transmitted, 3 packets received, 0% packet loss
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">round-trip min/avg/max = 20.9/20.9/20.9 ms
</span></span></code></pre></td></tr></table>
</div>
</div><p>从 hping3 的结果中，你可以看到，往返延迟 RTT 为 20.9ms。</p>
<p>当然，我们用 traceroute，也可以得到类似结果：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># --tcp 表示使用 TCP 协议，-p 表示端口号，-n 表示不对结果中的 IP 地址执行反向域名解析
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ traceroute --tcp -p 80 -n baidu.com
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">traceroute to baidu.com (123.125.115.110), 30 hops max, 60 byte packets
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 1  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 2  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 3  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 4  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 5  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 6  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 7  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 8  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 9  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">10  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">11  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">12  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">13  * * *
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">14  123.125.115.110  20.684 ms *  20.798 ms
</span></span></code></pre></td></tr></table>
</div>
</div><p>traceroute 会在路由的每一跳发送三个包，并在收到响应后，输出往返延时。如果无响应或者响应超时（默认 5s），就会输出一个星号。</p>
<p>知道了基于 TCP 测试网络服务延迟的方法后，接下来，我们就通过一个案例，来学习网络延迟升高时的分析思路。</p>
<h2 id="案例准备">案例准备</h2>
<p>下面的案例仍然基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。我使用的案例环境是这样的：</p>
<ul>
<li>机器配置：2 CPU，8GB 内存。</li>
<li>预先安装 docker、hping3、tcpdump、curl、wrk、Wireshark 等工具，比如 apt-get install docker.io hping3 tcpdump curl。</li>
</ul>
<p>这里的工具你应该都比较熟悉了，其中 wrk 的安装和使用方法在 <a href="./81497.md">怎么评估系统的网络性能</a> 中曾经介绍过。如果你还没有安装，请执行下面的命令来安装它：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ https://github.com/wg/wrk
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ cd wrk
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ apt-get install build-essential -y
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ make
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ sudo cp wrk /usr/local/bin/
</span></span></code></pre></td></tr></table>
</div>
</div><p>由于 Wireshark 需要图形界面，如果你的虚拟机没有图形界面，就可以把 Wireshark 安装到其他的机器中（比如 Windows 笔记本）。</p>
<p>本次案例用到两台虚拟机，我画了一张图来表示它们的关系。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/dff9d8ab6b0f9bcb56c7804198afb5ba.png" alt=""></p>
<p>接下来，我们打开两个终端，分别 SSH 登录到两台机器上（以下步骤，假设终端编号与图示 VM 编号一致），并安装上面提到的这些工具。注意，curl 和 wrk 只需要安装在客户端 VM（即 VM2）中。</p>
<p>同以前的案例一样，下面的所有命令都默认以 root 用户运行，如果你是用普通用户身份登陆系统，请运行 sudo su root 命令切换到 root 用户。</p>
<blockquote>
<p>如果安装过程中有什么问题，同样鼓励你先自己搜索解决，解决不了的，可以在留言区向我提问。如果你以前已经安装过了，就可以忽略这一点了。</p>
</blockquote>
<p>接下来，我们就进入到案例操作的环节。</p>
<h2 id="案例分析">案例分析</h2>
<p>为了对比得出延迟增大的影响，首先，我们来运行一个最简单的 Nginx，也就是用官方的 Nginx 镜像启动一个容器。在终端一中，执行下面的命令，运行官方 Nginx，它会在 80 端口监听：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker run --network=host --name=good -itd nginx
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">fb4ed7cb9177d10e270f8320a7fb64717eac3451114c9fab3c50e02be2e88ba2
</span></span></code></pre></td></tr></table>
</div>
</div><p>继续在终端一中，执行下面的命令，运行案例应用，它会监听 8080 端口：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker run --name nginx --network=host -itd feisky/nginx:latency
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">b99bd136dcfd907747d9c803fdc0255e578bad6d66f4e9c32b826d75b6812724
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后，在终端二中执行 curl 命令，验证两个容器已经正常启动。如果一切正常，你将看到如下的输出：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 80 端口正常
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ curl http://192.168.0.30
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&lt;!DOCTYPE html&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&lt;html&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&lt;/body&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&lt;/html&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> # 8080 端口正常
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ curl http://192.168.0.30:8080
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&lt;/body&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&lt;/html&gt;
</span></span></code></pre></td></tr></table>
</div>
</div><p>接着，我们再用上面提到的 hping3，来测试它们的延迟，看看有什么区别。还是在终端二，执行下面的命令，分别测试案例机器 80 端口和 8080 端口的延迟：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 测试 80 端口延迟
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ hping3 -c 3 -S -p 80 192.168.0.30
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=80 flags=SA seq=0 win=29200 rtt=7.8 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=80 flags=SA seq=1 win=29200 rtt=7.7 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=80 flags=SA seq=2 win=29200 rtt=7.6 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> --- 192.168.0.30 hping statistic ---
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">3 packets transmitted, 3 packets received, 0% packet loss
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">round-trip min/avg/max = 7.6/7.7/7.8 ms
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 测试 8080 端口延迟
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ hping3 -c 3 -S -p 8080 192.168.0.30
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=8080 flags=SA seq=0 win=29200 rtt=7.7 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=8080 flags=SA seq=1 win=29200 rtt=7.6 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=64 DF id=0 sport=8080 flags=SA seq=2 win=29200 rtt=7.3 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> --- 192.168.0.30 hping statistic ---
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">3 packets transmitted, 3 packets received, 0% packet loss
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">round-trip min/avg/max = 7.3/7.6/7.7 ms
</span></span></code></pre></td></tr></table>
</div>
</div><p>从这个输出你可以看到，两个端口的延迟差不多，都是 7ms。不过，这只是单个请求的情况。换成并发请求的话，又会怎么样呢？接下来，我们就用 wrk 试试。</p>
<p>这次在终端二中，执行下面的新命令，分别测试案例机器并发 100 时，80 端口和 8080 端口的性能：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 测试 80 端口性能
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ # wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Running 10s test @ http://192.168.0.30/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  2 threads and 100 connections
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    Latency     9.19ms   12.32ms 319.61ms   97.80%
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    Req/Sec     6.20k   426.80     8.25k    85.50%
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  Latency Distribution
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     50%    7.78ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     75%    8.22ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     90%    9.14ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     99%   50.53ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  123558 requests in 10.01s, 100.15MB read
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Requests/sec:  12340.91
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Transfer/sec:     10.00MB
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 测试 8080 端口性能
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30:8080/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Running 10s test @ http://192.168.0.30:8080/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  2 threads and 100 connections
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    Latency    43.60ms    6.41ms  56.58ms   97.06%
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    Req/Sec     1.15k   120.29     1.92k    88.50%
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  Latency Distribution
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     50%   44.02ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     75%   44.33ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     90%   47.62ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     99%   48.88ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  22853 requests in 10.01s, 18.55MB read
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Requests/sec:   2283.31
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Transfer/sec:      1.85MB
</span></span></code></pre></td></tr></table>
</div>
</div><p>从上面两个输出可以看到，官方 Nginx（监听在 80 端口）的平均延迟是 9.19ms，而案例 Nginx 的平均延迟（监听在 8080 端口）则是 43.6ms。从延迟的分布上来看，官方 Nginx 90% 的请求，都可以在 9ms 以内完成；而案例 Nginx 50% 的请求，就已经达到了 44 ms。</p>
<p>再结合上面 hping3 的输出，我们很容易发现，案例 Nginx 在并发请求下的延迟增大了很多，这是怎么回事呢？</p>
<p>分析方法我想你已经想到了，上节课学过的，使用 tcpdump 抓取收发的网络包，分析网络的收发过程有没有问题。</p>
<p>接下来，我们在终端一中，执行下面的 tcpdump 命令，抓取 8080 端口上收发的网络包，并保存到 nginx.pcap 文件：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ tcpdump -nn tcp port 8080 -w nginx.pcap
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后切换到终端二中，重新执行 wrk 命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 测试 8080 端口性能
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30:8080/
</span></span></code></pre></td></tr></table>
</div>
</div><p>当 wrk 命令结束后，再次切换回终端一，并按下 Ctrl+C 结束 tcpdump 命令。然后，再把抓取到的 nginx.pcap，复制到装有 Wireshark 的机器中（如果 VM1 已经带有图形界面，那么可以跳过复制步骤），并用 Wireshark 打开它。</p>
<p>由于网络包的数量比较多，我们可以先过滤一下。比如，在选择一个包后，你可以单击右键并选择“Follow” -&gt; “TCP Stream”，如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/e6fe86d36a068f0b4cddecebd3314a0a.png" alt=""></p>
<p>然后，关闭弹出来的对话框，回到 Wireshark 主窗口。这时候，你会发现 Wireshark 已经自动帮你设置了一个过滤表达式 tcp.stream eq 24。如下图所示（图中省去了源和目的 IP 地址）：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/caf7e26663f78025b64351409dd6902b.png" alt=""></p>
<p>从这里，你可以看到这个 TCP 连接从三次握手开始的每个请求和响应情况。当然，这可能还不够直观，你可以继续点击菜单栏里的 Statics -&gt; Flow Graph，选中“Limit to display filter”并设置 Flow type 为“TCP Flows”：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/f2aba6f1196e316a3066f8c01c0888b7.png" alt=""></p>
<p>注意，这个图的左边是客户端，而右边是 Nginx 服务器。通过这个图就可以看出，前面三次握手，以及第一次 HTTP 请求和响应还是挺快的，但第二次 HTTP 请求就比较慢了，特别是客户端在收到服务器第一个分组后，40ms 后才发出了 ACK 响应（图中蓝色行）。</p>
<p>看到 40ms 这个值，你有没有想起什么东西呢？实际上，这是 TCP 延迟确认（Delayed ACK）的最小超时时间。</p>
<p>这里我解释一下延迟确认。这是针对 TCP ACK 的一种优化机制，也就是说，不用每次请求都发送一个 ACK，而是先等一会儿（比如 40ms），看看有没有“顺风车”。如果这段时间内，正好有其他包需要发送，那就捎带着 ACK 一起发送过去。当然，如果一直等不到其他包，那就超时后单独发送 ACK。</p>
<p>因为案例中 40ms 发生在客户端上，我们有理由怀疑，是客户端开启了延迟确认机制。而这儿的客户端，实际上就是前面运行的 wrk。</p>
<p>查询 TCP 文档（执行 man tcp），你就会发现，只有 TCP 套接字专门设置了 TCP_QUICKACK，才会开启快速确认模式；否则，默认情况下，采用的就是延迟确认机制：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">TCP_QUICKACK (since Linux 2.4.4)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              Enable  quickack mode if set or disable quickack mode if cleared.  In quickack mode, acks are sent imme‐
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              diately, rather than delayed if needed in accordance to normal TCP operation.  This flag is  not  perma‐
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              nent,  it only enables a switch to or from quickack mode.  Subsequent operation of the TCP protocol will
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              once again enter/leave quickack mode depending on internal  protocol  processing  and  factors  such  as
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              delayed ack timeouts occurring and data transfer.  This option should not be used in code intended to be
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              portable.
</span></span></code></pre></td></tr></table>
</div>
</div><p>为了验证我们的猜想，确认 wrk 的行为，我们可以用 strace，来观察 wrk 为套接字设置了哪些 TCP 选项。</p>
<p>比如，你可以切换到终端二中，执行下面的命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ strace -f wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30:8080/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">setsockopt(52, SOL_TCP, TCP_NODELAY, [1], 4) = 0
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">...
</span></span></code></pre></td></tr></table>
</div>
</div><p>这样，你可以看到，wrk 只设置了 TCP_NODELAY 选项，而没有设置 TCP_QUICKACK。这说明 wrk 采用的正是延迟确认，也就解释了上面这个 40ms 的问题。</p>
<p>不过，别忘了，这只是客户端的行为，按理来说，Nginx 服务器不应该受到这个行为的影响。那是不是我们分析网络包时，漏掉了什么线索呢？让我们回到 Wireshark 重新观察一下。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/c68925f12d475a2d79c972f0504cb3e5.png" alt=""></p>
<p>仔细观察 Wireshark 的界面，其中，1173 号包，就是刚才说到的延迟 ACK 包；下一行的 1175，则是 Nginx 发送的第二个分组包，它跟 697 号包组合起来，构成一个完整的 HTTP 响应（ACK 号都是 85）。</p>
<p>第二个分组没跟前一个分组（697 号）一起发送，而是等到客户端对第一个分组的 ACK 后（1173 号）才发送，这看起来跟延迟确认有点像，只不过，这儿不再是 ACK，而是发送数据。</p>
<p>看到这里，我估计你想起了一个东西—— Nagle 算法（纳格算法）。进一步分析案例前，我先简单介绍一下这个算法。</p>
<p>Nagle 算法，是 TCP 协议中用于减少小包发送数量的一种优化算法，目的是为了提高实际带宽的利用率。</p>
<p>举个例子，当有效负载只有 1 字节时，再加上 TCP 头部和 IP 头部分别占用的 20 字节，整个网络包就是 41 字节，这样实际带宽的利用率只有 2.4%（1/41）。往大了说，如果整个网络带宽都被这种小包占满，那整个网络的有效利用率就太低了。</p>
<p>Nagle 算法正是为了解决这个问题。它通过合并 TCP 小包，提高网络带宽的利用率。Nagle 算法规定，一个 TCP 连接上，最多只能有一个未被确认的未完成分组；在收到这个分组的 ACK 前，不发送其他分组。这些小分组会被组合起来，并在收到 ACK 后，用同一个分组发送出去。</p>
<p>显然，Nagle 算法本身的想法还是挺好的，但是知道 Linux 默认的延迟确认机制后，你应该就不这么想了。因为它们一起使用时，网络延迟会明显。如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/5f81533adec2669c919c9be6db50186b.png" alt=""></p>
<ul>
<li>当 Sever 发送了第一个分组后，由于 Client 开启了延迟确认，就需要等待 40ms 后才会回复 ACK。</li>
<li>同时，由于 Server 端开启了 Nagle，而这时还没收到第一个分组的 ACK，Server 也会在这里一直等着。</li>
<li>直到 40ms 超时后，Client 才会回复 ACK，然后，Server 才会继续发送第二个分组。</li>
</ul>
<p>既然可能是 Nagle 的问题，那该怎么知道，案例 Nginx 有没有开启 Nagle 呢？</p>
<p>查询 tcp 的文档，你就会知道，只有设置了 TCP_NODELAY 后，Nagle 算法才会禁用。所以，我们只需要查看 Nginx 的 tcp_nodelay 选项就可以了。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">TCP_NODELAY
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              If set, disable the Nagle algorithm.  This means that segments are always sent as soon as possible, even
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              if there is only a small amount of data.  When not set, data is buffered until  there  is  a  sufficient
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              amount  to  send out, thereby avoiding the frequent sending of small packets, which results in poor uti‐
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              lization of the network.  This option is overridden by TCP_CORK; however, setting this option forces  an
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">              explicit flush of pending output, even if TCP_CORK is currently set.
</span></span></code></pre></td></tr></table>
</div>
</div><p>我们回到终端一中，执行下面的命令，查看案例 Nginx 的配置:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker exec nginx cat /etc/nginx/nginx.conf | grep tcp_nodelay
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    tcp_nodelay    off;
</span></span></code></pre></td></tr></table>
</div>
</div><p>果然，你可以看到，案例 Nginx 的 tcp_nodelay 是关闭的，将其设置为 on，应该就可以解决了。</p>
<p>改完后，问题是否就解决了呢？自然需要验证我们一下。修改后的应用，我已经打包到了 Docker 镜像中，在终端一中执行下面的命令，你就可以启动它：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 删除案例应用
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker rm -f nginx
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> # 启动优化后的应用
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker run --name nginx --network=host -itd feisky/nginx:nodelay
</span></span></code></pre></td></tr></table>
</div>
</div><p>接着，切换到终端二，重新执行 wrk 测试延迟：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30:8080/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Running 10s test @ http://192.168.0.30:8080/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  2 threads and 100 connections
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    Latency     9.58ms   14.98ms 350.08ms   97.91%
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    Req/Sec     6.22k   282.13     6.93k    68.50%
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  Latency Distribution
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     50%    7.78ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     75%    8.20ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     90%    9.02ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">     99%   73.14ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  123990 requests in 10.01s, 100.50MB read
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Requests/sec:  12384.04
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Transfer/sec:     10.04MB
</span></span></code></pre></td></tr></table>
</div>
</div><p>果然，现在延迟已经缩短成了 9ms，跟我们测试的官方 Nginx 镜像是一样的（Nginx 默认就是开启 tcp_nodelay 的） 。</p>
<p>作为对比，我们用 tcpdump，抓取优化后的网络包（这儿实际上抓取的是官方 Nginx 监听的 80 端口）。你可以得到下面的结果：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/fb9b3b64fe3626b7d6357ca8e2ecbaba.png" alt=""></p>
<p>从图中你可以发现，由于 Nginx 不用再等 ACK，536 和 540 两个分组是连续发送的；而客户端呢，虽然仍开启了延迟确认，但这时收到了两个需要回复 ACK 的包，所以也不用等 40ms，可以直接合并回复 ACK。</p>
<p>案例最后，不要忘记停止这两个容器应用。在终端一中，执行下面的命令，就可以删除案例应用：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker rm -f nginx good
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="小结">小结</h2>
<p>今天，我们学习了网络延迟增大后的分析方法。网络延迟，是最核心的网络性能指标。由于网络传输、网络包处理等各种因素的影响，网络延迟不可避免。但过大的网络延迟，会直接影响用户的体验。</p>
<p>所以，在发现网络延迟增大后，你可以用 traceroute、hping3、tcpdump、Wireshark、strace 等多种工具，来定位网络中的潜在问题。比如，</p>
<ul>
<li>使用 hping3 以及 wrk 等工具，确认单次请求和并发请求情况的网络延迟是否正常。</li>
<li>使用 traceroute，确认路由是否正确，并查看路由中每一跳网关的延迟。</li>
<li>使用 tcpdump 和 Wireshark，确认网络包的收发是否正常。</li>
<li>使用 strace 等，观察应用程序对网络套接字的调用情况是否正常。</li>
</ul>
<p>这样，你就可以依次从路由、网络包的收发、再到应用程序等，逐层排查，直到定位问题根源。</p>
<h2 id="思考">思考</h2>
<p>最后，我想邀请你一起来聊聊，你所理解的网络延迟，以及在发现网络延迟增大时，你又是怎么分析的呢？你可以结合今天的内容，和你自己的操作记录，来总结思路。</p>
<p>欢迎在留言区和我讨论，也欢迎把这篇文章分享给你的同事、朋友。我们一起在实战中演练，在交流中进步。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/f3ab291e71ad0a9d7fe2c894ccb9706a.png" alt=""></p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/">Linux性能优化实战</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/40__%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E4%B8%89%E9%AB%98%E6%80%A7%E8%83%BD%E9%98%9F%E5%88%97disruptor/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">40__案例分析（三）：高性能队列Disruptor</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/40__%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E6%B8%B8%E8%AE%B011-_%E7%A8%8B%E5%BA%8F%E4%B8%96%E7%95%8C%E9%87%8C%E7%9A%84%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/">
            <span class="next-text nav-default">40__编程范式游记（11）-_程序世界里的编程范式</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

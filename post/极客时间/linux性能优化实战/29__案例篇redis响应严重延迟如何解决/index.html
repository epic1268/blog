<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>29__案例篇：Redis响应严重延迟，如何解决？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是倪朋飞。
上一节，我们一起分析了一个基于 MySQL 的商品搜索案例，先来回顾一下。
在访问商品搜索接口时，我们发现接口的响应特别慢。通过对系统 CPU、内存和磁盘 I/O 等资源使用情况的分析，我们发现这时出现了磁盘的 I/O 瓶颈，并且正是案例应用导致的。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/29__%E6%A1%88%E4%BE%8B%E7%AF%87redis%E5%93%8D%E5%BA%94%E4%B8%A5%E9%87%8D%E5%BB%B6%E8%BF%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/29__%E6%A1%88%E4%BE%8B%E7%AF%87redis%E5%93%8D%E5%BA%94%E4%B8%A5%E9%87%8D%E5%BB%B6%E8%BF%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="29__案例篇：Redis响应严重延迟，如何解决？">
  <meta property="og:description" content="你好，我是倪朋飞。
上一节，我们一起分析了一个基于 MySQL 的商品搜索案例，先来回顾一下。
在访问商品搜索接口时，我们发现接口的响应特别慢。通过对系统 CPU、内存和磁盘 I/O 等资源使用情况的分析，我们发现这时出现了磁盘的 I/O 瓶颈，并且正是案例应用导致的。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Linux性能优化实战">

  <meta itemprop="name" content="29__案例篇：Redis响应严重延迟，如何解决？">
  <meta itemprop="description" content="你好，我是倪朋飞。
上一节，我们一起分析了一个基于 MySQL 的商品搜索案例，先来回顾一下。
在访问商品搜索接口时，我们发现接口的响应特别慢。通过对系统 CPU、内存和磁盘 I/O 等资源使用情况的分析，我们发现这时出现了磁盘的 I/O 瓶颈，并且正是案例应用导致的。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="6563">
  <meta itemprop="keywords" content="Linux性能优化实战">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="29__案例篇：Redis响应严重延迟，如何解决？">
  <meta name="twitter:description" content="你好，我是倪朋飞。
上一节，我们一起分析了一个基于 MySQL 的商品搜索案例，先来回顾一下。
在访问商品搜索接口时，我们发现接口的响应特别慢。通过对系统 CPU、内存和磁盘 I/O 等资源使用情况的分析，我们发现这时出现了磁盘的 I/O 瓶颈，并且正是案例应用导致的。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">29__案例篇：Redis响应严重延迟，如何解决？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 6563 字 </span>
          <span class="more-meta"> 预计阅读 14 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#案例准备">案例准备</a></li>
        <li><a href="#案例分析">案例分析</a></li>
        <li><a href="#小结">小结</a></li>
        <li><a href="#思考">思考</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是倪朋飞。</p>
<p>上一节，我们一起分析了一个基于 MySQL 的商品搜索案例，先来回顾一下。</p>
<p>在访问商品搜索接口时，我们发现接口的响应特别慢。通过对系统 CPU、内存和磁盘 I/O 等资源使用情况的分析，我们发现这时出现了磁盘的 I/O 瓶颈，并且正是案例应用导致的。</p>
<p>接着，我们借助 pidstat，发现罪魁祸首是 mysqld 进程。我们又通过 strace、lsof，找出了 mysqld 正在读的文件。根据文件的名字和路径，我们找出了 mysqld 正在操作的数据库和数据表。综合这些信息，我们猜测这是一个没利用索引导致的慢查询问题。</p>
<p>为了验证猜测，我们到 MySQL 命令行终端，使用数据库分析工具发现，案例应用访问的字段果然没有索引。既然猜测是正确的，那增加索引后，问题就自然解决了。</p>
<p>从这个案例你会发现，MySQL 的 MyISAM 引擎，主要依赖系统缓存加速磁盘 I/O 的访问。可如果系统中还有其他应用同时运行，MyISAM 引擎很难充分利用系统缓存。缓存可能会被其他应用程序占用，甚至被清理掉。</p>
<p>所以，一般我并不建议，把应用程序的性能优化完全建立在系统缓存上。最好能在应用程序的内部分配内存，构建完全自主控制的缓存；或者使用第三方的缓存应用，比如 Memcached、Redis 等。</p>
<p>Redis 是最常用的键值存储系统之一，常用作数据库、高速缓存和消息队列代理等。Redis 基于内存来存储数据，不过，为了保证在服务器异常时数据不丢失，很多情况下，我们要为它配置持久化，而这就可能会引发磁盘 I/O 的性能问题。</p>
<p>今天，我就带你一起来分析一个利用 Redis 作为缓存的案例。这同样是一个基于 Python Flask 的应用程序，它提供了一个 查询缓存的接口，但接口的响应时间比较长，并不能满足线上系统的要求。</p>
<p>非常感谢携程系统研发部资深后端工程师董国星，帮助提供了今天的案例。</p>
<h2 id="案例准备">案例准备</h2>
<p>本次案例还是基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。我使用的案例环境如下所示：</p>
<ul>
<li>机器配置：2 CPU，8GB 内存</li>
<li>预先安装 docker、sysstat、git、make 等工具，如 apt install <a href="./docker.io.md">docker.io</a> sysstat</li>
</ul>
<p>今天的案例由 Python 应用 +Redis 两部分组成。其中，Python 应用是一个基于 Flask 的应用，它会利用 Redis，来管理应用程序的缓存，并对外提供三个 HTTP 接口：</p>
<ul>
<li>/：返回 hello redis；</li>
<li>/init/：插入指定数量的缓存数据，如果不指定数量，默认的是 5000 条；</li>
<li>缓存的键格式为 uuid:</li>
<li>缓存的值为 good、bad 或 normal 三者之一</li>
<li>/get_cache/&lt;type_name&gt;：查询指定值的缓存数据，并返回处理时间。其中，type_name 参数只支持 good, bad 和 normal（也就是找出具有相同 value 的 key 列表）。</li>
</ul>
<p>由于应用比较多，为了方便你运行，我把它们打包成了两个 Docker 镜像，并推送到了 <a href="./redis-slow.md">Github</a> 上。这样你就只需要运行几条命令，就可以启动了。</p>
<p>今天的案例需要两台虚拟机，其中一台用作案例分析的目标机器，运行 Flask 应用，它的 IP 地址是 192.168.0.10；而另一台作为客户端，请求缓存查询接口。我画了一张图来表示它们的关系。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/4148c5d0616b65f23ca40f43214f44ac.png" alt=""></p>
<p>接下来，打开两个终端，分别 SSH 登录到这两台虚拟机中，并在第一台虚拟机中安装上述工具。</p>
<p>跟以前一样，案例中所有命令都默认以 root 用户运行，如果你是用普通用户身份登陆系统，请运行 sudo su root 命令切换到 root 用户。</p>
<p>到这里，准备工作就完成了。接下来，我们正式进入操作环节。</p>
<h2 id="案例分析">案例分析</h2>
<p>首先，我们在第一个终端中，执行下面的命令，运行本次案例要分析的目标应用。正常情况下，你应该可以看到下面的输出：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 注意下面的随机字符串是容器 ID，每次运行均会不同，并且你不需要关注它
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker run --name=redis -itd -p 10000:80 feisky/redis-server
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">ec41cb9e4dd5cb7079e1d9f72b7cee7de67278dbd3bd0956b4c0846bff211803
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker run --name=app --network=container:redis -itd feisky/redis-app
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">2c54eb252d0552448320d9155a2618b799a1e71d7289ec7277a61e72a9de5fd0
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后，再运行 docker ps 命令，确认两个容器都处于运行（Up）状态：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker ps
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS                             NAMES
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">2c54eb252d05        feisky/redis-app      &#34;python /app.py&#34;         48 seconds ago      Up 47 seconds                                         app
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">ec41cb9e4dd5        feisky/redis-server   &#34;docker-entrypoint.s…&#34;   49 seconds ago      Up 48 seconds       6379/tcp, 0.0.0.0:10000-&gt;80/tcp   redis
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 
</span></span></code></pre></td></tr></table>
</div>
</div><p>今天的应用在 10000 端口监听，所以你可以通过 <a href="http://192.168.0.10:10000">http://192.168.0.10:10000</a> ，来访问前面提到的三个接口。</p>
<p>比如，我们切换到第二个终端，使用 curl 工具，访问应用首页。如果你看到 <code>hello redis</code> 的输出，说明应用正常启动：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ curl http://192.168.0.10:10000/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">hello redis
</span></span></code></pre></td></tr></table>
</div>
</div><p>接下来，继续在终端二中，执行下面的 curl 命令，来调用应用的 /init 接口，初始化 Redis 缓存，并且插入 5000 条缓存信息。这个过程比较慢，比如我的机器就花了十几分钟时间。耐心等一会儿后，你会看到下面这行输出：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 案例插入 5000 条数据，在实践时可以根据磁盘的类型适当调整，比如使用 SSD 时可以调大，而 HDD 可以适当调小
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ curl http://192.168.0.10:10000/init/5000
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">{&#34;elapsed_seconds&#34;:30.26814079284668,&#34;keys_initialized&#34;:5000}
</span></span></code></pre></td></tr></table>
</div>
</div><p>继续执行下一个命令，访问应用的缓存查询接口。如果一切正常，你会看到如下输出：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ curl http://192.168.0.10:10000/get_cache
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">{&#34;count&#34;:1677,&#34;data&#34;:[&#34;d97662fa-06ac-11e9-92c7-0242ac110002&#34;,...],&#34;elapsed_seconds&#34;:10.545469760894775,&#34;type&#34;:&#34;good&#34;}
</span></span></code></pre></td></tr></table>
</div>
</div><p>我们看到，这个接口调用居然要花 10 秒！这么长的响应时间，显然不能满足实际的应用需求。</p>
<p>到底出了什么问题呢？我们还是要用前面学过的性能工具和原理，来找到这个瓶颈。</p>
<p>不过别急，同样为了避免分析过程中客户端的请求结束，在进行性能分析前，我们先要把 curl 命令放到一个循环里来执行。你可以在终端二中，继续执行下面的命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ while true; do curl http://192.168.0.10:10000/get_cache; done
</span></span></code></pre></td></tr></table>
</div>
</div><p>接下来，再重新回到终端一，查找接口响应慢的“病因”。</p>
<p>最近几个案例的现象都是响应很慢，这种情况下，我们自然先会怀疑，是不是系统资源出现了瓶颈。所以，先观察 CPU、内存和磁盘 I/O 等的使用情况肯定不会错。</p>
<p>我们先在终端一中执行 top 命令，分析系统的 CPU 使用情况：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">$</span> <span class="n">top</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">top</span> <span class="o">-</span> <span class="mi">12</span><span class="p">:</span><span class="mi">46</span><span class="p">:</span><span class="mi">18</span> <span class="n">up</span> <span class="mi">11</span> <span class="n">days</span><span class="p">,</span>  <span class="mi">8</span><span class="p">:</span><span class="mi">49</span><span class="p">,</span>  <span class="mi">1</span> <span class="n">user</span><span class="p">,</span>  <span class="nb">load</span> <span class="n">average</span><span class="p">:</span> <span class="mf">1.36</span><span class="p">,</span> <span class="mf">1.36</span><span class="p">,</span> <span class="mf">1.04</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Tasks</span><span class="p">:</span> <span class="mi">137</span> <span class="n">total</span><span class="p">,</span>   <span class="mi">1</span> <span class="n">running</span><span class="p">,</span>  <span class="mi">79</span> <span class="n">sleeping</span><span class="p">,</span>   <span class="mi">0</span> <span class="n">stopped</span><span class="p">,</span>   <span class="mi">0</span> <span class="n">zombie</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">%</span><span class="n">Cpu0</span>  <span class="p">:</span>  <span class="mf">6.0</span> <span class="n">us</span><span class="p">,</span>  <span class="mf">2.7</span> <span class="n">sy</span><span class="p">,</span>  <span class="mf">0.0</span> <span class="n">ni</span><span class="p">,</span>  <span class="mf">5.7</span> <span class="n">id</span><span class="p">,</span> <span class="mf">84.7</span> <span class="n">wa</span><span class="p">,</span>  <span class="mf">0.0</span> <span class="n">hi</span><span class="p">,</span>  <span class="mf">1.0</span> <span class="n">si</span><span class="p">,</span>  <span class="mf">0.0</span> <span class="n">st</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">%</span><span class="n">Cpu1</span>  <span class="p">:</span>  <span class="mf">1.0</span> <span class="n">us</span><span class="p">,</span>  <span class="mf">3.0</span> <span class="n">sy</span><span class="p">,</span>  <span class="mf">0.0</span> <span class="n">ni</span><span class="p">,</span> <span class="mf">94.7</span> <span class="n">id</span><span class="p">,</span>  <span class="mf">0.0</span> <span class="n">wa</span><span class="p">,</span>  <span class="mf">0.0</span> <span class="n">hi</span><span class="p">,</span>  <span class="mf">1.3</span> <span class="n">si</span><span class="p">,</span>  <span class="mf">0.0</span> <span class="n">st</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">KiB</span> <span class="n">Mem</span> <span class="p">:</span>  <span class="mi">8169300</span> <span class="n">total</span><span class="p">,</span>  <span class="mi">7342244</span> <span class="n">free</span><span class="p">,</span>   <span class="mi">432912</span> <span class="n">used</span><span class="p">,</span>   <span class="mi">394144</span> <span class="n">buff</span><span class="o">/</span><span class="n">cache</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">KiB</span> <span class="n">Swap</span><span class="p">:</span>        <span class="mi">0</span> <span class="n">total</span><span class="p">,</span>        <span class="mi">0</span> <span class="n">free</span><span class="p">,</span>        <span class="mi">0</span> <span class="n">used</span><span class="o">.</span>  <span class="mi">7478748</span> <span class="n">avail</span> <span class="n">Mem</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="n">PID</span> <span class="n">USER</span>      <span class="n">PR</span>  <span class="n">NI</span>    <span class="n">VIRT</span>    <span class="n">RES</span>    <span class="n">SHR</span> <span class="n">S</span>  <span class="o">%</span><span class="n">CPU</span> <span class="o">%</span><span class="n">MEM</span>     <span class="n">TIME</span><span class="o">+</span> <span class="n">COMMAND</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> <span class="mi">9181</span> <span class="n">root</span>      <span class="mi">20</span>   <span class="mi">0</span>  <span class="mi">193004</span>  <span class="mi">27304</span>   <span class="mi">8716</span> <span class="n">S</span>   <span class="mf">8.6</span>  <span class="mf">0.3</span>   <span class="mi">0</span><span class="p">:</span><span class="mf">07.15</span> <span class="n">python</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> <span class="mi">9085</span> <span class="n">systemd</span><span class="o">+</span>  <span class="mi">20</span>   <span class="mi">0</span>   <span class="mi">28352</span>   <span class="mi">9760</span>   <span class="mi">1860</span> <span class="n">D</span>   <span class="mf">5.0</span>  <span class="mf">0.1</span>   <span class="mi">0</span><span class="p">:</span><span class="mf">04.34</span> <span class="n">redis</span><span class="o">-</span><span class="n">server</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="mi">368</span> <span class="n">root</span>      <span class="mi">20</span>   <span class="mi">0</span>       <span class="mi">0</span>      <span class="mi">0</span>      <span class="mi">0</span> <span class="n">D</span>   <span class="mf">1.0</span>  <span class="mf">0.0</span>   <span class="mi">0</span><span class="p">:</span><span class="mf">33.88</span> <span class="n">jbd2</span><span class="o">/</span><span class="n">sda1</span><span class="o">-</span><span class="mi">8</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="mi">149</span> <span class="n">root</span>       <span class="mi">0</span> <span class="o">-</span><span class="mi">20</span>       <span class="mi">0</span>      <span class="mi">0</span>      <span class="mi">0</span> <span class="n">I</span>   <span class="mf">0.3</span>  <span class="mf">0.0</span>   <span class="mi">0</span><span class="p">:</span><span class="mf">10.63</span> <span class="n">kworker</span><span class="o">/</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="n">H</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> <span class="mi">1549</span> <span class="n">root</span>      <span class="mi">20</span>   <span class="mi">0</span>  <span class="mi">236716</span>  <span class="mi">24576</span>   <span class="mi">9864</span> <span class="n">S</span>   <span class="mf">0.3</span>  <span class="mf">0.3</span>  <span class="mi">91</span><span class="p">:</span><span class="mf">37.30</span> <span class="n">python3</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>观察 top 的输出可以发现，CPU0 的 iowait 比较高，已经达到了 84%；而各个进程的 CPU 使用率都不太高，最高的 python 和 redis-server，也分别只有 8% 和 5%。再看内存，总内存 8GB，剩余内存还有 7GB 多，显然内存也没啥问题。</p>
<p>综合 top 的信息，最有嫌疑的就是 iowait。所以，接下来还是要继续分析，是不是 I/O 问题。</p>
<p>还在第一个终端中，先按下 Ctrl+C，停止 top 命令；然后，执行下面的 iostat 命令，查看有没有 I/O 性能问题：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ iostat -d -x 1
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">sda              0.00  492.00      0.00   2672.00     0.00   176.00   0.00  26.35    0.00    1.76   0.00     0.00     5.43   0.00   0.00
</span></span></code></pre></td></tr></table>
</div>
</div><p>观察 iostat 的输出，我们发现，磁盘 sda 每秒的写数据（wkB/s）为 2.5MB，I/O 使用率（%util）是 0。看来，虽然有些 I/O 操作，但并没导致磁盘的 I/O 瓶颈。</p>
<p>排查一圈儿下来，CPU 和内存使用没问题，I/O 也没有瓶颈，接下来好像就没啥分析方向了？</p>
<p>碰到这种情况，还是那句话，反思一下，是不是又漏掉什么有用线索了。你可以先自己思考一下，从分析对象（案例应用）、系统原理和性能工具这三个方向下功夫，回忆它们的特性，查找现象的异常，再继续往下走。</p>
<p>回想一下，今天的案例问题是从 Redis 缓存中查询数据慢。对查询来说，对应的 I/O 应该是磁盘的读操作，但刚才我们用 iostat 看到的却是写操作。虽说 I/O 本身并没有性能瓶颈，但这里的磁盘写也是比较奇怪的。为什么会有磁盘写呢？那我们就得知道，到底是哪个进程在写磁盘。</p>
<p>要知道 I/O 请求来自哪些进程，还是要靠我们的老朋友 pidstat。在终端一中运行下面的 pidstat 命令，观察进程的 I/O 情况：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ pidstat -d 1
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">12:49:35      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">12:49:36        0       368      0.00     16.00      0.00      86  jbd2/sda1-8
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">12:49:36      100      9085      0.00    636.00      0.00       1  redis-server
</span></span></code></pre></td></tr></table>
</div>
</div><p>从 pidstat 的输出，我们看到，I/O 最多的进程是 PID 为 9085 的 redis-server，并且它也刚好是在写磁盘。这说明，确实是 redis-server 在进行磁盘写。</p>
<p>当然，光找到读写磁盘的进程还不够，我们还要再用 strace+lsof 组合，看看 redis-server 到底在写什么。</p>
<p>接下来，还是在终端一中，执行 strace 命令，并且指定 redis-server 的进程号 9085：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># -f 表示跟踪子进程和子线程，-T 表示显示系统调用的时长，-tt 表示显示跟踪时间
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ strace -f -T -tt -p 9085
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.826131 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 65, NULL, 8) = 1 &lt;0.000055&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.826301 read(8, &#34;*2\r\n$3\r\nGET\r\n$41\r\nuuid:5b2e76cc-&#34;..., 16384) = 61 &lt;0.000071&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.826477 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) &lt;0.000063&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.826645 write(8, &#34;$3\r\nbad\r\n&#34;, 9) = 9 &lt;0.000173&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.826907 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 65, NULL, 8) = 1 &lt;0.000032&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.827030 read(8, &#34;*2\r\n$3\r\nGET\r\n$41\r\nuuid:55862ada-&#34;..., 16384) = 61 &lt;0.000044&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.827149 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) &lt;0.000043&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.827285 write(8, &#34;$3\r\nbad\r\n&#34;, 9) = 9 &lt;0.000141&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.827514 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 64, NULL, 8) = 1 &lt;0.000049&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.827641 read(8, &#34;*2\r\n$3\r\nGET\r\n$41\r\nuuid:53522908-&#34;..., 16384) = 61 &lt;0.000043&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.827784 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) &lt;0.000034&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.827945 write(8, &#34;$4\r\ngood\r\n&#34;, 10) = 10 &lt;0.000288&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.828339 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 63, NULL, 8) = 1 &lt;0.000057&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.828486 read(8, &#34;*3\r\n$4\r\nSADD\r\n$4\r\ngood\r\n$36\r\n535&#34;..., 16384) = 67 &lt;0.000040&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.828623 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) &lt;0.000052&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.828760 write(7, &#34;*3\r\n$4\r\nSADD\r\n$4\r\ngood\r\n$36\r\n535&#34;..., 67) = 67 &lt;0.000060&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.828970 fdatasync(7) = 0 &lt;0.005415&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:20:16.834493 write(8, &#34;:1\r\n&#34;, 4) = 4 &lt;0.000250&gt;
</span></span></code></pre></td></tr></table>
</div>
</div><p>观察一会儿，有没有发现什么有趣的现象呢？</p>
<p>事实上，从系统调用来看，epoll_pwait、read、write、fdatasync 这些系统调用都比较频繁。那么，刚才观察到的写磁盘，应该就是 write 或者 fdatasync 导致的了。</p>
<p>接着再来运行 lsof 命令，找出这些系统调用的操作对象：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ lsof -p 9085
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">redis-ser 9085 systemd-network    3r     FIFO   0,12      0t0 15447970 pipe
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">redis-ser 9085 systemd-network    4w     FIFO   0,12      0t0 15447970 pipe
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">redis-ser 9085 systemd-network    5u  a_inode   0,13        0    10179 [eventpoll]
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">redis-ser 9085 systemd-network    6u     sock    0,9      0t0 15447972 protocol: TCP
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">redis-ser 9085 systemd-network    7w      REG    8,1  8830146  2838532 /data/appendonly.aof
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">redis-ser 9085 systemd-network    8u     sock    0,9      0t0 15448709 protocol: TCP
</span></span></code></pre></td></tr></table>
</div>
</div><p>现在你会发现，描述符编号为 3 的是一个 pipe 管道，5 号是 eventpoll，7 号是一个普通文件，而 8 号是一个 TCP socket。</p>
<p>结合磁盘写的现象，我们知道，只有 7 号普通文件才会产生磁盘写，而它操作的文件路径是 /data/appendonly.aof，相应的系统调用包括 write 和 fdatasync。</p>
<p>如果你对 Redis 的持久化配置比较熟，看到这个文件路径以及 fdatasync 的系统调用，你应该能想到，这对应着正是 Redis 持久化配置中的 appendonly 和 appendfsync 选项。很可能是因为它们的配置不合理，导致磁盘写比较多。</p>
<p>接下来就验证一下这个猜测，我们可以通过 Redis 的命令行工具，查询这两个选项的配置。</p>
<p>继续在终端一中，运行下面的命令，查询 appendonly 和 appendfsync 的配置：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker exec -it redis redis-cli config get &#39;append*&#39;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">1) &#34;appendfsync&#34;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">2) &#34;always&#34;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">3) &#34;appendonly&#34;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">4) &#34;yes&#34;
</span></span></code></pre></td></tr></table>
</div>
</div><p>从这个结果你可以发现，appendfsync 配置的是 always，而 appendonly 配置的是 yes。这两个选项的详细含义，你可以从 <a href="./persistence.md">Redis Persistence</a> 的文档中查到，这里我做一下简单介绍。</p>
<p>Redis 提供了两种数据持久化的方式，分别是快照和追加文件。</p>
<p><strong>快照方式</strong>，会按照指定的时间间隔，生成数据的快照，并且保存到磁盘文件中。为了避免阻塞主进程，Redis 还会 fork 出一个子进程，来负责快照的保存。这种方式的性能好，无论是备份还是恢复，都比追加文件好很多。</p>
<p>不过，它的缺点也很明显。在数据量大时，fork 子进程需要用到比较大的内存，保存数据也很耗时。所以，你需要设置一个比较长的时间间隔来应对，比如至少 5 分钟。这样，如果发生故障，你丢失的就是几分钟的数据。</p>
<p><strong>追加文件</strong>，则是用在文件末尾追加记录的方式，对 Redis 写入的数据，依次进行持久化，所以它的持久化也更安全。</p>
<p>此外，它还提供了一个用 appendfsync 选项设置 fsync 的策略，确保写入的数据都落到磁盘中，具体选项包括 always、everysec、no 等。</p>
<ul>
<li>always 表示，每个操作都会执行一次 fsync，是最为安全的方式；</li>
<li>everysec 表示，每秒钟调用一次 fsync，这样可以保证即使是最坏情况下，也只丢失 1 秒的数据；</li>
<li>而 no 表示交给操作系统来处理。</li>
</ul>
<p>回忆一下我们刚刚看到的配置，appendfsync 配置的是 always，意味着每次写数据时，都会调用一次 fsync，从而造成比较大的磁盘 I/O 压力。</p>
<p>当然，你还可以用 strace，观察这个系统调用的执行情况。比如通过 -e 选项指定 fdatasync 后，你就会得到下面的结果：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ strace -f -p 9085 -T -tt -e fdatasync
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">strace: Process 9085 attached with 4 threads
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:22:52.013547 fdatasync(7) = 0 &lt;0.007112&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:22:52.022467 fdatasync(7) = 0 &lt;0.008572&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:22:52.032223 fdatasync(7) = 0 &lt;0.006769&gt;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[pid  9085] 14:22:52.139629 fdatasync(7) = 0 &lt;0.008183&gt;
</span></span></code></pre></td></tr></table>
</div>
</div><p>从这里你可以看到，每隔 10ms 左右，就会有一次 fdatasync 调用，并且每次调用本身也要消耗 7~8ms。</p>
<p>不管哪种方式，都可以验证我们的猜想，配置确实不合理。这样，我们就找出了 Redis 正在进行写入的文件，也知道了产生大量 I/O 的原因。</p>
<p>不过，回到最初的疑问，为什么查询时会有磁盘写呢？按理来说不应该只有数据的读取吗？这就需要我们再来审查一下 strace -f -T -tt -p 9085 的结果。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">read(8, &#34;*2\r\n$3\r\nGET\r\n$41\r\nuuid:53522908-&#34;..., 16384)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">write(8, &#34;$4\r\ngood\r\n&#34;, 10)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">read(8, &#34;*3\r\n$4\r\nSADD\r\n$4\r\ngood\r\n$36\r\n535&#34;..., 16384)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">write(7, &#34;*3\r\n$4\r\nSADD\r\n$4\r\ngood\r\n$36\r\n535&#34;..., 67)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">write(8, &#34;:1\r\n&#34;, 4)
</span></span></code></pre></td></tr></table>
</div>
</div><p>细心的你应该记得，根据 lsof 的分析，文件描述符编号为 7 的是一个普通文件 /data/appendonly.aof，而编号为 8 的是 TCP socket。而观察上面的内容，8 号对应的 TCP 读写，是一个标准的“请求 - 响应”格式，即：</p>
<ul>
<li>从 socket 读取 GET uuid:53522908-… 后，响应 good；</li>
<li>再从 socket 读取 SADD good 535… 后，响应 1。</li>
</ul>
<p>对 Redis 来说，SADD 是一个写操作，所以 Redis 还会把它保存到用于持久化的 appendonly.aof 文件中。</p>
<p>观察更多的 strace 结果，你会发现，每当 GET 返回 good 时，随后都会有一个 SADD 操作，这也就导致了，明明是查询接口，Redis 却有大量的磁盘写。</p>
<p>到这里，我们就找出了 Redis 写磁盘的原因。不过，在下最终结论前，我们还是要确认一下，8 号 TCP socket 对应的 Redis 客户端，到底是不是我们的案例应用。</p>
<p>我们可以给 lsof 命令加上 -i 选项，找出 TCP socket 对应的 TCP 连接信息。不过，由于 Redis 和 Python 应用都在容器中运行，我们需要进入容器的网络命名空间内部，才能看到完整的 TCP 连接。</p>
<blockquote>
<p>注意：下面的命令用到的 <a href="./nsenter.1.md">nsenter</a> 工具，可以进入容器命名空间。如果你的系统没有安装，请运行下面命令安装 nsenter：<br>
docker run &ndash;rm -v /usr/local/bin:/target jpetazzo/nsenter</p>
</blockquote>
<p>还是在终端一中，运行下面的命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># 由于这两个容器共享同一个网络命名空间，所以我们只需要进入 app 的网络命名空间即可
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ PID=$(docker inspect --format {{.State.Pid}} app)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># -i 表示显示网络套接字信息
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ nsenter --target $PID --net -- lsof -i
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">COMMAND    PID            USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">redis-ser 9085 systemd-network    6u  IPv4 15447972      0t0  TCP localhost:6379 (LISTEN)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">redis-ser 9085 systemd-network    8u  IPv4 15448709      0t0  TCP localhost:6379-&gt;localhost:32996 (ESTABLISHED)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">python    9181            root    3u  IPv4 15448677      0t0  TCP *:http (LISTEN)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">python    9181            root    5u  IPv4 15449632      0t0  TCP localhost:32996-&gt;localhost:6379 (ESTABLISHED)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> 
</span></span></code></pre></td></tr></table>
</div>
</div><p>这次我们可以看到，redis-server 的 8 号文件描述符，对应 TCP 连接 localhost:6379-&gt;localhost:32996。其中，localhost:6379 是 redis-server 自己的监听端口，自然 localhost:32996 就是 redis 的客户端。再观察最后一行，localhost:32996 对应的，正是我们的 Python 应用程序（进程号为 9181）。</p>
<p>历经各种波折，我们总算找出了 Redis 响应延迟的潜在原因。总结一下，我们找到两个问题。</p>
<p>第一个问题，Redis 配置的 appendfsync 是 always，这就导致 Redis 每次的写操作，都会触发 fdatasync 系统调用。今天的案例，没必要用这么高频的同步写，使用默认的 1s 时间间隔，就足够了。</p>
<p>第二个问题，Python 应用在查询接口中会调用 Redis 的 SADD 命令，这很可能是不合理使用缓存导致的。</p>
<p>对于第一个配置问题，我们可以执行下面的命令，把 appendfsync 改成 everysec：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker exec -it redis redis-cli config set appendfsync everysec
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">OK
</span></span></code></pre></td></tr></table>
</div>
</div><p>改完后，切换到终端二中查看，你会发现，现在的请求时间，已经缩短到了 0.9s：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">{..., &#34;elapsed_seconds&#34;:0.9368953704833984,&#34;type&#34;:&#34;good&#34;}
</span></span></code></pre></td></tr></table>
</div>
</div><p>而第二个问题，就要查看应用的源码了。点击 <a href="./app.py.md">Github</a> ，你就可以查看案例应用的源代码：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">def get_cache(type_name):
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    &#39;&#39;&#39;handler for /get_cache&#39;&#39;&#39;
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    for key in redis_client.scan_iter(&#34;uuid:*&#34;):
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        value = redis_client.get(key)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        if value == type_name:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            redis_client.sadd(type_name, key[5:])
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    data = list(redis_client.smembers(type_name))
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    redis_client.delete(type_name)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    return jsonify({&#34;type&#34;: type_name, &#39;count&#39;: len(data), &#39;data&#39;: data})
</span></span></code></pre></td></tr></table>
</div>
</div><p>果然，Python 应用把 Redis 当成临时空间，用来存储查询过程中找到的数据。不过我们知道，这些数据放内存中就可以了，完全没必要再通过网络调用存储到 Redis 中。</p>
<p>基于这个思路，我把修改后的代码也推送到了相同的源码文件中，你可以通过 <a href="http://192.168.0.10:10000/get%5Fcache%5Fdata">http://192.168.0.10:10000/get%5Fcache%5Fdata</a> 这个接口来访问它。</p>
<p>我们切换到终端二，按 Ctrl+C 停止之前的 curl 命令；然后执行下面的 curl 命令，调用 <a href="http://192.168.0.10:10000/get%5Fcache%5Fdata">http://192.168.0.10:10000/get%5Fcache%5Fdata</a> 新接口：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ while true; do curl http://192.168.0.10:10000/get_cache_data; done
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">{...,&#34;elapsed_seconds&#34;:0.16034674644470215,&#34;type&#34;:&#34;good&#34;}
</span></span></code></pre></td></tr></table>
</div>
</div><p>你可以发现，解决第二个问题后，新接口的性能又有了进一步的提升，从刚才的 0.9s，再次缩短成了不到 0.2s。</p>
<p>当然，案例最后，不要忘记清理案例应用。你可以切换到终端一中，执行下面的命令进行清理：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker rm -f app redis
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="小结">小结</h2>
<p>今天我带你一起分析了一个 Redis 缓存的案例。</p>
<p>我们先用 top、iostat，分析了系统的 CPU、内存和磁盘使用情况，不过却发现，系统资源并没有出现瓶颈。这个时候想要进一步分析的话，该从哪个方向着手呢？</p>
<p>通过今天的案例你会发现，为了进一步分析，就需要你对系统和应用程序的工作原理有一定的了解。</p>
<p>比如，今天的案例中，虽然磁盘 I/O 并没有出现瓶颈，但从 Redis 的原理来说，查询缓存时不应该出现大量的磁盘 I/O 写操作。</p>
<p>顺着这个思路，我们继续借助 pidstat、strace、lsof、nsenter 等一系列的工具，找出了两个潜在问题，一个是 Redis 的不合理配置，另一个是 Python 应用对 Redis 的滥用。找到瓶颈后，相应的优化工作自然就比较轻松了。</p>
<h2 id="思考">思考</h2>
<p>最后给你留一个思考题。从上一节 MySQL 到今天 Redis 的案例分析，你有没有发现 I/O 性能问题的分析规律呢？如果你有任何想法或心得，都可以记录下来。</p>
<p>当然，这两个案例这并不能涵盖所有的 I/O 性能问题。你在实际工作中，还碰到过哪些 I/O 性能问题吗？你又是怎么分析的呢？</p>
<p>欢迎在留言区和我讨论，也欢迎把这篇文章分享给你的同事、朋友。我们一起在实战中演练，在交流中进步。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/f3ab291e71ad0a9d7fe2c894ccb9706a.png" alt=""></p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/">Linux性能优化实战</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A140%E9%97%AE/29__service_mesh%E5%A6%82%E4%BD%95%E5%B1%8F%E8%94%BD%E6%9C%8D%E5%8A%A1%E5%8C%96%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86%E7%BB%86%E8%8A%82/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">29__Service_Mesh：如何屏蔽服务化系统的服务治理细节？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%9330%E8%AE%B2/29__%E4%BA%A7%E5%93%81%E5%9B%BE%E9%89%B4%E5%93%AA%E4%BA%9B%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%80%BC%E5%BE%97%E7%9C%8B/">
            <span class="next-text nav-default">29__产品图鉴：哪些分布式数据库值得看？</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>47__案例篇：服务器总是时不时丢包，我该怎么办？（上） - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是倪朋飞。
上一节，我们梳理了，应用程序容器化后性能下降的分析方法。一起先简单回顾下。
容器利用 Linux 内核提供的命名空间技术，将不同应用程序的运行隔离起来，并用统一的镜像，来管理应用程序的依赖环境。这为应用程序的管理和维护，带来了极大的便捷性，并进一步催生了微服务、云原生等新一代技术架构。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/47__%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%BB%E6%98%AF%E6%97%B6%E4%B8%8D%E6%97%B6%E4%B8%A2%E5%8C%85%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8A/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/47__%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%BB%E6%98%AF%E6%97%B6%E4%B8%8D%E6%97%B6%E4%B8%A2%E5%8C%85%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8A/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="47__案例篇：服务器总是时不时丢包，我该怎么办？（上）">
  <meta property="og:description" content="你好，我是倪朋飞。
上一节，我们梳理了，应用程序容器化后性能下降的分析方法。一起先简单回顾下。
容器利用 Linux 内核提供的命名空间技术，将不同应用程序的运行隔离起来，并用统一的镜像，来管理应用程序的依赖环境。这为应用程序的管理和维护，带来了极大的便捷性，并进一步催生了微服务、云原生等新一代技术架构。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="Linux性能优化实战">

  <meta itemprop="name" content="47__案例篇：服务器总是时不时丢包，我该怎么办？（上）">
  <meta itemprop="description" content="你好，我是倪朋飞。
上一节，我们梳理了，应用程序容器化后性能下降的分析方法。一起先简单回顾下。
容器利用 Linux 内核提供的命名空间技术，将不同应用程序的运行隔离起来，并用统一的镜像，来管理应用程序的依赖环境。这为应用程序的管理和维护，带来了极大的便捷性，并进一步催生了微服务、云原生等新一代技术架构。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="4462">
  <meta itemprop="keywords" content="Linux性能优化实战">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="47__案例篇：服务器总是时不时丢包，我该怎么办？（上）">
  <meta name="twitter:description" content="你好，我是倪朋飞。
上一节，我们梳理了，应用程序容器化后性能下降的分析方法。一起先简单回顾下。
容器利用 Linux 内核提供的命名空间技术，将不同应用程序的运行隔离起来，并用统一的镜像，来管理应用程序的依赖环境。这为应用程序的管理和维护，带来了极大的便捷性，并进一步催生了微服务、云原生等新一代技术架构。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">47__案例篇：服务器总是时不时丢包，我该怎么办？（上）</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 4462 字 </span>
          <span class="more-meta"> 预计阅读 9 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#案例准备">案例准备</a></li>
        <li><a href="#案例分析">案例分析</a>
          <ul>
            <li><a href="#链路层">链路层</a></li>
            <li><a href="#网络层和传输层">网络层和传输层</a></li>
          </ul>
        </li>
        <li><a href="#小结">小结</a></li>
        <li><a href="#思考">思考</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是倪朋飞。</p>
<p>上一节，我们梳理了，应用程序容器化后性能下降的分析方法。一起先简单回顾下。</p>
<p>容器利用 Linux 内核提供的命名空间技术，将不同应用程序的运行隔离起来，并用统一的镜像，来管理应用程序的依赖环境。这为应用程序的管理和维护，带来了极大的便捷性，并进一步催生了微服务、云原生等新一代技术架构。</p>
<p>不过，虽说有很多优势，但容器化也会对应用程序的性能带来一定影响。比如，上一节我们一起分析的 Java 应用，就容易发生启动过慢、运行一段时间后 OOM 退出等问题。当你碰到这种问题时，不要慌，我们前面四大基础模块中的各种思路，都依然适用。</p>
<p>实际上，我们专栏中的很多案例都在容器中运行。容器化后，应用程序会通过命名空间进行隔离。所以，你在分析时，不要忘了结合命名空间、cgroups、iptables 等来综合分析。比如：</p>
<ul>
<li>cgroups 会影响容器应用的运行；</li>
<li>iptables 中的 NAT，会影响容器的网络性能；</li>
<li>叠加文件系统，会影响应用的 I/O 性能等。</li>
</ul>
<p>关于 NAT 的影响，我在网络模块的 <a href="./83189.md">如何优化 NAT 性能</a> 文章中，已经为你介绍了很多优化思路。今天，我们一起来看另一种情况，也就是丢包的分析方法。</p>
<p>所谓丢包，是指在网络数据的收发过程中，由于种种原因，数据包还没传输到应用程序中，就被丢弃了。这些被丢弃包的数量，除以总的传输包数，也就是我们常说的<strong>丢包率</strong>。丢包率是网络性能中最核心的指标之一。</p>
<p>丢包通常会带来严重的性能下降，特别是对 TCP 来说，丢包通常意味着网络拥塞和重传，进而还会导致网络延迟增大、吞吐降低。</p>
<p>接下来，我就以最常用的反向代理服务器 Nginx 为例，带你一起看看，如何分析网络丢包的问题。由于内容比较多，这个案例将分为上下两篇来讲解，今天我们先看第一部分内容。</p>
<h2 id="案例准备">案例准备</h2>
<p>今天的案例需要用到两台虚拟机，还是基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。我使用的案例环境如下所示：</p>
<ul>
<li>机器配置：2 CPU，8GB 内存。</li>
<li>预先安装 docker、curl、hping3 等工具，如 apt install docker.io curl hping3。</li>
</ul>
<p>这些工具，我们在前面的案例中已经多次使用，这里就不再重复介绍。</p>
<p>现在，打开两个终端，分别登录到这两台虚拟机中，并安装上述工具。</p>
<p>注意，以下所有命令都默认以 root 用户运行，如果你用普通用户身份登陆系统，请运行 sudo su root 命令，切换到 root 用户。</p>
<blockquote>
<p>如果安装过程有问题，你可以先上网搜索解决，实在解决不了的，记得在留言区向我提问。</p>
</blockquote>
<p>到这里，准备工作就完成了。接下来，我们正式进入操作环节。</p>
<h2 id="案例分析">案例分析</h2>
<p>我们今天要分析的案例是一个 Nginx 应用，如下图所示，hping3 和 curl 是 Nginx 的客户端。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/eee6c075999a343c251795164687b31b.png" alt=""></p>
<p>为了方便你运行，我已经把它打包成了一个 Docker 镜像，并推送到 Docker Hub 中。你可以直接按照下面的步骤来运行它。</p>
<p>在终端一中执行下面的命令，启动 Nginx 应用，并在 80 端口监听。如果一切正常，你应该可以看到如下的输出：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker run --name nginx --hostname nginx --privileged -p 80:80 -itd feisky/nginx:drop
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">dae0202cc27e5082b282a6aeeb1398fcec423c642e63322da2a97b9ebd7538e0
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后，执行 docker ps 命令，查询容器的状态，你会发现容器已经处于运行状态（Up）了：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker ps
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                NAMES
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">dae0202cc27e        feisky/nginx:drop   &#34;/start.sh&#34;         4 minutes ago       Up 4 minutes        0.0.0.0:80-&gt;80/tcp   nginx
</span></span></code></pre></td></tr></table>
</div>
</div><p>不过，从 docker ps 的输出，我们只能知道容器处于运行状态，至于 Nginx 是否可以正常处理外部请求，还需要进一步的确认。</p>
<p>接着，我们切换到终端二中，执行下面的 hping3 命令，进一步验证 Nginx 是不是真的可以正常访问了。注意，这里我没有使用 ping，是因为 ping 基于 ICMP 协议，而 Nginx 使用的是 TCP 协议。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"># -c 表示发送 10 个请求，-S 表示使用 TCP SYN，-p 指定端口为 80
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ hping3 -c 10 -S -p 80 192.168.0.30
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=3 win=5120 rtt=7.5 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=4 win=5120 rtt=7.4 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=5 win=5120 rtt=3.3 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=7 win=5120 rtt=3.0 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=6 win=5120 rtt=3027.2 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> --- 192.168.0.30 hping statistic ---
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">10 packets transmitted, 5 packets received, 50% packet loss
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">round-trip min/avg/max = 3.0/609.7/3027.2 ms
</span></span></code></pre></td></tr></table>
</div>
</div><p>从 hping3 的输出中，我们可以发现，发送了 10 个请求包，却只收到了 5 个回复，50% 的包都丢了。再观察每个请求的 RTT 可以发现，RTT 也有非常大的波动变化，小的时候只有 3ms，而大的时候则有 3s。</p>
<p>根据这些输出，我们基本能判断，已经发生了丢包现象。可以猜测，3s 的 RTT，很可能是因为丢包后重传导致的。那到底是哪里发生了丢包呢？</p>
<p>排查之前，我们可以回忆一下 Linux 的网络收发流程，先从理论上分析，哪里有可能会发生丢包。你不妨拿出手边的笔和纸，边回忆边在纸上梳理，思考清楚再继续下面的内容。</p>
<p>在这里，为了帮你理解网络丢包的原理，我画了一张图，你可以保存并打印出来使用：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/7b194e40fb35f34e975ce44a4a210e2e.png" alt=""></p>
<p>从图中你可以看出，可能发生丢包的位置，实际上贯穿了整个网络协议栈。换句话说，全程都有丢包的可能。比如我们从下往上看：</p>
<ul>
<li>在两台 VM 连接之间，可能会发生传输失败的错误，比如网络拥塞、线路错误等；</li>
<li>在网卡收包后，环形缓冲区可能会因为溢出而丢包；</li>
<li>在链路层，可能会因为网络帧校验失败、QoS 等而丢包；</li>
<li>在 IP 层，可能会因为路由失败、组包大小超过 MTU 等而丢包；</li>
<li>在传输层，可能会因为端口未监听、资源占用超过内核限制等而丢包；</li>
<li>在套接字层，可能会因为套接字缓冲区溢出而丢包；</li>
<li>在应用层，可能会因为应用程序异常而丢包；</li>
<li>此外，如果配置了 iptables 规则，这些网络包也可能因为 iptables 过滤规则而丢包。</li>
</ul>
<p>当然，上面这些问题，还有可能同时发生在通信的两台机器中。不过，由于我们没对 VM2 做任何修改，并且 VM2 也只运行了一个最简单的 hping3 命令，这儿不妨假设它是没有问题的。</p>
<p>为了简化整个排查过程，我们还可以进一步假设，VM1 的网络和内核配置也没问题。这样一来，有可能发生问题的位置，就都在容器内部了。</p>
<p>现在我们切换回终端一，执行下面的命令，进入容器的终端中：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ docker exec -it nginx bash
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">root@nginx:/#
</span></span></code></pre></td></tr></table>
</div>
</div><p>在这里简单说明一下，接下来的所有分析，前面带有 <em>root@nginx:/#</em> 的操作，都表示在容器中进行。</p>
<blockquote>
<p>注意：实际环境中，容器内部和外部都有可能发生问题。不过不要担心，容器内、外部的分析步骤和思路都是一样的，只不过要花更多的时间而已。</p>
</blockquote>
<p>那么，接下来，我们就可以从协议栈中，逐层排查丢包问题。</p>
<h3 id="链路层">链路层</h3>
<p>首先，来看最底下的链路层。当缓冲区溢出等原因导致网卡丢包时，Linux 会在网卡收发数据的统计信息中，记录下收发错误的次数。</p>
<p>你可以通过 ethtool 或者 netstat，来查看网卡的丢包记录。比如，可以在容器中执行下面的命令，查看丢包情况：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">root@nginx:/# netstat -i
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Kernel Interface table
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">eth0       100       31      0      0 0             8      0      0      0 BMRU
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">lo       65536        0      0      0 0             0      0      0      0 LRU
</span></span></code></pre></td></tr></table>
</div>
</div><p>输出中的 RX-OK、RX-ERR、RX-DRP、RX-OVR，分别表示接收时的总包数、总错误数、进入 Ring Buffer 后因其他原因（如内存不足）导致的丢包数以及 Ring Buffer 溢出导致的丢包数。</p>
<p>TX-OK、TX-ERR、TX-DRP、TX-OVR 也代表类似的含义，只不过是指发送时对应的各个指标。</p>
<blockquote>
<p>注意，由于 Docker 容器的虚拟网卡，实际上是一对 veth pair，一端接入容器中用作 eth0，另一端在主机中接入 docker0 网桥中。veth 驱动并没有实现网络统计的功能，所以使用 ethtool -S 命令，无法得到网卡收发数据的汇总信息。</p>
</blockquote>
<p>从这个输出中，我们没有发现任何错误，说明容器的虚拟网卡没有丢包。不过要注意，如果用 tc 等工具配置了 QoS，那么 tc 规则导致的丢包，就不会包含在网卡的统计信息中。</p>
<p>所以接下来，我们还要检查一下 eth0 上是否配置了 tc 规则，并查看有没有丢包。我们继续容器终端中，执行下面的 tc 命令，不过这次注意添加 -s 选项，以输出统计信息：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">root@nginx:/# tc -s qdisc show dev eth0
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">qdisc netem 800d: root refcnt 2 limit 1000 loss 30%
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> Sent 432 bytes 8 pkt (dropped 4, overlimits 0 requeues 0)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> backlog 0b 0p requeues 0
</span></span></code></pre></td></tr></table>
</div>
</div><p>从 tc 的输出中可以看到，eth0 上面配置了一个网络模拟排队规则（qdisc netem），并且配置了丢包率为 30%（loss 30%）。再看后面的统计信息，发送了 8 个包，但是丢了 4 个。</p>
<p>看来，应该就是这里，导致 Nginx 回复的响应包，被 netem 模块给丢了。</p>
<p>既然发现了问题，解决方法也就很简单了，直接删掉 netem 模块就可以了。我们可以继续在容器终端中，执行下面的命令，删除 tc 中的 netem 模块：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">root@nginx:/# tc qdisc del dev eth0 root netem loss 30%
</span></span></code></pre></td></tr></table>
</div>
</div><p>删除后，问题到底解决了没？我们切换到终端二中，重新执行刚才的 hping3 命令，看看现在还有没有问题：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ hping3 -c 10 -S -p 80 192.168.0.30
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=0 win=5120 rtt=7.9 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=2 win=5120 rtt=1003.8 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=5 win=5120 rtt=7.6 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=6 win=5120 rtt=7.4 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=9 win=5120 rtt=3.0 ms
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> --- 192.168.0.30 hping statistic ---
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">10 packets transmitted, 5 packets received, 50% packet loss
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">round-trip min/avg/max = 3.0/205.9/1003.8 ms
</span></span></code></pre></td></tr></table>
</div>
</div><p>不幸的是，从 hping3 的输出中，我们可以看到，跟前面现象一样，还是 50% 的丢包；RTT 的波动也仍旧很大，从 3ms 到 1s。</p>
<p>显然，问题还是没解决，丢包还在继续发生。不过，既然链路层已经排查完了，我们就继续向上层分析，看看网络层和传输层有没有问题。</p>
<h3 id="网络层和传输层">网络层和传输层</h3>
<p>我们知道，在网络层和传输层中，引发丢包的因素非常多。不过，其实想确认是否丢包，是非常简单的事，因为 Linux 已经为我们提供了各个协议的收发汇总情况。</p>
<p>我们继续在容器终端中，执行下面的 netstat -s 命令，就可以看到协议的收发汇总，以及错误信息了：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">root@nginx:/# netstat -s
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Ip:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    Forwarding: 1					// 开启转发
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    31 total packets received		// 总收包数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 forwarded						// 转发包数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 incoming packets discarded	// 接收丢包数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    25 incoming packets delivered	// 接收的数据包数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    15 requests sent out			// 发出的数据包数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Icmp:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 ICMP messages received		// 收到的 ICMP 包数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 input ICMP message failed		// 收到 ICMP 失败数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    ICMP input histogram:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 ICMP messages sent			//ICMP 发送数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 ICMP messages failed			//ICMP 失败数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    ICMP output histogram:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Tcp:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 active connection openings	// 主动连接数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 passive connection openings	// 被动连接数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    11 failed connection attempts	// 失败连接尝试数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 connection resets received	// 接收的连接重置数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 connections established		// 建立连接数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    25 segments received			// 已接收报文数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    21 segments sent out			// 已发送报文数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    4 segments retransmitted		// 重传报文数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 bad segments received			// 错误报文数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 resets sent					// 发出的连接重置数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Udp:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 packets received
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    ...
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">TcpExt:
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    11 resets received for embryonic SYN_RECV sockets	// 半连接重置数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    0 packet headers predicted
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    TCPTimeouts: 7		// 超时数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    TCPSynRetrans: 4	//SYN 重传数
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	...
</span></span></code></pre></td></tr></table>
</div>
</div><p>netstat 汇总了 IP、ICMP、TCP、UDP 等各种协议的收发统计信息。不过，我们的目的是排查丢包问题，所以这里主要观察的是错误数、丢包数以及重传数。</p>
<p>根据上面的输出，你可以看到，只有 TCP 协议发生了丢包和重传，分别是：</p>
<ul>
<li>11 次连接失败重试（11 failed connection attempts）</li>
<li>4 次重传（4 segments retransmitted）</li>
<li>11 次半连接重置（11 resets received for embryonic SYN_RECV sockets）</li>
<li>4 次 SYN 重传（TCPSynRetrans）</li>
<li>7 次超时（TCPTimeouts）</li>
</ul>
<p>这个结果告诉我们，TCP 协议有多次超时和失败重试，并且主要错误是半连接重置。换句话说，主要的失败，都是三次握手失败。</p>
<p>不过，虽然在这儿看到了这么多失败，但具体失败的根源还是无法确定。所以，我们还需要继续顺着协议栈来分析。接下来的几层又该如何分析呢？你不妨自己先来思考操作一下，下一节我们继续来一起探讨。</p>
<h2 id="小结">小结</h2>
<p>网络丢包，通常会带来严重的性能下降，特别是对 TCP 来说，丢包通常意味着网络拥塞和重传，进一步还会导致网络延迟增大、吞吐降低。</p>
<p>今天的这个案例，我们学会了如何从链路层、网络层和传输层等入手，分析网络丢包的问题。不过，案例最后，我们还没有找出最终的性能瓶颈，下一节，我将继续为你讲解。</p>
<h2 id="思考">思考</h2>
<p>最后，给你留一个思考题，也是案例最后提到的问题。</p>
<p>今天我们只分析了链路层、网络层以及传输层等。而根据 TCP/IP 协议栈和 Linux 网络收发原理，还有很多我们没分析到的地方。那么，接下来，我们又该如何分析，才能破获这个案例，找出“真凶”呢？</p>
<p>欢迎在留言区和我讨论，也欢迎把这篇文章分享给你的同事、朋友。我们一起在实战中演练，在交流中进步。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/f3ab291e71ad0a9d7fe2c894ccb9706a.png" alt=""></p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E6%88%98/">Linux性能优化实战</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/47__ssd%E7%A1%AC%E7%9B%98%E4%B8%8B%E5%A6%82%E4%BD%95%E5%AE%8C%E6%88%90%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84kpi/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">47__SSD硬盘（下）：如何完成性能优化的KPI？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/47__%E5%BC%B9%E5%8A%9B%E8%AE%BE%E8%AE%A1%E7%AF%87%E4%B9%8B%E9%87%8D%E8%AF%95%E8%AE%BE%E8%AE%A1/">
            <span class="next-text nav-default">47__弹力设计篇之“重试设计”</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

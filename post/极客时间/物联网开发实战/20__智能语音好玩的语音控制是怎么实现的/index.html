<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>20__智能语音：好玩的语音控制是怎么实现的？ - Docs</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="你好，我是郭朝斌。
实战篇的前几讲，我们打造了联网智能电灯，并实现了跟光照传感器的场景联动。今天我们来玩一个更酷的，智能音箱。
智能音箱为我们提供了一种更加自然的交互方式，所以亚马逊的 Echo 产品一经问世，就迅速流行起来。与智能家居结合之后，它更是引起了行业巨头的注意，被认为是很有发展潜力的用户入口和平台级产品。
" /><meta name="keywords" content="技术文档, docs, 极客时间" />






<meta name="generator" content="Hugo 0.140.2 with theme even" />


<link rel="canonical" href="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/20__%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E5%A5%BD%E7%8E%A9%E7%9A%84%E8%AF%AD%E9%9F%B3%E6%8E%A7%E5%88%B6%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:url" content="https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/20__%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E5%A5%BD%E7%8E%A9%E7%9A%84%E8%AF%AD%E9%9F%B3%E6%8E%A7%E5%88%B6%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84/">
  <meta property="og:site_name" content="Docs">
  <meta property="og:title" content="20__智能语音：好玩的语音控制是怎么实现的？">
  <meta property="og:description" content="你好，我是郭朝斌。
实战篇的前几讲，我们打造了联网智能电灯，并实现了跟光照传感器的场景联动。今天我们来玩一个更酷的，智能音箱。
智能音箱为我们提供了一种更加自然的交互方式，所以亚马逊的 Echo 产品一经问世，就迅速流行起来。与智能家居结合之后，它更是引起了行业巨头的注意，被认为是很有发展潜力的用户入口和平台级产品。">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-01-10T00:00:00+00:00">
    <meta property="article:tag" content="物联网开发实战">

  <meta itemprop="name" content="20__智能语音：好玩的语音控制是怎么实现的？">
  <meta itemprop="description" content="你好，我是郭朝斌。
实战篇的前几讲，我们打造了联网智能电灯，并实现了跟光照传感器的场景联动。今天我们来玩一个更酷的，智能音箱。
智能音箱为我们提供了一种更加自然的交互方式，所以亚马逊的 Echo 产品一经问世，就迅速流行起来。与智能家居结合之后，它更是引起了行业巨头的注意，被认为是很有发展潜力的用户入口和平台级产品。">
  <meta itemprop="datePublished" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="dateModified" content="2024-01-10T00:00:00+00:00">
  <meta itemprop="wordCount" content="5469">
  <meta itemprop="keywords" content="物联网开发实战">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="20__智能语音：好玩的语音控制是怎么实现的？">
  <meta name="twitter:description" content="你好，我是郭朝斌。
实战篇的前几讲，我们打造了联网智能电灯，并实现了跟光照传感器的场景联动。今天我们来玩一个更酷的，智能音箱。
智能音箱为我们提供了一种更加自然的交互方式，所以亚马逊的 Echo 产品一经问世，就迅速流行起来。与智能家居结合之后，它更是引起了行业巨头的注意，被认为是很有发展潜力的用户入口和平台级产品。">

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Docs</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Docs</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">20__智能语音：好玩的语音控制是怎么实现的？</h1>

      <div class="post-meta">
        <span class="post-time"> 10100-01-10 </span>
        <div class="post-category">
            <a href="/categories/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/"> 极客时间 </a>
            </div>
          <span class="more-meta"> 约 5469 字 </span>
          <span class="more-meta"> 预计阅读 11 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#智能音箱的技术架构">智能音箱的技术架构</a>
          <ul>
            <li><a href="#拾音">拾音</a></li>
            <li><a href="#前端语音信号处理">前端语音信号处理</a></li>
            <li><a href="#语音唤醒">语音唤醒</a></li>
            <li><a href="#语音识别">语音识别</a></li>
            <li><a href="#自然语言理解">自然语言理解</a></li>
            <li><a href="#技能">技能</a></li>
            <li><a href="#自然语言生成">自然语言生成</a></li>
            <li><a href="#语音合成">语音合成</a></li>
          </ul>
        </li>
        <li><a href="#智能音箱的开发">智能音箱的开发</a>
          <ul>
            <li><a href="#麦克风阵列">麦克风阵列</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#uncomment-line-below-then-apt-get-update-to-enable-apt-get-source">Uncomment line below then &lsquo;apt-get update&rsquo; to enable &lsquo;apt-get source&rsquo;</a></li>
    <li><a href="#uncomment-line-below-then-apt-get-update-to-enable-apt-get-source-1">Uncomment line below then &lsquo;apt-get update&rsquo; to enable &lsquo;apt-get source&rsquo;</a>
      <ul>
        <li>
          <ul>
            <li><a href="#语音唤醒-1">语音唤醒</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#filekwsdemopy">File：kwsdemo.py</a></li>
    <li><a href="#sleep-forever">Sleep forever</a>
      <ul>
        <li>
          <ul>
            <li><a href="#语音识别-1">语音识别</a></li>
            <li><a href="#语音合成-1">语音合成</a></li>
          </ul>
        </li>
        <li><a href="#通过智能音箱控制电灯">通过智能音箱控制电灯</a></li>
        <li><a href="#小结">小结</a></li>
        <li><a href="#思考题">思考题</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>你好，我是郭朝斌。</p>
<p>实战篇的前几讲，我们打造了联网智能电灯，并实现了跟光照传感器的场景联动。今天我们来玩一个更酷的，智能音箱。</p>
<p>智能音箱为我们提供了一种更加自然的交互方式，所以亚马逊的 Echo 产品一经问世，就迅速流行起来。与智能家居结合之后，它更是引起了行业巨头的注意，被认为是很有发展潜力的用户入口和平台级产品。</p>
<p>我们先不论智能音箱最终到底能不能发展成智能家居的平台级产品，至少这波热潮已经极大地推动了相关技术的发展，而且用户覆盖率也有了很大的提升。</p>
<p>这一讲我就为你介绍一下智能音箱的语音控制是怎么实现的，并且带你动手完成开发过程。</p>
<h2 id="智能音箱的技术架构">智能音箱的技术架构</h2>
<p>智能音箱主要涉及<strong>拾音</strong>、<strong>前端信号处理</strong>、<strong>语音识别</strong>、<strong>自然语言处理</strong>和<strong>语音合成</strong>等技术，现在一些产品甚至提供了声纹识别技术。</p>
<p>当然，智能音箱最重要的是提供各种功能，完成一些任务，比如控制电灯的开和关，这被称为<strong>技能</strong>。</p>
<p>整体的技术架构如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/8a89eb3aa8e9c24cc0568a4fe534ca61.png" alt=""></p>
<p>接下来，我会逐个讲解这些技术组成。</p>
<h3 id="拾音">拾音</h3>
<p>拾音，就是通过<strong>麦克风</strong>获取你的语音。</p>
<p>我们都用微信发送过语音消息，手机就是通过麦克风来获取你说的话的，这么说起来，拾音好像很简单。但是，智能音箱应对的环境要更复杂，因为用户可能在比较远的地方下达语音指令。</p>
<p>因此，智能音箱上一般采用<strong>麦克风阵列</strong>（Mic Array），也就是按照一定规则排列的多个麦克风，比如下图展示的就是Amazon Echo由 7 个麦克风组成的阵列（绿色圆圈部分）。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/65712a167f2959205f51f69fa1be8b81.png" alt=""></p>
<h3 id="前端语音信号处理">前端语音信号处理</h3>
<p>在收集到声音信号后，还需要进行前端语音信号处理。只有经过处理，智能音箱才能获取到相对干净的语音信号，也才能提高后面的语音识别的准确率。</p>
<p>这些处理技术包括回声消除（Acoustic Echo Cancellaction, AEC）、噪音抑制（Noise Suppression，NS）、语音检测（Voice Activity Detection，VAD）、声源定位（Direction of Arrival estimation，DOA）、波束成型（Beamforming）和混响消除（Speech Dereverberation）等。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/1731d522f0cbd14a5e8a0aa1958dbc75.png" alt=""></p>
<h3 id="语音唤醒">语音唤醒</h3>
<p>语音唤醒（Keyword Spotting，KWS），就是通过特定的<strong>唤醒词</strong>来激活智能音箱，以便进行后续的语音交互任务。这样做一方面可以保护用户的隐私，因为只有唤醒后，音箱才收集和识别用户的语音信息，另一方面也可以简化语音的识别和理解，比如小米智能音箱的“小爱同学”就是这样的唤醒词。</p>
<h3 id="语音识别">语音识别</h3>
<p>语音识别（Automatic Speech Recognition，ASR），主要完成的任务是将语音转换成文本，所以也被称为 STT（Speech to Text）。</p>
<h3 id="自然语言理解">自然语言理解</h3>
<p>自然语言理解（Natural Language Understanding，NLU），是对语音识别生成的文本进行处理，识别用户的意图，并生产结构化的数据。</p>
<p>当然，以现在的人工智能发展水平来看，自然语言理解还有很长的路要走。这也是我们常发现智能音箱不够“智能”的原因。</p>
<h3 id="技能">技能</h3>
<p>技能（Skills）一般要借助后端云平台的强大能力，云平台可以提供知识图谱、家居设备远程控制和音乐等音频资源等能力。</p>
<h3 id="自然语言生成">自然语言生成</h3>
<p>自然语言生成（Natural Language Generation，NLG），就是将各种技能的响应结果组织成文本语言。比如当你询问天气时，根据获取的天气状况和温度等信息生成“北京今天晴，最高温度 5°，最低温度 -6°”这样的语句。自然语言生成和自然语言理解都属于<strong>自然语言处理</strong>（Natural Language Processing，NLP）的范畴。</p>
<h3 id="语音合成">语音合成</h3>
<p>语音合成（Speech Synthesis），就是将自然语言生成的文本转换为语音的形式，提供给智能音箱播放出来，给人的感觉就像和音箱在对话。因此，这个过程也叫做 TTS（Text to Speech）。</p>
<h2 id="智能音箱的开发">智能音箱的开发</h2>
<p>了解完智能音箱的基本技术构成，下面我们就基于树莓派开发一个自己的简易智能音箱吧。</p>
<p>首先，我需要说明一下树莓派的系统。为什么呢？因为在第 15 讲中，我们安装了 Gladys Assistant 系统镜像，而这个系统 Raspbian 是基于 Debian buster 版本的，一些语音识别开源库对于 buster 的支持并不够好。</p>
<p>所以，如果你的树莓派是 Raspberry Pi 3 系列，强烈建议你把系统镜像切换成 <strong>Debian stretch</strong> 版本。通过这个链接就可以下载基于 Debian stretch 版本的 Raspbian 镜像文件压缩包，安装还是使用 Etcher 工具，你可以回头看一下第 15 讲的介绍。</p>
<p>至于树莓派 Raspberry Pi 4 系列，因为官方系统 Raspbian 只有 buster 版本支持，所以我们还是继续基于第 15 讲的系统开发。</p>
<h3 id="麦克风阵列">麦克风阵列</h3>
<p>麦克风阵列我使用的是 <strong>ReSpeaker 2-Mics Pi HAT</strong>，它的 2 个麦克风分布在模组的两边。我们现在来配置一下，让它可以在树莓派上正常工作。</p>
<p>你可以通过下面的命令安装它的驱动程序。首先，你最好切换一下树莓派的软件安装源，将它切换到国内的腾讯云安装源，这样下载安装的速度比较快。运行下面的命令修改配置文件：</p>
<p>$ sudo vim /etc/apt/sources.list</p>
<p>将文件修改为下面的内容：</p>
<p>deb <a href="https://mirrors.cloud.tencent.com/raspbian/raspbian/">https://mirrors.cloud.tencent.com/raspbian/raspbian/</a> buster main contrib non-free rpi</p>
<h1 id="uncomment-line-below-then-apt-get-update-to-enable-apt-get-source">Uncomment line below then &lsquo;apt-get update&rsquo; to enable &lsquo;apt-get source&rsquo;</h1>
<p>deb-src <a href="https://mirrors.cloud.tencent.com/raspbian/raspbian/">https://mirrors.cloud.tencent.com/raspbian/raspbian/</a> buster main contrib non-free rpi</p>
<p>修改另一个软件安装源的配置文件，命令如下所示：</p>
<p>$ sudo vim /etc/apt/sources.list.d/raspi.list</p>
<p>修改后的文件内容如下：</p>
<p>deb <a href="https://mirrors.cloud.tencent.com/raspberrypi/">https://mirrors.cloud.tencent.com/raspberrypi/</a> buster main</p>
<h1 id="uncomment-line-below-then-apt-get-update-to-enable-apt-get-source-1">Uncomment line below then &lsquo;apt-get update&rsquo; to enable &lsquo;apt-get source&rsquo;</h1>
<p>deb-src <a href="https://mirrors.cloud.tencent.com/raspberrypi/">https://mirrors.cloud.tencent.com/raspberrypi/</a> buster main</p>
<p>然后，你需要运行下面的命令更新安装源：</p>
<p>$ sudo apt-get clean all<br>
$ sudo apt-get update</p>
<p>现在，你可以运行下面命令安装麦克风阵列的驱动程序。因为这个驱动依赖的 wm8960 编解码器没有包含在树莓派系统的内核里面，需要重新加载内核，编译驱动，所以整个过程比较久。在等待的过程中，你可以先阅读这一讲的其他部分。</p>
<p>$ sudo apt-get install git<br>
$ git clone &ndash;depth=1 <a href="https://github.com/respeaker/seeed-voicecard">https://github.com/respeaker/seeed-voicecard</a><br>
$ cd seeed-voicecard<br>
$ sudo ./install.sh<br>
$ sudo reboot</p>
<p>树莓派重启之后，你可以在树莓派终端输入下面的命令，查看音频的输入和输出设备是否正常工作。</p>
<p>$ arecord -l<br>
$ aplay -l</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/2fa404b94c033a1043913c916c210621.png" alt=""></p>
<p>如果一切正常，我们就可以测试录音和播放功能了。在 ReSpeaker 2-Mics Pi HAT 的耳机插口上插入耳机或者扬声器，运行下面的命令，并说几句话。</p>
<p>$ arecord -d 5 test.wav<br>
$ aplay test.wav</p>
<p>另外，你也可以通过软件 <strong>AlsaMixer</strong>（命令 alsamixer）来配置声音设置和调整音量，左、右箭头键用于选择通道或设备，向上、向下箭头控制当前所选设备的音量。退出程序使用 ALT + Q，或者按 Esc 键。</p>
<p>为了简化开发，也考虑到麦克风硬件的限制，我们这里就先不关注前端语音信号处理的相关开发了。接下来，我们直接来到实现语音唤醒的环节。</p>
<h3 id="语音唤醒-1">语音唤醒</h3>
<p>为了实现语音唤醒，我们需要选择一个轻量级的、可以在树莓派上运行的唤醒词监测器软件。</p>
<p>你可能首先想到的是 <strong>Snowboy</strong>，没错，它确实是一个非常流行的工具。不过，Snowboy 团队在 2020 年初的时候宣布，2020 年 12 月 31 日会停止提供服务，所以我们只能寻找替代方案。</p>
<p>我选择的是Mycroft Precise，它是一个基于 RNN 神经网络的语音唤醒工具。</p>
<p>接下来，我们在树莓派安装 Mycroft Precise。因为需要训练唤醒词模型，我们需要基于源代码来编译、安装。</p>
<p>首先，我们通过 git 命令把 Mycroft Precise 的源代码下载到树莓派的 /home/pi 目录：</p>
<p>$ cd ~<br>
$ git clone <a href="https://github.com/mycroftai/mycroft-precise">https://github.com/mycroftai/mycroft-precise</a><br>
$ cd mycroft-precise</p>
<p>在安装之前，把 pypi 的安装源修改到清华数据源，可以获得更快的下载速度。我们打开目录中的 setup.sh 文件：</p>
<p>$ vim setup.sh</p>
<p>将文件中的这行内容：</p>
<p>extra-index-url=https://www.piwheels.org/simple</p>
<p>替换成下面的内容：</p>
<p>index-url=https://pypi.tuna.tsinghua.edu.cn/simple<br>
extra-index-url=https://www.piwheels.org/simple</p>
<p>然后，我们运行它自带的安装脚本，开始编译和安装。中间如果执行中断，可以重新执行这个命令，继续安装过程。（提示：有些 ARM 平台的库只有 piwheels 上有，所以这些库安装时速度还是很慢。这种情况下，可以电脑上使用下载工具获取这个模块的安装文件，然后上传到树莓派上，手动安装。）</p>
<p>$ ./setup.sh</p>
<p>安装完成后，我们开始使用 Mycroft Precise 来训练一个唤醒词模型，唤醒词可以根据喜好来选择，比如“极客时间”。</p>
<p>我们需要先激活 Python 的虚拟环境，因为 Mycroft Precise 在安装过程中创建了这个虚拟环境。</p>
<p>$ source .venv/bin/activate</p>
<p>接下来，我们通过工具 precise-collect 来收集语音模型训练的声音素材，运行后，根据提示录制 12 段声音。</p>
<p>$ precise-collect<br>
Audio name (Ex. recording-##): geektime.##</p>
<p>Press space to record (esc to exit)&hellip;<br>
Recording&hellip;<br>
Saved as geektime-00.wav<br>
Press space to record (esc to exit)&hellip;</p>
<p>然后，我们需要将这些声音随机分为两份，一份是训练样本，包括 8 个声音文件，另一份是测试样本，包括 4 个声音文件，并且把这两份样本分别放到 geektime/wake-word/ 和 /geektime/test/wake-word/ 这两个目录下面。</p>
<p>接着，我们执行下面的命令，生成神经网络模型 geektime.net：</p>
<p>$ precise-train -e 60 geektime.net geektime/</p>
<p>最后，我们还需要将 geektime.net 的模型格式做一下转换，将它从 Keras 模型格式改为 TensorFlow 模型格式，因为 TensorFlow 模型更加通用。</p>
<p>$ precise-convert geektime.net</p>
<p>执行完成之后，我们会得到两个文件：</p>
<ol>
<li>geektime.pb，TensorFlow 模型文件</li>
<li>geektime.pb.params，包含 Mycroft Precise 在处理音频时需要的一些参数信息。</li>
</ol>
<p>当然，为了提高模型的准确性，我们还可以使用 precise-train-incremental 工具来增加负样本，重新训练刚才的模型。如果环境复杂的话，你可以尝试一下。</p>
<p>然后，我们可以运行一段代码来测试这个唤醒词模型。不过，因为 portaudio 这个库在树莓派上运行有问题，我们需要先修复一下 portaudio 库。你可以运行下面的命令：</p>
<p>$ sudo apt-get remove libportaudio2<br>
$ sudo apt-get install libasound2-dev<br>
$ git clone -b alsapatch <a href="https://github.com/gglockner/portaudio">https://github.com/gglockner/portaudio</a><br>
$ cd portaudio<br>
$ ./configure &amp;&amp; make<br>
$ sudo make install<br>
$ sudo ldconfig</p>
<p>测试程序的代码如下：</p>
<h1 id="filekwsdemopy">File：kwsdemo.py</h1>
<p>#!/usr/bin/env python3</p>
<p>from precise_runner import PreciseEngine, PreciseRunner</p>
<p>engine = PreciseEngine(&lsquo;precise-engine/precise-engine&rsquo;, &lsquo;geektime.pb&rsquo;)<br>
runner = PreciseRunner(engine, on_activation=lambda: print(&lsquo;hello&rsquo;))<br>
runner.start()</p>
<h1 id="sleep-forever">Sleep forever</h1>
<p>from time import sleep<br>
while True:<br>
sleep(10)</p>
<p>现在，我们把 kwsdemo.py 文件，还有两个 geektime.pb 模型相关的文件，都上传到树莓派的 Mycroft Precise 目录下，然后运行 kwsdemo.py 文件，说出“极客时间”几个字，就会看到终端显示出“hello”这个单词。</p>
<h3 id="语音识别-1">语音识别</h3>
<p>对于语音识别，我们直接采用腾讯云提供的语音识别 SDK 来完成（你需要提前在腾讯云控制台开通这个服务）。它会将语音发送到云端，由云端服务器计算出文本信息。你可以通过下面命令来安装：</p>
<p>$ pip3 install tencentcloud-sdk-python</p>
<p>在开始使用之前，你需要访问这个链接创建一个密钥，然后记录下 SecretId 和 SecretKey 的信息。</p>
<p>你可以参考下面的代码，来完成一个录音文件的识别。</p>
<p>from tencentcloud.common import credential<br>
from tencentcloud.common.profile.client_profile import ClientProfile<br>
from tencentcloud.common.profile.http_profile import HttpProfile<br>
from tencentcloud.common.exception.tencent_cloud_sdk_exception import TencentCloudSDKException<br>
from tencentcloud.asr.v20190614 import asr_client, models<br>
import base64<br>
import io<br>
import sys</p>
<p>SECRET_ID = &ldquo;你的 Secret ID&rdquo;<br>
SECRET_KEY = &ldquo;你的 Secret Key&rdquo;</p>
<p>try:<br>
cred = credential.Credential(SECRET_ID, SECRET_KEY)<br>
httpProfile = HttpProfile()<br>
httpProfile.endpoint = &ldquo;asr.tencentcloudapi.com&rdquo;<br>
clientProfile = ClientProfile()<br>
clientProfile.httpProfile = httpProfile<br>
clientProfile.signMethod = &ldquo;TC3-HMAC-SHA256&rdquo; <br>
client = asr_client.AsrClient(cred, &ldquo;ap-beijing&rdquo;, clientProfile)<br>
#读取文件以及 base64<br>
with open(&rsquo;./geektime-00.wav&rsquo;, &ldquo;rb&rdquo;) as f:<br>
if sys.version_info[0] == 2:<br>
content = base64.b64encode(f.read())<br>
else:<br>
content = base64.b64encode(f.read()).decode(&lsquo;utf-8&rsquo;)<br>
f.close()<br>
#发送请求<br>
req = models.SentenceRecognitionRequest()<br>
params = {&ldquo;ProjectId&rdquo;:0,&ldquo;SubServiceType&rdquo;:2,&ldquo;SourceType&rdquo;:1,&ldquo;UsrAudioKey&rdquo;:&ldquo;sessionid-geektime&rdquo;}<br>
req._deserialize(params)<br>
req.DataLen = len(content)<br>
req.Data = content<br>
req.EngSerViceType = &ldquo;16k_zh&rdquo;<br>
req.VoiceFormat = &ldquo;wav&rdquo;<br>
resp = client.SentenceRecognition(req)<br>
print(resp.to_json_string())</p>
<p>except TencentCloudSDKException as err:<br>
print(err)</p>
<h3 id="语音合成-1">语音合成</h3>
<p>接下来，我来介绍一下语音合成。</p>
<p>你可能会问，刚才介绍技术架构的时候，不是还讲了自然语言理解、技能和自然语言生成吗？这里怎么跳过去了呢？</p>
<p>首先，因为我们的任务很简单，只需要查询语音识别的文本中是否有“开”、“灯”，和“关”、“灯”就可以完成判断，所以自然语言理解直接判断字符串是否匹配即可。</p>
<p>其次，我们要实现控制智能电灯，这个技能我在后面会介绍。</p>
<p>最后，智能音箱只需要反馈执行开关灯的结果就可以，比如“我已经把灯打开了”或者“我已经把灯关了”，自然语言生成的部分按照固定的文本就可以了，不需要考虑动态生成的问题。</p>
<p>语音合成，就是我们希望把类似“我已经把灯关了”这样的文本信息，转换为音频，便于智能音箱播放出来。你可以基于离线的 TTS 引擎来实现，比如HanTTS这个项目。</p>
<p>当然，我们也可以使用腾讯云的语音合成服务（你需要提前在腾讯云控制台开通这个服务）。你可以参考下面的代码：</p>
<p>import json<br>
import base64</p>
<p>from tencentcloud.common import credential<br>
from tencentcloud.common.profile.client_profile import ClientProfile<br>
from tencentcloud.common.profile.http_profile import HttpProfile<br>
from tencentcloud.common.exception.tencent_cloud_sdk_exception import TencentCloudSDKException<br>
from tencentcloud.tts.v20190823 import tts_client, models</p>
<p>SECRET_ID = &ldquo;你的 Secret ID&rdquo;<br>
SECRET_KEY = &ldquo;你的 Secret Key&rdquo;</p>
<p>try:<br>
cred = credential.Credential(SECRET_ID, SECRET_KEY)<br>
httpProfile = HttpProfile()<br>
httpProfile.endpoint = &ldquo;tts.tencentcloudapi.com&rdquo;</p>
<pre><code>clientProfile = ClientProfile()  
clientProfile.httpProfile = httpProfile  
client = tts_client.TtsClient(cred, &quot;ap-beijing&quot;, clientProfile)   

req = models.TextToVoiceRequest()  
params = {  
    &quot;Text&quot;: &quot;我已经把灯关了&quot;,  
    &quot;SessionId&quot;: &quot;sessionid-geektime&quot;,  
    &quot;ModelType&quot;: 1,  
    &quot;ProjectId&quot;: 0,  
    &quot;VoiceType&quot;: 1002  
}  
req.from_json_string(json.dumps(params))  

resp = client.TextToVoice(req)   
print(resp.to_json_string())   

if resp.Audio is not None:  
    audio = resp.Audio  
    data = base64.b64decode(audio)  
    wav_file = open(&quot;temp.wav&quot;, &quot;wb&quot;)  
    wav_file.write(data)  
    wav_file.close()  
</code></pre>
<p>except TencentCloudSDKException as err:<br>
print(err)</p>
<h2 id="通过智能音箱控制电灯">通过智能音箱控制电灯</h2>
<p>为了实现控制智能电灯的目的，我们需要借助物联网平台提供的开发接口。</p>
<p>首先，我们进入物联网开发平台，选择“智能家居”项目。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/0f401e1935ecf99913f0a1b56fc9d085.png" alt=""></p>
<p>然后，点击左侧的“应用开发”，进入新建应用的界面，点击“新建应用”。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/2bfb67dd2ac654beb6b73ac0a8182a15.png" alt=""></p>
<p>完成后，点击应用列表里面的应用名称，进入应用的详情页面。你可以看到应用的 SecretId 和 SecretKey 信息。这里，你需要将下面“关联产品”中的智能电灯勾选上。只有建立关联，应用才可以控制这个设备。</p>
<p><img src="https://raw.githubusercontent.com/epic1268/images/master/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/ff9fa6864cb1e813c50dfb251a497ce8.png" alt=""></p>
<p>具体代码可以参考腾讯提供的开源实现，包括iOS、Android和小程序。</p>
<p>不过，这种方式需要用户账号的登录认证，在树莓派上不太方便。还有一个方式就是基于物联网开发平台提供的通用 API 接口。其中的“设备远程控制”接口可以满足我们的需求。</p>
<p>具体的控制方法，你可以参考下面的代码（注意，目前只支持 ap-guangzhou 区域）。</p>
<p>import json<br>
from led2.main import PRODUCT_ID<br>
from tencentcloud.common import credential<br>
from tencentcloud.common.profile.client_profile import ClientProfile<br>
from tencentcloud.common.profile.http_profile import HttpProfile<br>
from tencentcloud.common.exception.tencent_cloud_sdk_exception import TencentCloudSDKException<br>
from tencentcloud.iotexplorer.v20190423 import iotexplorer_client, models</p>
<p>SECRET_ID = &ldquo;你的 Secret ID&rdquo;<br>
SECRET_KEY = &ldquo;你的 Secret Key&rdquo;<br>
PRODUCT_ID = &ldquo;你的 ProductID&rdquo;</p>
<p>def Light_control(state):<br>
try:<br>
cred = credential.Credential(SECRET_ID, SECRET_KEY)<br>
httpProfile = HttpProfile()<br>
httpProfile.endpoint = &ldquo;iotexplorer.tencentcloudapi.com&rdquo;</p>
<pre><code>    clientProfile = ClientProfile()  
    clientProfile.httpProfile = httpProfile  
    client = iotexplorer_client.IotexplorerClient(cred, &quot;ap-guangzhou&quot;, clientProfile)   

    req = models.ControlDeviceDataRequest()  
    data = {  
        &quot;power_switch&quot;: state  
    }  
    data_str = json.dumps(data)  

    params = {  
        &quot;DeviceName&quot;: &quot;Led_1&quot;,  
        &quot;ProductId&quot;: PRODUCT_ID,  
        &quot;Data&quot;: data_str  
    }  
    req.from_json_string(json.dumps(params))  

    resp = client.ControlDeviceData(req)   
    print(resp.to_json_string())   

except TencentCloudSDKException as err:   
    print(err)   
</code></pre>
<p>Light_control(0)</p>
<h2 id="小结">小结</h2>
<p>总结一下，在这一讲中，我介绍了智能音箱的技术架构，以及在树莓派上用于实现智能音箱的一些可选的技术方案，并且带你实现了语音控制智能电灯的目的。你需要重点关注的知识有：</p>
<ol>
<li>智能音箱的实现，需要前端音箱本体和后端云平台上一系列技术的支持。这些技术有前端的拾音、语音信号处理、语音唤醒和播音，以及后端的语音识别、自然语言理解、技能、自然语言生成和语音合成。</li>
<li>在树莓派的实现上，拾音可以选择使用麦克风阵列，因为基于麦克风阵列可以更好地实现前端语音信号处理，比如声源定位和波束成型等。</li>
<li>语言唤醒需要在智能音箱本体上实现，所以需要一些轻量级的识别引擎和训练好的唤醒词模型。之前比较流行的 Snowboy 将要停止服务，这里我选择了 Mycroft Precise 这个开源方案。</li>
<li>语音识别、自然语言理解、技能、自然语言生成和语音合成等任务适合基于云平台的能力来实现，因为云平台的计算能力更强，有更好的性能和准确度。</li>
</ol>
<p>智能音箱的技术也一直在发展，比如现在越来越多的智能音箱开始配备屏幕和摄像头，这为智能音箱引入了声音、UI 和视觉等多模态的交互方式，相应地，这也给声纹识别、人脸识别和动作识别等技术带来了新的应用场景。我相信智能音箱未来的产品形态和功能还会不断地进化和发展。</p>
<h2 id="思考题">思考题</h2>
<p>最后，我给你留一个思考题吧。</p>
<p>在这一讲中，我们是通过物联网平台提供的 API 接口来控制智能电灯的。除了这种方式，你还能想到其他的方法来远程控制智能电灯吗？你能实现一个虚拟的联网开关，基于场景联动来控制智能电灯的开和关吗？</p>
<p>欢迎你在留言区写下你思考的结果，也欢迎你将这一讲分享给你的朋友，大家一起交流学习。</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content"></span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        10100-01-10
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E7%89%A9%E8%81%94%E7%BD%91%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98/">物联网开发实战</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E4%BD%93%E9%AA%8C%E8%AE%BE%E8%AE%A1%E6%A1%88%E4%BE%8B%E8%AF%BE/20__%E6%80%8E%E6%A0%B7%E5%88%A9%E7%94%A8%E8%AE%BE%E8%AE%A1%E4%B8%AD%E5%8F%B0%E8%AE%A9%E8%AE%BE%E8%AE%A1%E5%B8%88%E4%B8%8D%E5%8A%A0%E7%8F%AD/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">20__怎样利用设计中台让设计师不加班？</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE/20__%E6%A1%8C%E9%9D%A2%E5%BC%80%E5%8F%91%E7%9A%84%E5%AE%8F%E8%A7%82%E8%A7%86%E8%A7%92/">
            <span class="next-text nav-default">20__桌面开发的宏观视角</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2024 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-FVZ07KBD4X"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-FVZ07KBD4X');
        }
      </script>






</body>
</html>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark性能调优实战 on Docs</title>
    <link>https://politcloud.org/tags/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/</link>
    <description>Recent content in Spark性能调优实战 on Docs</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 10 Jan 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://politcloud.org/tags/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>01__性能调优的必要性：Spark本身就很快，为啥还需要我调优？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/01__%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7spark%E6%9C%AC%E8%BA%AB%E5%B0%B1%E5%BE%88%E5%BF%AB%E4%B8%BA%E5%95%A5%E8%BF%98%E9%9C%80%E8%A6%81%E6%88%91%E8%B0%83%E4%BC%98/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/01__%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7spark%E6%9C%AC%E8%BA%AB%E5%B0%B1%E5%BE%88%E5%BF%AB%E4%B8%BA%E5%95%A5%E8%BF%98%E9%9C%80%E8%A6%81%E6%88%91%E8%B0%83%E4%BC%98/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在日常的开发工作中，我发现有个现象很普遍。很多开发者都认为 Spark 的执行性能已经非常强了，实际工作中只要按部就班地实现业务功能就可以了，没有必要进行性能调优。&lt;/p&gt;</description>
    </item>
    <item>
      <title>02__性能调优的本质：调优的手段五花八门，该从哪里入手？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/02__%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%84%E6%9C%AC%E8%B4%A8%E8%B0%83%E4%BC%98%E7%9A%84%E6%89%8B%E6%AE%B5%E4%BA%94%E8%8A%B1%E5%85%AB%E9%97%A8%E8%AF%A5%E4%BB%8E%E5%93%AA%E9%87%8C%E5%85%A5%E6%89%8B/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/02__%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%84%E6%9C%AC%E8%B4%A8%E8%B0%83%E4%BC%98%E7%9A%84%E6%89%8B%E6%AE%B5%E4%BA%94%E8%8A%B1%E5%85%AB%E9%97%A8%E8%AF%A5%E4%BB%8E%E5%93%AA%E9%87%8C%E5%85%A5%E6%89%8B/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;上节课，我们探讨了性能调优的必要性，结论是：尽管 Spark 自身运行高效，但作为开发者，我们仍然需要对应用进行性能调优。&lt;/p&gt;&#xA;&lt;p&gt;那么问题来了，性能调优该怎么做呢？面对成百上千行应用代码、近百个 Spark 配置项，我们该从哪里入手呢？我认为，要想弄清性能调优怎么入手，必须先得搞明白性能调优的本质是什么。&lt;/p&gt;</description>
    </item>
    <item>
      <title>03__RDD：为什么你必须要理解弹性分布式数据集？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/03__rdd%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E5%BF%85%E9%A1%BB%E8%A6%81%E7%90%86%E8%A7%A3%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/03__rdd%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E5%BF%85%E9%A1%BB%E8%A6%81%E7%90%86%E8%A7%A3%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;从今天开始，我们进入原理篇的学习。我会以性能调优为导向，给你详细讲讲 Spark 中的核心概念 RDD 和 DAG，以及重要组件调度系统、存储系统和内存管理。这节课，咱们先来说说 RDD。&lt;/p&gt;</description>
    </item>
    <item>
      <title>04__DAG与流水线：到底啥叫“内存计算”？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/04__dag%E4%B8%8E%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%88%B0%E5%BA%95%E5%95%A5%E5%8F%AB%E5%86%85%E5%AD%98%E8%AE%A1%E7%AE%97/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/04__dag%E4%B8%8E%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%88%B0%E5%BA%95%E5%95%A5%E5%8F%AB%E5%86%85%E5%AD%98%E8%AE%A1%E7%AE%97/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在日常的开发工作中，我发现有两种现象很普遍。&lt;/p&gt;&#xA;&lt;p&gt;第一种是缓存的滥用。无论是 RDD，还是 DataFrame，凡是能产生数据集的地方，开发同学一律用 cache 进行缓存，结果就是应用的执行性能奇差无比。开发同学也很委屈：“Spark 不是内存计算的吗？为什么把数据缓存到内存里去，性能反而更差了？”&lt;/p&gt;</description>
    </item>
    <item>
      <title>05__调度系统：“数据不动代码动”到底是什么意思？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/05__%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8A%A8%E4%BB%A3%E7%A0%81%E5%8A%A8%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/05__%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8A%A8%E4%BB%A3%E7%A0%81%E5%8A%A8%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在日常的开发与调优工作中，为了充分利用硬件资源，我们往往需要手工调节任务并行度来提升 CPU 利用率，控制任务并行度的参数是 Spark 的配置项：spark.default.parallelism。增加并行度确实能够充分利用闲置的 CPU 线程，但是，parallelism 数值也不宜过大，过大反而会引入过多的调度开销，得不偿失。&lt;/p&gt;</description>
    </item>
    <item>
      <title>06__存储系统：空间换时间，还是时间换空间？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/06__%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%A9%BA%E9%97%B4%E6%8D%A2%E6%97%B6%E9%97%B4%E8%BF%98%E6%98%AF%E6%97%B6%E9%97%B4%E6%8D%A2%E7%A9%BA%E9%97%B4/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/06__%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%A9%BA%E9%97%B4%E6%8D%A2%E6%97%B6%E9%97%B4%E8%BF%98%E6%98%AF%E6%97%B6%E9%97%B4%E6%8D%A2%E7%A9%BA%E9%97%B4/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;今天，我们来学习 Spark 的存储系统，它和我们上一讲学过的调度系统一样，都是 Spark 分布式计算引擎的基础设施之一。&lt;/p&gt;&#xA;&lt;p&gt;你可能会问：“在日常的开发工作中，除了业务逻辑实现，我真的需要去关心这么底层的东西吗？”确实，存储系统离开发者比较远。不过，如果把目光落在存储系统所服务的对象上，你很可能会改变这种看法。&lt;/p&gt;</description>
    </item>
    <item>
      <title>07__内存管理基础：Spark如何高效利用有限的内存空间？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/07__%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%9F%BA%E7%A1%80spark%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E5%88%A9%E7%94%A8%E6%9C%89%E9%99%90%E7%9A%84%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/07__%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%9F%BA%E7%A1%80spark%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E5%88%A9%E7%94%A8%E6%9C%89%E9%99%90%E7%9A%84%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;对于 Spark 这样的内存计算引擎来说，内存的管理与利用至关重要。业务应用只有充分利用内存，才能让执行性能达到最优。&lt;/p&gt;&#xA;&lt;p&gt;那么，你知道 Spark 是如何使用内存的吗？不同的内存区域之间的关系是什么，它们又是如何划分的？今天这一讲，我就结合一个有趣的小故事，来和你深入探讨一下 Spark 内存管理的基础知识。&lt;/p&gt;</description>
    </item>
    <item>
      <title>08__应用开发三原则：如何拓展自己的开发边界？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/08__%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B8%89%E5%8E%9F%E5%88%99%E5%A6%82%E4%BD%95%E6%8B%93%E5%B1%95%E8%87%AA%E5%B7%B1%E7%9A%84%E5%BC%80%E5%8F%91%E8%BE%B9%E7%95%8C/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/08__%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B8%89%E5%8E%9F%E5%88%99%E5%A6%82%E4%BD%95%E6%8B%93%E5%B1%95%E8%87%AA%E5%B7%B1%E7%9A%84%E5%BC%80%E5%8F%91%E8%BE%B9%E7%95%8C/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;从今天开始，我们就进入通用性能调优篇的学习了。这一篇，我们会从基本的开发原则、配置项、Shuffle 以及硬件资源这四个方面，去学习一些通用的调优方法和技巧，它们会适用于所有的计算场景。&lt;/p&gt;</description>
    </item>
    <item>
      <title>09__调优一筹莫展，配置项速查手册让你事半功倍！（上）</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/09__%E8%B0%83%E4%BC%98%E4%B8%80%E7%AD%B9%E8%8E%AB%E5%B1%95%E9%85%8D%E7%BD%AE%E9%A1%B9%E9%80%9F%E6%9F%A5%E6%89%8B%E5%86%8C%E8%AE%A9%E4%BD%A0%E4%BA%8B%E5%8D%8A%E5%8A%9F%E5%80%8D%E4%B8%8A/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/09__%E8%B0%83%E4%BC%98%E4%B8%80%E7%AD%B9%E8%8E%AB%E5%B1%95%E9%85%8D%E7%BD%AE%E9%A1%B9%E9%80%9F%E6%9F%A5%E6%89%8B%E5%86%8C%E8%AE%A9%E4%BD%A0%E4%BA%8B%E5%8D%8A%E5%8A%9F%E5%80%8D%E4%B8%8A/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;对于 Spark 性能调优来说，应用开发和配置项设置是两个最主要也最常用的入口。但在日常的调优工作中，每当我们需要从配置项入手寻找调优思路的时候，一打开 Spark 官网的 Configuration 页面，映入眼帘的就是上百个配置项。它们有的需要设置 True 或 False，有的需要给定明确的数值才能使用。这难免让我们蒙头转向、无所适从。&lt;/p&gt;</description>
    </item>
    <item>
      <title>10_调优一筹莫展，配置项速查手册让你事半功倍！（下）</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/10_%E8%B0%83%E4%BC%98%E4%B8%80%E7%AD%B9%E8%8E%AB%E5%B1%95%E9%85%8D%E7%BD%AE%E9%A1%B9%E9%80%9F%E6%9F%A5%E6%89%8B%E5%86%8C%E8%AE%A9%E4%BD%A0%E4%BA%8B%E5%8D%8A%E5%8A%9F%E5%80%8D%E4%B8%8B/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/10_%E8%B0%83%E4%BC%98%E4%B8%80%E7%AD%B9%E8%8E%AB%E5%B1%95%E9%85%8D%E7%BD%AE%E9%A1%B9%E9%80%9F%E6%9F%A5%E6%89%8B%E5%86%8C%E8%AE%A9%E4%BD%A0%E4%BA%8B%E5%8D%8A%E5%8A%9F%E5%80%8D%E4%B8%8B/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;上一讲，我们讲了硬件资源类的配置项。这一讲，我们继续说说 Shuffle 类和 Spark SQL 大类都有哪些配置项，它们的含义和作用，以及它们能解决的问题。同时，和上一讲一样，我们今天讲到的配置项也全部会围绕 Executors 展开。&lt;/p&gt;</description>
    </item>
    <item>
      <title>11__Shuffle的工作原理：为什么说Shuffle是一时无两的性能杀手？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/11__shuffle%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4shuffle%E6%98%AF%E4%B8%80%E6%97%B6%E6%97%A0%E4%B8%A4%E7%9A%84%E6%80%A7%E8%83%BD%E6%9D%80%E6%89%8B/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/11__shuffle%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4shuffle%E6%98%AF%E4%B8%80%E6%97%B6%E6%97%A0%E4%B8%A4%E7%9A%84%E6%80%A7%E8%83%BD%E6%9D%80%E6%89%8B/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;一提到 Shuffle，你能想到什么？我想很多人的第一反应都是应用中最顽固、最难解决的性能瓶颈。&lt;/p&gt;&#xA;&lt;p&gt;在之前的课程中，我们也不止一次地提到 Shuffle，尤其是在开发原则那一讲，我还建议你遵循“能省则省、能拖则拖”的原则，在应用中尽量去避免 Shuffle，如果受业务逻辑所限确实不能避免，就尽可能地把 Shuffle 往后拖。&lt;/p&gt;</description>
    </item>
    <item>
      <title>12__广播变量（一）：克制Shuffle，如何一招制胜！</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/12__%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E4%B8%80%E5%85%8B%E5%88%B6shuffle%E5%A6%82%E4%BD%95%E4%B8%80%E6%8B%9B%E5%88%B6%E8%83%9C/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/12__%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E4%B8%80%E5%85%8B%E5%88%B6shuffle%E5%A6%82%E4%BD%95%E4%B8%80%E6%8B%9B%E5%88%B6%E8%83%9C/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在数据分析领域，数据关联（Joins）是 Shuffle 操作的高发区，二者如影随从。可以说，有 Joins 的地方，就有 Shuffle。&lt;/p&gt;&#xA;&lt;p&gt;我们说过，面对 Shuffle，开发者应当“能省则省、能拖则拖”。我们已经讲过了怎么拖，拖指的就是，把应用中会引入 Shuffle 的操作尽可能地往后面的计算步骤去拖。那具体该怎么省呢？&lt;/p&gt;</description>
    </item>
    <item>
      <title>13__广播变量（二）：有哪些途径让Spark_SQL选择Broadcast_Joins？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/13__%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E4%BA%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E9%80%94%E5%BE%84%E8%AE%A9spark_sql%E9%80%89%E6%8B%A9broadcast_joins/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/13__%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E4%BA%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E9%80%94%E5%BE%84%E8%AE%A9spark_sql%E9%80%89%E6%8B%A9broadcast_joins/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;上一讲我们说到，在数据关联场景中，广播变量是克制 Shuffle 的杀手锏，用 Broadcast Joins 取代 Shuffle Joins 可以大幅提升执行性能。但是，很多同学只会使用默认的广播变量，不会去调优。那么，我们该怎么保证 Spark 在运行时优先选择 Broadcast Joins 策略呢？&lt;/p&gt;</description>
    </item>
    <item>
      <title>14__CPU视角：如何高效地利用CPU？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/14__cpu%E8%A7%86%E8%A7%92%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E5%9C%B0%E5%88%A9%E7%94%A8cpu/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/14__cpu%E8%A7%86%E8%A7%92%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E5%9C%B0%E5%88%A9%E7%94%A8cpu/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在日常的开发与调优工作中，总有同学向我抱怨：“为什么我的应用 CPU 利用率这么低？偌大的集群，CPU 利用率才 10%！”确实，较低的 CPU 利用率不仅对宝贵的硬件资源来说是一种非常大的浪费，也会让应用端到端的执行性能很难达到令人满意的效果。那么，在分布式应用开发中，我们到底该如何高效地利用 CPU？&lt;/p&gt;</description>
    </item>
    <item>
      <title>15__内存视角（一）：如何最大化内存的使用效率？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/15__%E5%86%85%E5%AD%98%E8%A7%86%E8%A7%92%E4%B8%80%E5%A6%82%E4%BD%95%E6%9C%80%E5%A4%A7%E5%8C%96%E5%86%85%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E6%95%88%E7%8E%87/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/15__%E5%86%85%E5%AD%98%E8%A7%86%E8%A7%92%E4%B8%80%E5%A6%82%E4%BD%95%E6%9C%80%E5%A4%A7%E5%8C%96%E5%86%85%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E6%95%88%E7%8E%87/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;上一讲我们说，想要提升 CPU 利用率，最重要的就是合理分配执行内存，但是，执行内存只是 Spark 内存分区的一部分。因此，想要合理分配执行内存，我们必须先从整体上合理划分好 Spark 所有的内存区域。&lt;/p&gt;</description>
    </item>
    <item>
      <title>16__内存视角（二）：如何有效避免Cache滥用？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/16__%E5%86%85%E5%AD%98%E8%A7%86%E8%A7%92%E4%BA%8C%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E9%81%BF%E5%85%8Dcache%E6%BB%A5%E7%94%A8/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/16__%E5%86%85%E5%AD%98%E8%A7%86%E8%A7%92%E4%BA%8C%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E9%81%BF%E5%85%8Dcache%E6%BB%A5%E7%94%A8/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在 Spark 的应用开发中，有效利用 Cache 往往能大幅提升执行性能。&lt;/p&gt;&#xA;&lt;p&gt;但某一天，有位同学却和我说，自己加了 Cache 之后，执行性能反而变差了。仔细看了这位同学的代码之后，我吓了一跳。代码中充斥着大量的&lt;code&gt;.cache&lt;/code&gt;，无论是 RDD，还是 DataFrame，但凡有分布式数据集的地方，后面几乎都跟着个&lt;code&gt;.cache&lt;/code&gt;。显然，Cache 滥用是执行性能变差的始作俑者。&lt;/p&gt;</description>
    </item>
    <item>
      <title>17__内存视角（三）：OOM都是谁的锅？怎么破？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/17__%E5%86%85%E5%AD%98%E8%A7%86%E8%A7%92%E4%B8%89oom%E9%83%BD%E6%98%AF%E8%B0%81%E7%9A%84%E9%94%85%E6%80%8E%E4%B9%88%E7%A0%B4/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/17__%E5%86%85%E5%AD%98%E8%A7%86%E8%A7%92%E4%B8%89oom%E9%83%BD%E6%98%AF%E8%B0%81%E7%9A%84%E9%94%85%E6%80%8E%E4%B9%88%E7%A0%B4/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;无论是批处理、流计算，还是数据分析、机器学习，只要是在 Spark 作业中，我们总能见到 OOM（Out Of Memory，内存溢出）的身影。一旦出现 OOM，作业就会中断，应用的业务功能也都无法执行。因此，及时处理 OOM 问题是我们日常开发中一项非常重要的工作。&lt;/p&gt;</description>
    </item>
    <item>
      <title>18__磁盘视角：如果内存无限大，磁盘还有用武之地吗？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/18__%E7%A3%81%E7%9B%98%E8%A7%86%E8%A7%92%E5%A6%82%E6%9E%9C%E5%86%85%E5%AD%98%E6%97%A0%E9%99%90%E5%A4%A7%E7%A3%81%E7%9B%98%E8%BF%98%E6%9C%89%E7%94%A8%E6%AD%A6%E4%B9%8B%E5%9C%B0%E5%90%97/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/18__%E7%A3%81%E7%9B%98%E8%A7%86%E8%A7%92%E5%A6%82%E6%9E%9C%E5%86%85%E5%AD%98%E6%97%A0%E9%99%90%E5%A4%A7%E7%A3%81%E7%9B%98%E8%BF%98%E6%9C%89%E7%94%A8%E6%AD%A6%E4%B9%8B%E5%9C%B0%E5%90%97/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;我们都知道，Spark 的优势在于内存计算。一提到“内存计算”，我们的第一反应都是：执行效率高！但如果听到“基于磁盘的计算”，就会觉得性能肯定好不到哪儿去。甚至有的人会想，如果 Spark 的内存无限大就好了，这样我们就可以把磁盘完全抛弃掉。当然，这个假设大概率不会成真，而且这种一刀切的思维也不正确。&lt;/p&gt;</description>
    </item>
    <item>
      <title>184-Spark性能调优实战</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/184-spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/184-spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/</guid>
      <description></description>
    </item>
    <item>
      <title>19__网络视角：如何有效降低网络开销？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/19__%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%92%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E9%99%8D%E4%BD%8E%E7%BD%91%E7%BB%9C%E5%BC%80%E9%94%80/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/19__%E7%BD%91%E7%BB%9C%E8%A7%86%E8%A7%92%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E9%99%8D%E4%BD%8E%E7%BD%91%E7%BB%9C%E5%BC%80%E9%94%80/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在平衡不同硬件资源的时候，相比 CPU、内存、磁盘，网络开销无疑是最拖后腿的那一个，这一点在处理延迟上表现得非常明显。&lt;/p&gt;&#xA;&lt;p&gt;下图就是不同硬件资源的处理延迟对比结果，我们可以看到最小的处理单位是纳秒。你可能对纳秒没什么概念，所以为了方便对比，我把纳秒等比放大到秒。这样，其他硬件资源的处理延迟也会跟着放大。最后一对比我们会发现，网络延迟是以天为单位的！&lt;/p&gt;</description>
    </item>
    <item>
      <title>20__RDD和DataFrame：既生瑜、何生亮</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/20__rdd%E5%92%8Cdataframe%E6%97%A2%E7%94%9F%E7%91%9C%E4%BD%95%E7%94%9F%E4%BA%AE/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/20__rdd%E5%92%8Cdataframe%E6%97%A2%E7%94%9F%E7%91%9C%E4%BD%95%E7%94%9F%E4%BA%AE/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;从今天开始，我们进入 Spark SQL 性能调优篇的学习。在这一篇中，我会先带你学习 Spark SQL 已有的优化机制，如 Catalyst、Tungsten 这些核心组件，以及 AQE、DPP 等新特性。深入理解这些内置的优化机制，会让你在开发应用之初就有一个比较高的起点。然后，针对数据分析中的典型场景，如数据关联，我们再去深入探讨性能调优的方法和技巧。&lt;/p&gt;</description>
    </item>
    <item>
      <title>21__Catalyst逻辑计划：你的SQL语句是怎么被优化的？（上）</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/21__catalyst%E9%80%BB%E8%BE%91%E8%AE%A1%E5%88%92%E4%BD%A0%E7%9A%84sql%E8%AF%AD%E5%8F%A5%E6%98%AF%E6%80%8E%E4%B9%88%E8%A2%AB%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%8A/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/21__catalyst%E9%80%BB%E8%BE%91%E8%AE%A1%E5%88%92%E4%BD%A0%E7%9A%84sql%E8%AF%AD%E5%8F%A5%E6%98%AF%E6%80%8E%E4%B9%88%E8%A2%AB%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%8A/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;上一讲我们说，Spark SQL 已经取代 Spark Core 成为了新一代的内核优化引擎，所有 Spark 子框架都能共享 Spark SQL 带来的性能红利，所以在 Spark 历次发布的新版本中，Spark SQL 占比最大。因此，Spark SQL 的优化过程是我们必须要掌握的。&lt;/p&gt;</description>
    </item>
    <item>
      <title>22__Catalyst物理计划：你的SQL语句是怎么被优化的（下）？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/22__catalyst%E7%89%A9%E7%90%86%E8%AE%A1%E5%88%92%E4%BD%A0%E7%9A%84sql%E8%AF%AD%E5%8F%A5%E6%98%AF%E6%80%8E%E4%B9%88%E8%A2%AB%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%8B/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/22__catalyst%E7%89%A9%E7%90%86%E8%AE%A1%E5%88%92%E4%BD%A0%E7%9A%84sql%E8%AF%AD%E5%8F%A5%E6%98%AF%E6%80%8E%E4%B9%88%E8%A2%AB%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%8B/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;上一讲我们说了，Catalyst 优化器的逻辑优化过程包含两个环节：逻辑计划解析和逻辑计划优化。逻辑优化的最终目的就是要把 Unresolved Logical Plan 从次优的 Analyzed Logical Plan 最终变身为执行高效的 Optimized Logical Plan。&lt;/p&gt;</description>
    </item>
    <item>
      <title>23__钨丝计划：Tungsten给开发者带来了哪些福报？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/23__%E9%92%A8%E4%B8%9D%E8%AE%A1%E5%88%92tungsten%E7%BB%99%E5%BC%80%E5%8F%91%E8%80%85%E5%B8%A6%E6%9D%A5%E4%BA%86%E5%93%AA%E4%BA%9B%E7%A6%8F%E6%8A%A5/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/23__%E9%92%A8%E4%B8%9D%E8%AE%A1%E5%88%92tungsten%E7%BB%99%E5%BC%80%E5%8F%91%E8%80%85%E5%B8%A6%E6%9D%A5%E4%BA%86%E5%93%AA%E4%BA%9B%E7%A6%8F%E6%8A%A5/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;通过前两讲的学习，我们知道在 Spark SQL 这颗智能大脑中，“左脑”Catalyst 优化器负责把查询语句最终转换成可执行的 Physical Plan。但是，把 Physical Plan 直接丢给 Spark 去执行并不是最优的选择，最优的选择是把它交给“右脑”Tungsten 再做一轮优化。&lt;/p&gt;</description>
    </item>
    <item>
      <title>24__Spark_3.0（一）：AQE的3个特性怎么才能用好？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/24__spark_3.0%E4%B8%80aqe%E7%9A%843%E4%B8%AA%E7%89%B9%E6%80%A7%E6%80%8E%E4%B9%88%E6%89%8D%E8%83%BD%E7%94%A8%E5%A5%BD/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/24__spark_3.0%E4%B8%80aqe%E7%9A%843%E4%B8%AA%E7%89%B9%E6%80%A7%E6%80%8E%E4%B9%88%E6%89%8D%E8%83%BD%E7%94%A8%E5%A5%BD/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;目前，距离 Spark 3.0 版本的发布已经将近一年的时间了，这次版本升级添加了自适应查询执行（AQE）、动态分区剪裁（DPP）和扩展的 Join Hints 等新特性。利用好这些新特性，可以让我们的性能调优如虎添翼。因此，我会用三讲的时间和你聊聊它们。今天，我们先来说说 AQE。&lt;/p&gt;</description>
    </item>
    <item>
      <title>25__Spark_3.0（二）：DPP特性该怎么用？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/25__spark_3.0%E4%BA%8Cdpp%E7%89%B9%E6%80%A7%E8%AF%A5%E6%80%8E%E4%B9%88%E7%94%A8/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/25__spark_3.0%E4%BA%8Cdpp%E7%89%B9%E6%80%A7%E8%AF%A5%E6%80%8E%E4%B9%88%E7%94%A8/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;DPP（Dynamic Partition Pruning，动态分区剪裁）是 Spark 3.0 版本中第二个引人注目的特性，它指的是在星型数仓的数据关联场景中，可以充分利用过滤之后的维度表，大幅削减事实表的数据扫描量，从整体上提升关联计算的执行性能。&lt;/p&gt;</description>
    </item>
    <item>
      <title>26__Join_Hints指南：不同场景下，如何选择Join策略？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/26__join_hints%E6%8C%87%E5%8D%97%E4%B8%8D%E5%90%8C%E5%9C%BA%E6%99%AF%E4%B8%8B%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9join%E7%AD%96%E7%95%A5/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/26__join_hints%E6%8C%87%E5%8D%97%E4%B8%8D%E5%90%8C%E5%9C%BA%E6%99%AF%E4%B8%8B%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9join%E7%AD%96%E7%95%A5/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在数据分析领域，数据关联可以说是最常见的计算场景了。因为使用的频率很高，所以 Spark 为我们准备了非常丰富的关联形式，包括 Inner Join、Left Join、Right Join、Anti Join、Semi Join 等等。&lt;/p&gt;</description>
    </item>
    <item>
      <title>27__大表Join小表：广播变量容不下小表怎么办？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/27__%E5%A4%A7%E8%A1%A8join%E5%B0%8F%E8%A1%A8%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E5%AE%B9%E4%B8%8D%E4%B8%8B%E5%B0%8F%E8%A1%A8%E6%80%8E%E4%B9%88%E5%8A%9E/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/27__%E5%A4%A7%E8%A1%A8join%E5%B0%8F%E8%A1%A8%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F%E5%AE%B9%E4%B8%8D%E4%B8%8B%E5%B0%8F%E8%A1%A8%E6%80%8E%E4%B9%88%E5%8A%9E/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在数据分析领域，大表 Join 小表的场景非常普遍。不过，大小是个相对的概念，通常来说，大表与小表尺寸相差 3 倍以上，我们就将其归类为“大表 Join 小表”的计算场景。因此，大表 Join 小表，仅仅意味着参与关联的两张表尺寸悬殊。&lt;/p&gt;</description>
    </item>
    <item>
      <title>28__大表Join大表（一）：什么是“分而治之”的调优思路？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/28__%E5%A4%A7%E8%A1%A8join%E5%A4%A7%E8%A1%A8%E4%B8%80%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E8%80%8C%E6%B2%BB%E4%B9%8B%E7%9A%84%E8%B0%83%E4%BC%98%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/28__%E5%A4%A7%E8%A1%A8join%E5%A4%A7%E8%A1%A8%E4%B8%80%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E8%80%8C%E6%B2%BB%E4%B9%8B%E7%9A%84%E8%B0%83%E4%BC%98%E6%80%9D%E8%B7%AF/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;上一讲，我们探讨了“大表 Join 小表”场景的调优思路和应对方法。那么，除了大表 Join 小表的场景，数据分析领域有没有“大表 Join 大表”的场景呢？确实是有的，它指的是参与 Join 的两张体量较大的事实表，尺寸相差在 3 倍以内，且全部无法放进广播变量。&lt;/p&gt;</description>
    </item>
    <item>
      <title>29__大表Join大表（二）：什么是负隅顽抗的调优思路？</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/29__%E5%A4%A7%E8%A1%A8join%E5%A4%A7%E8%A1%A8%E4%BA%8C%E4%BB%80%E4%B9%88%E6%98%AF%E8%B4%9F%E9%9A%85%E9%A1%BD%E6%8A%97%E7%9A%84%E8%B0%83%E4%BC%98%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/29__%E5%A4%A7%E8%A1%A8join%E5%A4%A7%E8%A1%A8%E4%BA%8C%E4%BB%80%E4%B9%88%E6%98%AF%E8%B4%9F%E9%9A%85%E9%A1%BD%E6%8A%97%E7%9A%84%E8%B0%83%E4%BC%98%E6%80%9D%E8%B7%AF/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在上一讲，我们说了应对“大表 Join 大表”的第一种调优思路是分而治之，也就是把一个庞大而又复杂的 Shuffle Join 转化为多个轻量的 Broadcast Joins。这一讲，我们接着来讲第二种调优思路：负隅顽抗。&lt;/p&gt;</description>
    </item>
    <item>
      <title>30_应用开发：北京市小客车（汽油车）摇号趋势分析</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/30_%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E5%8C%97%E4%BA%AC%E5%B8%82%E5%B0%8F%E5%AE%A2%E8%BD%A6%E6%B1%BD%E6%B2%B9%E8%BD%A6%E6%91%87%E5%8F%B7%E8%B6%8B%E5%8A%BF%E5%88%86%E6%9E%90/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/30_%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E5%8C%97%E4%BA%AC%E5%B8%82%E5%B0%8F%E5%AE%A2%E8%BD%A6%E6%B1%BD%E6%B2%B9%E8%BD%A6%E6%91%87%E5%8F%B7%E8%B6%8B%E5%8A%BF%E5%88%86%E6%9E%90/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;如果你也在北京生活，那小汽车摇号这件事大概率也和你息息相关。我身边很多人也一直都和我抱怨说：“小汽车摇号这件事太难了，遥遥无期，完全看不到希望，感觉还没买彩票靠谱呢”。&lt;/p&gt;</description>
    </item>
    <item>
      <title>31__性能调优：手把手带你提升应用的执行性能</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/31__%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E6%8F%90%E5%8D%87%E5%BA%94%E7%94%A8%E7%9A%84%E6%89%A7%E8%A1%8C%E6%80%A7%E8%83%BD/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/31__%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E6%8F%90%E5%8D%87%E5%BA%94%E7%94%A8%E7%9A%84%E6%89%A7%E8%A1%8C%E6%80%A7%E8%83%BD/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;在上一讲，我们一起完成了小汽车摇号趋势分析的应用开发，解决了 5 个案例。今天这一讲，我们逐一对这 5 个案例做性能调优，一起把专栏中学过的知识和技巧应用到实战中去。&lt;/p&gt;</description>
    </item>
    <item>
      <title>结束语__在时间面前，做一个笃定学习的人</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/%E7%BB%93%E6%9D%9F%E8%AF%AD__%E5%9C%A8%E6%97%B6%E9%97%B4%E9%9D%A2%E5%89%8D%E5%81%9A%E4%B8%80%E4%B8%AA%E7%AC%83%E5%AE%9A%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%BA%BA/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/%E7%BB%93%E6%9D%9F%E8%AF%AD__%E5%9C%A8%E6%97%B6%E9%97%B4%E9%9D%A2%E5%89%8D%E5%81%9A%E4%B8%80%E4%B8%AA%E7%AC%83%E5%AE%9A%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%BA%BA/</guid>
      <description>&lt;p&gt;你好，我是吴磊。&lt;/p&gt;&#xA;&lt;p&gt;时间犹如白驹过隙，不知不觉，就到了要和你说再见的时候。当编辑对我说：“老师，这周要把结束语赶出来哟”，我忽然愣住了，觉得有些恍惚和不真实，并没有像往常那样脱口而出：“好嘞，没问题！”因为我似乎已经习惯了赶稿子，也习惯了回答评论区的问题，习惯了和大家互动，更习惯了在群里插科打诨……&lt;/p&gt;</description>
    </item>
    <item>
      <title>开篇词__Spark性能调优，你该掌握这些“套路”</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/%E5%BC%80%E7%AF%87%E8%AF%8D__spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%BD%A0%E8%AF%A5%E6%8E%8C%E6%8F%A1%E8%BF%99%E4%BA%9B%E5%A5%97%E8%B7%AF/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/%E5%BC%80%E7%AF%87%E8%AF%8D__spark%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%BD%A0%E8%AF%A5%E6%8E%8C%E6%8F%A1%E8%BF%99%E4%BA%9B%E5%A5%97%E8%B7%AF/</guid>
      <description>&lt;p&gt;你好，我是吴磊，欢迎和我一起探索 Spark 应用的性能优化。&lt;/p&gt;&#xA;&lt;p&gt;2020 年 6 月，Spark 正式发布了新版本，从 2.4 直接跨越到了 3.0。这次大版本升级的亮点就在于性能优化，它添加了诸如自适应查询执行（AQE）、动态分区剪裁（DPP）、扩展的 Join Hints 等新特性。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

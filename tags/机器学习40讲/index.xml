<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习40讲 on Docs</title>
    <link>https://politcloud.org/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/</link>
    <description>Recent content in 机器学习40讲 on Docs</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 10 Jan 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://politcloud.org/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>01__频率视角下的机器学习</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/01__%E9%A2%91%E7%8E%87%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/01__%E9%A2%91%E7%8E%87%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;p&gt;在“人工智能基础课”中我曾提到，“概率”（probability）这个基本概念存在着两种解读方式，它们分别对应着&lt;strong&gt;概率的频率学派&lt;/strong&gt;（Frequentist）和&lt;strong&gt;贝叶斯学派&lt;/strong&gt;（Bayesian）。而解读方式上的差异也延伸到了以概率为基础的其他学科，尤其是机器学习之中。&lt;/p&gt;</description>
    </item>
    <item>
      <title>02__贝叶斯视角下的机器学习</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/02__%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/02__%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;p&gt;在上一篇文章中，我向你介绍了频率学派对概率、统计和机器学习的理解。今天则要转换视角，看一看贝叶斯学派解决这些问题的思路。&lt;/p&gt;&#xA;&lt;p&gt;还记得那个“九死一生”的例子吗？对其中 90% 的概率更直观、也更合理的解释是生病之后生还的可能性。之所以说频率主义的解释牵强，是因为没有哪个人能倒霉到三番五次地得这个病。当多次独立重复试验不可能实现时，就不存在从频率角度解读概率的理论基础。&lt;/p&gt;</description>
    </item>
    <item>
      <title>03__学什么与怎么学</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/03__%E5%AD%A6%E4%BB%80%E4%B9%88%E4%B8%8E%E6%80%8E%E4%B9%88%E5%AD%A6/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/03__%E5%AD%A6%E4%BB%80%E4%B9%88%E4%B8%8E%E6%80%8E%E4%B9%88%E5%AD%A6/</guid>
      <description>&lt;p&gt;男孩还是女孩？这是个问题！&lt;/p&gt;&#xA;&lt;p&gt;在中国人的生活中，生男生女可谓兹事体大，多少幸福与烦恼都因此而起。那么有没有办法提前做出准确的预测呢？当然有啦！通常在怀孕 4 个月时，胎儿的性别就可以通过 B 超得到准确的判断了，所以只要问一问医生轻松搞定。但是出于职业道德和执业法规的要求，医生一般是不会透露胎儿性别的。想要在怀孕的早期判断，终归还是要依赖祖辈流传下来的经验。&lt;/p&gt;</description>
    </item>
    <item>
      <title>04__计算学习理论</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/04__%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/04__%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/</guid>
      <description>&lt;p&gt;无论是频率学派的方法还是贝叶斯学派的方法，解决的都是怎么学的问题。但对一个给定的问题到底能够学到什么程度，还需要专门的&lt;strong&gt;计算学习理论&lt;/strong&gt;（computational learning theory）来解释。与机器学习中的各类具体算法相比，这部分内容会略显抽象。&lt;/p&gt;</description>
    </item>
    <item>
      <title>05__模型的分类方式</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/05__%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E7%B1%BB%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/05__%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%88%86%E7%B1%BB%E6%96%B9%E5%BC%8F/</guid>
      <description>&lt;p&gt;机器学习学的是输入和输出之间的映射关系，学到的映射会以模型的形式出现。从今天开始，我将和你聊聊关于模型的一些主题。&lt;/p&gt;&#xA;&lt;p&gt;大多数情况下，机器学习的任务是求解输入输出单独或者共同符合的概率分布，或者拟合输入输出之间的数量关系。&lt;strong&gt;从数据的角度看，如果待求解的概率分布或者数量关系可以用一组有限且固定数目的参数完全刻画，求出的模型就是参数模型（parametric model）；反过来，不满足这个条件的模型就是非参数模型（non-parametric model）&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>06__模型的设计准则</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/06__%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%87%86%E5%88%99/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/06__%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%87%86%E5%88%99/</guid>
      <description>&lt;p&gt;上学时你一定过学习新知识的经历：首先要结合老师的讲解进行消化理解，接着要做些练习题找到问题并加强巩固，最后通过考试来检验学习的最终效果。机器学习需要根据问题特点和已有数据确定&lt;strong&gt;具有最强解释性或预测力的模型&lt;/strong&gt;，其过程也可以划分为类似于“学习 - 练习 - 考试”这样的三个阶段，每个阶段的目标和使用的资源可以归纳如下：&lt;/p&gt;</description>
    </item>
    <item>
      <title>07__模型的验证方法</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/07__%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%AA%8C%E8%AF%81%E6%96%B9%E6%B3%95/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/07__%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%AA%8C%E8%AF%81%E6%96%B9%E6%B3%95/</guid>
      <description>&lt;p&gt;模型本身及其背后学习方法的&lt;strong&gt;泛化性能&lt;/strong&gt;（generalization performance），也就是模型对未知数据的预测能力，是机器学习的核心问题。可在一个问题的学习中，往往会出现不同的模型在训练集上具有类似的性能，这时就需要利用模型验证来从这些备选中做出选择。&lt;/p&gt;</description>
    </item>
    <item>
      <title>08__模型的评估指标</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/08__%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/08__%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</guid>
      <description>&lt;p&gt;用训练数据集拟合出备选模型的参数，再用验证数据集选出最优模型后，接下来就到了是骡子是马牵出来溜溜，也就是模型评估的阶段了。模型评估中使用的是测试数据集，通过衡量模型在从未出现过的数据上的性能来估计模型的泛化特性。为简便起见，我将以二分类任务为例来说明度量模型性能的不同指标。&lt;/p&gt;</description>
    </item>
    <item>
      <title>09__实验设计</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/09__%E5%AE%9E%E9%AA%8C%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/09__%E5%AE%9E%E9%AA%8C%E8%AE%BE%E8%AE%A1/</guid>
      <description>&lt;p&gt;和其他科学学科一样，机器学习也会借助实验获取关于目标的信息。宏观来看，实验的设计与分析正在逐渐脱离具体问题的限定，有成为一门独立学科的趋势。不管是物理学还是经济学，对实验的处理都存在着一些共性的准则。在本篇文章中，我就和你简单谈谈机器学习中有关实验设计与分析的一些原则性问题。&lt;/p&gt;</description>
    </item>
    <item>
      <title>10__特征预处理</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/10__%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/10__%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86/</guid>
      <description>&lt;p&gt;华盛顿大学教授、《终极算法》（The Master Algorithm）的作者佩德罗·多明戈斯曾在 Communications of The ACM 第 55 卷第 10 期上发表了一篇名为《机器学习你不得不知的那些事》（A Few Useful Things to Know about Machine Learning）的小文，介绍了 12 条机器学习中的“金科玉律”，其中的 7/8 两条说的就是对数据的作用的认识。&lt;/p&gt;</description>
    </item>
    <item>
      <title>11__基础线性回归：一元与多元</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/11__%E5%9F%BA%E7%A1%80%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%80%E5%85%83%E4%B8%8E%E5%A4%9A%E5%85%83/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/11__%E5%9F%BA%E7%A1%80%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%80%E5%85%83%E4%B8%8E%E5%A4%9A%E5%85%83/</guid>
      <description>&lt;p&gt;从今天开始，专栏将进入统计机器学习模块。虽然统计机器学习中千姿百态的模型让人眼花缭乱，但究其本原，它们都来源于最原始的&lt;strong&gt;线性回归&lt;/strong&gt;（linear regression）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>12__正则化处理：收缩方法与边际化</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/12__%E6%AD%A3%E5%88%99%E5%8C%96%E5%A4%84%E7%90%86%E6%94%B6%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B8%8E%E8%BE%B9%E9%99%85%E5%8C%96/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/12__%E6%AD%A3%E5%88%99%E5%8C%96%E5%A4%84%E7%90%86%E6%94%B6%E7%BC%A9%E6%96%B9%E6%B3%95%E4%B8%8E%E8%BE%B9%E9%99%85%E5%8C%96/</guid>
      <description>&lt;p&gt;今天的内容是线性回归的正则化扩展。正则化称得上是机器学习里的刮骨疗毒，刮的是过拟合（overfitting）这个任何机器学习方法都无法摆脱的附骨之疽。&lt;/p&gt;</description>
    </item>
    <item>
      <title>13__线性降维：主成分的使用</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/13__%E7%BA%BF%E6%80%A7%E9%99%8D%E7%BB%B4%E4%B8%BB%E6%88%90%E5%88%86%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/13__%E7%BA%BF%E6%80%A7%E9%99%8D%E7%BB%B4%E4%B8%BB%E6%88%90%E5%88%86%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>&lt;p&gt;在前一篇文章中，我以岭回归和 LASSO 为例介绍了线性回归的正则化处理。这两种方法都属于&lt;strong&gt;收缩方法&lt;/strong&gt;（shrinkage method），它们能够使线性回归的系数连续变化。但和岭回归不同的是，LASSO 可以将一部分属性的系数收缩为 0，事实上起到了筛选属性的作用。&lt;/p&gt;</description>
    </item>
    <item>
      <title>14__非线性降维：流形学习</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/14__%E9%9D%9E%E7%BA%BF%E6%80%A7%E9%99%8D%E7%BB%B4%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/14__%E9%9D%9E%E7%BA%BF%E6%80%A7%E9%99%8D%E7%BB%B4%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;p&gt;“云行雨施，品物流形”，这是儒家经典《易经》对万物流变的描述。两千多年之后，“流形”一词被数学家借鉴，用于命名与欧几里得空间局部同胚的拓扑空间。&lt;/p&gt;</description>
    </item>
    <item>
      <title>15__从回归到分类：联系函数与降维</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/15__%E4%BB%8E%E5%9B%9E%E5%BD%92%E5%88%B0%E5%88%86%E7%B1%BB%E8%81%94%E7%B3%BB%E5%87%BD%E6%95%B0%E4%B8%8E%E9%99%8D%E7%BB%B4/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/15__%E4%BB%8E%E5%9B%9E%E5%BD%92%E5%88%B0%E5%88%86%E7%B1%BB%E8%81%94%E7%B3%BB%E5%87%BD%E6%95%B0%E4%B8%8E%E9%99%8D%E7%BB%B4/</guid>
      <description>&lt;p&gt;线性模型最初被用来解决回归问题（regression），可在实际应用中，更加普遍的是分类问题（classification）。要用线性模型解决分类问题的话，就需要将线性模型原始的连续输出转换成不同的类别。&lt;/p&gt;</description>
    </item>
    <item>
      <title>16__建模非正态分布：广义线性模型</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/16__%E5%BB%BA%E6%A8%A1%E9%9D%9E%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/16__%E5%BB%BA%E6%A8%A1%E9%9D%9E%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;p&gt;直观来看，上一篇文章介绍的逻辑回归只是对普通线性回归的输出加以变换，以满足问题的需要。但在这简单的现象背后，以逻辑回归为代表的这类线性模型的推广具有更加深刻的数学内涵，因而被称为&lt;strong&gt;广义线性模型&lt;/strong&gt;（generalized linear model）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>17__几何角度看分类：支持向量机</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/17__%E5%87%A0%E4%BD%95%E8%A7%92%E5%BA%A6%E7%9C%8B%E5%88%86%E7%B1%BB%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/17__%E5%87%A0%E4%BD%95%E8%A7%92%E5%BA%A6%E7%9C%8B%E5%88%86%E7%B1%BB%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</guid>
      <description>&lt;p&gt;前文中介绍过的逻辑回归是基于似然度的分类方法，通过对数据概率建模来得到软输出。而在另一类基于判别式的硬输出分类方法中，代表性较强的就得数今天要介绍的支持向量机了。&lt;/p&gt;</description>
    </item>
    <item>
      <title>18__从全局到局部：核技巧</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/18__%E4%BB%8E%E5%85%A8%E5%B1%80%E5%88%B0%E5%B1%80%E9%83%A8%E6%A0%B8%E6%8A%80%E5%B7%A7/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/18__%E4%BB%8E%E5%85%A8%E5%B1%80%E5%88%B0%E5%B1%80%E9%83%A8%E6%A0%B8%E6%8A%80%E5%B7%A7/</guid>
      <description>&lt;p&gt;俗话说得好：“支持向量机有三宝，间隔对偶核技巧”。在上一篇文章中我和你分享了间隔这个核心概念，今天就来看看对偶和核技巧的使用。对偶性主要应用在最优决策边界的求解中，其逻辑比较简单。&lt;/p&gt;</description>
    </item>
    <item>
      <title>19__非参数化的局部模型：K近邻</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/19__%E9%9D%9E%E5%8F%82%E6%95%B0%E5%8C%96%E7%9A%84%E5%B1%80%E9%83%A8%E6%A8%A1%E5%9E%8Bk%E8%BF%91%E9%82%BB/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/19__%E9%9D%9E%E5%8F%82%E6%95%B0%E5%8C%96%E7%9A%84%E5%B1%80%E9%83%A8%E6%A8%A1%E5%9E%8Bk%E8%BF%91%E9%82%BB/</guid>
      <description>&lt;p&gt;到目前为止，专栏中介绍的机器学习模型都属于参数模型，它们利用训练数据求解出关于问题的一般性知识，再将这些知识通过全局性模型的结构和参数加以外化。&lt;/p&gt;</description>
    </item>
    <item>
      <title>20__基于距离的学习：聚类与度量学习</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/20__%E5%9F%BA%E4%BA%8E%E8%B7%9D%E7%A6%BB%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%81%9A%E7%B1%BB%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/20__%E5%9F%BA%E4%BA%8E%E8%B7%9D%E7%A6%BB%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%81%9A%E7%B1%BB%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;p&gt;截至目前，我所介绍的模型都属于监督学习范畴，它们处理具有标签的输入数据，给出意义明确的输出，回归模型输出的是连续的回归值，分类模型输出的是离散的类别标签，这些模型都属于&lt;strong&gt;预测模型&lt;/strong&gt;（predictive model）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>21__基函数扩展：属性的非线性化</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/21__%E5%9F%BA%E5%87%BD%E6%95%B0%E6%89%A9%E5%B1%95%E5%B1%9E%E6%80%A7%E7%9A%84%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%8C%96/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/21__%E5%9F%BA%E5%87%BD%E6%95%B0%E6%89%A9%E5%B1%95%E5%B1%9E%E6%80%A7%E7%9A%84%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%8C%96/</guid>
      <description>&lt;p&gt;虽然线性回归是机器学习中最基础的模型，但它的表达能力会天然地受到线性函数的限制，用它来模拟多项式函数或者指数函数等非线性的关系时，不可避免地会出现误差。要获得更强的表达能力，必须要把非线性的元素纳入到学习模型之中。&lt;/p&gt;</description>
    </item>
    <item>
      <title>22__自适应的基函数：神经网络</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/22__%E8%87%AA%E9%80%82%E5%BA%94%E7%9A%84%E5%9F%BA%E5%87%BD%E6%95%B0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/22__%E8%87%AA%E9%80%82%E5%BA%94%E7%9A%84%E5%9F%BA%E5%87%BD%E6%95%B0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</guid>
      <description>&lt;p&gt;回眸人工神经网络的前半生，不由得让人唏嘘造化弄人。出道即巅峰的它经历了短暂的辉煌之后便以惊人的速度陨落，几乎沦落到人人喊打的境地。可谁曾想三十年河东三十年河西，一位天才的出现让神经网络起死回生，众人的态度也迅速从避之不及变成趋之若鹜。如果人工神经网络果真有一天如人所愿实现了智能，不知它会对自己的命运作何评价。&lt;/p&gt;</description>
    </item>
    <item>
      <title>23__层次化的神经网络：深度学习</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/23__%E5%B1%82%E6%AC%A1%E5%8C%96%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/23__%E5%B1%82%E6%AC%A1%E5%8C%96%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;p&gt;虽然只是对生物神经网络的低水平模仿，人工神经网络却给机器学习打开了一扇全新的大门。自适应的特性让它能够灵活地更新参数，非线性则赋予它具有更加强大的表达能力。曾经的阿喀琉斯之踵——异或问题也随着隐藏层的引入迎刃而解，由原始特征重构而成的导出特征使多层感知器摆脱了对数据集线性可分的限制，呈现在神经网络前方的是大有可为的广阔天地。&lt;/p&gt;</description>
    </item>
    <item>
      <title>24__深度编解码：表示学习</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/24__%E6%B7%B1%E5%BA%A6%E7%BC%96%E8%A7%A3%E7%A0%81%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/24__%E6%B7%B1%E5%BA%A6%E7%BC%96%E8%A7%A3%E7%A0%81%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;p&gt;在上一讲中我提到，深度学习既可以用于解释也可以用于预测。在实际中，这两个功能通常被组合使用，解释功能可以看作编码器，对高维信息进行低维重构；预测功能则可以看作解码器，将低维重构恢复成高维信息。&lt;/p&gt;</description>
    </item>
    <item>
      <title>25__基于特征的区域划分：树模型</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/25__%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E7%9A%84%E5%8C%BA%E5%9F%9F%E5%88%92%E5%88%86%E6%A0%91%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/25__%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E7%9A%84%E5%8C%BA%E5%9F%9F%E5%88%92%E5%88%86%E6%A0%91%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;p&gt;不知道你是否留意过非洲的地图？和其他大洲按照地理边界划分国界的方式不同，很多非洲国家的国境线都是规则的直线条组合。这种非自然的划分背后隐藏着一段屈辱的历史：19 世纪起，欧洲的资本主义新贵们开始了对非洲的掠夺。而在巧取豪夺资源之外，他们也没有忘记抢占地盘，这些横平竖直的国境线就是对当年殖民主义者瓜分非洲无声的控诉。&lt;/p&gt;</description>
    </item>
    <item>
      <title>26__集成化处理：Boosting与Bagging</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/26__%E9%9B%86%E6%88%90%E5%8C%96%E5%A4%84%E7%90%86boosting%E4%B8%8Ebagging/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/26__%E9%9B%86%E6%88%90%E5%8C%96%E5%A4%84%E7%90%86boosting%E4%B8%8Ebagging/</guid>
      <description>&lt;p&gt;伊壁鸠鲁（Epicurus）是古希腊一位伟大的哲学家，其哲学思想自成一派。在认识论上，伊壁鸠鲁最核心的观点就是“多重解释原则”（Prinicple of Multiple Explanantions），其内容是当多种理论都能符合观察到的现象时，就要将它们全部保留。这在某种程度上可以看成是机器学习中集成方法的哲学基础。&lt;/p&gt;</description>
    </item>
    <item>
      <title>27__万能模型：梯度提升与随机森林</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/27__%E4%B8%87%E8%83%BD%E6%A8%A1%E5%9E%8B%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/27__%E4%B8%87%E8%83%BD%E6%A8%A1%E5%9E%8B%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</guid>
      <description>&lt;p&gt;上一篇文章中我和你分享了提升法和装袋法这两种典型的集成方法，它们都可以用在决策树模型上，对多棵不同的树进行组合。然而直接使用这两种集成方法只是初级的策略，将它们的强化版用在决策树上可以得到更加强大的万能模型，也就是梯度提升决策树和随机森林。&lt;/p&gt;</description>
    </item>
    <item>
      <title>28__最简单的概率图：朴素贝叶斯</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/28__%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E6%A6%82%E7%8E%87%E5%9B%BE%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/28__%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E6%A6%82%E7%8E%87%E5%9B%BE%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</guid>
      <description>&lt;p&gt;从今天起，我们将进入概率图模型的模块，以贝叶斯的角度重新审视机器学习。&lt;/p&gt;&#xA;&lt;p&gt;在机器学习任务中，输入和输出之间并不是简单的一对一的决定关系，两者之间通常存在着一些可见或不可见的中间变量。要计算输出变量的概率分布，就得把这些中间变量纳入到建模的框架之中。要简洁明快地表达多个变量之间的复杂的相关关系，&lt;strong&gt;图模型&lt;/strong&gt;无疑是理想的选择。将图模型和概率模型结合起来，就是这个模块的主题——&lt;strong&gt;概率图模型&lt;/strong&gt;（probabilistic graphical model）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>29__有向图模型：贝叶斯网络</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/29__%E6%9C%89%E5%90%91%E5%9B%BE%E6%A8%A1%E5%9E%8B%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/29__%E6%9C%89%E5%90%91%E5%9B%BE%E6%A8%A1%E5%9E%8B%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/</guid>
      <description>&lt;p&gt;在上一篇文章中，我和你分享了最简单的概率图模型——朴素贝叶斯分类器。由于朴素贝叶斯假定不同的属性相互独立，因而它的概率图具有发散的星型结构。但在实际当中，这样的条件独立性几乎是不可能满足的，属性之间总会有些概率性的关联，如果将属性之间的关联体现在概率图模型中，就相当于把朴素贝叶斯中互相独立的结点联结起来，得到的正是贝叶斯网络。&lt;/p&gt;</description>
    </item>
    <item>
      <title>30__无向图模型：马尔可夫随机场</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/30__%E6%97%A0%E5%90%91%E5%9B%BE%E6%A8%A1%E5%9E%8B%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%9A%8F%E6%9C%BA%E5%9C%BA/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/30__%E6%97%A0%E5%90%91%E5%9B%BE%E6%A8%A1%E5%9E%8B%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%9A%8F%E6%9C%BA%E5%9C%BA/</guid>
      <description>&lt;p&gt;作为有向图模型的代表，贝叶斯网络将随机变量之间的条件独立性与依赖关系嵌入到图结构之中，既有助于直观表示，又能简化计算。但这是不是意味着贝叶斯网络可以通吃所有概率关系呢？并非如此。&lt;/p&gt;</description>
    </item>
    <item>
      <title>31__建模连续分布：高斯网络</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/31__%E5%BB%BA%E6%A8%A1%E8%BF%9E%E7%BB%AD%E5%88%86%E5%B8%83%E9%AB%98%E6%96%AF%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/31__%E5%BB%BA%E6%A8%A1%E8%BF%9E%E7%BB%AD%E5%88%86%E5%B8%83%E9%AB%98%E6%96%AF%E7%BD%91%E7%BB%9C/</guid>
      <description>&lt;p&gt;无论是贝叶斯网络还是马尔可夫随机场，定义的变量都服从取值有限的离散分布，变量之间的关联则可以用有限维度的矩阵来表示。如果将随机变量的范围从离散型扩展到连续型，变量的可能取值就有无穷多个，这时变量之间的依赖关系就不能再用表格的形式来表示了，需要重新定义概率图模型中的相互作用与条件独立性。&lt;/p&gt;</description>
    </item>
    <item>
      <title>32__从有限到无限：高斯过程</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/32__%E4%BB%8E%E6%9C%89%E9%99%90%E5%88%B0%E6%97%A0%E9%99%90%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/32__%E4%BB%8E%E6%9C%89%E9%99%90%E5%88%B0%E6%97%A0%E9%99%90%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/</guid>
      <description>&lt;p&gt;上一讲中我基于高斯分布介绍了建模连续型分布的高斯网络，其中所用到的多元高斯分布是一元高斯分布的扩展与推广。但在多元高斯分布中，变量的数目依然是有限的。如果像傅里叶变换（Fourier transform）那样，将无数个服从高斯概率的随机变量叠加到一起，这个在向量空间上形成的高斯分布就变成了函数空间上的高斯过程。&lt;/p&gt;</description>
    </item>
    <item>
      <title>33__序列化建模：隐马尔可夫模型</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/33__%E5%BA%8F%E5%88%97%E5%8C%96%E5%BB%BA%E6%A8%A1%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/33__%E5%BA%8F%E5%88%97%E5%8C%96%E5%BB%BA%E6%A8%A1%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;p&gt;前几讲中介绍概率图模型都没有涉及“时间”尺度，模型所表示的都是同一时刻下的状态，因而不能建模随机变量的动态特性。如果要定义系统在时间尺度上的演化，就需要引入&lt;strong&gt;系统状态&lt;/strong&gt;（system state）的概念，每一时刻的系统状态都是表示系统属性的随机变量。&lt;/p&gt;</description>
    </item>
    <item>
      <title>34__连续序列化模型：线性动态系统</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/34__%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97%E5%8C%96%E6%A8%A1%E5%9E%8B%E7%BA%BF%E6%80%A7%E5%8A%A8%E6%80%81%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/34__%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97%E5%8C%96%E6%A8%A1%E5%9E%8B%E7%BA%BF%E6%80%A7%E5%8A%A8%E6%80%81%E7%B3%BB%E7%BB%9F/</guid>
      <description>&lt;p&gt;在隐马尔可夫模型中，一般的假设是状态和观测都是离散的随机变量。如果假定隐藏的状态变量满足连续分布，那么得到的就是线性动态系统。虽然这个概念更多地出现在信号处理与控制论中，看起来和机器学习风马牛不相及，但是从马尔可夫性和贝叶斯概率的角度观察，&lt;strong&gt;线性系统也是一类重要的处理序列化数据的模型&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>35__精确推断：变量消除及其拓展</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/35__%E7%B2%BE%E7%A1%AE%E6%8E%A8%E6%96%AD%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4%E5%8F%8A%E5%85%B6%E6%8B%93%E5%B1%95/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/35__%E7%B2%BE%E7%A1%AE%E6%8E%A8%E6%96%AD%E5%8F%98%E9%87%8F%E6%B6%88%E9%99%A4%E5%8F%8A%E5%85%B6%E6%8B%93%E5%B1%95/</guid>
      <description>&lt;p&gt;在前面的几讲中，我和你分享了概率图模型中的一些代表性模型，它们都属于表示（representation）的范畴，将关系通过结点和有向边精确地表示出来。接下来，我们将对概率图模型的推断任务加以介绍。&lt;/p&gt;</description>
    </item>
    <item>
      <title>36__确定近似推断：变分贝叶斯</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/36__%E7%A1%AE%E5%AE%9A%E8%BF%91%E4%BC%BC%E6%8E%A8%E6%96%AD%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/36__%E7%A1%AE%E5%AE%9A%E8%BF%91%E4%BC%BC%E6%8E%A8%E6%96%AD%E5%8F%98%E5%88%86%E8%B4%9D%E5%8F%B6%E6%96%AF/</guid>
      <description>&lt;p&gt;虽然精确推断能够准确计算结果，但它的应用范围却严重受限。当网络的规模较大、结点较多时，大量复杂的因子会严重削弱精确推断的可操作性，虽然这类方法在原则上依然可行，却难以解决实际问题。&lt;/p&gt;</description>
    </item>
    <item>
      <title>37__随机近似推断：MCMC</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/37__%E9%9A%8F%E6%9C%BA%E8%BF%91%E4%BC%BC%E6%8E%A8%E6%96%ADmcmc/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/37__%E9%9A%8F%E6%9C%BA%E8%BF%91%E4%BC%BC%E6%8E%A8%E6%96%ADmcmc/</guid>
      <description>&lt;p&gt;本质上说，确定性近似是遵循着一定的原则，使用一个分布来近似另一个分布，近似结果取决于确定的规则。可是在很多预测任务中，完整的后验分布并不是必需的，我们关注的对象只是某个因变量在后验分布下的期望，或者具有最大后验概率的那个取值。这时再使用确定性近似来计算预测结果，尤其是连续函数在连续分布下的预测结果又是个在计算上颇为棘手的问题。&lt;/p&gt;</description>
    </item>
    <item>
      <title>38__完备数据下的参数学习：有向图与无向图</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/38__%E5%AE%8C%E5%A4%87%E6%95%B0%E6%8D%AE%E4%B8%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%E6%9C%89%E5%90%91%E5%9B%BE%E4%B8%8E%E6%97%A0%E5%90%91%E5%9B%BE/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/38__%E5%AE%8C%E5%A4%87%E6%95%B0%E6%8D%AE%E4%B8%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%E6%9C%89%E5%90%91%E5%9B%BE%E4%B8%8E%E6%97%A0%E5%90%91%E5%9B%BE/</guid>
      <description>&lt;p&gt;介绍完表示和推断之后，我们将进入概率图模型的最后一个任务，也就是学习问题。&lt;/p&gt;&#xA;&lt;p&gt;在推断任务中，我们会根据已知的模型来确定实例的特性，模型的结构和参数都作为输入的一部分出现。&lt;strong&gt;学习任务&lt;/strong&gt;（model learning）则是将推断任务的过程颠倒过来，根据数据来构造出能够反映数据潜在规律的模型，也就是对概率图模型的训练。&lt;/p&gt;</description>
    </item>
    <item>
      <title>38-机器学习40讲</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/38-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/38-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/</guid>
      <description></description>
    </item>
    <item>
      <title>39__隐变量下的参数学习：EM方法与混合模型</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/39__%E9%9A%90%E5%8F%98%E9%87%8F%E4%B8%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0em%E6%96%B9%E6%B3%95%E4%B8%8E%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/39__%E9%9A%90%E5%8F%98%E9%87%8F%E4%B8%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0em%E6%96%B9%E6%B3%95%E4%B8%8E%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;p&gt;前面我曾介绍过隐马尔可夫和线性动态系统这类隐变量模型。所谓的隐变量表示的其实是数据的不完整性，也就是训练数据并不能给出关于模型结果的全部信息，因此只能对模型中未知的状态做出概率性的推测。&lt;/p&gt;</description>
    </item>
    <item>
      <title>40__结构学习：基于约束与基于评分</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/40__%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E5%9F%BA%E4%BA%8E%E7%BA%A6%E6%9D%9F%E4%B8%8E%E5%9F%BA%E4%BA%8E%E8%AF%84%E5%88%86/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/40__%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E5%9F%BA%E4%BA%8E%E7%BA%A6%E6%9D%9F%E4%B8%8E%E5%9F%BA%E4%BA%8E%E8%AF%84%E5%88%86/</guid>
      <description>&lt;p&gt;看完了参数学习，我们再来看看结构学习。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;结构学习&lt;/strong&gt;（structure learning）的任务是找到与数据匹配度最高的网络结构，需要同时学习未知图模型的结构和参数。这也很容易理解：模型的结构都不知道，参数自然也是不知道的，所以需要一并来学习。&lt;strong&gt;结构学习的任务是根据训练数据集找到结构最恰当的模型&lt;/strong&gt;，这无疑比参数学习要复杂得多，也有更多的不确定性。&lt;/p&gt;</description>
    </item>
    <item>
      <title>结课__终有一天，你将为今天的付出骄傲</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/%E7%BB%93%E8%AF%BE__%E7%BB%88%E6%9C%89%E4%B8%80%E5%A4%A9%E4%BD%A0%E5%B0%86%E4%B8%BA%E4%BB%8A%E5%A4%A9%E7%9A%84%E4%BB%98%E5%87%BA%E9%AA%84%E5%82%B2/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/%E7%BB%93%E8%AF%BE__%E7%BB%88%E6%9C%89%E4%B8%80%E5%A4%A9%E4%BD%A0%E5%B0%86%E4%B8%BA%E4%BB%8A%E5%A4%A9%E7%9A%84%E4%BB%98%E5%87%BA%E9%AA%84%E5%82%B2/</guid>
      <description>&lt;p&gt;不知不觉间，又一个 40 期的机器学习专栏也走到了尾声。在专栏里，我从理解概率的两大流派入手，以每种流派中的各个模型为主线，对统计机器学习和贝叶斯机器学习做了系统的介绍，并从这些模型中梳理出它们之间关系的脉络，帮助你尽可能地从更加宏观的角度来理解模型内部的关联。&lt;/p&gt;</description>
    </item>
    <item>
      <title>开篇词__打通修炼机器学习的任督二脉</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/%E5%BC%80%E7%AF%87%E8%AF%8D__%E6%89%93%E9%80%9A%E4%BF%AE%E7%82%BC%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%BB%BB%E7%9D%A3%E4%BA%8C%E8%84%89/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/%E5%BC%80%E7%AF%87%E8%AF%8D__%E6%89%93%E9%80%9A%E4%BF%AE%E7%82%BC%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%BB%BB%E7%9D%A3%E4%BA%8C%E8%84%89/</guid>
      <description>&lt;p&gt;你好，我是王天一，我在“机器学习 40 讲”欢迎你的到来！&lt;/p&gt;&#xA;&lt;p&gt;在上一季的专栏中，我与你一起走马观花地浏览了学习人工智能所需要的基础数学、当前流行的深度学习、以及其他可能实现智能的技术路径。广义的人工智能概念可以说包罗万象，其中每一个细分的子领域发展到今天都值得大书特书。40 篇文章的篇幅绘出的人工智能轮廓就像是一幅低分辨率的全景画，覆盖广度的同时必然难以兼顾深度。&lt;/p&gt;</description>
    </item>
    <item>
      <title>总结课__贝叶斯学习的模型体系</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/%E6%80%BB%E7%BB%93%E8%AF%BE__%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%BD%93%E7%B3%BB/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/%E6%80%BB%E7%BB%93%E8%AF%BE__%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%BD%93%E7%B3%BB/</guid>
      <description>&lt;p&gt;在今天这篇总结中，我将对贝叶斯机器学习中涉及的模型做一个系统的梳理。虽然这个模块的主题是概率图模型，内容也围绕着概率图的三大问题——表示、推断和学习展开，但概率图归根结底是手段，其目的是&lt;strong&gt;将概率分布用图结构表示出来，进而从贝叶斯定理出发，从概率角度解决机器学习的问题&lt;/strong&gt;。因此从宏观的角度来对概率模型加以整理是很有必要的。&lt;/p&gt;</description>
    </item>
    <item>
      <title>总结课__机器学习的模型体系</title>
      <link>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/%E6%80%BB%E7%BB%93%E8%AF%BE__%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%BD%93%E7%B3%BB/</link>
      <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://politcloud.org/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A040%E8%AE%B2/%E6%80%BB%E7%BB%93%E8%AF%BE__%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%BD%93%E7%B3%BB/</guid>
      <description>&lt;p&gt;用 17 讲的篇幅，我和你分享了目前机器学习中的大多数主流模型。可是除开了解了各自的原理，这些模型背后的共性规律在哪里，这些规律又将如何指导对于新模型的理解呢？这就是今天这篇总结的主题。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
